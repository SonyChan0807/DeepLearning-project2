{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import Tensor \n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def forward(self, x):   \n",
    "        self.x = x.clone()\n",
    "        return x.clamp(min=0)\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        output = self.x.clone()\n",
    "        output[output > 0] = 1\n",
    "        output[output < 0] = 0\n",
    "#         print(\"forwarded x\")\n",
    "#         print(self.x[:5])\n",
    "#         print(\"output\")\n",
    "#         print(output[:5])\n",
    "#         print(\"dz come\")\n",
    "#         print(dz[:5])\n",
    "#         print(\"backwarded update\")\n",
    "#         print(dz.mul(output).shape)\n",
    "        return dz.mul(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x.clone()\n",
    "        self.output = Tensor.tanh(x)\n",
    "        return self.output;\n",
    "\n",
    "    def backward(self, dz):\n",
    "#         print(\"forwarded x\")\n",
    "#         print(self.x[:5])\n",
    "#         print(\"output\")\n",
    "#         print(self.output[:5])\n",
    "#         print(\"dz come\")\n",
    "#         print(dz[:5])\n",
    "#         print(\"backwarded update\")\n",
    "#         print(dz.mul(1.0 - Tensor.tanh(self.x).pow(2))[:5])\n",
    "        return dz.mul(1.0 - Tensor.tanh(self.x).pow(2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \n",
    "    def __init__(self, input_size ,hidden_nodes):    \n",
    "        \n",
    "        # Initialize weight, bias xavie initializer\n",
    "        stdv = 1. / math.sqrt(input_size)\n",
    "        self.w = Tensor(hidden_nodes, input_size).uniform_(-stdv, stdv)\n",
    "        self.b = Tensor(hidden_nodes).uniform_(-stdv, stdv) \n",
    "        self.dw = Tensor(self.w.size()).zero_()\n",
    "        self.db = Tensor(self.b.size()).zero_()\n",
    "#         self.db = Tensor(self.b.size()).normal_(-10,100)\n",
    "#         self.dw = Tensor(self.w.size()).normal_(-10,100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x.clone()\n",
    "        s = x.matmul(self.w.t()) + self.b\n",
    "        return s\n",
    "        \n",
    "    def backward(self, dz):\n",
    "        \n",
    "        dx = dz.matmul(self.w)\n",
    "        dw = self.x.t().matmul(dz)\n",
    "        db = dz.t().sum(1)\n",
    "        \n",
    "        self.dw += dw\n",
    "        self.db += db\n",
    "        \n",
    "        return dx\n",
    "        \n",
    "    def params(self):\n",
    "        return (self.w, self.b, self.dw,self.db)\n",
    "    \n",
    "    \n",
    "    def update_params(self, lambda_):\n",
    "        self.w -= lambda_ * self.dw\n",
    "        self.b -= lambda_ * self.db\n",
    "        \n",
    "    \n",
    "    def zero_gradient(self):\n",
    "        self.dw.zero_()\n",
    "        self.db.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossMSE: \n",
    "        \n",
    "    def forward(self, t, x):\n",
    "        self.t = t.clone()\n",
    "        self.x = x.clone()\n",
    "        self.output = (self.x - self.t).pow(2).mean()\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self):\n",
    "#         print(\"t\")\n",
    "#         print(self.t)\n",
    "#         print(\"x\")\n",
    "#         print(self.x)\n",
    "#         print(\"error\")\n",
    "#         print(self.output)\n",
    "        dloss = 2 * (self.t - self.x)/self.x.shape[0]/2\n",
    "#         print(self.x.shape)\n",
    "        return dloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    \n",
    "    def __init__(self, layer_modules):\n",
    "        self.layer_modules = layer_modules\n",
    "\n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        module_input = x_input.clone()\n",
    "        \n",
    "        # hidden layer\n",
    "        for i in range(len(self.layer_modules)): \n",
    "            module_output = self.layer_modules[i].forward(module_input)\n",
    "            module_input = module_output\n",
    "        return module_output\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        for i in range(len(self.layer_modules) - 1, -1, -1):\n",
    "            dz = self.layer_modules[i].backward(dz) \n",
    "    \n",
    "    def update_params(self, lambda_):\n",
    "        for m in self.layer_modules:\n",
    "            if isinstance(m, Linear): \n",
    "                m.update_params(lambda_);\n",
    "\n",
    "    \n",
    "    def zero_gradient(self):\n",
    "        for m in self.layer_modules:\n",
    "            if isinstance(m, Linear):\n",
    "                m.zero_gradient()\n",
    "    \n",
    "    def get_params(self):\n",
    "        for m in self.layer_modules:\n",
    "            print('{},{}'.format(m.params()[0], m.params()[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, test_input, test_target, nb_epochs, lr,mini_batch_size ):\n",
    "    \n",
    "    criterion = LossMSE()\n",
    "    \n",
    "    for m in range(nb_epochs):\n",
    "\n",
    "        total_loss = 0    \n",
    "        \n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model.forward(train_input.narrow(0, b, mini_batch_size))\n",
    "#             print(output)\n",
    "            total_loss  += criterion.forward(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_gradient()\n",
    "            dloss = criterion.backward()\n",
    "#             print(\"dloss\")\n",
    "#             print(dloss[:5])\n",
    "            model.backward(dloss)\n",
    "            model.update_params(lr)\n",
    "        \n",
    "        train_errors = compute_nb_errors(model, train_input, train_target)\n",
    "        test_errors = compute_nb_errors(model, test_input, test_target)\n",
    "        print(\"================================{}===================================\".format(m))\n",
    "        \n",
    "        print(  '{}/{}: train_loss: {} train_error {:.02f}% test_error {:.02f}%'.format(m , nb_epochs,total_loss,\n",
    "                train_errors/ train_input.size(0) * 100,\n",
    "                test_errors / test_input.size(0) * 100))  \n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model.forward(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(0, mini_batch_size):\n",
    "            if data_target[b + k][predicted_classes[k]]  < 0:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlijPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc02d10b080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = torch.FloatTensor(1000,2).uniform_(0, 1) - 0.5\n",
    "distance = torch.sqrt(torch.pow(data[:, 0], 2) + torch.pow(data[:,1],2)).view(-1,1)\n",
    "radius = 1 / math.sqrt(2 * math.pi)\n",
    "inside = distance.clone().apply_(lambda x : 1 if x < radius else  -1)\n",
    "outside = distance.clone().apply_(lambda x : 1 if x > radius else  -1)\n",
    "\n",
    "target = torch.cat((inside, outside),1)\n",
    "\n",
    "\n",
    "data = (data - data.mean())/ data.std()\n",
    "# plt.scatter(data[:,0], data[:,1], c=inside)\n",
    "# plt.show()\n",
    "plt.scatter(data[:,0], data[:,1], c=inside.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheng-chun-epfl/anaconda3/lib/python3.6/site-packages/torch/tensor.py:309: UserWarning: other is not broadcastable to self, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return self.add_(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================0===================================\n",
      "0/4000: train_loss: 4.780328210016014 train_error 57.00% test_error 58.00%\n",
      "================================1===================================\n",
      "1/4000: train_loss: 4.777900358905317 train_error 56.88% test_error 58.00%\n",
      "================================2===================================\n",
      "2/4000: train_loss: 4.7754955504520336 train_error 56.75% test_error 58.00%\n",
      "================================3===================================\n",
      "3/4000: train_loss: 4.773112261058995 train_error 56.62% test_error 58.50%\n",
      "================================4===================================\n",
      "4/4000: train_loss: 4.7707496307545805 train_error 56.75% test_error 58.00%\n",
      "================================5===================================\n",
      "5/4000: train_loss: 4.76840884860605 train_error 56.75% test_error 58.00%\n",
      "================================6===================================\n",
      "6/4000: train_loss: 4.766089662672021 train_error 56.75% test_error 58.00%\n",
      "================================7===================================\n",
      "7/4000: train_loss: 4.763791268484201 train_error 56.75% test_error 58.00%\n",
      "================================8===================================\n",
      "8/4000: train_loss: 4.7615128825861035 train_error 56.75% test_error 58.00%\n",
      "================================9===================================\n",
      "9/4000: train_loss: 4.759254772713175 train_error 56.62% test_error 58.00%\n",
      "================================10===================================\n",
      "10/4000: train_loss: 4.757017595511861 train_error 56.62% test_error 58.00%\n",
      "================================11===================================\n",
      "11/4000: train_loss: 4.754800382872345 train_error 56.62% test_error 58.00%\n",
      "================================12===================================\n",
      "12/4000: train_loss: 4.7526044405391445 train_error 56.75% test_error 58.00%\n",
      "================================13===================================\n",
      "13/4000: train_loss: 4.75042802586453 train_error 56.75% test_error 58.00%\n",
      "================================14===================================\n",
      "14/4000: train_loss: 4.748271387960995 train_error 56.75% test_error 57.50%\n",
      "================================15===================================\n",
      "15/4000: train_loss: 4.746134343903977 train_error 56.75% test_error 57.00%\n",
      "================================16===================================\n",
      "16/4000: train_loss: 4.744016167470255 train_error 56.75% test_error 57.00%\n",
      "================================17===================================\n",
      "17/4000: train_loss: 4.741917136668926 train_error 56.62% test_error 57.00%\n",
      "================================18===================================\n",
      "18/4000: train_loss: 4.739837321779924 train_error 56.50% test_error 57.00%\n",
      "================================19===================================\n",
      "19/4000: train_loss: 4.737776531471172 train_error 56.38% test_error 57.00%\n",
      "================================20===================================\n",
      "20/4000: train_loss: 4.735733473011059 train_error 56.25% test_error 56.50%\n",
      "================================21===================================\n",
      "21/4000: train_loss: 4.7337069398607134 train_error 56.12% test_error 56.50%\n",
      "================================22===================================\n",
      "22/4000: train_loss: 4.731697304452537 train_error 56.12% test_error 56.50%\n",
      "================================23===================================\n",
      "23/4000: train_loss: 4.729704429894919 train_error 56.12% test_error 56.50%\n",
      "================================24===================================\n",
      "24/4000: train_loss: 4.7277290755067956 train_error 56.00% test_error 56.50%\n",
      "================================25===================================\n",
      "25/4000: train_loss: 4.72577129043173 train_error 55.88% test_error 56.50%\n",
      "================================26===================================\n",
      "26/4000: train_loss: 4.723828531154432 train_error 55.75% test_error 56.50%\n",
      "================================27===================================\n",
      "27/4000: train_loss: 4.721902177165029 train_error 55.88% test_error 56.50%\n",
      "================================28===================================\n",
      "28/4000: train_loss: 4.719993866581936 train_error 56.00% test_error 56.50%\n",
      "================================29===================================\n",
      "29/4000: train_loss: 4.718101666487055 train_error 55.62% test_error 56.50%\n",
      "================================30===================================\n",
      "30/4000: train_loss: 4.716226465777727 train_error 55.62% test_error 56.50%\n",
      "================================31===================================\n",
      "31/4000: train_loss: 4.714368843142875 train_error 55.62% test_error 56.50%\n",
      "================================32===================================\n",
      "32/4000: train_loss: 4.7125282099517065 train_error 55.50% test_error 56.50%\n",
      "================================33===================================\n",
      "33/4000: train_loss: 4.710703554825159 train_error 55.50% test_error 56.50%\n",
      "================================34===================================\n",
      "34/4000: train_loss: 4.708895052727312 train_error 55.25% test_error 56.50%\n",
      "================================35===================================\n",
      "35/4000: train_loss: 4.707102418381255 train_error 55.25% test_error 56.50%\n",
      "================================36===================================\n",
      "36/4000: train_loss: 4.705325198274805 train_error 55.25% test_error 56.50%\n",
      "================================37===================================\n",
      "37/4000: train_loss: 4.70356291385484 train_error 55.25% test_error 56.50%\n",
      "================================38===================================\n",
      "38/4000: train_loss: 4.701815749788657 train_error 55.12% test_error 56.50%\n",
      "================================39===================================\n",
      "39/4000: train_loss: 4.700082975310506 train_error 55.12% test_error 56.50%\n",
      "================================40===================================\n",
      "40/4000: train_loss: 4.698364566637902 train_error 55.12% test_error 56.50%\n",
      "================================41===================================\n",
      "41/4000: train_loss: 4.696662209874485 train_error 55.25% test_error 56.50%\n",
      "================================42===================================\n",
      "42/4000: train_loss: 4.6949746174784375 train_error 55.12% test_error 56.50%\n",
      "================================43===================================\n",
      "43/4000: train_loss: 4.693300993203884 train_error 55.12% test_error 56.50%\n",
      "================================44===================================\n",
      "44/4000: train_loss: 4.691641153650125 train_error 54.87% test_error 56.50%\n",
      "================================45===================================\n",
      "45/4000: train_loss: 4.689994913351256 train_error 54.75% test_error 56.50%\n",
      "================================46===================================\n",
      "46/4000: train_loss: 4.688362598138629 train_error 54.75% test_error 56.50%\n",
      "================================47===================================\n",
      "47/4000: train_loss: 4.686745623743628 train_error 54.75% test_error 56.50%\n",
      "================================48===================================\n",
      "48/4000: train_loss: 4.6851426498219375 train_error 54.62% test_error 56.50%\n",
      "================================49===================================\n",
      "49/4000: train_loss: 4.68355305096251 train_error 54.50% test_error 56.50%\n",
      "================================50===================================\n",
      "50/4000: train_loss: 4.681976723815315 train_error 54.62% test_error 56.50%\n",
      "================================51===================================\n",
      "51/4000: train_loss: 4.680412105701398 train_error 54.62% test_error 56.50%\n",
      "================================52===================================\n",
      "52/4000: train_loss: 4.6788602886314035 train_error 54.62% test_error 56.50%\n",
      "================================53===================================\n",
      "53/4000: train_loss: 4.677320298546692 train_error 54.50% test_error 56.50%\n",
      "================================54===================================\n",
      "54/4000: train_loss: 4.675792292063124 train_error 54.37% test_error 56.50%\n",
      "================================55===================================\n",
      "55/4000: train_loss: 4.6742762973124625 train_error 54.37% test_error 56.50%\n",
      "================================56===================================\n",
      "56/4000: train_loss: 4.6727711266896215 train_error 54.50% test_error 57.00%\n",
      "================================57===================================\n",
      "57/4000: train_loss: 4.671278184184339 train_error 54.50% test_error 57.00%\n",
      "================================58===================================\n",
      "58/4000: train_loss: 4.669797465784941 train_error 54.62% test_error 57.00%\n",
      "================================59===================================\n",
      "59/4000: train_loss: 4.66832859996939 train_error 54.62% test_error 57.00%\n",
      "================================60===================================\n",
      "60/4000: train_loss: 4.6668712704931385 train_error 54.50% test_error 57.50%\n",
      "================================61===================================\n",
      "61/4000: train_loss: 4.665424601871054 train_error 54.37% test_error 57.50%\n",
      "================================62===================================\n",
      "62/4000: train_loss: 4.663989420530852 train_error 54.37% test_error 57.50%\n",
      "================================63===================================\n",
      "63/4000: train_loss: 4.662565676348749 train_error 54.25% test_error 57.50%\n",
      "================================64===================================\n",
      "64/4000: train_loss: 4.661153102950193 train_error 54.37% test_error 58.00%\n",
      "================================65===================================\n",
      "65/4000: train_loss: 4.659751187930815 train_error 54.25% test_error 58.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================66===================================\n",
      "66/4000: train_loss: 4.658360312331934 train_error 54.25% test_error 58.00%\n",
      "================================67===================================\n",
      "67/4000: train_loss: 4.656980329535436 train_error 54.37% test_error 58.00%\n",
      "================================68===================================\n",
      "68/4000: train_loss: 4.65561136605218 train_error 54.62% test_error 58.50%\n",
      "================================69===================================\n",
      "69/4000: train_loss: 4.654253007166553 train_error 54.75% test_error 58.50%\n",
      "================================70===================================\n",
      "70/4000: train_loss: 4.652905130139551 train_error 54.75% test_error 58.50%\n",
      "================================71===================================\n",
      "71/4000: train_loss: 4.651566819066648 train_error 54.87% test_error 58.00%\n",
      "================================72===================================\n",
      "72/4000: train_loss: 4.650237467421684 train_error 54.87% test_error 58.00%\n",
      "================================73===================================\n",
      "73/4000: train_loss: 4.648918083740864 train_error 54.75% test_error 57.50%\n",
      "================================74===================================\n",
      "74/4000: train_loss: 4.6476088424446065 train_error 54.62% test_error 58.00%\n",
      "================================75===================================\n",
      "75/4000: train_loss: 4.646310485424474 train_error 55.00% test_error 58.50%\n",
      "================================76===================================\n",
      "76/4000: train_loss: 4.645021107038483 train_error 55.00% test_error 58.50%\n",
      "================================77===================================\n",
      "77/4000: train_loss: 4.643741076851729 train_error 55.00% test_error 58.50%\n",
      "================================78===================================\n",
      "78/4000: train_loss: 4.64246980084572 train_error 55.12% test_error 58.50%\n",
      "================================79===================================\n",
      "79/4000: train_loss: 4.64120759061072 train_error 55.12% test_error 58.50%\n",
      "================================80===================================\n",
      "80/4000: train_loss: 4.639954581463243 train_error 55.25% test_error 58.50%\n",
      "================================81===================================\n",
      "81/4000: train_loss: 4.638710841564461 train_error 55.38% test_error 58.50%\n",
      "================================82===================================\n",
      "82/4000: train_loss: 4.637476206135471 train_error 55.38% test_error 58.00%\n",
      "================================83===================================\n",
      "83/4000: train_loss: 4.636250565389637 train_error 55.62% test_error 58.50%\n",
      "================================84===================================\n",
      "84/4000: train_loss: 4.635035059116781 train_error 55.75% test_error 58.50%\n",
      "================================85===================================\n",
      "85/4000: train_loss: 4.633828980629332 train_error 55.62% test_error 58.50%\n",
      "================================86===================================\n",
      "86/4000: train_loss: 4.632631180707831 train_error 55.75% test_error 58.50%\n",
      "================================87===================================\n",
      "87/4000: train_loss: 4.631441701157018 train_error 55.75% test_error 58.50%\n",
      "================================88===================================\n",
      "88/4000: train_loss: 4.630259796467144 train_error 55.75% test_error 58.50%\n",
      "================================89===================================\n",
      "89/4000: train_loss: 4.629086072822101 train_error 55.88% test_error 58.50%\n",
      "================================90===================================\n",
      "90/4000: train_loss: 4.627921327259392 train_error 55.75% test_error 58.50%\n",
      "================================91===================================\n",
      "91/4000: train_loss: 4.626764722445515 train_error 55.75% test_error 58.50%\n",
      "================================92===================================\n",
      "92/4000: train_loss: 4.625616757026874 train_error 55.62% test_error 58.50%\n",
      "================================93===================================\n",
      "93/4000: train_loss: 4.624477542110253 train_error 55.75% test_error 58.50%\n",
      "================================94===================================\n",
      "94/4000: train_loss: 4.623346352942754 train_error 55.75% test_error 58.50%\n",
      "================================95===================================\n",
      "95/4000: train_loss: 4.622223411006853 train_error 55.75% test_error 58.50%\n",
      "================================96===================================\n",
      "96/4000: train_loss: 4.6211081247520625 train_error 55.75% test_error 58.50%\n",
      "================================97===================================\n",
      "97/4000: train_loss: 4.619999976954423 train_error 55.75% test_error 58.50%\n",
      "================================98===================================\n",
      "98/4000: train_loss: 4.618899171033409 train_error 55.62% test_error 58.50%\n",
      "================================99===================================\n",
      "99/4000: train_loss: 4.617806423585861 train_error 55.62% test_error 58.50%\n",
      "================================100===================================\n",
      "100/4000: train_loss: 4.6167224709573205 train_error 55.62% test_error 58.50%\n",
      "================================101===================================\n",
      "101/4000: train_loss: 4.615645996702369 train_error 55.50% test_error 58.50%\n",
      "================================102===================================\n",
      "102/4000: train_loss: 4.614576571201905 train_error 55.50% test_error 58.50%\n",
      "================================103===================================\n",
      "103/4000: train_loss: 4.613512716679834 train_error 55.12% test_error 58.50%\n",
      "================================104===================================\n",
      "104/4000: train_loss: 4.6124562008259815 train_error 54.87% test_error 58.50%\n",
      "================================105===================================\n",
      "105/4000: train_loss: 4.611406599564943 train_error 54.75% test_error 58.50%\n",
      "================================106===================================\n",
      "106/4000: train_loss: 4.6103631265670995 train_error 54.75% test_error 58.50%\n",
      "================================107===================================\n",
      "107/4000: train_loss: 4.609326208687853 train_error 54.87% test_error 58.50%\n",
      "================================108===================================\n",
      "108/4000: train_loss: 4.608295627348125 train_error 54.87% test_error 58.50%\n",
      "================================109===================================\n",
      "109/4000: train_loss: 4.607270350593607 train_error 54.75% test_error 58.50%\n",
      "================================110===================================\n",
      "110/4000: train_loss: 4.606251285767648 train_error 54.75% test_error 58.00%\n",
      "================================111===================================\n",
      "111/4000: train_loss: 4.605240167896264 train_error 54.75% test_error 58.00%\n",
      "================================112===================================\n",
      "112/4000: train_loss: 4.60423467530869 train_error 54.87% test_error 58.00%\n",
      "================================113===================================\n",
      "113/4000: train_loss: 4.603234848373104 train_error 55.00% test_error 58.00%\n",
      "================================114===================================\n",
      "114/4000: train_loss: 4.602240447425284 train_error 55.00% test_error 58.00%\n",
      "================================115===================================\n",
      "115/4000: train_loss: 4.6012516312696965 train_error 54.87% test_error 58.00%\n",
      "================================116===================================\n",
      "116/4000: train_loss: 4.6002699060621675 train_error 54.87% test_error 58.00%\n",
      "================================117===================================\n",
      "117/4000: train_loss: 4.59929504301399 train_error 54.87% test_error 58.00%\n",
      "================================118===================================\n",
      "118/4000: train_loss: 4.598325843138155 train_error 54.87% test_error 58.00%\n",
      "================================119===================================\n",
      "119/4000: train_loss: 4.5973620461486275 train_error 55.12% test_error 58.50%\n",
      "================================120===================================\n",
      "120/4000: train_loss: 4.596403474190738 train_error 55.12% test_error 58.50%\n",
      "================================121===================================\n",
      "121/4000: train_loss: 4.595450503248722 train_error 55.12% test_error 58.50%\n",
      "================================122===================================\n",
      "122/4000: train_loss: 4.594503177907318 train_error 55.25% test_error 58.50%\n",
      "================================123===================================\n",
      "123/4000: train_loss: 4.5935611001076175 train_error 55.38% test_error 58.50%\n",
      "================================124===================================\n",
      "124/4000: train_loss: 4.59262349589495 train_error 55.50% test_error 58.50%\n",
      "================================125===================================\n",
      "125/4000: train_loss: 4.591691358210519 train_error 55.50% test_error 58.00%\n",
      "================================126===================================\n",
      "126/4000: train_loss: 4.590765065401792 train_error 55.50% test_error 58.50%\n",
      "================================127===================================\n",
      "127/4000: train_loss: 4.589844004425686 train_error 55.62% test_error 58.50%\n",
      "================================128===================================\n",
      "128/4000: train_loss: 4.588927455309313 train_error 55.75% test_error 58.50%\n",
      "================================129===================================\n",
      "129/4000: train_loss: 4.588017146990169 train_error 55.75% test_error 58.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================130===================================\n",
      "130/4000: train_loss: 4.587112747994251 train_error 55.88% test_error 58.50%\n",
      "================================131===================================\n",
      "131/4000: train_loss: 4.586213428317569 train_error 55.88% test_error 58.50%\n",
      "================================132===================================\n",
      "132/4000: train_loss: 4.585319272917696 train_error 55.88% test_error 58.50%\n",
      "================================133===================================\n",
      "133/4000: train_loss: 4.5844299992383455 train_error 55.88% test_error 58.50%\n",
      "================================134===================================\n",
      "134/4000: train_loss: 4.58354515839601 train_error 56.00% test_error 58.50%\n",
      "================================135===================================\n",
      "135/4000: train_loss: 4.582665899242274 train_error 56.00% test_error 58.50%\n",
      "================================136===================================\n",
      "136/4000: train_loss: 4.581791706979275 train_error 56.00% test_error 58.00%\n",
      "================================137===================================\n",
      "137/4000: train_loss: 4.580921930328477 train_error 56.00% test_error 58.00%\n",
      "================================138===================================\n",
      "138/4000: train_loss: 4.580057487054728 train_error 55.88% test_error 58.00%\n",
      "================================139===================================\n",
      "139/4000: train_loss: 4.579198580158409 train_error 55.75% test_error 58.00%\n",
      "================================140===================================\n",
      "140/4000: train_loss: 4.578344559650869 train_error 55.62% test_error 58.00%\n",
      "================================141===================================\n",
      "141/4000: train_loss: 4.577495699140709 train_error 55.62% test_error 58.00%\n",
      "================================142===================================\n",
      "142/4000: train_loss: 4.576653150343336 train_error 55.75% test_error 58.00%\n",
      "================================143===================================\n",
      "143/4000: train_loss: 4.575816924269311 train_error 55.75% test_error 58.00%\n",
      "================================144===================================\n",
      "144/4000: train_loss: 4.574984232448042 train_error 55.88% test_error 58.00%\n",
      "================================145===================================\n",
      "145/4000: train_loss: 4.574153856178746 train_error 55.75% test_error 58.00%\n",
      "================================146===================================\n",
      "146/4000: train_loss: 4.5733277083863495 train_error 55.75% test_error 58.00%\n",
      "================================147===================================\n",
      "147/4000: train_loss: 4.572505679826718 train_error 55.75% test_error 58.00%\n",
      "================================148===================================\n",
      "148/4000: train_loss: 4.571687758394983 train_error 55.75% test_error 58.00%\n",
      "================================149===================================\n",
      "149/4000: train_loss: 4.570873891743831 train_error 55.75% test_error 58.00%\n",
      "================================150===================================\n",
      "150/4000: train_loss: 4.570064031630754 train_error 55.75% test_error 57.50%\n",
      "================================151===================================\n",
      "151/4000: train_loss: 4.569258220561315 train_error 55.75% test_error 57.50%\n",
      "================================152===================================\n",
      "152/4000: train_loss: 4.5684564867522575 train_error 55.75% test_error 57.50%\n",
      "================================153===================================\n",
      "153/4000: train_loss: 4.567660144641995 train_error 55.75% test_error 57.50%\n",
      "================================154===================================\n",
      "154/4000: train_loss: 4.566868093630765 train_error 55.62% test_error 57.50%\n",
      "================================155===================================\n",
      "155/4000: train_loss: 4.566079695855733 train_error 55.50% test_error 57.50%\n",
      "================================156===================================\n",
      "156/4000: train_loss: 4.5652950447076 train_error 55.38% test_error 57.00%\n",
      "================================157===================================\n",
      "157/4000: train_loss: 4.564514106635469 train_error 55.25% test_error 57.00%\n",
      "================================158===================================\n",
      "158/4000: train_loss: 4.563736821280327 train_error 55.25% test_error 57.00%\n",
      "================================159===================================\n",
      "159/4000: train_loss: 4.562962666414678 train_error 55.00% test_error 57.00%\n",
      "================================160===================================\n",
      "160/4000: train_loss: 4.56219150067307 train_error 55.00% test_error 57.00%\n",
      "================================161===================================\n",
      "161/4000: train_loss: 4.561423441052902 train_error 55.00% test_error 57.00%\n",
      "================================162===================================\n",
      "162/4000: train_loss: 4.560660605775192 train_error 55.00% test_error 57.00%\n",
      "================================163===================================\n",
      "163/4000: train_loss: 4.5599018559372055 train_error 55.00% test_error 57.00%\n",
      "================================164===================================\n",
      "164/4000: train_loss: 4.55914784071967 train_error 55.00% test_error 57.00%\n",
      "================================165===================================\n",
      "165/4000: train_loss: 4.558396776102017 train_error 54.87% test_error 57.00%\n",
      "================================166===================================\n",
      "166/4000: train_loss: 4.557648401514161 train_error 54.50% test_error 57.00%\n",
      "================================167===================================\n",
      "167/4000: train_loss: 4.556903223621193 train_error 54.37% test_error 56.50%\n",
      "================================168===================================\n",
      "168/4000: train_loss: 4.556161066407803 train_error 54.37% test_error 56.50%\n",
      "================================169===================================\n",
      "169/4000: train_loss: 4.555421930870507 train_error 54.50% test_error 56.50%\n",
      "================================170===================================\n",
      "170/4000: train_loss: 4.554685931704007 train_error 54.50% test_error 56.50%\n",
      "================================171===================================\n",
      "171/4000: train_loss: 4.553953290274366 train_error 54.62% test_error 56.50%\n",
      "================================172===================================\n",
      "172/4000: train_loss: 4.553224241877906 train_error 54.62% test_error 56.50%\n",
      "================================173===================================\n",
      "173/4000: train_loss: 4.552498967475258 train_error 54.62% test_error 56.50%\n",
      "================================174===================================\n",
      "174/4000: train_loss: 4.551775954556652 train_error 54.62% test_error 56.50%\n",
      "================================175===================================\n",
      "175/4000: train_loss: 4.551055377679877 train_error 54.62% test_error 56.50%\n",
      "================================176===================================\n",
      "176/4000: train_loss: 4.550337448953651 train_error 54.62% test_error 56.50%\n",
      "================================177===================================\n",
      "177/4000: train_loss: 4.549622279061005 train_error 54.50% test_error 56.50%\n",
      "================================178===================================\n",
      "178/4000: train_loss: 4.548909686598927 train_error 54.25% test_error 56.50%\n",
      "================================179===================================\n",
      "179/4000: train_loss: 4.548198432312347 train_error 54.12% test_error 56.50%\n",
      "================================180===================================\n",
      "180/4000: train_loss: 4.547489946014248 train_error 54.12% test_error 56.00%\n",
      "================================181===================================\n",
      "181/4000: train_loss: 4.546784166311845 train_error 54.00% test_error 56.00%\n",
      "================================182===================================\n",
      "182/4000: train_loss: 4.546081342594698 train_error 53.87% test_error 56.00%\n",
      "================================183===================================\n",
      "183/4000: train_loss: 4.545381183321588 train_error 53.75% test_error 56.00%\n",
      "================================184===================================\n",
      "184/4000: train_loss: 4.5446833291836075 train_error 53.87% test_error 56.00%\n",
      "================================185===================================\n",
      "185/4000: train_loss: 4.5439882362261415 train_error 53.87% test_error 56.00%\n",
      "================================186===================================\n",
      "186/4000: train_loss: 4.543295926037244 train_error 53.87% test_error 56.00%\n",
      "================================187===================================\n",
      "187/4000: train_loss: 4.542603559321724 train_error 53.87% test_error 56.00%\n",
      "================================188===================================\n",
      "188/4000: train_loss: 4.541913454243914 train_error 53.87% test_error 56.00%\n",
      "================================189===================================\n",
      "189/4000: train_loss: 4.541225920226425 train_error 53.62% test_error 56.00%\n",
      "================================190===================================\n",
      "190/4000: train_loss: 4.540540743083693 train_error 53.62% test_error 56.00%\n",
      "================================191===================================\n",
      "191/4000: train_loss: 4.539858069871552 train_error 53.62% test_error 56.00%\n",
      "================================192===================================\n",
      "192/4000: train_loss: 4.53917761865072 train_error 53.50% test_error 56.00%\n",
      "================================193===================================\n",
      "193/4000: train_loss: 4.538499645120464 train_error 53.50% test_error 56.00%\n",
      "================================194===================================\n",
      "194/4000: train_loss: 4.537823649165221 train_error 53.50% test_error 56.00%\n",
      "================================195===================================\n",
      "195/4000: train_loss: 4.537148101427592 train_error 53.62% test_error 56.00%\n",
      "================================196===================================\n",
      "196/4000: train_loss: 4.536474034930579 train_error 53.62% test_error 56.00%\n",
      "================================197===================================\n",
      "197/4000: train_loss: 4.535802976656705 train_error 53.62% test_error 56.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================198===================================\n",
      "198/4000: train_loss: 4.535134818227961 train_error 53.62% test_error 56.00%\n",
      "================================199===================================\n",
      "199/4000: train_loss: 4.534470596774481 train_error 53.62% test_error 56.00%\n",
      "================================200===================================\n",
      "200/4000: train_loss: 4.5338085769861936 train_error 53.62% test_error 56.00%\n",
      "================================201===================================\n",
      "201/4000: train_loss: 4.533148775692098 train_error 53.62% test_error 55.50%\n",
      "================================202===================================\n",
      "202/4000: train_loss: 4.532489870977589 train_error 53.87% test_error 55.00%\n",
      "================================203===================================\n",
      "203/4000: train_loss: 4.531832544947974 train_error 53.87% test_error 55.00%\n",
      "================================204===================================\n",
      "204/4000: train_loss: 4.531177538712509 train_error 53.87% test_error 55.00%\n",
      "================================205===================================\n",
      "205/4000: train_loss: 4.530526997372508 train_error 53.87% test_error 55.00%\n",
      "================================206===================================\n",
      "206/4000: train_loss: 4.529878519522026 train_error 53.87% test_error 55.00%\n",
      "================================207===================================\n",
      "207/4000: train_loss: 4.529231498092413 train_error 53.87% test_error 55.00%\n",
      "================================208===================================\n",
      "208/4000: train_loss: 4.528585421247407 train_error 53.75% test_error 55.00%\n",
      "================================209===================================\n",
      "209/4000: train_loss: 4.527941314605997 train_error 53.75% test_error 55.00%\n",
      "================================210===================================\n",
      "210/4000: train_loss: 4.52729914793279 train_error 53.75% test_error 55.00%\n",
      "================================211===================================\n",
      "211/4000: train_loss: 4.526658822884784 train_error 53.75% test_error 55.00%\n",
      "================================212===================================\n",
      "212/4000: train_loss: 4.526020326493308 train_error 53.75% test_error 55.00%\n",
      "================================213===================================\n",
      "213/4000: train_loss: 4.525383615726605 train_error 53.75% test_error 55.00%\n",
      "================================214===================================\n",
      "214/4000: train_loss: 4.524748622416519 train_error 53.75% test_error 55.00%\n",
      "================================215===================================\n",
      "215/4000: train_loss: 4.524114343617112 train_error 53.50% test_error 54.50%\n",
      "================================216===================================\n",
      "216/4000: train_loss: 4.523480595932343 train_error 53.50% test_error 54.50%\n",
      "================================217===================================\n",
      "217/4000: train_loss: 4.522848495156505 train_error 53.37% test_error 54.50%\n",
      "================================218===================================\n",
      "218/4000: train_loss: 4.522218112237752 train_error 53.25% test_error 54.50%\n",
      "================================219===================================\n",
      "219/4000: train_loss: 4.521589344218373 train_error 53.25% test_error 54.50%\n",
      "================================220===================================\n",
      "220/4000: train_loss: 4.5209626391669735 train_error 53.25% test_error 54.50%\n",
      "================================221===================================\n",
      "221/4000: train_loss: 4.520337979923934 train_error 53.25% test_error 54.50%\n",
      "================================222===================================\n",
      "222/4000: train_loss: 4.51971419531852 train_error 53.25% test_error 54.50%\n",
      "================================223===================================\n",
      "223/4000: train_loss: 4.519092504051515 train_error 53.00% test_error 54.50%\n",
      "================================224===================================\n",
      "224/4000: train_loss: 4.518472299831919 train_error 52.88% test_error 54.50%\n",
      "================================225===================================\n",
      "225/4000: train_loss: 4.517854011910967 train_error 53.00% test_error 54.50%\n",
      "================================226===================================\n",
      "226/4000: train_loss: 4.517237955704331 train_error 52.88% test_error 54.50%\n",
      "================================227===================================\n",
      "227/4000: train_loss: 4.516622284878977 train_error 52.88% test_error 54.50%\n",
      "================================228===================================\n",
      "228/4000: train_loss: 4.516008136468008 train_error 53.00% test_error 54.50%\n",
      "================================229===================================\n",
      "229/4000: train_loss: 4.515396067206748 train_error 53.00% test_error 54.50%\n",
      "================================230===================================\n",
      "230/4000: train_loss: 4.514785365303978 train_error 53.00% test_error 54.00%\n",
      "================================231===================================\n",
      "231/4000: train_loss: 4.514176233923063 train_error 53.00% test_error 54.00%\n",
      "================================232===================================\n",
      "232/4000: train_loss: 4.513567562401295 train_error 53.00% test_error 54.00%\n",
      "================================233===================================\n",
      "233/4000: train_loss: 4.512959202006459 train_error 53.00% test_error 54.00%\n",
      "================================234===================================\n",
      "234/4000: train_loss: 4.512351995403879 train_error 53.00% test_error 54.00%\n",
      "================================235===================================\n",
      "235/4000: train_loss: 4.511745655196719 train_error 53.00% test_error 54.00%\n",
      "================================236===================================\n",
      "236/4000: train_loss: 4.511141207050532 train_error 53.12% test_error 54.00%\n",
      "================================237===================================\n",
      "237/4000: train_loss: 4.510538019197993 train_error 53.12% test_error 54.00%\n",
      "================================238===================================\n",
      "238/4000: train_loss: 4.509936502482742 train_error 53.00% test_error 54.00%\n",
      "================================239===================================\n",
      "239/4000: train_loss: 4.509336001658812 train_error 53.12% test_error 54.00%\n",
      "================================240===================================\n",
      "240/4000: train_loss: 4.508735589054414 train_error 53.25% test_error 54.00%\n",
      "================================241===================================\n",
      "241/4000: train_loss: 4.50813552214764 train_error 53.25% test_error 54.00%\n",
      "================================242===================================\n",
      "242/4000: train_loss: 4.507536587826907 train_error 53.12% test_error 54.00%\n",
      "================================243===================================\n",
      "243/4000: train_loss: 4.506938720219768 train_error 53.12% test_error 54.00%\n",
      "================================244===================================\n",
      "244/4000: train_loss: 4.506342935133725 train_error 53.12% test_error 54.00%\n",
      "================================245===================================\n",
      "245/4000: train_loss: 4.505746741075999 train_error 53.00% test_error 54.00%\n",
      "================================246===================================\n",
      "246/4000: train_loss: 4.505150948022492 train_error 52.88% test_error 53.50%\n",
      "================================247===================================\n",
      "247/4000: train_loss: 4.504556313850918 train_error 52.88% test_error 53.50%\n",
      "================================248===================================\n",
      "248/4000: train_loss: 4.503962907395326 train_error 53.00% test_error 53.50%\n",
      "================================249===================================\n",
      "249/4000: train_loss: 4.503370746220462 train_error 53.00% test_error 53.50%\n",
      "================================250===================================\n",
      "250/4000: train_loss: 4.502780171516351 train_error 52.88% test_error 53.50%\n",
      "================================251===================================\n",
      "251/4000: train_loss: 4.502191209476441 train_error 52.88% test_error 53.50%\n",
      "================================252===================================\n",
      "252/4000: train_loss: 4.501602512034587 train_error 52.75% test_error 53.50%\n",
      "================================253===================================\n",
      "253/4000: train_loss: 4.501013129637576 train_error 52.75% test_error 53.50%\n",
      "================================254===================================\n",
      "254/4000: train_loss: 4.50042392842006 train_error 52.88% test_error 53.00%\n",
      "================================255===================================\n",
      "255/4000: train_loss: 4.4998360701091595 train_error 52.75% test_error 52.50%\n",
      "================================256===================================\n",
      "256/4000: train_loss: 4.499247586200946 train_error 52.75% test_error 52.50%\n",
      "================================257===================================\n",
      "257/4000: train_loss: 4.498658521845937 train_error 52.75% test_error 52.50%\n",
      "================================258===================================\n",
      "258/4000: train_loss: 4.498069064775482 train_error 52.62% test_error 52.50%\n",
      "================================259===================================\n",
      "259/4000: train_loss: 4.49747956128791 train_error 52.62% test_error 52.50%\n",
      "================================260===================================\n",
      "260/4000: train_loss: 4.4968908729823305 train_error 52.62% test_error 52.00%\n",
      "================================261===================================\n",
      "261/4000: train_loss: 4.496303278268314 train_error 52.62% test_error 52.00%\n",
      "================================262===================================\n",
      "262/4000: train_loss: 4.495716798403301 train_error 52.62% test_error 52.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================263===================================\n",
      "263/4000: train_loss: 4.495131015572697 train_error 52.50% test_error 52.00%\n",
      "================================264===================================\n",
      "264/4000: train_loss: 4.494544446477667 train_error 52.50% test_error 52.00%\n",
      "================================265===================================\n",
      "265/4000: train_loss: 4.493959274827502 train_error 52.38% test_error 52.00%\n",
      "================================266===================================\n",
      "266/4000: train_loss: 4.493376688212156 train_error 52.38% test_error 52.00%\n",
      "================================267===================================\n",
      "267/4000: train_loss: 4.492794258161448 train_error 52.25% test_error 52.00%\n",
      "================================268===================================\n",
      "268/4000: train_loss: 4.492212342000567 train_error 52.00% test_error 52.50%\n",
      "================================269===================================\n",
      "269/4000: train_loss: 4.4916308775357905 train_error 52.00% test_error 52.50%\n",
      "================================270===================================\n",
      "270/4000: train_loss: 4.491051116622984 train_error 52.00% test_error 52.50%\n",
      "================================271===================================\n",
      "271/4000: train_loss: 4.490474023837596 train_error 52.00% test_error 52.50%\n",
      "================================272===================================\n",
      "272/4000: train_loss: 4.489898026986047 train_error 51.88% test_error 52.50%\n",
      "================================273===================================\n",
      "273/4000: train_loss: 4.489322213656269 train_error 51.88% test_error 52.50%\n",
      "================================274===================================\n",
      "274/4000: train_loss: 4.4887470174720505 train_error 51.75% test_error 52.50%\n",
      "================================275===================================\n",
      "275/4000: train_loss: 4.488172179451213 train_error 51.75% test_error 52.50%\n",
      "================================276===================================\n",
      "276/4000: train_loss: 4.487597641260363 train_error 51.75% test_error 52.50%\n",
      "================================277===================================\n",
      "277/4000: train_loss: 4.4870242555299775 train_error 51.75% test_error 52.50%\n",
      "================================278===================================\n",
      "278/4000: train_loss: 4.486451723310164 train_error 51.88% test_error 52.50%\n",
      "================================279===================================\n",
      "279/4000: train_loss: 4.485880392575637 train_error 52.00% test_error 52.50%\n",
      "================================280===================================\n",
      "280/4000: train_loss: 4.485310633350164 train_error 52.00% test_error 52.50%\n",
      "================================281===================================\n",
      "281/4000: train_loss: 4.484740941124037 train_error 51.88% test_error 52.50%\n",
      "================================282===================================\n",
      "282/4000: train_loss: 4.484172079642303 train_error 51.88% test_error 52.50%\n",
      "================================283===================================\n",
      "283/4000: train_loss: 4.483603518707677 train_error 51.88% test_error 52.50%\n",
      "================================284===================================\n",
      "284/4000: train_loss: 4.483035553134978 train_error 51.88% test_error 52.50%\n",
      "================================285===================================\n",
      "285/4000: train_loss: 4.482468296568841 train_error 51.88% test_error 52.50%\n",
      "================================286===================================\n",
      "286/4000: train_loss: 4.4819011457311 train_error 51.88% test_error 52.50%\n",
      "================================287===================================\n",
      "287/4000: train_loss: 4.481334338127636 train_error 51.88% test_error 52.50%\n",
      "================================288===================================\n",
      "288/4000: train_loss: 4.4807680838368835 train_error 51.88% test_error 52.50%\n",
      "================================289===================================\n",
      "289/4000: train_loss: 4.480202187746763 train_error 52.00% test_error 52.50%\n",
      "================================290===================================\n",
      "290/4000: train_loss: 4.479636770533398 train_error 52.00% test_error 52.50%\n",
      "================================291===================================\n",
      "291/4000: train_loss: 4.479071779889055 train_error 52.00% test_error 53.00%\n",
      "================================292===================================\n",
      "292/4000: train_loss: 4.478506895047612 train_error 52.00% test_error 53.00%\n",
      "================================293===================================\n",
      "293/4000: train_loss: 4.477943290909752 train_error 51.88% test_error 53.00%\n",
      "================================294===================================\n",
      "294/4000: train_loss: 4.477380327302963 train_error 51.88% test_error 53.00%\n",
      "================================295===================================\n",
      "295/4000: train_loss: 4.476817733226344 train_error 51.88% test_error 53.00%\n",
      "================================296===================================\n",
      "296/4000: train_loss: 4.476255515157245 train_error 51.88% test_error 53.00%\n",
      "================================297===================================\n",
      "297/4000: train_loss: 4.475694034304469 train_error 51.88% test_error 53.00%\n",
      "================================298===================================\n",
      "298/4000: train_loss: 4.47513459789101 train_error 51.88% test_error 53.00%\n",
      "================================299===================================\n",
      "299/4000: train_loss: 4.474574396451936 train_error 51.88% test_error 53.00%\n",
      "================================300===================================\n",
      "300/4000: train_loss: 4.474013955709524 train_error 51.62% test_error 53.00%\n",
      "================================301===================================\n",
      "301/4000: train_loss: 4.47345377638936 train_error 51.38% test_error 53.00%\n",
      "================================302===================================\n",
      "302/4000: train_loss: 4.4728940308932215 train_error 51.62% test_error 52.50%\n",
      "================================303===================================\n",
      "303/4000: train_loss: 4.472334585227072 train_error 51.62% test_error 52.50%\n",
      "================================304===================================\n",
      "304/4000: train_loss: 4.471775023187511 train_error 51.62% test_error 52.50%\n",
      "================================305===================================\n",
      "305/4000: train_loss: 4.471213376950473 train_error 51.62% test_error 52.50%\n",
      "================================306===================================\n",
      "306/4000: train_loss: 4.470650477958843 train_error 51.50% test_error 52.50%\n",
      "================================307===================================\n",
      "307/4000: train_loss: 4.470088682291099 train_error 51.38% test_error 52.50%\n",
      "================================308===================================\n",
      "308/4000: train_loss: 4.46952743966598 train_error 51.25% test_error 52.50%\n",
      "================================309===================================\n",
      "309/4000: train_loss: 4.4689687817171215 train_error 51.25% test_error 52.50%\n",
      "================================310===================================\n",
      "310/4000: train_loss: 4.468411157084629 train_error 51.25% test_error 52.50%\n",
      "================================311===================================\n",
      "311/4000: train_loss: 4.467854024525732 train_error 51.12% test_error 53.00%\n",
      "================================312===================================\n",
      "312/4000: train_loss: 4.467297475570813 train_error 51.12% test_error 53.00%\n",
      "================================313===================================\n",
      "313/4000: train_loss: 4.466739279343747 train_error 51.12% test_error 53.00%\n",
      "================================314===================================\n",
      "314/4000: train_loss: 4.466181030650623 train_error 51.12% test_error 53.00%\n",
      "================================315===================================\n",
      "315/4000: train_loss: 4.465623139915988 train_error 51.12% test_error 53.00%\n",
      "================================316===================================\n",
      "316/4000: train_loss: 4.465066204695031 train_error 51.12% test_error 53.00%\n",
      "================================317===================================\n",
      "317/4000: train_loss: 4.464508675779216 train_error 51.12% test_error 53.50%\n",
      "================================318===================================\n",
      "318/4000: train_loss: 4.463950337297283 train_error 51.12% test_error 53.50%\n",
      "================================319===================================\n",
      "319/4000: train_loss: 4.4633921240922065 train_error 51.00% test_error 53.50%\n",
      "================================320===================================\n",
      "320/4000: train_loss: 4.462834032345563 train_error 50.88% test_error 53.50%\n",
      "================================321===================================\n",
      "321/4000: train_loss: 4.462275390592404 train_error 50.75% test_error 53.50%\n",
      "================================322===================================\n",
      "322/4000: train_loss: 4.461714985836298 train_error 50.50% test_error 53.50%\n",
      "================================323===================================\n",
      "323/4000: train_loss: 4.461153776594438 train_error 50.50% test_error 53.50%\n",
      "================================324===================================\n",
      "324/4000: train_loss: 4.460591227528639 train_error 50.50% test_error 53.50%\n",
      "================================325===================================\n",
      "325/4000: train_loss: 4.460028611505404 train_error 50.50% test_error 53.50%\n",
      "================================326===================================\n",
      "326/4000: train_loss: 4.459465871807188 train_error 50.50% test_error 53.50%\n",
      "================================327===================================\n",
      "327/4000: train_loss: 4.458902838081122 train_error 50.50% test_error 53.50%\n",
      "================================328===================================\n",
      "328/4000: train_loss: 4.458339770985767 train_error 50.50% test_error 53.50%\n",
      "================================329===================================\n",
      "329/4000: train_loss: 4.457776694260538 train_error 50.50% test_error 53.50%\n",
      "================================330===================================\n",
      "330/4000: train_loss: 4.457213131245226 train_error 50.50% test_error 53.50%\n",
      "================================331===================================\n",
      "331/4000: train_loss: 4.456650257143192 train_error 50.50% test_error 53.00%\n",
      "================================332===================================\n",
      "332/4000: train_loss: 4.456088660960085 train_error 50.50% test_error 53.00%\n",
      "================================333===================================\n",
      "333/4000: train_loss: 4.455527439787984 train_error 50.50% test_error 53.00%\n",
      "================================334===================================\n",
      "334/4000: train_loss: 4.454966108640655 train_error 50.50% test_error 52.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================335===================================\n",
      "335/4000: train_loss: 4.454404218299315 train_error 50.50% test_error 52.50%\n",
      "================================336===================================\n",
      "336/4000: train_loss: 4.453841399154626 train_error 50.38% test_error 52.50%\n",
      "================================337===================================\n",
      "337/4000: train_loss: 4.453277716618031 train_error 50.38% test_error 52.50%\n",
      "================================338===================================\n",
      "338/4000: train_loss: 4.4527125670062375 train_error 50.38% test_error 52.00%\n",
      "================================339===================================\n",
      "339/4000: train_loss: 4.4521467573754485 train_error 50.38% test_error 52.00%\n",
      "================================340===================================\n",
      "340/4000: train_loss: 4.451581355277449 train_error 50.25% test_error 52.00%\n",
      "================================341===================================\n",
      "341/4000: train_loss: 4.451017183456569 train_error 50.25% test_error 52.00%\n",
      "================================342===================================\n",
      "342/4000: train_loss: 4.450452851629816 train_error 50.25% test_error 52.00%\n",
      "================================343===================================\n",
      "343/4000: train_loss: 4.449888434577733 train_error 50.12% test_error 52.00%\n",
      "================================344===================================\n",
      "344/4000: train_loss: 4.449323161798529 train_error 50.12% test_error 52.50%\n",
      "================================345===================================\n",
      "345/4000: train_loss: 4.448755930825136 train_error 50.12% test_error 52.50%\n",
      "================================346===================================\n",
      "346/4000: train_loss: 4.448188313050196 train_error 50.12% test_error 52.50%\n",
      "================================347===================================\n",
      "347/4000: train_loss: 4.447619650536216 train_error 50.00% test_error 52.50%\n",
      "================================348===================================\n",
      "348/4000: train_loss: 4.447049811827019 train_error 50.00% test_error 52.50%\n",
      "================================349===================================\n",
      "349/4000: train_loss: 4.446479848320596 train_error 49.88% test_error 52.50%\n",
      "================================350===================================\n",
      "350/4000: train_loss: 4.445910261981189 train_error 49.88% test_error 52.50%\n",
      "================================351===================================\n",
      "351/4000: train_loss: 4.445338691417128 train_error 50.00% test_error 53.00%\n",
      "================================352===================================\n",
      "352/4000: train_loss: 4.4447664355300365 train_error 50.00% test_error 53.00%\n",
      "================================353===================================\n",
      "353/4000: train_loss: 4.444194280155934 train_error 49.88% test_error 53.00%\n",
      "================================354===================================\n",
      "354/4000: train_loss: 4.443623640062288 train_error 49.88% test_error 53.00%\n",
      "================================355===================================\n",
      "355/4000: train_loss: 4.4430530997272575 train_error 49.88% test_error 53.00%\n",
      "================================356===================================\n",
      "356/4000: train_loss: 4.44248157566879 train_error 49.88% test_error 53.00%\n",
      "================================357===================================\n",
      "357/4000: train_loss: 4.4419076436804605 train_error 49.88% test_error 53.00%\n",
      "================================358===================================\n",
      "358/4000: train_loss: 4.441330193718896 train_error 49.88% test_error 53.00%\n",
      "================================359===================================\n",
      "359/4000: train_loss: 4.440750814699568 train_error 49.88% test_error 53.00%\n",
      "================================360===================================\n",
      "360/4000: train_loss: 4.440171697018668 train_error 49.88% test_error 52.50%\n",
      "================================361===================================\n",
      "361/4000: train_loss: 4.439592050365173 train_error 49.88% test_error 52.50%\n",
      "================================362===================================\n",
      "362/4000: train_loss: 4.439012079960667 train_error 49.75% test_error 52.50%\n",
      "================================363===================================\n",
      "363/4000: train_loss: 4.438431399674155 train_error 49.75% test_error 52.50%\n",
      "================================364===================================\n",
      "364/4000: train_loss: 4.437848959113471 train_error 49.75% test_error 52.50%\n",
      "================================365===================================\n",
      "365/4000: train_loss: 4.437266185288317 train_error 49.75% test_error 52.50%\n",
      "================================366===================================\n",
      "366/4000: train_loss: 4.436683006654493 train_error 49.75% test_error 52.50%\n",
      "================================367===================================\n",
      "367/4000: train_loss: 4.436099992590025 train_error 49.75% test_error 52.50%\n",
      "================================368===================================\n",
      "368/4000: train_loss: 4.4355173116875815 train_error 49.88% test_error 52.50%\n",
      "================================369===================================\n",
      "369/4000: train_loss: 4.434934597369284 train_error 49.88% test_error 52.50%\n",
      "================================370===================================\n",
      "370/4000: train_loss: 4.434350225403905 train_error 49.88% test_error 52.50%\n",
      "================================371===================================\n",
      "371/4000: train_loss: 4.433765479996801 train_error 49.88% test_error 52.50%\n",
      "================================372===================================\n",
      "372/4000: train_loss: 4.433178792223335 train_error 49.75% test_error 52.50%\n",
      "================================373===================================\n",
      "373/4000: train_loss: 4.4325907434569665 train_error 49.75% test_error 52.50%\n",
      "================================374===================================\n",
      "374/4000: train_loss: 4.432001837026328 train_error 49.75% test_error 52.50%\n",
      "================================375===================================\n",
      "375/4000: train_loss: 4.431412037583067 train_error 49.62% test_error 52.50%\n",
      "================================376===================================\n",
      "376/4000: train_loss: 4.430822469084523 train_error 49.50% test_error 53.00%\n",
      "================================377===================================\n",
      "377/4000: train_loss: 4.430232457518578 train_error 49.50% test_error 53.00%\n",
      "================================378===================================\n",
      "378/4000: train_loss: 4.429642038177699 train_error 49.50% test_error 53.00%\n",
      "================================379===================================\n",
      "379/4000: train_loss: 4.4290501388208945 train_error 49.38% test_error 53.00%\n",
      "================================380===================================\n",
      "380/4000: train_loss: 4.428457241384312 train_error 49.38% test_error 53.00%\n",
      "================================381===================================\n",
      "381/4000: train_loss: 4.427863800376653 train_error 49.38% test_error 53.00%\n",
      "================================382===================================\n",
      "382/4000: train_loss: 4.427269788887352 train_error 49.25% test_error 53.00%\n",
      "================================383===================================\n",
      "383/4000: train_loss: 4.4266752339294175 train_error 49.12% test_error 53.00%\n",
      "================================384===================================\n",
      "384/4000: train_loss: 4.426080329949036 train_error 49.00% test_error 53.50%\n",
      "================================385===================================\n",
      "385/4000: train_loss: 4.425484555978327 train_error 49.00% test_error 53.50%\n",
      "================================386===================================\n",
      "386/4000: train_loss: 4.42488980341237 train_error 49.00% test_error 53.50%\n",
      "================================387===================================\n",
      "387/4000: train_loss: 4.424295567465014 train_error 49.00% test_error 53.50%\n",
      "================================388===================================\n",
      "388/4000: train_loss: 4.423701245649718 train_error 49.00% test_error 53.50%\n",
      "================================389===================================\n",
      "389/4000: train_loss: 4.423106773989275 train_error 49.00% test_error 53.50%\n",
      "================================390===================================\n",
      "390/4000: train_loss: 4.422511876793578 train_error 48.75% test_error 53.50%\n",
      "================================391===================================\n",
      "391/4000: train_loss: 4.421915608653799 train_error 48.88% test_error 53.00%\n",
      "================================392===================================\n",
      "392/4000: train_loss: 4.421318230074831 train_error 48.88% test_error 53.00%\n",
      "================================393===================================\n",
      "393/4000: train_loss: 4.420719090052881 train_error 48.88% test_error 53.00%\n",
      "================================394===================================\n",
      "394/4000: train_loss: 4.420120057216846 train_error 48.62% test_error 53.00%\n",
      "================================395===================================\n",
      "395/4000: train_loss: 4.419521802808158 train_error 48.62% test_error 53.00%\n",
      "================================396===================================\n",
      "396/4000: train_loss: 4.418924221401102 train_error 48.62% test_error 53.00%\n",
      "================================397===================================\n",
      "397/4000: train_loss: 4.41832677888684 train_error 48.62% test_error 53.00%\n",
      "================================398===================================\n",
      "398/4000: train_loss: 4.417729392126202 train_error 48.62% test_error 53.00%\n",
      "================================399===================================\n",
      "399/4000: train_loss: 4.417131747580133 train_error 48.62% test_error 53.00%\n",
      "================================400===================================\n",
      "400/4000: train_loss: 4.416533572738991 train_error 48.50% test_error 53.00%\n",
      "================================401===================================\n",
      "401/4000: train_loss: 4.415934963366016 train_error 48.50% test_error 53.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================402===================================\n",
      "402/4000: train_loss: 4.41533622588031 train_error 48.50% test_error 53.00%\n",
      "================================403===================================\n",
      "403/4000: train_loss: 4.414737568334676 train_error 48.50% test_error 53.00%\n",
      "================================404===================================\n",
      "404/4000: train_loss: 4.41413765901234 train_error 48.50% test_error 53.00%\n",
      "================================405===================================\n",
      "405/4000: train_loss: 4.413536792765372 train_error 48.50% test_error 53.00%\n",
      "================================406===================================\n",
      "406/4000: train_loss: 4.412935823313893 train_error 48.38% test_error 53.00%\n",
      "================================407===================================\n",
      "407/4000: train_loss: 4.412331366669386 train_error 48.25% test_error 53.00%\n",
      "================================408===================================\n",
      "408/4000: train_loss: 4.411722045666538 train_error 48.25% test_error 53.00%\n",
      "================================409===================================\n",
      "409/4000: train_loss: 4.41111194989644 train_error 48.12% test_error 53.00%\n",
      "================================410===================================\n",
      "410/4000: train_loss: 4.410503535810858 train_error 48.12% test_error 53.00%\n",
      "================================411===================================\n",
      "411/4000: train_loss: 4.409895037766546 train_error 48.12% test_error 53.00%\n",
      "================================412===================================\n",
      "412/4000: train_loss: 4.409284858629108 train_error 48.12% test_error 53.00%\n",
      "================================413===================================\n",
      "413/4000: train_loss: 4.40867305546999 train_error 48.00% test_error 53.00%\n",
      "================================414===================================\n",
      "414/4000: train_loss: 4.408060710718855 train_error 48.00% test_error 53.00%\n",
      "================================415===================================\n",
      "415/4000: train_loss: 4.40744766861666 train_error 48.00% test_error 53.00%\n",
      "================================416===================================\n",
      "416/4000: train_loss: 4.406833910327405 train_error 47.88% test_error 53.00%\n",
      "================================417===================================\n",
      "417/4000: train_loss: 4.406219379063696 train_error 47.88% test_error 53.00%\n",
      "================================418===================================\n",
      "418/4000: train_loss: 4.405602811579593 train_error 47.88% test_error 53.00%\n",
      "================================419===================================\n",
      "419/4000: train_loss: 4.4049836664134645 train_error 47.88% test_error 53.00%\n",
      "================================420===================================\n",
      "420/4000: train_loss: 4.404362278087065 train_error 47.88% test_error 53.00%\n",
      "================================421===================================\n",
      "421/4000: train_loss: 4.4037397844111545 train_error 47.88% test_error 53.00%\n",
      "================================422===================================\n",
      "422/4000: train_loss: 4.403117109099403 train_error 47.88% test_error 53.00%\n",
      "================================423===================================\n",
      "423/4000: train_loss: 4.402493975060061 train_error 47.88% test_error 53.00%\n",
      "================================424===================================\n",
      "424/4000: train_loss: 4.401869143620133 train_error 47.88% test_error 53.00%\n",
      "================================425===================================\n",
      "425/4000: train_loss: 4.4012433177419 train_error 47.88% test_error 53.00%\n",
      "================================426===================================\n",
      "426/4000: train_loss: 4.400617240751163 train_error 47.75% test_error 53.00%\n",
      "================================427===================================\n",
      "427/4000: train_loss: 4.39998902800493 train_error 47.75% test_error 53.00%\n",
      "================================428===================================\n",
      "428/4000: train_loss: 4.3993585815327245 train_error 47.75% test_error 52.50%\n",
      "================================429===================================\n",
      "429/4000: train_loss: 4.39872702291701 train_error 47.75% test_error 52.50%\n",
      "================================430===================================\n",
      "430/4000: train_loss: 4.398092918973417 train_error 47.75% test_error 53.00%\n",
      "================================431===================================\n",
      "431/4000: train_loss: 4.397456091088243 train_error 47.62% test_error 53.00%\n",
      "================================432===================================\n",
      "432/4000: train_loss: 4.396817782530562 train_error 47.62% test_error 53.00%\n",
      "================================433===================================\n",
      "433/4000: train_loss: 4.396178407757542 train_error 47.62% test_error 53.00%\n",
      "================================434===================================\n",
      "434/4000: train_loss: 4.395538333812729 train_error 47.62% test_error 53.00%\n",
      "================================435===================================\n",
      "435/4000: train_loss: 4.394897526176646 train_error 47.62% test_error 53.00%\n",
      "================================436===================================\n",
      "436/4000: train_loss: 4.394256239351817 train_error 47.62% test_error 53.00%\n",
      "================================437===================================\n",
      "437/4000: train_loss: 4.393614053684287 train_error 47.62% test_error 53.00%\n",
      "================================438===================================\n",
      "438/4000: train_loss: 4.392971398001537 train_error 47.62% test_error 53.00%\n",
      "================================439===================================\n",
      "439/4000: train_loss: 4.392328208405525 train_error 47.62% test_error 53.00%\n",
      "================================440===================================\n",
      "440/4000: train_loss: 4.391683115963824 train_error 47.62% test_error 53.00%\n",
      "================================441===================================\n",
      "441/4000: train_loss: 4.3910375924129035 train_error 47.62% test_error 52.50%\n",
      "================================442===================================\n",
      "442/4000: train_loss: 4.390391405443661 train_error 47.62% test_error 52.50%\n",
      "================================443===================================\n",
      "443/4000: train_loss: 4.389744495907798 train_error 47.62% test_error 52.50%\n",
      "================================444===================================\n",
      "444/4000: train_loss: 4.389095968464389 train_error 47.50% test_error 52.50%\n",
      "================================445===================================\n",
      "445/4000: train_loss: 4.388443665369414 train_error 47.50% test_error 52.50%\n",
      "================================446===================================\n",
      "446/4000: train_loss: 4.387788923783228 train_error 47.50% test_error 52.50%\n",
      "================================447===================================\n",
      "447/4000: train_loss: 4.387133757807314 train_error 47.50% test_error 52.50%\n",
      "================================448===================================\n",
      "448/4000: train_loss: 4.3864773711515594 train_error 47.38% test_error 52.50%\n",
      "================================449===================================\n",
      "449/4000: train_loss: 4.3858185281278566 train_error 47.12% test_error 52.50%\n",
      "================================450===================================\n",
      "450/4000: train_loss: 4.385158870546147 train_error 47.12% test_error 52.50%\n",
      "================================451===================================\n",
      "451/4000: train_loss: 4.384498324114829 train_error 47.12% test_error 52.50%\n",
      "================================452===================================\n",
      "452/4000: train_loss: 4.38383737531025 train_error 47.12% test_error 52.50%\n",
      "================================453===================================\n",
      "453/4000: train_loss: 4.383176185679622 train_error 47.25% test_error 52.50%\n",
      "================================454===================================\n",
      "454/4000: train_loss: 4.382512507829815 train_error 47.25% test_error 52.50%\n",
      "================================455===================================\n",
      "455/4000: train_loss: 4.381846938533709 train_error 47.12% test_error 52.00%\n",
      "================================456===================================\n",
      "456/4000: train_loss: 4.381180538795888 train_error 47.12% test_error 52.00%\n",
      "================================457===================================\n",
      "457/4000: train_loss: 4.380512611013837 train_error 47.12% test_error 52.00%\n",
      "================================458===================================\n",
      "458/4000: train_loss: 4.379843387547881 train_error 47.12% test_error 52.00%\n",
      "================================459===================================\n",
      "459/4000: train_loss: 4.379173246417195 train_error 47.12% test_error 52.00%\n",
      "================================460===================================\n",
      "460/4000: train_loss: 4.378502017320134 train_error 47.00% test_error 52.00%\n",
      "================================461===================================\n",
      "461/4000: train_loss: 4.377828561821953 train_error 47.00% test_error 52.00%\n",
      "================================462===================================\n",
      "462/4000: train_loss: 4.377153160907327 train_error 47.00% test_error 52.00%\n",
      "================================463===================================\n",
      "463/4000: train_loss: 4.376476933327503 train_error 47.00% test_error 52.00%\n",
      "================================464===================================\n",
      "464/4000: train_loss: 4.375799150704406 train_error 47.00% test_error 52.00%\n",
      "================================465===================================\n",
      "465/4000: train_loss: 4.375120176761412 train_error 47.12% test_error 52.00%\n",
      "================================466===================================\n",
      "466/4000: train_loss: 4.3744399783946575 train_error 47.12% test_error 52.00%\n",
      "================================467===================================\n",
      "467/4000: train_loss: 4.373758753072471 train_error 47.12% test_error 52.00%\n",
      "================================468===================================\n",
      "468/4000: train_loss: 4.373077740911395 train_error 47.12% test_error 52.00%\n",
      "================================469===================================\n",
      "469/4000: train_loss: 4.372395493146032 train_error 47.12% test_error 52.00%\n",
      "================================470===================================\n",
      "470/4000: train_loss: 4.3717107028188185 train_error 47.00% test_error 52.00%\n",
      "================================471===================================\n",
      "471/4000: train_loss: 4.371022944697179 train_error 47.00% test_error 52.00%\n",
      "================================472===================================\n",
      "472/4000: train_loss: 4.370332872862928 train_error 47.00% test_error 52.00%\n",
      "================================473===================================\n",
      "473/4000: train_loss: 4.369642325239257 train_error 47.00% test_error 52.00%\n",
      "================================474===================================\n",
      "474/4000: train_loss: 4.368950514681638 train_error 47.00% test_error 52.00%\n",
      "================================475===================================\n",
      "475/4000: train_loss: 4.368257118551991 train_error 47.00% test_error 52.00%\n",
      "================================476===================================\n",
      "476/4000: train_loss: 4.367562745581381 train_error 47.00% test_error 52.00%\n",
      "================================477===================================\n",
      "477/4000: train_loss: 4.36686827159021 train_error 47.00% test_error 52.00%\n",
      "================================478===================================\n",
      "478/4000: train_loss: 4.366173416599631 train_error 47.00% test_error 52.00%\n",
      "================================479===================================\n",
      "479/4000: train_loss: 4.36547677573748 train_error 46.88% test_error 52.00%\n",
      "================================480===================================\n",
      "480/4000: train_loss: 4.364778555077501 train_error 46.75% test_error 52.00%\n",
      "================================481===================================\n",
      "481/4000: train_loss: 4.364078736663796 train_error 46.75% test_error 52.00%\n",
      "================================482===================================\n",
      "482/4000: train_loss: 4.363377377982252 train_error 46.88% test_error 52.00%\n",
      "================================483===================================\n",
      "483/4000: train_loss: 4.362675269562752 train_error 46.88% test_error 52.00%\n",
      "================================484===================================\n",
      "484/4000: train_loss: 4.3619714691396805 train_error 46.75% test_error 52.00%\n",
      "================================485===================================\n",
      "485/4000: train_loss: 4.361265306789428 train_error 46.75% test_error 52.00%\n",
      "================================486===================================\n",
      "486/4000: train_loss: 4.360557468174957 train_error 46.50% test_error 52.00%\n",
      "================================487===================================\n",
      "487/4000: train_loss: 4.359848332232795 train_error 46.50% test_error 52.00%\n",
      "================================488===================================\n",
      "488/4000: train_loss: 4.359138325131498 train_error 46.50% test_error 52.00%\n",
      "================================489===================================\n",
      "489/4000: train_loss: 4.358426782088355 train_error 46.50% test_error 52.00%\n",
      "================================490===================================\n",
      "490/4000: train_loss: 4.357712125508114 train_error 46.50% test_error 52.00%\n",
      "================================491===================================\n",
      "491/4000: train_loss: 4.35699458649382 train_error 46.50% test_error 52.00%\n",
      "================================492===================================\n",
      "492/4000: train_loss: 4.356275902478955 train_error 46.50% test_error 52.00%\n",
      "================================493===================================\n",
      "493/4000: train_loss: 4.355554692093283 train_error 46.50% test_error 52.00%\n",
      "================================494===================================\n",
      "494/4000: train_loss: 4.354830357646569 train_error 46.50% test_error 52.00%\n",
      "================================495===================================\n",
      "495/4000: train_loss: 4.354105632281862 train_error 46.50% test_error 52.00%\n",
      "================================496===================================\n",
      "496/4000: train_loss: 4.353380733537488 train_error 46.50% test_error 52.00%\n",
      "================================497===================================\n",
      "497/4000: train_loss: 4.352654441720807 train_error 46.50% test_error 52.00%\n",
      "================================498===================================\n",
      "498/4000: train_loss: 4.351927028605715 train_error 46.50% test_error 52.00%\n",
      "================================499===================================\n",
      "499/4000: train_loss: 4.35119858101476 train_error 46.50% test_error 52.00%\n",
      "================================500===================================\n",
      "500/4000: train_loss: 4.350467118523084 train_error 46.50% test_error 52.00%\n",
      "================================501===================================\n",
      "501/4000: train_loss: 4.3497349592018875 train_error 46.38% test_error 52.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================502===================================\n",
      "502/4000: train_loss: 4.34900312811602 train_error 46.38% test_error 52.00%\n",
      "================================503===================================\n",
      "503/4000: train_loss: 4.348270320780575 train_error 46.25% test_error 52.00%\n",
      "================================504===================================\n",
      "504/4000: train_loss: 4.347537467256188 train_error 46.25% test_error 52.00%\n",
      "================================505===================================\n",
      "505/4000: train_loss: 4.346802700934932 train_error 46.12% test_error 52.00%\n",
      "================================506===================================\n",
      "506/4000: train_loss: 4.346067725475877 train_error 46.12% test_error 52.00%\n",
      "================================507===================================\n",
      "507/4000: train_loss: 4.345331639070064 train_error 46.12% test_error 52.00%\n",
      "================================508===================================\n",
      "508/4000: train_loss: 4.344594473154284 train_error 46.12% test_error 52.00%\n",
      "================================509===================================\n",
      "509/4000: train_loss: 4.343856322220526 train_error 46.12% test_error 52.00%\n",
      "================================510===================================\n",
      "510/4000: train_loss: 4.343117679967545 train_error 46.12% test_error 52.00%\n",
      "================================511===================================\n",
      "511/4000: train_loss: 4.3423791913222525 train_error 46.12% test_error 52.00%\n",
      "================================512===================================\n",
      "512/4000: train_loss: 4.341639811522327 train_error 46.12% test_error 52.00%\n",
      "================================513===================================\n",
      "513/4000: train_loss: 4.3408963799662885 train_error 46.25% test_error 52.00%\n",
      "================================514===================================\n",
      "514/4000: train_loss: 4.3401506351586425 train_error 46.25% test_error 52.00%\n",
      "================================515===================================\n",
      "515/4000: train_loss: 4.339404167560861 train_error 46.25% test_error 52.00%\n",
      "================================516===================================\n",
      "516/4000: train_loss: 4.338657541205176 train_error 46.25% test_error 52.00%\n",
      "================================517===================================\n",
      "517/4000: train_loss: 4.337910055024549 train_error 46.25% test_error 52.00%\n",
      "================================518===================================\n",
      "518/4000: train_loss: 4.337162161050365 train_error 46.25% test_error 52.00%\n",
      "================================519===================================\n",
      "519/4000: train_loss: 4.3364138155616825 train_error 46.25% test_error 52.00%\n",
      "================================520===================================\n",
      "520/4000: train_loss: 4.335663839243352 train_error 46.25% test_error 52.00%\n",
      "================================521===================================\n",
      "521/4000: train_loss: 4.334910306860693 train_error 46.12% test_error 52.00%\n",
      "================================522===================================\n",
      "522/4000: train_loss: 4.3341520665492865 train_error 46.12% test_error 52.00%\n",
      "================================523===================================\n",
      "523/4000: train_loss: 4.3333910404052585 train_error 46.12% test_error 52.00%\n",
      "================================524===================================\n",
      "524/4000: train_loss: 4.33262694561854 train_error 46.12% test_error 52.00%\n",
      "================================525===================================\n",
      "525/4000: train_loss: 4.33185898961965 train_error 46.12% test_error 52.00%\n",
      "================================526===================================\n",
      "526/4000: train_loss: 4.331087033343501 train_error 46.12% test_error 52.00%\n",
      "================================527===================================\n",
      "527/4000: train_loss: 4.330310260946863 train_error 46.12% test_error 52.00%\n",
      "================================528===================================\n",
      "528/4000: train_loss: 4.329530373467132 train_error 46.12% test_error 52.00%\n",
      "================================529===================================\n",
      "529/4000: train_loss: 4.328746739919297 train_error 46.12% test_error 52.00%\n",
      "================================530===================================\n",
      "530/4000: train_loss: 4.327961840573698 train_error 46.00% test_error 52.00%\n",
      "================================531===================================\n",
      "531/4000: train_loss: 4.327175737447106 train_error 46.00% test_error 52.00%\n",
      "================================532===================================\n",
      "532/4000: train_loss: 4.326388227320276 train_error 46.00% test_error 52.00%\n",
      "================================533===================================\n",
      "533/4000: train_loss: 4.325598769853823 train_error 46.00% test_error 52.00%\n",
      "================================534===================================\n",
      "534/4000: train_loss: 4.324807900437154 train_error 46.00% test_error 52.00%\n",
      "================================535===================================\n",
      "535/4000: train_loss: 4.324016336719506 train_error 46.00% test_error 52.00%\n",
      "================================536===================================\n",
      "536/4000: train_loss: 4.323222580216824 train_error 46.00% test_error 52.00%\n",
      "================================537===================================\n",
      "537/4000: train_loss: 4.32242757236585 train_error 45.88% test_error 52.00%\n",
      "================================538===================================\n",
      "538/4000: train_loss: 4.321631991183385 train_error 45.88% test_error 52.00%\n",
      "================================539===================================\n",
      "539/4000: train_loss: 4.32083664282225 train_error 45.75% test_error 52.00%\n",
      "================================540===================================\n",
      "540/4000: train_loss: 4.320039759781212 train_error 45.75% test_error 52.00%\n",
      "================================541===================================\n",
      "541/4000: train_loss: 4.319240414579399 train_error 45.75% test_error 52.00%\n",
      "================================542===================================\n",
      "542/4000: train_loss: 4.31843839403242 train_error 45.62% test_error 52.00%\n",
      "================================543===================================\n",
      "543/4000: train_loss: 4.3176346316561105 train_error 45.62% test_error 52.00%\n",
      "================================544===================================\n",
      "544/4000: train_loss: 4.316829722225666 train_error 45.62% test_error 52.00%\n",
      "================================545===================================\n",
      "545/4000: train_loss: 4.316023542047478 train_error 45.62% test_error 52.00%\n",
      "================================546===================================\n",
      "546/4000: train_loss: 4.315215590274892 train_error 45.62% test_error 52.00%\n",
      "================================547===================================\n",
      "547/4000: train_loss: 4.314406238691881 train_error 45.50% test_error 52.00%\n",
      "================================548===================================\n",
      "548/4000: train_loss: 4.313596205427312 train_error 45.50% test_error 52.00%\n",
      "================================549===================================\n",
      "549/4000: train_loss: 4.3127845877036455 train_error 45.50% test_error 52.00%\n",
      "================================550===================================\n",
      "550/4000: train_loss: 4.311972715612501 train_error 45.38% test_error 52.00%\n",
      "================================551===================================\n",
      "551/4000: train_loss: 4.311159961139783 train_error 45.38% test_error 52.00%\n",
      "================================552===================================\n",
      "552/4000: train_loss: 4.310345691521651 train_error 45.38% test_error 52.00%\n",
      "================================553===================================\n",
      "553/4000: train_loss: 4.3095289600268005 train_error 45.38% test_error 52.00%\n",
      "================================554===================================\n",
      "554/4000: train_loss: 4.3087099137669425 train_error 45.38% test_error 52.00%\n",
      "================================555===================================\n",
      "555/4000: train_loss: 4.307888716883026 train_error 45.38% test_error 52.00%\n",
      "================================556===================================\n",
      "556/4000: train_loss: 4.307065894226544 train_error 45.38% test_error 52.00%\n",
      "================================557===================================\n",
      "557/4000: train_loss: 4.306240764320828 train_error 45.38% test_error 52.00%\n",
      "================================558===================================\n",
      "558/4000: train_loss: 4.305414547729306 train_error 45.38% test_error 52.00%\n",
      "================================559===================================\n",
      "559/4000: train_loss: 4.304587003956549 train_error 45.38% test_error 52.00%\n",
      "================================560===================================\n",
      "560/4000: train_loss: 4.303759172176942 train_error 45.38% test_error 52.00%\n",
      "================================561===================================\n",
      "561/4000: train_loss: 4.302930402415805 train_error 45.38% test_error 52.00%\n",
      "================================562===================================\n",
      "562/4000: train_loss: 4.302100826259702 train_error 45.38% test_error 52.00%\n",
      "================================563===================================\n",
      "563/4000: train_loss: 4.301270068828016 train_error 45.38% test_error 52.00%\n",
      "================================564===================================\n",
      "564/4000: train_loss: 4.300440774364397 train_error 45.38% test_error 52.00%\n",
      "================================565===================================\n",
      "565/4000: train_loss: 4.2996099377051 train_error 45.38% test_error 52.00%\n",
      "================================566===================================\n",
      "566/4000: train_loss: 4.298775551612489 train_error 45.38% test_error 52.00%\n",
      "================================567===================================\n",
      "567/4000: train_loss: 4.297939749341458 train_error 45.38% test_error 52.00%\n",
      "================================568===================================\n",
      "568/4000: train_loss: 4.297101852754131 train_error 45.38% test_error 52.00%\n",
      "================================569===================================\n",
      "569/4000: train_loss: 4.296262913565151 train_error 45.25% test_error 52.00%\n",
      "================================570===================================\n",
      "570/4000: train_loss: 4.295422829790041 train_error 45.25% test_error 52.00%\n",
      "================================571===================================\n",
      "571/4000: train_loss: 4.294581801537424 train_error 45.25% test_error 52.00%\n",
      "================================572===================================\n",
      "572/4000: train_loss: 4.293739432021975 train_error 45.25% test_error 52.00%\n",
      "================================573===================================\n",
      "573/4000: train_loss: 4.292896244097501 train_error 45.25% test_error 52.00%\n",
      "================================574===================================\n",
      "574/4000: train_loss: 4.292052077017725 train_error 45.12% test_error 52.00%\n",
      "================================575===================================\n",
      "575/4000: train_loss: 4.291207455033437 train_error 45.12% test_error 52.00%\n",
      "================================576===================================\n",
      "576/4000: train_loss: 4.2903618122078475 train_error 45.12% test_error 52.00%\n",
      "================================577===================================\n",
      "577/4000: train_loss: 4.289513440942391 train_error 45.12% test_error 52.00%\n",
      "================================578===================================\n",
      "578/4000: train_loss: 4.288661721181125 train_error 45.00% test_error 52.00%\n",
      "================================579===================================\n",
      "579/4000: train_loss: 4.287808641730808 train_error 45.00% test_error 52.00%\n",
      "================================580===================================\n",
      "580/4000: train_loss: 4.286952629820444 train_error 44.88% test_error 51.50%\n",
      "================================581===================================\n",
      "581/4000: train_loss: 4.286092350687832 train_error 44.75% test_error 51.50%\n",
      "================================582===================================\n",
      "582/4000: train_loss: 4.285229582902975 train_error 44.75% test_error 51.50%\n",
      "================================583===================================\n",
      "583/4000: train_loss: 4.284365381663665 train_error 44.62% test_error 51.50%\n",
      "================================584===================================\n",
      "584/4000: train_loss: 4.283500561090186 train_error 44.62% test_error 51.50%\n",
      "================================585===================================\n",
      "585/4000: train_loss: 4.282634427021258 train_error 44.62% test_error 51.00%\n",
      "================================586===================================\n",
      "586/4000: train_loss: 4.281766682248563 train_error 44.62% test_error 51.00%\n",
      "================================587===================================\n",
      "587/4000: train_loss: 4.280898671317846 train_error 44.62% test_error 51.00%\n",
      "================================588===================================\n",
      "588/4000: train_loss: 4.280029812571592 train_error 44.62% test_error 51.00%\n",
      "================================589===================================\n",
      "589/4000: train_loss: 4.279160059760325 train_error 44.62% test_error 51.00%\n",
      "================================590===================================\n",
      "590/4000: train_loss: 4.278291060174816 train_error 44.62% test_error 51.00%\n",
      "================================591===================================\n",
      "591/4000: train_loss: 4.27742305025924 train_error 44.50% test_error 51.00%\n",
      "================================592===================================\n",
      "592/4000: train_loss: 4.276553894425742 train_error 44.38% test_error 51.00%\n",
      "================================593===================================\n",
      "593/4000: train_loss: 4.275684118387289 train_error 44.25% test_error 51.00%\n",
      "================================594===================================\n",
      "594/4000: train_loss: 4.274812807086855 train_error 44.25% test_error 51.00%\n",
      "================================595===================================\n",
      "595/4000: train_loss: 4.273940092967823 train_error 44.12% test_error 51.00%\n",
      "================================596===================================\n",
      "596/4000: train_loss: 4.2730668640090155 train_error 44.12% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================597===================================\n",
      "597/4000: train_loss: 4.272193843009881 train_error 44.12% test_error 51.00%\n",
      "================================598===================================\n",
      "598/4000: train_loss: 4.2713194103864955 train_error 44.25% test_error 51.00%\n",
      "================================599===================================\n",
      "599/4000: train_loss: 4.270446086334996 train_error 44.25% test_error 51.00%\n",
      "================================600===================================\n",
      "600/4000: train_loss: 4.269572385675274 train_error 44.25% test_error 51.00%\n",
      "================================601===================================\n",
      "601/4000: train_loss: 4.268697467958555 train_error 44.12% test_error 51.00%\n",
      "================================602===================================\n",
      "602/4000: train_loss: 4.26782020425424 train_error 44.12% test_error 50.50%\n",
      "================================603===================================\n",
      "603/4000: train_loss: 4.266941665196791 train_error 44.12% test_error 50.50%\n",
      "================================604===================================\n",
      "604/4000: train_loss: 4.266061928989365 train_error 44.12% test_error 50.50%\n",
      "================================605===================================\n",
      "605/4000: train_loss: 4.265182751640677 train_error 44.12% test_error 50.50%\n",
      "================================606===================================\n",
      "606/4000: train_loss: 4.2643024834617975 train_error 44.12% test_error 50.50%\n",
      "================================607===================================\n",
      "607/4000: train_loss: 4.263420119774528 train_error 44.12% test_error 50.50%\n",
      "================================608===================================\n",
      "608/4000: train_loss: 4.262534848968499 train_error 44.12% test_error 50.50%\n",
      "================================609===================================\n",
      "609/4000: train_loss: 4.261647947966122 train_error 44.12% test_error 50.50%\n",
      "================================610===================================\n",
      "610/4000: train_loss: 4.260760054676793 train_error 44.12% test_error 49.50%\n",
      "================================611===================================\n",
      "611/4000: train_loss: 4.259871667008847 train_error 44.12% test_error 49.50%\n",
      "================================612===================================\n",
      "612/4000: train_loss: 4.258983203233219 train_error 44.12% test_error 49.50%\n",
      "================================613===================================\n",
      "613/4000: train_loss: 4.258093268941157 train_error 44.12% test_error 49.50%\n",
      "================================614===================================\n",
      "614/4000: train_loss: 4.2572019150992855 train_error 44.00% test_error 49.50%\n",
      "================================615===================================\n",
      "615/4000: train_loss: 4.256309066284448 train_error 44.00% test_error 49.50%\n",
      "================================616===================================\n",
      "616/4000: train_loss: 4.255414972077124 train_error 44.00% test_error 49.50%\n",
      "================================617===================================\n",
      "617/4000: train_loss: 4.254520100541413 train_error 44.00% test_error 49.50%\n",
      "================================618===================================\n",
      "618/4000: train_loss: 4.253624553889967 train_error 43.88% test_error 49.50%\n",
      "================================619===================================\n",
      "619/4000: train_loss: 4.252731666807085 train_error 43.88% test_error 49.50%\n",
      "================================620===================================\n",
      "620/4000: train_loss: 4.251838597166352 train_error 43.62% test_error 49.50%\n",
      "================================621===================================\n",
      "621/4000: train_loss: 4.250944717009552 train_error 43.62% test_error 49.50%\n",
      "================================622===================================\n",
      "622/4000: train_loss: 4.2500505119143055 train_error 43.62% test_error 49.50%\n",
      "================================623===================================\n",
      "623/4000: train_loss: 4.249153952393681 train_error 43.50% test_error 49.50%\n",
      "================================624===================================\n",
      "624/4000: train_loss: 4.2482537765428425 train_error 43.50% test_error 49.50%\n",
      "================================625===================================\n",
      "625/4000: train_loss: 4.247351433639414 train_error 43.50% test_error 49.50%\n",
      "================================626===================================\n",
      "626/4000: train_loss: 4.246447846335359 train_error 43.50% test_error 49.50%\n",
      "================================627===================================\n",
      "627/4000: train_loss: 4.245543462424538 train_error 43.50% test_error 49.50%\n",
      "================================628===================================\n",
      "628/4000: train_loss: 4.244638114878908 train_error 43.50% test_error 49.50%\n",
      "================================629===================================\n",
      "629/4000: train_loss: 4.243731031147763 train_error 43.50% test_error 49.50%\n",
      "================================630===================================\n",
      "630/4000: train_loss: 4.242824634066783 train_error 43.50% test_error 49.50%\n",
      "================================631===================================\n",
      "631/4000: train_loss: 4.241917884387076 train_error 43.50% test_error 49.50%\n",
      "================================632===================================\n",
      "632/4000: train_loss: 4.241011134930886 train_error 43.50% test_error 49.50%\n",
      "================================633===================================\n",
      "633/4000: train_loss: 4.240102918446064 train_error 43.50% test_error 49.50%\n",
      "================================634===================================\n",
      "634/4000: train_loss: 4.239194719251246 train_error 43.50% test_error 49.50%\n",
      "================================635===================================\n",
      "635/4000: train_loss: 4.238284946274944 train_error 43.50% test_error 49.50%\n",
      "================================636===================================\n",
      "636/4000: train_loss: 4.237373511851765 train_error 43.50% test_error 49.50%\n",
      "================================637===================================\n",
      "637/4000: train_loss: 4.236458264379762 train_error 43.38% test_error 49.50%\n",
      "================================638===================================\n",
      "638/4000: train_loss: 4.235540827093646 train_error 43.38% test_error 49.50%\n",
      "================================639===================================\n",
      "639/4000: train_loss: 4.234621733338573 train_error 43.38% test_error 49.50%\n",
      "================================640===================================\n",
      "640/4000: train_loss: 4.233702475349419 train_error 43.38% test_error 49.50%\n",
      "================================641===================================\n",
      "641/4000: train_loss: 4.232783162225969 train_error 43.38% test_error 49.50%\n",
      "================================642===================================\n",
      "642/4000: train_loss: 4.23186215961352 train_error 43.38% test_error 49.50%\n",
      "================================643===================================\n",
      "643/4000: train_loss: 4.230940616442822 train_error 43.38% test_error 49.50%\n",
      "================================644===================================\n",
      "644/4000: train_loss: 4.230017656311393 train_error 43.38% test_error 49.50%\n",
      "================================645===================================\n",
      "645/4000: train_loss: 4.229093172871508 train_error 43.38% test_error 49.50%\n",
      "================================646===================================\n",
      "646/4000: train_loss: 4.228167146337219 train_error 43.38% test_error 49.50%\n",
      "================================647===================================\n",
      "647/4000: train_loss: 4.227239613304846 train_error 43.38% test_error 49.50%\n",
      "================================648===================================\n",
      "648/4000: train_loss: 4.2263103592721745 train_error 43.38% test_error 49.50%\n",
      "================================649===================================\n",
      "649/4000: train_loss: 4.225380245796405 train_error 43.38% test_error 49.50%\n",
      "================================650===================================\n",
      "650/4000: train_loss: 4.224448638441973 train_error 43.38% test_error 49.50%\n",
      "================================651===================================\n",
      "651/4000: train_loss: 4.223515781839378 train_error 43.25% test_error 49.50%\n",
      "================================652===================================\n",
      "652/4000: train_loss: 4.222581838085317 train_error 43.25% test_error 49.50%\n",
      "================================653===================================\n",
      "653/4000: train_loss: 4.221646817536094 train_error 43.25% test_error 49.50%\n",
      "================================654===================================\n",
      "654/4000: train_loss: 4.220710679562762 train_error 43.12% test_error 49.50%\n",
      "================================655===================================\n",
      "655/4000: train_loss: 4.219773329175077 train_error 43.12% test_error 49.50%\n",
      "================================656===================================\n",
      "656/4000: train_loss: 4.218835307280533 train_error 43.12% test_error 49.50%\n",
      "================================657===================================\n",
      "657/4000: train_loss: 4.217896239007823 train_error 42.88% test_error 49.50%\n",
      "================================658===================================\n",
      "658/4000: train_loss: 4.216955235693604 train_error 42.88% test_error 49.50%\n",
      "================================659===================================\n",
      "659/4000: train_loss: 4.2160114535642785 train_error 42.62% test_error 49.50%\n",
      "================================660===================================\n",
      "660/4000: train_loss: 4.215063051609322 train_error 42.62% test_error 49.50%\n",
      "================================661===================================\n",
      "661/4000: train_loss: 4.214113274007104 train_error 42.62% test_error 49.50%\n",
      "================================662===================================\n",
      "662/4000: train_loss: 4.213162578842603 train_error 42.62% test_error 49.50%\n",
      "================================663===================================\n",
      "663/4000: train_loss: 4.212210778789594 train_error 42.62% test_error 49.50%\n",
      "================================664===================================\n",
      "664/4000: train_loss: 4.211257532672025 train_error 42.62% test_error 49.50%\n",
      "================================665===================================\n",
      "665/4000: train_loss: 4.21030239701271 train_error 42.62% test_error 49.50%\n",
      "================================666===================================\n",
      "666/4000: train_loss: 4.209344494603575 train_error 42.62% test_error 49.50%\n",
      "================================667===================================\n",
      "667/4000: train_loss: 4.20838098404929 train_error 42.62% test_error 49.50%\n",
      "================================668===================================\n",
      "668/4000: train_loss: 4.207415945576504 train_error 42.62% test_error 49.50%\n",
      "================================669===================================\n",
      "669/4000: train_loss: 4.206450754818507 train_error 42.62% test_error 49.50%\n",
      "================================670===================================\n",
      "670/4000: train_loss: 4.205483334325255 train_error 42.62% test_error 49.50%\n",
      "================================671===================================\n",
      "671/4000: train_loss: 4.20451536775101 train_error 42.62% test_error 49.50%\n",
      "================================672===================================\n",
      "672/4000: train_loss: 4.2035466289892796 train_error 42.62% test_error 49.50%\n",
      "================================673===================================\n",
      "673/4000: train_loss: 4.202575191259384 train_error 42.62% test_error 49.50%\n",
      "================================674===================================\n",
      "674/4000: train_loss: 4.201602912638336 train_error 42.50% test_error 49.50%\n",
      "================================675===================================\n",
      "675/4000: train_loss: 4.200630912194028 train_error 42.50% test_error 49.50%\n",
      "================================676===================================\n",
      "676/4000: train_loss: 4.199658009973355 train_error 42.50% test_error 49.50%\n",
      "================================677===================================\n",
      "677/4000: train_loss: 4.198683903845959 train_error 42.50% test_error 49.50%\n",
      "================================678===================================\n",
      "678/4000: train_loss: 4.197707228823565 train_error 42.50% test_error 49.50%\n",
      "================================679===================================\n",
      "679/4000: train_loss: 4.196728208586573 train_error 42.50% test_error 49.50%\n",
      "================================680===================================\n",
      "680/4000: train_loss: 4.195747585911303 train_error 42.50% test_error 49.50%\n",
      "================================681===================================\n",
      "681/4000: train_loss: 4.194765456952155 train_error 42.50% test_error 49.50%\n",
      "================================682===================================\n",
      "682/4000: train_loss: 4.193783609117381 train_error 42.38% test_error 49.00%\n",
      "================================683===================================\n",
      "683/4000: train_loss: 4.192799609010107 train_error 42.38% test_error 49.00%\n",
      "================================684===================================\n",
      "684/4000: train_loss: 4.19181246900931 train_error 42.38% test_error 49.00%\n",
      "================================685===================================\n",
      "685/4000: train_loss: 4.190823229718953 train_error 42.38% test_error 49.00%\n",
      "================================686===================================\n",
      "686/4000: train_loss: 4.18983365809545 train_error 42.25% test_error 49.00%\n",
      "================================687===================================\n",
      "687/4000: train_loss: 4.1888443762855605 train_error 42.25% test_error 49.00%\n",
      "================================688===================================\n",
      "688/4000: train_loss: 4.187855601492338 train_error 42.25% test_error 49.00%\n",
      "================================689===================================\n",
      "689/4000: train_loss: 4.186864521559327 train_error 42.25% test_error 49.00%\n",
      "================================690===================================\n",
      "690/4000: train_loss: 4.185872283731587 train_error 42.25% test_error 49.00%\n",
      "================================691===================================\n",
      "691/4000: train_loss: 4.184879069495946 train_error 42.25% test_error 49.00%\n",
      "================================692===================================\n",
      "692/4000: train_loss: 4.183885983289219 train_error 42.25% test_error 49.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================693===================================\n",
      "693/4000: train_loss: 4.182894856673665 train_error 42.25% test_error 49.00%\n",
      "================================694===================================\n",
      "694/4000: train_loss: 4.181903911693953 train_error 42.25% test_error 49.00%\n",
      "================================695===================================\n",
      "695/4000: train_loss: 4.18091202522628 train_error 42.25% test_error 49.00%\n",
      "================================696===================================\n",
      "696/4000: train_loss: 4.179919486618601 train_error 42.25% test_error 49.00%\n",
      "================================697===================================\n",
      "697/4000: train_loss: 4.1789282531524075 train_error 42.12% test_error 49.00%\n",
      "================================698===================================\n",
      "698/4000: train_loss: 4.177936690156348 train_error 42.12% test_error 49.00%\n",
      "================================699===================================\n",
      "699/4000: train_loss: 4.176943685524165 train_error 42.00% test_error 49.00%\n",
      "================================700===================================\n",
      "700/4000: train_loss: 4.175948390332051 train_error 42.00% test_error 49.00%\n",
      "================================701===================================\n",
      "701/4000: train_loss: 4.17495084782131 train_error 42.00% test_error 49.00%\n",
      "================================702===================================\n",
      "702/4000: train_loss: 4.173949665129184 train_error 42.00% test_error 49.00%\n",
      "================================703===================================\n",
      "703/4000: train_loss: 4.172944830437191 train_error 42.00% test_error 49.00%\n",
      "================================704===================================\n",
      "704/4000: train_loss: 4.171939549855888 train_error 42.00% test_error 49.00%\n",
      "================================705===================================\n",
      "705/4000: train_loss: 4.1709332294994965 train_error 42.00% test_error 49.00%\n",
      "================================706===================================\n",
      "706/4000: train_loss: 4.169925453369506 train_error 42.00% test_error 49.00%\n",
      "================================707===================================\n",
      "707/4000: train_loss: 4.168918332965113 train_error 42.00% test_error 49.00%\n",
      "================================708===================================\n",
      "708/4000: train_loss: 4.167912536296062 train_error 41.88% test_error 49.00%\n",
      "================================709===================================\n",
      "709/4000: train_loss: 4.166906408485956 train_error 41.88% test_error 49.00%\n",
      "================================710===================================\n",
      "710/4000: train_loss: 4.165898855426349 train_error 41.88% test_error 49.00%\n",
      "================================711===================================\n",
      "711/4000: train_loss: 4.164890212914907 train_error 41.75% test_error 49.00%\n",
      "================================712===================================\n",
      "712/4000: train_loss: 4.163879973366857 train_error 41.75% test_error 49.00%\n",
      "================================713===================================\n",
      "713/4000: train_loss: 4.16286787813995 train_error 41.75% test_error 49.00%\n",
      "================================714===================================\n",
      "714/4000: train_loss: 4.161853365940042 train_error 41.75% test_error 49.00%\n",
      "================================715===================================\n",
      "715/4000: train_loss: 4.160834024855867 train_error 41.75% test_error 49.00%\n",
      "================================716===================================\n",
      "716/4000: train_loss: 4.159813600154593 train_error 41.75% test_error 49.00%\n",
      "================================717===================================\n",
      "717/4000: train_loss: 4.1587911132071165 train_error 41.75% test_error 49.00%\n",
      "================================718===================================\n",
      "718/4000: train_loss: 4.157766864215954 train_error 41.75% test_error 49.00%\n",
      "================================719===================================\n",
      "719/4000: train_loss: 4.156741625596769 train_error 41.75% test_error 49.00%\n",
      "================================720===================================\n",
      "720/4000: train_loss: 4.155715160807595 train_error 41.75% test_error 49.00%\n",
      "================================721===================================\n",
      "721/4000: train_loss: 4.154687146740034 train_error 41.75% test_error 49.00%\n",
      "================================722===================================\n",
      "722/4000: train_loss: 4.153657063329592 train_error 41.75% test_error 49.00%\n",
      "================================723===================================\n",
      "723/4000: train_loss: 4.152624907549471 train_error 41.75% test_error 49.00%\n",
      "================================724===================================\n",
      "724/4000: train_loss: 4.151591160297394 train_error 41.62% test_error 49.00%\n",
      "================================725===================================\n",
      "725/4000: train_loss: 4.150556162949652 train_error 41.62% test_error 49.00%\n",
      "================================726===================================\n",
      "726/4000: train_loss: 4.149519928772934 train_error 41.62% test_error 49.00%\n",
      "================================727===================================\n",
      "727/4000: train_loss: 4.148482578215189 train_error 41.62% test_error 49.00%\n",
      "================================728===================================\n",
      "728/4000: train_loss: 4.14744425682351 train_error 41.62% test_error 49.00%\n",
      "================================729===================================\n",
      "729/4000: train_loss: 4.146403715969063 train_error 41.62% test_error 49.00%\n",
      "================================730===================================\n",
      "730/4000: train_loss: 4.145361599591561 train_error 41.50% test_error 49.00%\n",
      "================================731===================================\n",
      "731/4000: train_loss: 4.144317942759954 train_error 41.50% test_error 49.00%\n",
      "================================732===================================\n",
      "732/4000: train_loss: 4.143275369699113 train_error 41.50% test_error 49.00%\n",
      "================================733===================================\n",
      "733/4000: train_loss: 4.1422328920476135 train_error 41.50% test_error 49.00%\n",
      "================================734===================================\n",
      "734/4000: train_loss: 4.141188832470216 train_error 41.50% test_error 49.00%\n",
      "================================735===================================\n",
      "735/4000: train_loss: 4.140143402870744 train_error 41.50% test_error 49.00%\n",
      "================================736===================================\n",
      "736/4000: train_loss: 4.139095136872493 train_error 41.50% test_error 49.00%\n",
      "================================737===================================\n",
      "737/4000: train_loss: 4.13804567784071 train_error 41.50% test_error 49.00%\n",
      "================================738===================================\n",
      "738/4000: train_loss: 4.136994872512296 train_error 41.50% test_error 49.00%\n",
      "================================739===================================\n",
      "739/4000: train_loss: 4.135942425997928 train_error 41.50% test_error 49.00%\n",
      "================================740===================================\n",
      "740/4000: train_loss: 4.134888687971979 train_error 41.38% test_error 49.00%\n",
      "================================741===================================\n",
      "741/4000: train_loss: 4.133833137433976 train_error 41.38% test_error 49.00%\n",
      "================================742===================================\n",
      "742/4000: train_loss: 4.132775042536668 train_error 41.38% test_error 49.00%\n",
      "================================743===================================\n",
      "743/4000: train_loss: 4.131713756080717 train_error 41.38% test_error 49.00%\n",
      "================================744===================================\n",
      "744/4000: train_loss: 4.130649336194621 train_error 41.38% test_error 49.00%\n",
      "================================745===================================\n",
      "745/4000: train_loss: 4.1295825719274575 train_error 41.38% test_error 49.00%\n",
      "================================746===================================\n",
      "746/4000: train_loss: 4.1285141121177 train_error 41.38% test_error 49.00%\n",
      "================================747===================================\n",
      "747/4000: train_loss: 4.127444050158374 train_error 41.25% test_error 49.00%\n",
      "================================748===================================\n",
      "748/4000: train_loss: 4.126372690158896 train_error 41.25% test_error 49.00%\n",
      "================================749===================================\n",
      "749/4000: train_loss: 4.125300275548361 train_error 41.25% test_error 49.00%\n",
      "================================750===================================\n",
      "750/4000: train_loss: 4.124226738056168 train_error 41.25% test_error 49.00%\n",
      "================================751===================================\n",
      "751/4000: train_loss: 4.123152026510797 train_error 41.25% test_error 49.00%\n",
      "================================752===================================\n",
      "752/4000: train_loss: 4.122076515583322 train_error 41.25% test_error 49.00%\n",
      "================================753===================================\n",
      "753/4000: train_loss: 4.120999285168946 train_error 41.25% test_error 49.00%\n",
      "================================754===================================\n",
      "754/4000: train_loss: 4.119920045114123 train_error 41.25% test_error 49.00%\n",
      "================================755===================================\n",
      "755/4000: train_loss: 4.118840375053696 train_error 41.25% test_error 49.00%\n",
      "================================756===================================\n",
      "756/4000: train_loss: 4.117761950222775 train_error 41.25% test_error 49.00%\n",
      "================================757===================================\n",
      "757/4000: train_loss: 4.116683110478334 train_error 41.00% test_error 49.00%\n",
      "================================758===================================\n",
      "758/4000: train_loss: 4.1156033696606755 train_error 41.00% test_error 49.00%\n",
      "================================759===================================\n",
      "759/4000: train_loss: 4.114522939664312 train_error 41.00% test_error 49.00%\n",
      "================================760===================================\n",
      "760/4000: train_loss: 4.1134403791092335 train_error 41.00% test_error 49.00%\n",
      "================================761===================================\n",
      "761/4000: train_loss: 4.112352723293006 train_error 40.88% test_error 49.00%\n",
      "================================762===================================\n",
      "762/4000: train_loss: 4.1112636891053995 train_error 40.88% test_error 49.00%\n",
      "================================763===================================\n",
      "763/4000: train_loss: 4.110173646816984 train_error 40.88% test_error 49.00%\n",
      "================================764===================================\n",
      "764/4000: train_loss: 4.109081528210081 train_error 40.88% test_error 49.00%\n",
      "================================765===================================\n",
      "765/4000: train_loss: 4.107982939789071 train_error 40.88% test_error 49.00%\n",
      "================================766===================================\n",
      "766/4000: train_loss: 4.106882254751399 train_error 40.88% test_error 48.50%\n",
      "================================767===================================\n",
      "767/4000: train_loss: 4.105781347323209 train_error 40.88% test_error 48.50%\n",
      "================================768===================================\n",
      "768/4000: train_loss: 4.1046804114244875 train_error 40.75% test_error 48.50%\n",
      "================================769===================================\n",
      "769/4000: train_loss: 4.103578428467736 train_error 40.62% test_error 48.50%\n",
      "================================770===================================\n",
      "770/4000: train_loss: 4.102476059286856 train_error 40.62% test_error 48.50%\n",
      "================================771===================================\n",
      "771/4000: train_loss: 4.101372434152291 train_error 40.62% test_error 48.50%\n",
      "================================772===================================\n",
      "772/4000: train_loss: 4.1002708239387715 train_error 40.62% test_error 48.00%\n",
      "================================773===================================\n",
      "773/4000: train_loss: 4.099167893496342 train_error 40.62% test_error 48.00%\n",
      "================================774===================================\n",
      "774/4000: train_loss: 4.098062215759419 train_error 40.62% test_error 48.00%\n",
      "================================775===================================\n",
      "775/4000: train_loss: 4.096955355252139 train_error 40.62% test_error 47.50%\n",
      "================================776===================================\n",
      "776/4000: train_loss: 4.095847192723304 train_error 40.62% test_error 47.50%\n",
      "================================777===================================\n",
      "777/4000: train_loss: 4.094737691655755 train_error 40.62% test_error 47.00%\n",
      "================================778===================================\n",
      "778/4000: train_loss: 4.093626954806968 train_error 40.62% test_error 47.00%\n",
      "================================779===================================\n",
      "779/4000: train_loss: 4.092514555137605 train_error 40.62% test_error 47.00%\n",
      "================================780===================================\n",
      "780/4000: train_loss: 4.091400936562568 train_error 40.50% test_error 47.00%\n",
      "================================781===================================\n",
      "781/4000: train_loss: 4.090285808318295 train_error 40.50% test_error 47.00%\n",
      "================================782===================================\n",
      "782/4000: train_loss: 4.089170238645748 train_error 40.50% test_error 47.00%\n",
      "================================783===================================\n",
      "783/4000: train_loss: 4.088053534324281 train_error 40.50% test_error 47.00%\n",
      "================================784===================================\n",
      "784/4000: train_loss: 4.08693504571449 train_error 40.50% test_error 47.00%\n",
      "================================785===================================\n",
      "785/4000: train_loss: 4.08581499774009 train_error 40.50% test_error 47.00%\n",
      "================================786===================================\n",
      "786/4000: train_loss: 4.084693991364912 train_error 40.50% test_error 47.00%\n",
      "================================787===================================\n",
      "787/4000: train_loss: 4.083571496028453 train_error 40.50% test_error 47.00%\n",
      "================================788===================================\n",
      "788/4000: train_loss: 4.0824472386948765 train_error 40.50% test_error 47.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================789===================================\n",
      "789/4000: train_loss: 4.081321773035452 train_error 40.50% test_error 47.00%\n",
      "================================790===================================\n",
      "790/4000: train_loss: 4.080194766269996 train_error 40.50% test_error 47.00%\n",
      "================================791===================================\n",
      "791/4000: train_loss: 4.079066441990435 train_error 40.50% test_error 47.00%\n",
      "================================792===================================\n",
      "792/4000: train_loss: 4.07793823983986 train_error 40.50% test_error 47.00%\n",
      "================================793===================================\n",
      "793/4000: train_loss: 4.07680789580103 train_error 40.50% test_error 47.00%\n",
      "================================794===================================\n",
      "794/4000: train_loss: 4.075673860055394 train_error 40.50% test_error 47.00%\n",
      "================================795===================================\n",
      "795/4000: train_loss: 4.074538634680211 train_error 40.50% test_error 47.00%\n",
      "================================796===================================\n",
      "796/4000: train_loss: 4.073402137709782 train_error 40.50% test_error 47.00%\n",
      "================================797===================================\n",
      "797/4000: train_loss: 4.072264465219341 train_error 40.50% test_error 47.00%\n",
      "================================798===================================\n",
      "798/4000: train_loss: 4.071125035476871 train_error 40.38% test_error 47.00%\n",
      "================================799===================================\n",
      "799/4000: train_loss: 4.069981389394961 train_error 40.38% test_error 47.00%\n",
      "================================800===================================\n",
      "800/4000: train_loss: 4.068835147526116 train_error 40.38% test_error 47.00%\n",
      "================================801===================================\n",
      "801/4000: train_loss: 4.067687139366754 train_error 40.25% test_error 47.00%\n",
      "================================802===================================\n",
      "802/4000: train_loss: 4.06653754320927 train_error 40.12% test_error 47.00%\n",
      "================================803===================================\n",
      "803/4000: train_loss: 4.065385895888321 train_error 40.00% test_error 47.00%\n",
      "================================804===================================\n",
      "804/4000: train_loss: 4.064232877646573 train_error 40.00% test_error 47.00%\n",
      "================================805===================================\n",
      "805/4000: train_loss: 4.063078663689084 train_error 39.88% test_error 47.00%\n",
      "================================806===================================\n",
      "806/4000: train_loss: 4.061922129597515 train_error 39.88% test_error 47.00%\n",
      "================================807===================================\n",
      "807/4000: train_loss: 4.060762994289399 train_error 39.75% test_error 47.00%\n",
      "================================808===================================\n",
      "808/4000: train_loss: 4.059603368602693 train_error 39.62% test_error 47.00%\n",
      "================================809===================================\n",
      "809/4000: train_loss: 4.058444987786934 train_error 39.62% test_error 47.00%\n",
      "================================810===================================\n",
      "810/4000: train_loss: 4.057285983557813 train_error 39.62% test_error 47.00%\n",
      "================================811===================================\n",
      "811/4000: train_loss: 4.056125761237927 train_error 39.62% test_error 47.00%\n",
      "================================812===================================\n",
      "812/4000: train_loss: 4.054964129431173 train_error 39.50% test_error 47.00%\n",
      "================================813===================================\n",
      "813/4000: train_loss: 4.05380102136638 train_error 39.50% test_error 47.00%\n",
      "================================814===================================\n",
      "814/4000: train_loss: 4.052635898403824 train_error 39.50% test_error 47.00%\n",
      "================================815===================================\n",
      "815/4000: train_loss: 4.0514703050395475 train_error 39.50% test_error 47.00%\n",
      "================================816===================================\n",
      "816/4000: train_loss: 4.050304149747826 train_error 39.38% test_error 47.00%\n",
      "================================817===================================\n",
      "817/4000: train_loss: 4.049140225755981 train_error 39.38% test_error 47.00%\n",
      "================================818===================================\n",
      "818/4000: train_loss: 4.047977621373721 train_error 39.38% test_error 46.50%\n",
      "================================819===================================\n",
      "819/4000: train_loss: 4.046813796730712 train_error 39.38% test_error 46.50%\n",
      "================================820===================================\n",
      "820/4000: train_loss: 4.045649670497514 train_error 39.25% test_error 46.50%\n",
      "================================821===================================\n",
      "821/4000: train_loss: 4.044483266696334 train_error 39.25% test_error 46.50%\n",
      "================================822===================================\n",
      "822/4000: train_loss: 4.04331432803534 train_error 39.25% test_error 46.50%\n",
      "================================823===================================\n",
      "823/4000: train_loss: 4.042143893623725 train_error 39.25% test_error 46.50%\n",
      "================================824===================================\n",
      "824/4000: train_loss: 4.040972108636051 train_error 39.25% test_error 46.50%\n",
      "================================825===================================\n",
      "825/4000: train_loss: 4.0397999444883315 train_error 39.25% test_error 46.50%\n",
      "================================826===================================\n",
      "826/4000: train_loss: 4.038626807718538 train_error 39.25% test_error 46.50%\n",
      "================================827===================================\n",
      "827/4000: train_loss: 4.037452543410472 train_error 39.25% test_error 46.50%\n",
      "================================828===================================\n",
      "828/4000: train_loss: 4.036277516284026 train_error 39.25% test_error 46.50%\n",
      "================================829===================================\n",
      "829/4000: train_loss: 4.03510080951266 train_error 39.25% test_error 46.50%\n",
      "================================830===================================\n",
      "830/4000: train_loss: 4.033922523781657 train_error 39.25% test_error 46.50%\n",
      "================================831===================================\n",
      "831/4000: train_loss: 4.03274419833906 train_error 39.25% test_error 46.50%\n",
      "================================832===================================\n",
      "832/4000: train_loss: 4.03156438596081 train_error 39.25% test_error 46.50%\n",
      "================================833===================================\n",
      "833/4000: train_loss: 4.03038309331052 train_error 39.25% test_error 46.50%\n",
      "================================834===================================\n",
      "834/4000: train_loss: 4.029201136198826 train_error 39.25% test_error 46.50%\n",
      "================================835===================================\n",
      "835/4000: train_loss: 4.028019685545004 train_error 39.25% test_error 46.50%\n",
      "================================836===================================\n",
      "836/4000: train_loss: 4.026837121108547 train_error 39.25% test_error 46.50%\n",
      "================================837===================================\n",
      "837/4000: train_loss: 4.025653518326581 train_error 39.25% test_error 46.50%\n",
      "================================838===================================\n",
      "838/4000: train_loss: 4.024468700238503 train_error 39.25% test_error 46.50%\n",
      "================================839===================================\n",
      "839/4000: train_loss: 4.023282622704283 train_error 39.25% test_error 46.50%\n",
      "================================840===================================\n",
      "840/4000: train_loss: 4.0220958117442205 train_error 39.25% test_error 46.00%\n",
      "================================841===================================\n",
      "841/4000: train_loss: 4.020907071880065 train_error 39.25% test_error 46.00%\n",
      "================================842===================================\n",
      "842/4000: train_loss: 4.019717968301848 train_error 39.25% test_error 46.00%\n",
      "================================843===================================\n",
      "843/4000: train_loss: 4.018527380800807 train_error 39.12% test_error 46.00%\n",
      "================================844===================================\n",
      "844/4000: train_loss: 4.017335384846665 train_error 39.12% test_error 46.00%\n",
      "================================845===================================\n",
      "845/4000: train_loss: 4.016141619486734 train_error 39.00% test_error 46.00%\n",
      "================================846===================================\n",
      "846/4000: train_loss: 4.014946362045594 train_error 38.88% test_error 46.00%\n",
      "================================847===================================\n",
      "847/4000: train_loss: 4.013749651820399 train_error 38.88% test_error 46.00%\n",
      "================================848===================================\n",
      "848/4000: train_loss: 4.0125514028966425 train_error 38.88% test_error 46.00%\n",
      "================================849===================================\n",
      "849/4000: train_loss: 4.0113499091425915 train_error 38.75% test_error 46.00%\n",
      "================================850===================================\n",
      "850/4000: train_loss: 4.0101472931401805 train_error 38.75% test_error 46.00%\n",
      "================================851===================================\n",
      "851/4000: train_loss: 4.0089455646974965 train_error 38.62% test_error 46.00%\n",
      "================================852===================================\n",
      "852/4000: train_loss: 4.0077445829659695 train_error 38.62% test_error 46.50%\n",
      "================================853===================================\n",
      "853/4000: train_loss: 4.006541448412463 train_error 38.50% test_error 46.50%\n",
      "================================854===================================\n",
      "854/4000: train_loss: 4.00533647309523 train_error 38.50% test_error 46.50%\n",
      "================================855===================================\n",
      "855/4000: train_loss: 4.004130142759532 train_error 38.38% test_error 46.50%\n",
      "================================856===================================\n",
      "856/4000: train_loss: 4.0029239402432 train_error 38.38% test_error 46.50%\n",
      "================================857===================================\n",
      "857/4000: train_loss: 4.0017161518288775 train_error 38.38% test_error 46.50%\n",
      "================================858===================================\n",
      "858/4000: train_loss: 4.000505824876017 train_error 38.38% test_error 46.50%\n",
      "================================859===================================\n",
      "859/4000: train_loss: 3.999294116254896 train_error 38.38% test_error 46.50%\n",
      "================================860===================================\n",
      "860/4000: train_loss: 3.9980811209045353 train_error 38.38% test_error 46.50%\n",
      "================================861===================================\n",
      "861/4000: train_loss: 3.9968691233452414 train_error 38.38% test_error 46.50%\n",
      "================================862===================================\n",
      "862/4000: train_loss: 3.995655607832596 train_error 38.25% test_error 46.50%\n",
      "================================863===================================\n",
      "863/4000: train_loss: 3.9944404947478325 train_error 38.25% test_error 46.50%\n",
      "================================864===================================\n",
      "864/4000: train_loss: 3.9932225300651045 train_error 38.25% test_error 46.50%\n",
      "================================865===================================\n",
      "865/4000: train_loss: 3.992001323858276 train_error 38.25% test_error 46.50%\n",
      "================================866===================================\n",
      "866/4000: train_loss: 3.9907790204323828 train_error 38.25% test_error 46.50%\n",
      "================================867===================================\n",
      "867/4000: train_loss: 3.9895582482963805 train_error 38.25% test_error 46.50%\n",
      "================================868===================================\n",
      "868/4000: train_loss: 3.98833613160532 train_error 38.25% test_error 46.50%\n",
      "================================869===================================\n",
      "869/4000: train_loss: 3.987112399041653 train_error 38.25% test_error 46.50%\n",
      "================================870===================================\n",
      "870/4000: train_loss: 3.9858871599100527 train_error 38.25% test_error 46.50%\n",
      "================================871===================================\n",
      "871/4000: train_loss: 3.9846604454470795 train_error 38.12% test_error 46.50%\n",
      "================================872===================================\n",
      "872/4000: train_loss: 3.9834318355191503 train_error 38.12% test_error 46.50%\n",
      "================================873===================================\n",
      "873/4000: train_loss: 3.982201157757082 train_error 38.12% test_error 46.50%\n",
      "================================874===================================\n",
      "874/4000: train_loss: 3.980969046787359 train_error 38.12% test_error 46.50%\n",
      "================================875===================================\n",
      "875/4000: train_loss: 3.9797358963359146 train_error 38.12% test_error 46.50%\n",
      "================================876===================================\n",
      "876/4000: train_loss: 3.9785022707190367 train_error 38.12% test_error 46.50%\n",
      "================================877===================================\n",
      "877/4000: train_loss: 3.9772674768464635 train_error 38.12% test_error 46.50%\n",
      "================================878===================================\n",
      "878/4000: train_loss: 3.9760313627868893 train_error 38.12% test_error 46.50%\n",
      "================================879===================================\n",
      "879/4000: train_loss: 3.9747934955591337 train_error 38.12% test_error 46.50%\n",
      "================================880===================================\n",
      "880/4000: train_loss: 3.9735533363418654 train_error 38.00% test_error 46.50%\n",
      "================================881===================================\n",
      "881/4000: train_loss: 3.972311870842241 train_error 38.00% test_error 46.50%\n",
      "================================882===================================\n",
      "882/4000: train_loss: 3.971069100168534 train_error 38.00% test_error 46.50%\n",
      "================================883===================================\n",
      "883/4000: train_loss: 3.969824826125987 train_error 38.00% test_error 46.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================884===================================\n",
      "884/4000: train_loss: 3.9685811256710437 train_error 38.00% test_error 46.50%\n",
      "================================885===================================\n",
      "885/4000: train_loss: 3.9673375735245644 train_error 38.00% test_error 46.50%\n",
      "================================886===================================\n",
      "886/4000: train_loss: 3.966092687775381 train_error 38.00% test_error 46.50%\n",
      "================================887===================================\n",
      "887/4000: train_loss: 3.964844684880227 train_error 38.00% test_error 46.50%\n",
      "================================888===================================\n",
      "888/4000: train_loss: 3.963593730940483 train_error 37.88% test_error 46.50%\n",
      "================================889===================================\n",
      "889/4000: train_loss: 3.9623397526144983 train_error 37.88% test_error 46.50%\n",
      "================================890===================================\n",
      "890/4000: train_loss: 3.961085395193659 train_error 37.88% test_error 46.50%\n",
      "================================891===================================\n",
      "891/4000: train_loss: 3.9598307170625775 train_error 37.88% test_error 46.50%\n",
      "================================892===================================\n",
      "892/4000: train_loss: 3.958575026364997 train_error 37.88% test_error 46.50%\n",
      "================================893===================================\n",
      "893/4000: train_loss: 3.9573197764670476 train_error 37.88% test_error 46.50%\n",
      "================================894===================================\n",
      "894/4000: train_loss: 3.956063947840594 train_error 37.88% test_error 46.50%\n",
      "================================895===================================\n",
      "895/4000: train_loss: 3.9548070499673487 train_error 37.88% test_error 46.50%\n",
      "================================896===================================\n",
      "896/4000: train_loss: 3.95354916067794 train_error 37.88% test_error 46.50%\n",
      "================================897===================================\n",
      "897/4000: train_loss: 3.9522888970421626 train_error 37.88% test_error 46.50%\n",
      "================================898===================================\n",
      "898/4000: train_loss: 3.95102764215786 train_error 37.88% test_error 46.50%\n",
      "================================899===================================\n",
      "899/4000: train_loss: 3.949765165233985 train_error 37.75% test_error 46.50%\n",
      "================================900===================================\n",
      "900/4000: train_loss: 3.94850166275166 train_error 37.62% test_error 46.50%\n",
      "================================901===================================\n",
      "901/4000: train_loss: 3.9472365364339206 train_error 37.62% test_error 46.50%\n",
      "================================902===================================\n",
      "902/4000: train_loss: 3.9459706295980137 train_error 37.38% test_error 46.50%\n",
      "================================903===================================\n",
      "903/4000: train_loss: 3.944703500661999 train_error 37.38% test_error 45.50%\n",
      "================================904===================================\n",
      "904/4000: train_loss: 3.9434351590042938 train_error 37.38% test_error 45.50%\n",
      "================================905===================================\n",
      "905/4000: train_loss: 3.942166287917644 train_error 37.38% test_error 45.50%\n",
      "================================906===================================\n",
      "906/4000: train_loss: 3.9408972461335363 train_error 37.38% test_error 45.50%\n",
      "================================907===================================\n",
      "907/4000: train_loss: 3.9396289633167907 train_error 37.38% test_error 45.50%\n",
      "================================908===================================\n",
      "908/4000: train_loss: 3.938361307466403 train_error 37.38% test_error 45.50%\n",
      "================================909===================================\n",
      "909/4000: train_loss: 3.9370931845903394 train_error 37.38% test_error 45.50%\n",
      "================================910===================================\n",
      "910/4000: train_loss: 3.9358235489344224 train_error 37.38% test_error 45.50%\n",
      "================================911===================================\n",
      "911/4000: train_loss: 3.9345526491431517 train_error 37.38% test_error 45.50%\n",
      "================================912===================================\n",
      "912/4000: train_loss: 3.9332805069442838 train_error 37.25% test_error 45.50%\n",
      "================================913===================================\n",
      "913/4000: train_loss: 3.9320075766183438 train_error 37.25% test_error 45.50%\n",
      "================================914===================================\n",
      "914/4000: train_loss: 3.93073427317664 train_error 37.12% test_error 45.50%\n",
      "================================915===================================\n",
      "915/4000: train_loss: 3.92945993184112 train_error 37.12% test_error 45.50%\n",
      "================================916===================================\n",
      "916/4000: train_loss: 3.9281845173891634 train_error 37.12% test_error 45.50%\n",
      "================================917===================================\n",
      "917/4000: train_loss: 3.9269075691327453 train_error 37.12% test_error 45.50%\n",
      "================================918===================================\n",
      "918/4000: train_loss: 3.925630210745148 train_error 37.12% test_error 45.50%\n",
      "================================919===================================\n",
      "919/4000: train_loss: 3.9243544757319615 train_error 37.25% test_error 45.50%\n",
      "================================920===================================\n",
      "920/4000: train_loss: 3.9230789089016613 train_error 37.25% test_error 45.00%\n",
      "================================921===================================\n",
      "921/4000: train_loss: 3.921803831933066 train_error 37.25% test_error 45.00%\n",
      "================================922===================================\n",
      "922/4000: train_loss: 3.9205272965552282 train_error 37.25% test_error 44.50%\n",
      "================================923===================================\n",
      "923/4000: train_loss: 3.9192521046055484 train_error 37.12% test_error 44.50%\n",
      "================================924===================================\n",
      "924/4000: train_loss: 3.9179767710296436 train_error 37.12% test_error 44.50%\n",
      "================================925===================================\n",
      "925/4000: train_loss: 3.916701552402228 train_error 37.12% test_error 44.50%\n",
      "================================926===================================\n",
      "926/4000: train_loss: 3.915425862977281 train_error 37.12% test_error 44.50%\n",
      "================================927===================================\n",
      "927/4000: train_loss: 3.9141498373728245 train_error 37.00% test_error 44.00%\n",
      "================================928===================================\n",
      "928/4000: train_loss: 3.91287466599606 train_error 37.00% test_error 44.00%\n",
      "================================929===================================\n",
      "929/4000: train_loss: 3.911596675189212 train_error 37.00% test_error 44.00%\n",
      "================================930===================================\n",
      "930/4000: train_loss: 3.910317535814829 train_error 37.00% test_error 44.00%\n",
      "================================931===================================\n",
      "931/4000: train_loss: 3.9090377356484534 train_error 37.00% test_error 44.00%\n",
      "================================932===================================\n",
      "932/4000: train_loss: 3.907756175994873 train_error 37.00% test_error 44.00%\n",
      "================================933===================================\n",
      "933/4000: train_loss: 3.9064734764443707 train_error 37.00% test_error 43.50%\n",
      "================================934===================================\n",
      "934/4000: train_loss: 3.905189745002426 train_error 37.00% test_error 43.50%\n",
      "================================935===================================\n",
      "935/4000: train_loss: 3.903905136282556 train_error 37.00% test_error 43.50%\n",
      "================================936===================================\n",
      "936/4000: train_loss: 3.9026190477330234 train_error 37.00% test_error 43.50%\n",
      "================================937===================================\n",
      "937/4000: train_loss: 3.9013313298672436 train_error 37.00% test_error 43.50%\n",
      "================================938===================================\n",
      "938/4000: train_loss: 3.900041267960332 train_error 37.00% test_error 43.50%\n",
      "================================939===================================\n",
      "939/4000: train_loss: 3.898749990700744 train_error 37.00% test_error 43.50%\n",
      "================================940===================================\n",
      "940/4000: train_loss: 3.897458825036883 train_error 37.00% test_error 43.50%\n",
      "================================941===================================\n",
      "941/4000: train_loss: 3.8961665208684284 train_error 37.00% test_error 43.50%\n",
      "================================942===================================\n",
      "942/4000: train_loss: 3.8948715185606853 train_error 37.00% test_error 43.50%\n",
      "================================943===================================\n",
      "943/4000: train_loss: 3.8935749151138586 train_error 37.00% test_error 43.50%\n",
      "================================944===================================\n",
      "944/4000: train_loss: 3.892276874701493 train_error 37.00% test_error 43.50%\n",
      "================================945===================================\n",
      "945/4000: train_loss: 3.890976666356437 train_error 37.00% test_error 43.50%\n",
      "================================946===================================\n",
      "946/4000: train_loss: 3.889674908169545 train_error 37.00% test_error 43.50%\n",
      "================================947===================================\n",
      "947/4000: train_loss: 3.8883714838465675 train_error 37.00% test_error 43.50%\n",
      "================================948===================================\n",
      "948/4000: train_loss: 3.887067532106302 train_error 37.00% test_error 43.50%\n",
      "================================949===================================\n",
      "949/4000: train_loss: 3.8857629914535208 train_error 37.00% test_error 43.50%\n",
      "================================950===================================\n",
      "950/4000: train_loss: 3.8844584679743277 train_error 36.88% test_error 43.50%\n",
      "================================951===================================\n",
      "951/4000: train_loss: 3.8831537416996436 train_error 36.88% test_error 43.50%\n",
      "================================952===================================\n",
      "952/4000: train_loss: 3.8818467747513203 train_error 36.88% test_error 43.50%\n",
      "================================953===================================\n",
      "953/4000: train_loss: 3.880540753658861 train_error 36.88% test_error 43.50%\n",
      "================================954===================================\n",
      "954/4000: train_loss: 3.879233796126209 train_error 36.88% test_error 43.50%\n",
      "================================955===================================\n",
      "955/4000: train_loss: 3.877925655450672 train_error 36.88% test_error 43.50%\n",
      "================================956===================================\n",
      "956/4000: train_loss: 3.8766165365185588 train_error 36.75% test_error 43.50%\n",
      "================================957===================================\n",
      "957/4000: train_loss: 3.875306489891373 train_error 36.75% test_error 43.50%\n",
      "================================958===================================\n",
      "958/4000: train_loss: 3.873996138442308 train_error 36.75% test_error 43.50%\n",
      "================================959===================================\n",
      "959/4000: train_loss: 3.872686748551205 train_error 36.75% test_error 43.50%\n",
      "================================960===================================\n",
      "960/4000: train_loss: 3.8713769607618453 train_error 36.75% test_error 43.50%\n",
      "================================961===================================\n",
      "961/4000: train_loss: 3.8700666529266163 train_error 36.75% test_error 43.50%\n",
      "================================962===================================\n",
      "962/4000: train_loss: 3.8687555761402472 train_error 36.75% test_error 43.50%\n",
      "================================963===================================\n",
      "963/4000: train_loss: 3.8674431578814983 train_error 36.75% test_error 43.50%\n",
      "================================964===================================\n",
      "964/4000: train_loss: 3.8661304793227464 train_error 36.75% test_error 43.50%\n",
      "================================965===================================\n",
      "965/4000: train_loss: 3.8648175255721435 train_error 36.75% test_error 43.00%\n",
      "================================966===================================\n",
      "966/4000: train_loss: 3.863504143017344 train_error 36.75% test_error 43.00%\n",
      "================================967===================================\n",
      "967/4000: train_loss: 3.8621908007236194 train_error 36.75% test_error 43.00%\n",
      "================================968===================================\n",
      "968/4000: train_loss: 3.8608766957186162 train_error 36.75% test_error 43.00%\n",
      "================================969===================================\n",
      "969/4000: train_loss: 3.859562242417596 train_error 36.75% test_error 43.00%\n",
      "================================970===================================\n",
      "970/4000: train_loss: 3.8582470751507207 train_error 36.75% test_error 43.00%\n",
      "================================971===================================\n",
      "971/4000: train_loss: 3.856931479703635 train_error 36.75% test_error 43.00%\n",
      "================================972===================================\n",
      "972/4000: train_loss: 3.855616204435937 train_error 36.75% test_error 43.00%\n",
      "================================973===================================\n",
      "973/4000: train_loss: 3.854301028535702 train_error 36.75% test_error 43.00%\n",
      "================================974===================================\n",
      "974/4000: train_loss: 3.85298430536408 train_error 36.75% test_error 43.00%\n",
      "================================975===================================\n",
      "975/4000: train_loss: 3.8516665700962767 train_error 36.62% test_error 43.00%\n",
      "================================976===================================\n",
      "976/4000: train_loss: 3.850348950354382 train_error 36.62% test_error 43.00%\n",
      "================================977===================================\n",
      "977/4000: train_loss: 3.849031045795418 train_error 36.62% test_error 43.00%\n",
      "================================978===================================\n",
      "978/4000: train_loss: 3.847712087123655 train_error 36.62% test_error 43.00%\n",
      "================================979===================================\n",
      "979/4000: train_loss: 3.8463917231140656 train_error 36.62% test_error 43.00%\n",
      "================================980===================================\n",
      "980/4000: train_loss: 3.845071785738692 train_error 36.62% test_error 43.00%\n",
      "================================981===================================\n",
      "981/4000: train_loss: 3.8437526882067323 train_error 36.62% test_error 43.00%\n",
      "================================982===================================\n",
      "982/4000: train_loss: 3.8424318301398306 train_error 36.62% test_error 43.00%\n",
      "================================983===================================\n",
      "983/4000: train_loss: 3.8411098896851765 train_error 36.62% test_error 43.00%\n",
      "================================984===================================\n",
      "984/4000: train_loss: 3.8397868351638316 train_error 36.62% test_error 43.00%\n",
      "================================985===================================\n",
      "985/4000: train_loss: 3.838464830755256 train_error 36.50% test_error 43.00%\n",
      "================================986===================================\n",
      "986/4000: train_loss: 3.8371409533498806 train_error 36.50% test_error 43.00%\n",
      "================================987===================================\n",
      "987/4000: train_loss: 3.8358154521510004 train_error 36.38% test_error 43.00%\n",
      "================================988===================================\n",
      "988/4000: train_loss: 3.8344894963130356 train_error 36.38% test_error 43.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================989===================================\n",
      "989/4000: train_loss: 3.8331634473614393 train_error 36.25% test_error 43.00%\n",
      "================================990===================================\n",
      "990/4000: train_loss: 3.831837032092735 train_error 36.25% test_error 43.00%\n",
      "================================991===================================\n",
      "991/4000: train_loss: 3.8305105018196626 train_error 36.25% test_error 43.00%\n",
      "================================992===================================\n",
      "992/4000: train_loss: 3.829183224271983 train_error 36.25% test_error 43.00%\n",
      "================================993===================================\n",
      "993/4000: train_loss: 3.8278545078402386 train_error 36.25% test_error 43.00%\n",
      "================================994===================================\n",
      "994/4000: train_loss: 3.826525300070643 train_error 36.50% test_error 43.00%\n",
      "================================995===================================\n",
      "995/4000: train_loss: 3.8251966167474167 train_error 36.50% test_error 43.00%\n",
      "================================996===================================\n",
      "996/4000: train_loss: 3.823868103311397 train_error 36.50% test_error 43.00%\n",
      "================================997===================================\n",
      "997/4000: train_loss: 3.822539584520273 train_error 36.50% test_error 43.00%\n",
      "================================998===================================\n",
      "998/4000: train_loss: 3.8212104822415855 train_error 36.50% test_error 43.00%\n",
      "================================999===================================\n",
      "999/4000: train_loss: 3.8198811292089525 train_error 36.50% test_error 43.00%\n",
      "================================1000===================================\n",
      "1000/4000: train_loss: 3.818551698271185 train_error 36.50% test_error 43.00%\n",
      "================================1001===================================\n",
      "1001/4000: train_loss: 3.817221675994806 train_error 36.38% test_error 43.00%\n",
      "================================1002===================================\n",
      "1002/4000: train_loss: 3.8158896953565997 train_error 36.38% test_error 43.00%\n",
      "================================1003===================================\n",
      "1003/4000: train_loss: 3.8145568724069747 train_error 36.38% test_error 43.00%\n",
      "================================1004===================================\n",
      "1004/4000: train_loss: 3.813223193315789 train_error 36.38% test_error 43.00%\n",
      "================================1005===================================\n",
      "1005/4000: train_loss: 3.811888849963434 train_error 36.38% test_error 43.00%\n",
      "================================1006===================================\n",
      "1006/4000: train_loss: 3.8105541222728787 train_error 36.38% test_error 43.00%\n",
      "================================1007===================================\n",
      "1007/4000: train_loss: 3.809218883719295 train_error 36.38% test_error 43.00%\n",
      "================================1008===================================\n",
      "1008/4000: train_loss: 3.80788296317216 train_error 36.38% test_error 43.00%\n",
      "================================1009===================================\n",
      "1009/4000: train_loss: 3.8065459959954024 train_error 36.38% test_error 43.00%\n",
      "================================1010===================================\n",
      "1010/4000: train_loss: 3.805208109584637 train_error 36.38% test_error 43.00%\n",
      "================================1011===================================\n",
      "1011/4000: train_loss: 3.803869320363738 train_error 36.38% test_error 43.00%\n",
      "================================1012===================================\n",
      "1012/4000: train_loss: 3.8025297231180595 train_error 36.38% test_error 43.00%\n",
      "================================1013===================================\n",
      "1013/4000: train_loss: 3.8011896206019444 train_error 36.38% test_error 43.00%\n",
      "================================1014===================================\n",
      "1014/4000: train_loss: 3.799848526380956 train_error 36.38% test_error 43.00%\n",
      "================================1015===================================\n",
      "1015/4000: train_loss: 3.7985058901226147 train_error 36.38% test_error 43.00%\n",
      "================================1016===================================\n",
      "1016/4000: train_loss: 3.7971623694757 train_error 36.38% test_error 43.00%\n",
      "================================1017===================================\n",
      "1017/4000: train_loss: 3.7958186117280275 train_error 36.38% test_error 43.00%\n",
      "================================1018===================================\n",
      "1018/4000: train_loss: 3.794474343219772 train_error 36.50% test_error 43.00%\n",
      "================================1019===================================\n",
      "1019/4000: train_loss: 3.793129120138474 train_error 36.50% test_error 43.00%\n",
      "================================1020===================================\n",
      "1020/4000: train_loss: 3.7917835397366435 train_error 36.50% test_error 42.50%\n",
      "================================1021===================================\n",
      "1021/4000: train_loss: 3.79043775100261 train_error 36.38% test_error 42.50%\n",
      "================================1022===================================\n",
      "1022/4000: train_loss: 3.7890917892660942 train_error 36.38% test_error 42.50%\n",
      "================================1023===================================\n",
      "1023/4000: train_loss: 3.787743310132064 train_error 36.38% test_error 42.50%\n",
      "================================1024===================================\n",
      "1024/4000: train_loss: 3.7863944392325357 train_error 36.25% test_error 42.50%\n",
      "================================1025===================================\n",
      "1025/4000: train_loss: 3.7850454386556525 train_error 36.25% test_error 42.50%\n",
      "================================1026===================================\n",
      "1026/4000: train_loss: 3.7836961624445395 train_error 36.25% test_error 42.50%\n",
      "================================1027===================================\n",
      "1027/4000: train_loss: 3.7823469091206787 train_error 36.25% test_error 42.50%\n",
      "================================1028===================================\n",
      "1028/4000: train_loss: 3.7809978724643587 train_error 36.25% test_error 42.50%\n",
      "================================1029===================================\n",
      "1029/4000: train_loss: 3.7796474313596264 train_error 36.25% test_error 42.50%\n",
      "================================1030===================================\n",
      "1030/4000: train_loss: 3.778296712092124 train_error 36.25% test_error 42.50%\n",
      "================================1031===================================\n",
      "1031/4000: train_loss: 3.7769464606884866 train_error 36.25% test_error 42.50%\n",
      "================================1032===================================\n",
      "1032/4000: train_loss: 3.7755963477632033 train_error 36.12% test_error 42.50%\n",
      "================================1033===================================\n",
      "1033/4000: train_loss: 3.7742456808593126 train_error 36.12% test_error 42.50%\n",
      "================================1034===================================\n",
      "1034/4000: train_loss: 3.772895615408197 train_error 36.00% test_error 42.50%\n",
      "================================1035===================================\n",
      "1035/4000: train_loss: 3.771547333239578 train_error 36.00% test_error 42.50%\n",
      "================================1036===================================\n",
      "1036/4000: train_loss: 3.7701993408007546 train_error 36.00% test_error 42.50%\n",
      "================================1037===================================\n",
      "1037/4000: train_loss: 3.768849992523901 train_error 36.00% test_error 42.00%\n",
      "================================1038===================================\n",
      "1038/4000: train_loss: 3.767499843952246 train_error 36.00% test_error 42.00%\n",
      "================================1039===================================\n",
      "1039/4000: train_loss: 3.7661490382114424 train_error 36.00% test_error 42.00%\n",
      "================================1040===================================\n",
      "1040/4000: train_loss: 3.764798149089329 train_error 36.00% test_error 42.00%\n",
      "================================1041===================================\n",
      "1041/4000: train_loss: 3.76344593974296 train_error 36.00% test_error 42.00%\n",
      "================================1042===================================\n",
      "1042/4000: train_loss: 3.7620917075593026 train_error 36.00% test_error 42.00%\n",
      "================================1043===================================\n",
      "1043/4000: train_loss: 3.7607382928021256 train_error 35.88% test_error 42.00%\n",
      "================================1044===================================\n",
      "1044/4000: train_loss: 3.75938628077507 train_error 35.88% test_error 42.00%\n",
      "================================1045===================================\n",
      "1045/4000: train_loss: 3.758035325035453 train_error 35.88% test_error 42.00%\n",
      "================================1046===================================\n",
      "1046/4000: train_loss: 3.7566854646475982 train_error 35.88% test_error 42.00%\n",
      "================================1047===================================\n",
      "1047/4000: train_loss: 3.7553347608633345 train_error 35.88% test_error 42.00%\n",
      "================================1048===================================\n",
      "1048/4000: train_loss: 3.7539817283069716 train_error 35.88% test_error 42.00%\n",
      "================================1049===================================\n",
      "1049/4000: train_loss: 3.752626851098612 train_error 35.75% test_error 42.00%\n",
      "================================1050===================================\n",
      "1050/4000: train_loss: 3.7512720048241315 train_error 35.75% test_error 42.00%\n",
      "================================1051===================================\n",
      "1051/4000: train_loss: 3.7499168888665735 train_error 35.75% test_error 42.00%\n",
      "================================1052===================================\n",
      "1052/4000: train_loss: 3.748560780431144 train_error 35.62% test_error 42.00%\n",
      "================================1053===================================\n",
      "1053/4000: train_loss: 3.7472033522836865 train_error 35.62% test_error 42.00%\n",
      "================================1054===================================\n",
      "1054/4000: train_loss: 3.7458447527559473 train_error 35.50% test_error 42.00%\n",
      "================================1055===================================\n",
      "1055/4000: train_loss: 3.7444860277324916 train_error 35.50% test_error 42.00%\n",
      "================================1056===================================\n",
      "1056/4000: train_loss: 3.7431269985996183 train_error 35.50% test_error 42.00%\n",
      "================================1057===================================\n",
      "1057/4000: train_loss: 3.7417676433734597 train_error 35.50% test_error 42.00%\n",
      "================================1058===================================\n",
      "1058/4000: train_loss: 3.740410208245739 train_error 35.50% test_error 42.00%\n",
      "================================1059===================================\n",
      "1059/4000: train_loss: 3.7390546594886107 train_error 35.50% test_error 42.00%\n",
      "================================1060===================================\n",
      "1060/4000: train_loss: 3.7376997431972994 train_error 35.50% test_error 42.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1061===================================\n",
      "1061/4000: train_loss: 3.736347413393669 train_error 35.38% test_error 42.00%\n",
      "================================1062===================================\n",
      "1062/4000: train_loss: 3.7349959519738336 train_error 35.25% test_error 42.00%\n",
      "================================1063===================================\n",
      "1063/4000: train_loss: 3.7336437050020317 train_error 35.25% test_error 42.00%\n",
      "================================1064===================================\n",
      "1064/4000: train_loss: 3.732290301276371 train_error 35.25% test_error 42.00%\n",
      "================================1065===================================\n",
      "1065/4000: train_loss: 3.730937078688293 train_error 35.25% test_error 42.00%\n",
      "================================1066===================================\n",
      "1066/4000: train_loss: 3.729584144842811 train_error 35.25% test_error 42.00%\n",
      "================================1067===================================\n",
      "1067/4000: train_loss: 3.728229837166145 train_error 35.25% test_error 42.00%\n",
      "================================1068===================================\n",
      "1068/4000: train_loss: 3.726875553196296 train_error 35.25% test_error 42.00%\n",
      "================================1069===================================\n",
      "1069/4000: train_loss: 3.7255213658092545 train_error 35.25% test_error 42.00%\n",
      "================================1070===================================\n",
      "1070/4000: train_loss: 3.72416685145814 train_error 35.25% test_error 42.00%\n",
      "================================1071===================================\n",
      "1071/4000: train_loss: 3.722812879923731 train_error 35.12% test_error 42.00%\n",
      "================================1072===================================\n",
      "1072/4000: train_loss: 3.721458373698406 train_error 35.12% test_error 42.00%\n",
      "================================1073===================================\n",
      "1073/4000: train_loss: 3.7201044340897353 train_error 35.12% test_error 42.00%\n",
      "================================1074===================================\n",
      "1074/4000: train_loss: 3.718750304644927 train_error 35.12% test_error 42.00%\n",
      "================================1075===================================\n",
      "1075/4000: train_loss: 3.7173961344175037 train_error 35.00% test_error 42.50%\n",
      "================================1076===================================\n",
      "1076/4000: train_loss: 3.7160417618462818 train_error 35.00% test_error 42.50%\n",
      "================================1077===================================\n",
      "1077/4000: train_loss: 3.714687299267389 train_error 34.88% test_error 42.50%\n",
      "================================1078===================================\n",
      "1078/4000: train_loss: 3.7133324535889547 train_error 34.88% test_error 42.50%\n",
      "================================1079===================================\n",
      "1079/4000: train_loss: 3.7119775679009033 train_error 34.88% test_error 42.50%\n",
      "================================1080===================================\n",
      "1080/4000: train_loss: 3.7106226400239395 train_error 34.75% test_error 42.50%\n",
      "================================1081===================================\n",
      "1081/4000: train_loss: 3.7092684611212463 train_error 34.75% test_error 42.50%\n",
      "================================1082===================================\n",
      "1082/4000: train_loss: 3.7079167180880908 train_error 34.62% test_error 42.50%\n",
      "================================1083===================================\n",
      "1083/4000: train_loss: 3.7065663777152076 train_error 34.62% test_error 42.50%\n",
      "================================1084===================================\n",
      "1084/4000: train_loss: 3.7052163540991025 train_error 34.75% test_error 42.50%\n",
      "================================1085===================================\n",
      "1085/4000: train_loss: 3.70386689226143 train_error 34.75% test_error 42.50%\n",
      "================================1086===================================\n",
      "1086/4000: train_loss: 3.702517665694468 train_error 34.75% test_error 42.50%\n",
      "================================1087===================================\n",
      "1087/4000: train_loss: 3.701168436063454 train_error 34.75% test_error 42.50%\n",
      "================================1088===================================\n",
      "1088/4000: train_loss: 3.6998198072100057 train_error 34.75% test_error 42.50%\n",
      "================================1089===================================\n",
      "1089/4000: train_loss: 3.698471318134107 train_error 34.62% test_error 42.50%\n",
      "================================1090===================================\n",
      "1090/4000: train_loss: 3.6971221225708724 train_error 34.62% test_error 42.50%\n",
      "================================1091===================================\n",
      "1091/4000: train_loss: 3.6957725751539696 train_error 34.38% test_error 42.50%\n",
      "================================1092===================================\n",
      "1092/4000: train_loss: 3.6944244134332984 train_error 34.38% test_error 42.50%\n",
      "================================1093===================================\n",
      "1093/4000: train_loss: 3.6930761686945335 train_error 34.38% test_error 42.50%\n",
      "================================1094===================================\n",
      "1094/4000: train_loss: 3.691725725866854 train_error 34.38% test_error 42.50%\n",
      "================================1095===================================\n",
      "1095/4000: train_loss: 3.690374980256893 train_error 34.38% test_error 42.50%\n",
      "================================1096===================================\n",
      "1096/4000: train_loss: 3.689025303088129 train_error 34.25% test_error 42.50%\n",
      "================================1097===================================\n",
      "1097/4000: train_loss: 3.687675644606352 train_error 34.25% test_error 42.50%\n",
      "================================1098===================================\n",
      "1098/4000: train_loss: 3.6863240026915447 train_error 34.25% test_error 42.50%\n",
      "================================1099===================================\n",
      "1099/4000: train_loss: 3.684971651127562 train_error 34.25% test_error 42.50%\n",
      "================================1100===================================\n",
      "1100/4000: train_loss: 3.6836189571442084 train_error 34.25% test_error 42.50%\n",
      "================================1101===================================\n",
      "1101/4000: train_loss: 3.682266546548344 train_error 34.25% test_error 42.50%\n",
      "================================1102===================================\n",
      "1102/4000: train_loss: 3.680916402954608 train_error 34.25% test_error 42.50%\n",
      "================================1103===================================\n",
      "1103/4000: train_loss: 3.6795664726616817 train_error 33.88% test_error 42.50%\n",
      "================================1104===================================\n",
      "1104/4000: train_loss: 3.678216678616591 train_error 33.88% test_error 42.50%\n",
      "================================1105===================================\n",
      "1105/4000: train_loss: 3.676866827318445 train_error 33.88% test_error 42.50%\n",
      "================================1106===================================\n",
      "1106/4000: train_loss: 3.675515652894974 train_error 33.62% test_error 42.50%\n",
      "================================1107===================================\n",
      "1107/4000: train_loss: 3.6741625456372273 train_error 33.75% test_error 42.50%\n",
      "================================1108===================================\n",
      "1108/4000: train_loss: 3.6728095809090884 train_error 33.75% test_error 42.50%\n",
      "================================1109===================================\n",
      "1109/4000: train_loss: 3.6714573138393463 train_error 33.62% test_error 42.50%\n",
      "================================1110===================================\n",
      "1110/4000: train_loss: 3.6701048423303293 train_error 33.62% test_error 42.50%\n",
      "================================1111===================================\n",
      "1111/4000: train_loss: 3.6687517094006763 train_error 33.50% test_error 42.50%\n",
      "================================1112===================================\n",
      "1112/4000: train_loss: 3.6673975742375475 train_error 33.38% test_error 42.50%\n",
      "================================1113===================================\n",
      "1113/4000: train_loss: 3.666041801474057 train_error 33.38% test_error 42.50%\n",
      "================================1114===================================\n",
      "1114/4000: train_loss: 3.66468537740875 train_error 33.38% test_error 42.50%\n",
      "================================1115===================================\n",
      "1115/4000: train_loss: 3.6633286965917797 train_error 33.25% test_error 42.50%\n",
      "================================1116===================================\n",
      "1116/4000: train_loss: 3.661971790813841 train_error 33.12% test_error 42.00%\n",
      "================================1117===================================\n",
      "1117/4000: train_loss: 3.6606148364627735 train_error 33.12% test_error 42.00%\n",
      "================================1118===================================\n",
      "1118/4000: train_loss: 3.6592596618877726 train_error 33.12% test_error 42.00%\n",
      "================================1119===================================\n",
      "1119/4000: train_loss: 3.6579037989675998 train_error 33.12% test_error 42.00%\n",
      "================================1120===================================\n",
      "1120/4000: train_loss: 3.656547087007202 train_error 33.12% test_error 42.00%\n",
      "================================1121===================================\n",
      "1121/4000: train_loss: 3.655190654229373 train_error 33.12% test_error 42.00%\n",
      "================================1122===================================\n",
      "1122/4000: train_loss: 3.65383284390904 train_error 33.12% test_error 42.00%\n",
      "================================1123===================================\n",
      "1123/4000: train_loss: 3.652475682054646 train_error 33.12% test_error 42.00%\n",
      "================================1124===================================\n",
      "1124/4000: train_loss: 3.6511189453676343 train_error 33.12% test_error 42.00%\n",
      "================================1125===================================\n",
      "1125/4000: train_loss: 3.649761168975383 train_error 33.12% test_error 42.00%\n",
      "================================1126===================================\n",
      "1126/4000: train_loss: 3.6484026865661146 train_error 33.12% test_error 42.00%\n",
      "================================1127===================================\n",
      "1127/4000: train_loss: 3.6470444958982986 train_error 33.12% test_error 42.00%\n",
      "================================1128===================================\n",
      "1128/4000: train_loss: 3.6456864540278913 train_error 33.12% test_error 42.00%\n",
      "================================1129===================================\n",
      "1129/4000: train_loss: 3.6443299145251515 train_error 33.12% test_error 42.00%\n",
      "================================1130===================================\n",
      "1130/4000: train_loss: 3.6429732548957694 train_error 32.88% test_error 42.00%\n",
      "================================1131===================================\n",
      "1131/4000: train_loss: 3.6416156037710605 train_error 32.88% test_error 42.00%\n",
      "================================1132===================================\n",
      "1132/4000: train_loss: 3.6402587155112998 train_error 32.88% test_error 42.00%\n",
      "================================1133===================================\n",
      "1133/4000: train_loss: 3.6389027192955834 train_error 32.75% test_error 42.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1134===================================\n",
      "1134/4000: train_loss: 3.637547123837285 train_error 32.75% test_error 42.00%\n",
      "================================1135===================================\n",
      "1135/4000: train_loss: 3.636192978098989 train_error 32.75% test_error 42.00%\n",
      "================================1136===================================\n",
      "1136/4000: train_loss: 3.634839036096819 train_error 32.75% test_error 42.00%\n",
      "================================1137===================================\n",
      "1137/4000: train_loss: 3.6334839204978198 train_error 32.62% test_error 42.00%\n",
      "================================1138===================================\n",
      "1138/4000: train_loss: 3.632128869523294 train_error 32.62% test_error 42.00%\n",
      "================================1139===================================\n",
      "1139/4000: train_loss: 3.630774512360804 train_error 32.62% test_error 42.00%\n",
      "================================1140===================================\n",
      "1140/4000: train_loss: 3.629421496265568 train_error 32.62% test_error 42.00%\n",
      "================================1141===================================\n",
      "1141/4000: train_loss: 3.6280690841702743 train_error 32.62% test_error 42.00%\n",
      "================================1142===================================\n",
      "1142/4000: train_loss: 3.626716787950136 train_error 32.50% test_error 42.00%\n",
      "================================1143===================================\n",
      "1143/4000: train_loss: 3.6253640782414003 train_error 32.50% test_error 42.00%\n",
      "================================1144===================================\n",
      "1144/4000: train_loss: 3.624012851412408 train_error 32.50% test_error 42.00%\n",
      "================================1145===================================\n",
      "1145/4000: train_loss: 3.622662876904942 train_error 32.50% test_error 41.50%\n",
      "================================1146===================================\n",
      "1146/4000: train_loss: 3.621313210707158 train_error 32.38% test_error 41.50%\n",
      "================================1147===================================\n",
      "1147/4000: train_loss: 3.6199650019640104 train_error 32.38% test_error 41.50%\n",
      "================================1148===================================\n",
      "1148/4000: train_loss: 3.6186180164059625 train_error 32.12% test_error 41.50%\n",
      "================================1149===================================\n",
      "1149/4000: train_loss: 3.6172705411724744 train_error 32.12% test_error 41.50%\n",
      "================================1150===================================\n",
      "1150/4000: train_loss: 3.6159228737652302 train_error 32.12% test_error 41.50%\n",
      "================================1151===================================\n",
      "1151/4000: train_loss: 3.6145739987818524 train_error 32.12% test_error 41.50%\n",
      "================================1152===================================\n",
      "1152/4000: train_loss: 3.613225047378801 train_error 32.12% test_error 41.50%\n",
      "================================1153===================================\n",
      "1153/4000: train_loss: 3.6118772420380263 train_error 32.00% test_error 41.50%\n",
      "================================1154===================================\n",
      "1154/4000: train_loss: 3.61053114389535 train_error 32.00% test_error 41.50%\n",
      "================================1155===================================\n",
      "1155/4000: train_loss: 3.609185562347993 train_error 32.00% test_error 41.50%\n",
      "================================1156===================================\n",
      "1156/4000: train_loss: 3.6078398207901046 train_error 32.00% test_error 41.50%\n",
      "================================1157===================================\n",
      "1157/4000: train_loss: 3.6064957508584485 train_error 32.00% test_error 41.50%\n",
      "================================1158===================================\n",
      "1158/4000: train_loss: 3.6051526682637633 train_error 32.00% test_error 41.50%\n",
      "================================1159===================================\n",
      "1159/4000: train_loss: 3.60380943252705 train_error 32.00% test_error 41.00%\n",
      "================================1160===================================\n",
      "1160/4000: train_loss: 3.6024647106789054 train_error 32.00% test_error 41.00%\n",
      "================================1161===================================\n",
      "1161/4000: train_loss: 3.6011224086023863 train_error 32.00% test_error 41.00%\n",
      "================================1162===================================\n",
      "1162/4000: train_loss: 3.599780774535611 train_error 32.00% test_error 41.00%\n",
      "================================1163===================================\n",
      "1163/4000: train_loss: 3.5984414635179562 train_error 32.00% test_error 41.00%\n",
      "================================1164===================================\n",
      "1164/4000: train_loss: 3.5971030495641756 train_error 32.00% test_error 41.00%\n",
      "================================1165===================================\n",
      "1165/4000: train_loss: 3.59576629136689 train_error 32.00% test_error 41.00%\n",
      "================================1166===================================\n",
      "1166/4000: train_loss: 3.5944295993167907 train_error 32.00% test_error 41.00%\n",
      "================================1167===================================\n",
      "1167/4000: train_loss: 3.5930924172606318 train_error 32.00% test_error 41.00%\n",
      "================================1168===================================\n",
      "1168/4000: train_loss: 3.5917563069984317 train_error 32.00% test_error 41.00%\n",
      "================================1169===================================\n",
      "1169/4000: train_loss: 3.590422631055117 train_error 31.75% test_error 41.00%\n",
      "================================1170===================================\n",
      "1170/4000: train_loss: 3.5890888141142203 train_error 31.75% test_error 41.00%\n",
      "================================1171===================================\n",
      "1171/4000: train_loss: 3.5877550087589767 train_error 31.75% test_error 41.00%\n",
      "================================1172===================================\n",
      "1172/4000: train_loss: 3.58642297974322 train_error 31.62% test_error 41.00%\n",
      "================================1173===================================\n",
      "1173/4000: train_loss: 3.5850931740272793 train_error 31.62% test_error 41.00%\n",
      "================================1174===================================\n",
      "1174/4000: train_loss: 3.5837638990953566 train_error 31.62% test_error 41.00%\n",
      "================================1175===================================\n",
      "1175/4000: train_loss: 3.5824340644804757 train_error 31.50% test_error 41.00%\n",
      "================================1176===================================\n",
      "1176/4000: train_loss: 3.5811064053792507 train_error 31.50% test_error 41.00%\n",
      "================================1177===================================\n",
      "1177/4000: train_loss: 3.5797803704300897 train_error 31.37% test_error 41.00%\n",
      "================================1178===================================\n",
      "1178/4000: train_loss: 3.5784545448515566 train_error 31.37% test_error 41.00%\n",
      "================================1179===================================\n",
      "1179/4000: train_loss: 3.5771294907759876 train_error 31.25% test_error 41.00%\n",
      "================================1180===================================\n",
      "1180/4000: train_loss: 3.575804793583229 train_error 31.13% test_error 41.00%\n",
      "================================1181===================================\n",
      "1181/4000: train_loss: 3.574481425061822 train_error 31.13% test_error 41.00%\n",
      "================================1182===================================\n",
      "1182/4000: train_loss: 3.5731601240858435 train_error 31.13% test_error 41.00%\n",
      "================================1183===================================\n",
      "1183/4000: train_loss: 3.571842786078341 train_error 31.13% test_error 41.00%\n",
      "================================1184===================================\n",
      "1184/4000: train_loss: 3.570526132131927 train_error 31.13% test_error 41.00%\n",
      "================================1185===================================\n",
      "1185/4000: train_loss: 3.5692098962422465 train_error 31.13% test_error 41.00%\n",
      "================================1186===================================\n",
      "1186/4000: train_loss: 3.567894656448625 train_error 31.13% test_error 41.00%\n",
      "================================1187===================================\n",
      "1187/4000: train_loss: 3.5665780068328607 train_error 31.13% test_error 41.00%\n",
      "================================1188===================================\n",
      "1188/4000: train_loss: 3.565261589563452 train_error 31.13% test_error 41.00%\n",
      "================================1189===================================\n",
      "1189/4000: train_loss: 3.5639463764755055 train_error 31.00% test_error 41.00%\n",
      "================================1190===================================\n",
      "1190/4000: train_loss: 3.5626321325078605 train_error 31.00% test_error 41.00%\n",
      "================================1191===================================\n",
      "1191/4000: train_loss: 3.5613188108801843 train_error 31.00% test_error 41.00%\n",
      "================================1192===================================\n",
      "1192/4000: train_loss: 3.56000638732221 train_error 31.00% test_error 41.00%\n",
      "================================1193===================================\n",
      "1193/4000: train_loss: 3.5586955112591383 train_error 30.88% test_error 41.00%\n",
      "================================1194===================================\n",
      "1194/4000: train_loss: 3.557386717214249 train_error 30.88% test_error 41.00%\n",
      "================================1195===================================\n",
      "1195/4000: train_loss: 3.556079288283363 train_error 30.88% test_error 41.00%\n",
      "================================1196===================================\n",
      "1196/4000: train_loss: 3.554772342559881 train_error 30.75% test_error 41.00%\n",
      "================================1197===================================\n",
      "1197/4000: train_loss: 3.5534663563454525 train_error 30.63% test_error 41.00%\n",
      "================================1198===================================\n",
      "1198/4000: train_loss: 3.552162113864906 train_error 30.63% test_error 41.00%\n",
      "================================1199===================================\n",
      "1199/4000: train_loss: 3.550859138565138 train_error 30.50% test_error 41.00%\n",
      "================================1200===================================\n",
      "1200/4000: train_loss: 3.549558192216791 train_error 30.50% test_error 40.00%\n",
      "================================1201===================================\n",
      "1201/4000: train_loss: 3.548257309938781 train_error 30.50% test_error 40.00%\n",
      "================================1202===================================\n",
      "1202/4000: train_loss: 3.546958513110876 train_error 30.50% test_error 40.00%\n",
      "================================1203===================================\n",
      "1203/4000: train_loss: 3.5456618090858685 train_error 30.50% test_error 40.00%\n",
      "================================1204===================================\n",
      "1204/4000: train_loss: 3.5443658460211007 train_error 30.50% test_error 40.00%\n",
      "================================1205===================================\n",
      "1205/4000: train_loss: 3.543070049746893 train_error 30.25% test_error 40.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1206===================================\n",
      "1206/4000: train_loss: 3.541775749656372 train_error 30.00% test_error 40.00%\n",
      "================================1207===================================\n",
      "1207/4000: train_loss: 3.5404830883583056 train_error 30.00% test_error 40.00%\n",
      "================================1208===================================\n",
      "1208/4000: train_loss: 3.539191630417481 train_error 30.00% test_error 40.00%\n",
      "================================1209===================================\n",
      "1209/4000: train_loss: 3.5379023798136036 train_error 30.00% test_error 40.00%\n",
      "================================1210===================================\n",
      "1210/4000: train_loss: 3.5366144718416033 train_error 30.00% test_error 40.00%\n",
      "================================1211===================================\n",
      "1211/4000: train_loss: 3.535327237397432 train_error 30.00% test_error 40.00%\n",
      "================================1212===================================\n",
      "1212/4000: train_loss: 3.5340413963701574 train_error 30.00% test_error 40.00%\n",
      "================================1213===================================\n",
      "1213/4000: train_loss: 3.5327571572409946 train_error 30.00% test_error 40.00%\n",
      "================================1214===================================\n",
      "1214/4000: train_loss: 3.53147455918137 train_error 30.00% test_error 40.00%\n",
      "================================1215===================================\n",
      "1215/4000: train_loss: 3.530193245061673 train_error 29.88% test_error 40.00%\n",
      "================================1216===================================\n",
      "1216/4000: train_loss: 3.528913073809817 train_error 29.75% test_error 40.00%\n",
      "================================1217===================================\n",
      "1217/4000: train_loss: 3.5276336984569205 train_error 29.75% test_error 39.50%\n",
      "================================1218===================================\n",
      "1218/4000: train_loss: 3.526356679527089 train_error 29.50% test_error 39.50%\n",
      "================================1219===================================\n",
      "1219/4000: train_loss: 3.5250818590447306 train_error 29.50% test_error 39.50%\n",
      "================================1220===================================\n",
      "1220/4000: train_loss: 3.523808754836209 train_error 29.50% test_error 39.00%\n",
      "================================1221===================================\n",
      "1221/4000: train_loss: 3.522537397067062 train_error 29.38% test_error 38.50%\n",
      "================================1222===================================\n",
      "1222/4000: train_loss: 3.5212673865351825 train_error 29.38% test_error 38.50%\n",
      "================================1223===================================\n",
      "1223/4000: train_loss: 3.519999076859094 train_error 29.38% test_error 38.00%\n",
      "================================1224===================================\n",
      "1224/4000: train_loss: 3.5187336493330075 train_error 29.38% test_error 38.00%\n",
      "================================1225===================================\n",
      "1225/4000: train_loss: 3.5174679027311506 train_error 29.38% test_error 38.00%\n",
      "================================1226===================================\n",
      "1226/4000: train_loss: 3.51620416267775 train_error 29.38% test_error 38.00%\n",
      "================================1227===================================\n",
      "1227/4000: train_loss: 3.514942708243616 train_error 29.38% test_error 38.00%\n",
      "================================1228===================================\n",
      "1228/4000: train_loss: 3.5136835316149515 train_error 29.25% test_error 38.00%\n",
      "================================1229===================================\n",
      "1229/4000: train_loss: 3.5124257086822768 train_error 29.12% test_error 38.00%\n",
      "================================1230===================================\n",
      "1230/4000: train_loss: 3.511169697432779 train_error 29.12% test_error 38.00%\n",
      "================================1231===================================\n",
      "1231/4000: train_loss: 3.5099147527106105 train_error 29.00% test_error 38.00%\n",
      "================================1232===================================\n",
      "1232/4000: train_loss: 3.5086610097624362 train_error 28.75% test_error 38.00%\n",
      "================================1233===================================\n",
      "1233/4000: train_loss: 3.507408508546651 train_error 28.62% test_error 38.00%\n",
      "================================1234===================================\n",
      "1234/4000: train_loss: 3.506158136497252 train_error 28.62% test_error 38.00%\n",
      "================================1235===================================\n",
      "1235/4000: train_loss: 3.5049106615083288 train_error 28.62% test_error 38.00%\n",
      "================================1236===================================\n",
      "1236/4000: train_loss: 3.503664533519186 train_error 28.50% test_error 38.00%\n",
      "================================1237===================================\n",
      "1237/4000: train_loss: 3.502420230661519 train_error 28.50% test_error 38.00%\n",
      "================================1238===================================\n",
      "1238/4000: train_loss: 3.501176950489171 train_error 28.50% test_error 38.00%\n",
      "================================1239===================================\n",
      "1239/4000: train_loss: 3.4999350582528863 train_error 28.50% test_error 38.00%\n",
      "================================1240===================================\n",
      "1240/4000: train_loss: 3.498695433931425 train_error 28.50% test_error 38.00%\n",
      "================================1241===================================\n",
      "1241/4000: train_loss: 3.4974580885749313 train_error 28.38% test_error 38.00%\n",
      "================================1242===================================\n",
      "1242/4000: train_loss: 3.4962233120528983 train_error 28.38% test_error 38.00%\n",
      "================================1243===================================\n",
      "1243/4000: train_loss: 3.494991086991504 train_error 28.38% test_error 38.00%\n",
      "================================1244===================================\n",
      "1244/4000: train_loss: 3.493760908357799 train_error 28.38% test_error 37.50%\n",
      "================================1245===================================\n",
      "1245/4000: train_loss: 3.4925324410153555 train_error 28.38% test_error 37.50%\n",
      "================================1246===================================\n",
      "1246/4000: train_loss: 3.4913053700979804 train_error 28.38% test_error 37.50%\n",
      "================================1247===================================\n",
      "1247/4000: train_loss: 3.4900799393095077 train_error 28.38% test_error 37.50%\n",
      "================================1248===================================\n",
      "1248/4000: train_loss: 3.4888567017344756 train_error 28.38% test_error 37.50%\n",
      "================================1249===================================\n",
      "1249/4000: train_loss: 3.48763580724597 train_error 28.38% test_error 37.50%\n",
      "================================1250===================================\n",
      "1250/4000: train_loss: 3.4864168388489634 train_error 28.25% test_error 37.50%\n",
      "================================1251===================================\n",
      "1251/4000: train_loss: 3.485200581550598 train_error 28.25% test_error 37.50%\n",
      "================================1252===================================\n",
      "1252/4000: train_loss: 3.483986401432194 train_error 28.25% test_error 37.50%\n",
      "================================1253===================================\n",
      "1253/4000: train_loss: 3.482773823039606 train_error 28.25% test_error 37.50%\n",
      "================================1254===================================\n",
      "1254/4000: train_loss: 3.4815641662990675 train_error 28.12% test_error 37.50%\n",
      "================================1255===================================\n",
      "1255/4000: train_loss: 3.48035625169985 train_error 28.12% test_error 37.50%\n",
      "================================1256===================================\n",
      "1256/4000: train_loss: 3.4791497463639827 train_error 28.00% test_error 37.50%\n",
      "================================1257===================================\n",
      "1257/4000: train_loss: 3.4779441001219675 train_error 27.88% test_error 37.50%\n",
      "================================1258===================================\n",
      "1258/4000: train_loss: 3.476741280155256 train_error 27.88% test_error 37.50%\n",
      "================================1259===================================\n",
      "1259/4000: train_loss: 3.4755397784151136 train_error 27.75% test_error 38.00%\n",
      "================================1260===================================\n",
      "1260/4000: train_loss: 3.474339762991294 train_error 27.75% test_error 38.00%\n",
      "================================1261===================================\n",
      "1261/4000: train_loss: 3.4731399903493 train_error 27.75% test_error 38.00%\n",
      "================================1262===================================\n",
      "1262/4000: train_loss: 3.4719407317740845 train_error 27.75% test_error 38.00%\n",
      "================================1263===================================\n",
      "1263/4000: train_loss: 3.470741918082349 train_error 27.75% test_error 38.00%\n",
      "================================1264===================================\n",
      "1264/4000: train_loss: 3.4695439228089526 train_error 27.75% test_error 38.00%\n",
      "================================1265===================================\n",
      "1265/4000: train_loss: 3.4683466829918324 train_error 27.75% test_error 38.00%\n",
      "================================1266===================================\n",
      "1266/4000: train_loss: 3.4671500235050914 train_error 27.75% test_error 38.00%\n",
      "================================1267===================================\n",
      "1267/4000: train_loss: 3.4659558260720225 train_error 27.75% test_error 38.00%\n",
      "================================1268===================================\n",
      "1268/4000: train_loss: 3.464763605920598 train_error 27.75% test_error 37.50%\n",
      "================================1269===================================\n",
      "1269/4000: train_loss: 3.4635738353291528 train_error 27.75% test_error 37.50%\n",
      "================================1270===================================\n",
      "1270/4000: train_loss: 3.4623857372580096 train_error 27.75% test_error 37.50%\n",
      "================================1271===================================\n",
      "1271/4000: train_loss: 3.4612004959583285 train_error 27.75% test_error 37.50%\n",
      "================================1272===================================\n",
      "1272/4000: train_loss: 3.4600162675417963 train_error 27.75% test_error 37.50%\n",
      "================================1273===================================\n",
      "1273/4000: train_loss: 3.4588335356814786 train_error 27.75% test_error 37.50%\n",
      "================================1274===================================\n",
      "1274/4000: train_loss: 3.45765211106278 train_error 27.75% test_error 37.50%\n",
      "================================1275===================================\n",
      "1275/4000: train_loss: 3.4564720424916597 train_error 27.75% test_error 37.50%\n",
      "================================1276===================================\n",
      "1276/4000: train_loss: 3.455293759219349 train_error 27.75% test_error 37.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1277===================================\n",
      "1277/4000: train_loss: 3.454117591269314 train_error 27.75% test_error 37.50%\n",
      "================================1278===================================\n",
      "1278/4000: train_loss: 3.4529420823697 train_error 27.75% test_error 37.50%\n",
      "================================1279===================================\n",
      "1279/4000: train_loss: 3.4517680661287153 train_error 27.75% test_error 37.50%\n",
      "================================1280===================================\n",
      "1280/4000: train_loss: 3.450595441097394 train_error 27.75% test_error 37.50%\n",
      "================================1281===================================\n",
      "1281/4000: train_loss: 3.4494244862301273 train_error 27.62% test_error 37.50%\n",
      "================================1282===================================\n",
      "1282/4000: train_loss: 3.448255762504414 train_error 27.62% test_error 37.50%\n",
      "================================1283===================================\n",
      "1283/4000: train_loss: 3.4470884726801887 train_error 27.62% test_error 37.50%\n",
      "================================1284===================================\n",
      "1284/4000: train_loss: 3.445922384276055 train_error 27.62% test_error 37.00%\n",
      "================================1285===================================\n",
      "1285/4000: train_loss: 3.4447569232806563 train_error 27.62% test_error 36.50%\n",
      "================================1286===================================\n",
      "1286/4000: train_loss: 3.4435926611907783 train_error 27.62% test_error 36.50%\n",
      "================================1287===================================\n",
      "1287/4000: train_loss: 3.442428658935241 train_error 27.62% test_error 36.50%\n",
      "================================1288===================================\n",
      "1288/4000: train_loss: 3.441266623516567 train_error 27.62% test_error 36.50%\n",
      "================================1289===================================\n",
      "1289/4000: train_loss: 3.4401062853680924 train_error 27.62% test_error 36.50%\n",
      "================================1290===================================\n",
      "1290/4000: train_loss: 3.438947809333913 train_error 27.62% test_error 36.50%\n",
      "================================1291===================================\n",
      "1291/4000: train_loss: 3.4377907134918497 train_error 27.62% test_error 36.50%\n",
      "================================1292===================================\n",
      "1292/4000: train_loss: 3.436634688908234 train_error 27.62% test_error 36.50%\n",
      "================================1293===================================\n",
      "1293/4000: train_loss: 3.4354814903391526 train_error 27.62% test_error 36.50%\n",
      "================================1294===================================\n",
      "1294/4000: train_loss: 3.434332318087108 train_error 27.62% test_error 36.50%\n",
      "================================1295===================================\n",
      "1295/4000: train_loss: 3.433185331723653 train_error 27.62% test_error 36.50%\n",
      "================================1296===================================\n",
      "1296/4000: train_loss: 3.4320408014813437 train_error 27.62% test_error 36.50%\n",
      "================================1297===================================\n",
      "1297/4000: train_loss: 3.4308981819637125 train_error 27.62% test_error 36.50%\n",
      "================================1298===================================\n",
      "1298/4000: train_loss: 3.4297573430417105 train_error 27.62% test_error 36.50%\n",
      "================================1299===================================\n",
      "1299/4000: train_loss: 3.428618030352518 train_error 27.62% test_error 36.50%\n",
      "================================1300===================================\n",
      "1300/4000: train_loss: 3.4274798561492936 train_error 27.50% test_error 36.50%\n",
      "================================1301===================================\n",
      "1301/4000: train_loss: 3.426342529999092 train_error 27.50% test_error 36.00%\n",
      "================================1302===================================\n",
      "1302/4000: train_loss: 3.4252067565964537 train_error 27.50% test_error 36.00%\n",
      "================================1303===================================\n",
      "1303/4000: train_loss: 3.4240719206584616 train_error 27.38% test_error 36.00%\n",
      "================================1304===================================\n",
      "1304/4000: train_loss: 3.422938183657825 train_error 27.25% test_error 36.50%\n",
      "================================1305===================================\n",
      "1305/4000: train_loss: 3.4218042249046263 train_error 27.25% test_error 36.50%\n",
      "================================1306===================================\n",
      "1306/4000: train_loss: 3.420671693887561 train_error 27.25% test_error 36.50%\n",
      "================================1307===================================\n",
      "1307/4000: train_loss: 3.4195392051013185 train_error 27.25% test_error 36.50%\n",
      "================================1308===================================\n",
      "1308/4000: train_loss: 3.4184080393845218 train_error 27.25% test_error 36.50%\n",
      "================================1309===================================\n",
      "1309/4000: train_loss: 3.4172779642231763 train_error 27.25% test_error 36.50%\n",
      "================================1310===================================\n",
      "1310/4000: train_loss: 3.4161495179729533 train_error 27.12% test_error 36.50%\n",
      "================================1311===================================\n",
      "1311/4000: train_loss: 3.415022005564533 train_error 27.12% test_error 36.00%\n",
      "================================1312===================================\n",
      "1312/4000: train_loss: 3.413895733137615 train_error 27.12% test_error 36.00%\n",
      "================================1313===================================\n",
      "1313/4000: train_loss: 3.412771251136437 train_error 27.12% test_error 36.00%\n",
      "================================1314===================================\n",
      "1314/4000: train_loss: 3.4116481409734116 train_error 27.12% test_error 36.00%\n",
      "================================1315===================================\n",
      "1315/4000: train_loss: 3.4105259089311586 train_error 27.12% test_error 36.00%\n",
      "================================1316===================================\n",
      "1316/4000: train_loss: 3.4094045793870467 train_error 26.88% test_error 36.00%\n",
      "================================1317===================================\n",
      "1317/4000: train_loss: 3.4082843959284945 train_error 26.88% test_error 36.00%\n",
      "================================1318===================================\n",
      "1318/4000: train_loss: 3.407165694818832 train_error 26.88% test_error 36.00%\n",
      "================================1319===================================\n",
      "1319/4000: train_loss: 3.406048416066915 train_error 26.88% test_error 36.00%\n",
      "================================1320===================================\n",
      "1320/4000: train_loss: 3.404931946815923 train_error 26.88% test_error 36.00%\n",
      "================================1321===================================\n",
      "1321/4000: train_loss: 3.403816234800033 train_error 26.75% test_error 36.00%\n",
      "================================1322===================================\n",
      "1322/4000: train_loss: 3.4027019014488906 train_error 26.62% test_error 36.00%\n",
      "================================1323===================================\n",
      "1323/4000: train_loss: 3.401589013952762 train_error 26.62% test_error 35.50%\n",
      "================================1324===================================\n",
      "1324/4000: train_loss: 3.4004779516393318 train_error 26.62% test_error 35.50%\n",
      "================================1325===================================\n",
      "1325/4000: train_loss: 3.399368282570504 train_error 26.62% test_error 35.50%\n",
      "================================1326===================================\n",
      "1326/4000: train_loss: 3.3982605347316714 train_error 26.62% test_error 35.50%\n",
      "================================1327===================================\n",
      "1327/4000: train_loss: 3.397153599127196 train_error 26.50% test_error 35.50%\n",
      "================================1328===================================\n",
      "1328/4000: train_loss: 3.3960478449426588 train_error 26.38% test_error 35.50%\n",
      "================================1329===================================\n",
      "1329/4000: train_loss: 3.394944212436676 train_error 26.38% test_error 35.50%\n",
      "================================1330===================================\n",
      "1330/4000: train_loss: 3.393842098182067 train_error 26.38% test_error 35.50%\n",
      "================================1331===================================\n",
      "1331/4000: train_loss: 3.392741393102333 train_error 26.38% test_error 35.50%\n",
      "================================1332===================================\n",
      "1332/4000: train_loss: 3.3916420920426025 train_error 26.25% test_error 35.50%\n",
      "================================1333===================================\n",
      "1333/4000: train_loss: 3.390544320824556 train_error 26.12% test_error 35.50%\n",
      "================================1334===================================\n",
      "1334/4000: train_loss: 3.389449158362113 train_error 26.00% test_error 35.50%\n",
      "================================1335===================================\n",
      "1335/4000: train_loss: 3.388355692215264 train_error 26.00% test_error 35.50%\n",
      "================================1336===================================\n",
      "1336/4000: train_loss: 3.387265005116351 train_error 26.00% test_error 35.50%\n",
      "================================1337===================================\n",
      "1337/4000: train_loss: 3.3861770163988694 train_error 25.87% test_error 35.50%\n",
      "================================1338===================================\n",
      "1338/4000: train_loss: 3.385091054919176 train_error 25.75% test_error 35.50%\n",
      "================================1339===================================\n",
      "1339/4000: train_loss: 3.3840075325546786 train_error 25.75% test_error 35.50%\n",
      "================================1340===================================\n",
      "1340/4000: train_loss: 3.3829258602904155 train_error 25.75% test_error 35.50%\n",
      "================================1341===================================\n",
      "1341/4000: train_loss: 3.3818463552463798 train_error 25.62% test_error 35.50%\n",
      "================================1342===================================\n",
      "1342/4000: train_loss: 3.380768580203876 train_error 25.62% test_error 35.50%\n",
      "================================1343===================================\n",
      "1343/4000: train_loss: 3.3796922417357567 train_error 25.62% test_error 35.50%\n",
      "================================1344===================================\n",
      "1344/4000: train_loss: 3.378617194890976 train_error 25.50% test_error 35.50%\n",
      "================================1345===================================\n",
      "1345/4000: train_loss: 3.3775423866789787 train_error 25.50% test_error 35.50%\n",
      "================================1346===================================\n",
      "1346/4000: train_loss: 3.376467469409108 train_error 25.50% test_error 35.50%\n",
      "================================1347===================================\n",
      "1347/4000: train_loss: 3.3753939339192582 train_error 25.50% test_error 35.50%\n",
      "================================1348===================================\n",
      "1348/4000: train_loss: 3.3743213663855567 train_error 25.50% test_error 35.50%\n",
      "================================1349===================================\n",
      "1349/4000: train_loss: 3.3732479138951748 train_error 25.37% test_error 35.50%\n",
      "================================1350===================================\n",
      "1350/4000: train_loss: 3.3721755537949503 train_error 25.37% test_error 35.50%\n",
      "================================1351===================================\n",
      "1351/4000: train_loss: 3.3711046593356877 train_error 25.37% test_error 35.50%\n",
      "================================1352===================================\n",
      "1352/4000: train_loss: 3.3700357499113305 train_error 25.37% test_error 35.50%\n",
      "================================1353===================================\n",
      "1353/4000: train_loss: 3.368969370909035 train_error 25.37% test_error 35.50%\n",
      "================================1354===================================\n",
      "1354/4000: train_loss: 3.367904272931628 train_error 25.25% test_error 35.50%\n",
      "================================1355===================================\n",
      "1355/4000: train_loss: 3.366840489860624 train_error 25.25% test_error 35.50%\n",
      "================================1356===================================\n",
      "1356/4000: train_loss: 3.365778216747567 train_error 25.25% test_error 35.50%\n",
      "================================1357===================================\n",
      "1357/4000: train_loss: 3.3647179122222584 train_error 25.25% test_error 35.50%\n",
      "================================1358===================================\n",
      "1358/4000: train_loss: 3.363660163888708 train_error 25.25% test_error 35.50%\n",
      "================================1359===================================\n",
      "1359/4000: train_loss: 3.3626053775893525 train_error 25.00% test_error 35.50%\n",
      "================================1360===================================\n",
      "1360/4000: train_loss: 3.361552328420803 train_error 25.00% test_error 35.50%\n",
      "================================1361===================================\n",
      "1361/4000: train_loss: 3.3605009446013714 train_error 25.00% test_error 35.50%\n",
      "================================1362===================================\n",
      "1362/4000: train_loss: 3.359451074725948 train_error 25.00% test_error 35.50%\n",
      "================================1363===================================\n",
      "1363/4000: train_loss: 3.3584038570476697 train_error 25.00% test_error 35.50%\n",
      "================================1364===================================\n",
      "1364/4000: train_loss: 3.3573573587602006 train_error 25.00% test_error 35.50%\n",
      "================================1365===================================\n",
      "1365/4000: train_loss: 3.356311946883798 train_error 25.00% test_error 35.50%\n",
      "================================1366===================================\n",
      "1366/4000: train_loss: 3.3552676130831243 train_error 25.00% test_error 35.50%\n",
      "================================1367===================================\n",
      "1367/4000: train_loss: 3.354223908698186 train_error 25.00% test_error 35.50%\n",
      "================================1368===================================\n",
      "1368/4000: train_loss: 3.353181368964724 train_error 25.00% test_error 35.50%\n",
      "================================1369===================================\n",
      "1369/4000: train_loss: 3.352140447380952 train_error 25.00% test_error 35.50%\n",
      "================================1370===================================\n",
      "1370/4000: train_loss: 3.3511026548547673 train_error 25.00% test_error 35.50%\n",
      "================================1371===================================\n",
      "1371/4000: train_loss: 3.3500662043970078 train_error 25.00% test_error 35.50%\n",
      "================================1372===================================\n",
      "1372/4000: train_loss: 3.349031009930186 train_error 25.00% test_error 35.50%\n",
      "================================1373===================================\n",
      "1373/4000: train_loss: 3.3479969655303288 train_error 25.00% test_error 35.50%\n",
      "================================1374===================================\n",
      "1374/4000: train_loss: 3.3469646085379647 train_error 24.88% test_error 35.50%\n",
      "================================1375===================================\n",
      "1375/4000: train_loss: 3.345934286308475 train_error 24.88% test_error 35.50%\n",
      "================================1376===================================\n",
      "1376/4000: train_loss: 3.344905665302649 train_error 24.75% test_error 35.00%\n",
      "================================1377===================================\n",
      "1377/4000: train_loss: 3.3438785744691266 train_error 24.75% test_error 34.50%\n",
      "================================1378===================================\n",
      "1378/4000: train_loss: 3.342853501494974 train_error 24.75% test_error 34.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1379===================================\n",
      "1379/4000: train_loss: 3.3418309484189375 train_error 24.75% test_error 34.50%\n",
      "================================1380===================================\n",
      "1380/4000: train_loss: 3.3408103037439285 train_error 24.75% test_error 34.50%\n",
      "================================1381===================================\n",
      "1381/4000: train_loss: 3.3397909656353297 train_error 24.75% test_error 34.50%\n",
      "================================1382===================================\n",
      "1382/4000: train_loss: 3.3387722034100444 train_error 24.75% test_error 34.50%\n",
      "================================1383===================================\n",
      "1383/4000: train_loss: 3.337754533085972 train_error 24.75% test_error 34.50%\n",
      "================================1384===================================\n",
      "1384/4000: train_loss: 3.3367382836528123 train_error 24.75% test_error 34.50%\n",
      "================================1385===================================\n",
      "1385/4000: train_loss: 3.3357247083075343 train_error 24.75% test_error 34.50%\n",
      "================================1386===================================\n",
      "1386/4000: train_loss: 3.3347115246346215 train_error 24.75% test_error 34.50%\n",
      "================================1387===================================\n",
      "1387/4000: train_loss: 3.3336993866506965 train_error 24.75% test_error 34.50%\n",
      "================================1388===================================\n",
      "1388/4000: train_loss: 3.3326879703951997 train_error 24.75% test_error 34.50%\n",
      "================================1389===================================\n",
      "1389/4000: train_loss: 3.331676850640215 train_error 24.75% test_error 34.50%\n",
      "================================1390===================================\n",
      "1390/4000: train_loss: 3.3306670213351026 train_error 24.75% test_error 34.50%\n",
      "================================1391===================================\n",
      "1391/4000: train_loss: 3.329659003787674 train_error 24.75% test_error 34.50%\n",
      "================================1392===================================\n",
      "1392/4000: train_loss: 3.3286524416599423 train_error 24.75% test_error 34.50%\n",
      "================================1393===================================\n",
      "1393/4000: train_loss: 3.3276470610452815 train_error 24.75% test_error 34.50%\n",
      "================================1394===================================\n",
      "1394/4000: train_loss: 3.3266413078084587 train_error 24.75% test_error 34.50%\n",
      "================================1395===================================\n",
      "1395/4000: train_loss: 3.3256362695572896 train_error 24.75% test_error 34.50%\n",
      "================================1396===================================\n",
      "1396/4000: train_loss: 3.3246320412913337 train_error 24.88% test_error 34.50%\n",
      "================================1397===================================\n",
      "1397/4000: train_loss: 3.323628635401837 train_error 24.88% test_error 34.50%\n",
      "================================1398===================================\n",
      "1398/4000: train_loss: 3.3226267134957013 train_error 24.88% test_error 34.50%\n",
      "================================1399===================================\n",
      "1399/4000: train_loss: 3.3216264314483848 train_error 24.88% test_error 34.50%\n",
      "================================1400===================================\n",
      "1400/4000: train_loss: 3.3206276456825434 train_error 24.88% test_error 34.50%\n",
      "================================1401===================================\n",
      "1401/4000: train_loss: 3.3196299331774934 train_error 24.88% test_error 34.50%\n",
      "================================1402===================================\n",
      "1402/4000: train_loss: 3.3186327340546997 train_error 24.88% test_error 34.50%\n",
      "================================1403===================================\n",
      "1403/4000: train_loss: 3.317635745555162 train_error 24.88% test_error 34.50%\n",
      "================================1404===================================\n",
      "1404/4000: train_loss: 3.316638933876529 train_error 24.88% test_error 34.50%\n",
      "================================1405===================================\n",
      "1405/4000: train_loss: 3.3156430181395264 train_error 25.00% test_error 34.50%\n",
      "================================1406===================================\n",
      "1406/4000: train_loss: 3.3146471907477824 train_error 24.88% test_error 34.50%\n",
      "================================1407===================================\n",
      "1407/4000: train_loss: 3.3136529301479456 train_error 24.88% test_error 34.50%\n",
      "================================1408===================================\n",
      "1408/4000: train_loss: 3.3126608507242055 train_error 24.88% test_error 34.50%\n",
      "================================1409===================================\n",
      "1409/4000: train_loss: 3.3116707633528857 train_error 24.88% test_error 34.50%\n",
      "================================1410===================================\n",
      "1410/4000: train_loss: 3.310682438588701 train_error 24.88% test_error 34.50%\n",
      "================================1411===================================\n",
      "1411/4000: train_loss: 3.3096962865209205 train_error 24.88% test_error 34.50%\n",
      "================================1412===================================\n",
      "1412/4000: train_loss: 3.308712677252479 train_error 24.88% test_error 34.00%\n",
      "================================1413===================================\n",
      "1413/4000: train_loss: 3.3077310911146927 train_error 24.88% test_error 34.00%\n",
      "================================1414===================================\n",
      "1414/4000: train_loss: 3.3067512966971844 train_error 24.75% test_error 34.00%\n",
      "================================1415===================================\n",
      "1415/4000: train_loss: 3.305772979478352 train_error 24.75% test_error 34.00%\n",
      "================================1416===================================\n",
      "1416/4000: train_loss: 3.3047963739419353 train_error 24.75% test_error 34.00%\n",
      "================================1417===================================\n",
      "1417/4000: train_loss: 3.3038207019167016 train_error 24.75% test_error 34.00%\n",
      "================================1418===================================\n",
      "1418/4000: train_loss: 3.3028457601461563 train_error 24.75% test_error 34.00%\n",
      "================================1419===================================\n",
      "1419/4000: train_loss: 3.301872149063274 train_error 24.75% test_error 34.00%\n",
      "================================1420===================================\n",
      "1420/4000: train_loss: 3.3008995097083966 train_error 24.88% test_error 34.00%\n",
      "================================1421===================================\n",
      "1421/4000: train_loss: 3.299928301735781 train_error 24.88% test_error 34.00%\n",
      "================================1422===================================\n",
      "1422/4000: train_loss: 3.2989584557153284 train_error 24.75% test_error 34.00%\n",
      "================================1423===================================\n",
      "1423/4000: train_loss: 3.29799035448581 train_error 24.75% test_error 34.00%\n",
      "================================1424===================================\n",
      "1424/4000: train_loss: 3.297023325706832 train_error 24.75% test_error 34.00%\n",
      "================================1425===================================\n",
      "1425/4000: train_loss: 3.2960565574932845 train_error 24.75% test_error 34.00%\n",
      "================================1426===================================\n",
      "1426/4000: train_loss: 3.295090885600075 train_error 24.75% test_error 34.00%\n",
      "================================1427===================================\n",
      "1427/4000: train_loss: 3.294127303343266 train_error 24.75% test_error 34.00%\n",
      "================================1428===================================\n",
      "1428/4000: train_loss: 3.2931656802538782 train_error 24.75% test_error 34.00%\n",
      "================================1429===================================\n",
      "1429/4000: train_loss: 3.2922067104047166 train_error 24.75% test_error 34.00%\n",
      "================================1430===================================\n",
      "1430/4000: train_loss: 3.2912491173623133 train_error 24.75% test_error 34.00%\n",
      "================================1431===================================\n",
      "1431/4000: train_loss: 3.290293032885529 train_error 24.62% test_error 34.00%\n",
      "================================1432===================================\n",
      "1432/4000: train_loss: 3.289339348161593 train_error 24.62% test_error 34.00%\n",
      "================================1433===================================\n",
      "1433/4000: train_loss: 3.2883869705628603 train_error 24.62% test_error 34.00%\n",
      "================================1434===================================\n",
      "1434/4000: train_loss: 3.2874360959185287 train_error 24.62% test_error 34.00%\n",
      "================================1435===================================\n",
      "1435/4000: train_loss: 3.2864868560340255 train_error 24.62% test_error 34.00%\n",
      "================================1436===================================\n",
      "1436/4000: train_loss: 3.285540179684758 train_error 24.62% test_error 34.00%\n",
      "================================1437===================================\n",
      "1437/4000: train_loss: 3.28459551654756 train_error 24.62% test_error 34.00%\n",
      "================================1438===================================\n",
      "1438/4000: train_loss: 3.2836525728693235 train_error 24.62% test_error 34.00%\n",
      "================================1439===================================\n",
      "1439/4000: train_loss: 3.282711932570673 train_error 24.62% test_error 34.00%\n",
      "================================1440===================================\n",
      "1440/4000: train_loss: 3.281771425656043 train_error 24.62% test_error 34.00%\n",
      "================================1441===================================\n",
      "1441/4000: train_loss: 3.2808323650853706 train_error 24.62% test_error 34.00%\n",
      "================================1442===================================\n",
      "1442/4000: train_loss: 3.279894851618446 train_error 24.62% test_error 34.00%\n",
      "================================1443===================================\n",
      "1443/4000: train_loss: 3.2789588318252934 train_error 24.62% test_error 33.50%\n",
      "================================1444===================================\n",
      "1444/4000: train_loss: 3.27802399684675 train_error 24.62% test_error 33.50%\n",
      "================================1445===================================\n",
      "1445/4000: train_loss: 3.2770903705339878 train_error 24.62% test_error 33.50%\n",
      "================================1446===================================\n",
      "1446/4000: train_loss: 3.2761577124707397 train_error 24.62% test_error 33.50%\n",
      "================================1447===================================\n",
      "1447/4000: train_loss: 3.2752266101259737 train_error 24.62% test_error 33.50%\n",
      "================================1448===================================\n",
      "1448/4000: train_loss: 3.2742970161559057 train_error 24.62% test_error 33.50%\n",
      "================================1449===================================\n",
      "1449/4000: train_loss: 3.2733683571638537 train_error 24.62% test_error 33.50%\n",
      "================================1450===================================\n",
      "1450/4000: train_loss: 3.272440961138346 train_error 24.50% test_error 33.50%\n",
      "================================1451===================================\n",
      "1451/4000: train_loss: 3.27151508575771 train_error 24.50% test_error 33.50%\n",
      "================================1452===================================\n",
      "1452/4000: train_loss: 3.270590491043404 train_error 24.50% test_error 33.50%\n",
      "================================1453===================================\n",
      "1453/4000: train_loss: 3.2696654925309123 train_error 24.50% test_error 33.50%\n",
      "================================1454===================================\n",
      "1454/4000: train_loss: 3.268740401333198 train_error 24.50% test_error 33.00%\n",
      "================================1455===================================\n",
      "1455/4000: train_loss: 3.2678170920815317 train_error 24.50% test_error 33.00%\n",
      "================================1456===================================\n",
      "1456/4000: train_loss: 3.266895040930249 train_error 24.50% test_error 33.00%\n",
      "================================1457===================================\n",
      "1457/4000: train_loss: 3.2659745492832735 train_error 24.38% test_error 33.00%\n",
      "================================1458===================================\n",
      "1458/4000: train_loss: 3.265056977495551 train_error 24.38% test_error 33.00%\n",
      "================================1459===================================\n",
      "1459/4000: train_loss: 3.264142145281658 train_error 24.38% test_error 33.00%\n",
      "================================1460===================================\n",
      "1460/4000: train_loss: 3.2632295056339355 train_error 24.38% test_error 33.00%\n",
      "================================1461===================================\n",
      "1461/4000: train_loss: 3.262318372875452 train_error 24.38% test_error 33.00%\n",
      "================================1462===================================\n",
      "1462/4000: train_loss: 3.2614089161949233 train_error 24.25% test_error 33.00%\n",
      "================================1463===================================\n",
      "1463/4000: train_loss: 3.2605038951942698 train_error 24.25% test_error 33.00%\n",
      "================================1464===================================\n",
      "1464/4000: train_loss: 3.2596012062160296 train_error 24.25% test_error 33.00%\n",
      "================================1465===================================\n",
      "1465/4000: train_loss: 3.258698740792461 train_error 24.25% test_error 33.00%\n",
      "================================1466===================================\n",
      "1466/4000: train_loss: 3.2577971964795145 train_error 24.25% test_error 33.00%\n",
      "================================1467===================================\n",
      "1467/4000: train_loss: 3.2568978806911035 train_error 24.25% test_error 33.00%\n",
      "================================1468===================================\n",
      "1468/4000: train_loss: 3.2559998622071 train_error 24.25% test_error 33.00%\n",
      "================================1469===================================\n",
      "1469/4000: train_loss: 3.255102696418762 train_error 24.25% test_error 33.00%\n",
      "================================1470===================================\n",
      "1470/4000: train_loss: 3.2542064863583073 train_error 24.25% test_error 33.00%\n",
      "================================1471===================================\n",
      "1471/4000: train_loss: 3.2533117052912712 train_error 24.25% test_error 33.00%\n",
      "================================1472===================================\n",
      "1472/4000: train_loss: 3.2524182915966957 train_error 24.25% test_error 33.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1473===================================\n",
      "1473/4000: train_loss: 3.251528010931797 train_error 24.25% test_error 33.00%\n",
      "================================1474===================================\n",
      "1474/4000: train_loss: 3.2506403168756512 train_error 24.25% test_error 33.00%\n",
      "================================1475===================================\n",
      "1475/4000: train_loss: 3.2497549588372934 train_error 24.25% test_error 33.00%\n",
      "================================1476===================================\n",
      "1476/4000: train_loss: 3.2488716311007737 train_error 24.25% test_error 33.00%\n",
      "================================1477===================================\n",
      "1477/4000: train_loss: 3.2479894859250633 train_error 24.12% test_error 33.00%\n",
      "================================1478===================================\n",
      "1478/4000: train_loss: 3.2471088500740004 train_error 24.12% test_error 33.00%\n",
      "================================1479===================================\n",
      "1479/4000: train_loss: 3.2462295597139743 train_error 24.12% test_error 33.00%\n",
      "================================1480===================================\n",
      "1480/4000: train_loss: 3.2453505458356817 train_error 24.00% test_error 33.00%\n",
      "================================1481===================================\n",
      "1481/4000: train_loss: 3.2444731281511485 train_error 24.00% test_error 33.50%\n",
      "================================1482===================================\n",
      "1482/4000: train_loss: 3.243597449888475 train_error 24.00% test_error 33.00%\n",
      "================================1483===================================\n",
      "1483/4000: train_loss: 3.242723652957938 train_error 24.00% test_error 33.00%\n",
      "================================1484===================================\n",
      "1484/4000: train_loss: 3.241852018246427 train_error 24.00% test_error 33.00%\n",
      "================================1485===================================\n",
      "1485/4000: train_loss: 3.2409826837759463 train_error 24.00% test_error 33.00%\n",
      "================================1486===================================\n",
      "1486/4000: train_loss: 3.240115281092003 train_error 24.00% test_error 33.00%\n",
      "================================1487===================================\n",
      "1487/4000: train_loss: 3.239249822692946 train_error 24.00% test_error 33.00%\n",
      "================================1488===================================\n",
      "1488/4000: train_loss: 3.238385339207016 train_error 24.12% test_error 33.00%\n",
      "================================1489===================================\n",
      "1489/4000: train_loss: 3.2375209369929507 train_error 24.00% test_error 33.00%\n",
      "================================1490===================================\n",
      "1490/4000: train_loss: 3.236658791755326 train_error 24.00% test_error 33.00%\n",
      "================================1491===================================\n",
      "1491/4000: train_loss: 3.2357992419973014 train_error 24.00% test_error 33.00%\n",
      "================================1492===================================\n",
      "1492/4000: train_loss: 3.234941981635056 train_error 24.00% test_error 33.00%\n",
      "================================1493===================================\n",
      "1493/4000: train_loss: 3.23408667747397 train_error 24.00% test_error 33.00%\n",
      "================================1494===================================\n",
      "1494/4000: train_loss: 3.233232645280659 train_error 24.00% test_error 33.00%\n",
      "================================1495===================================\n",
      "1495/4000: train_loss: 3.232379799084738 train_error 24.00% test_error 32.50%\n",
      "================================1496===================================\n",
      "1496/4000: train_loss: 3.2315285926451907 train_error 24.00% test_error 32.50%\n",
      "================================1497===================================\n",
      "1497/4000: train_loss: 3.2306805149884896 train_error 24.00% test_error 32.50%\n",
      "================================1498===================================\n",
      "1498/4000: train_loss: 3.2298338502831756 train_error 23.88% test_error 32.50%\n",
      "================================1499===================================\n",
      "1499/4000: train_loss: 3.228988200225867 train_error 23.88% test_error 33.00%\n",
      "================================1500===================================\n",
      "1500/4000: train_loss: 3.228144830884412 train_error 23.88% test_error 33.00%\n",
      "================================1501===================================\n",
      "1501/4000: train_loss: 3.2273051289189607 train_error 23.88% test_error 33.00%\n",
      "================================1502===================================\n",
      "1502/4000: train_loss: 3.2264676460158084 train_error 23.88% test_error 33.00%\n",
      "================================1503===================================\n",
      "1503/4000: train_loss: 3.225631877700798 train_error 23.88% test_error 33.00%\n",
      "================================1504===================================\n",
      "1504/4000: train_loss: 3.2247975842794405 train_error 23.88% test_error 33.00%\n",
      "================================1505===================================\n",
      "1505/4000: train_loss: 3.2239649148471656 train_error 23.88% test_error 33.00%\n",
      "================================1506===================================\n",
      "1506/4000: train_loss: 3.223134169946425 train_error 23.88% test_error 33.00%\n",
      "================================1507===================================\n",
      "1507/4000: train_loss: 3.222304467968643 train_error 23.88% test_error 33.00%\n",
      "================================1508===================================\n",
      "1508/4000: train_loss: 3.2214753335295243 train_error 23.88% test_error 32.50%\n",
      "================================1509===================================\n",
      "1509/4000: train_loss: 3.220646942765452 train_error 23.88% test_error 32.50%\n",
      "================================1510===================================\n",
      "1510/4000: train_loss: 3.219819892300293 train_error 23.88% test_error 32.50%\n",
      "================================1511===================================\n",
      "1511/4000: train_loss: 3.2189944769488648 train_error 23.88% test_error 32.50%\n",
      "================================1512===================================\n",
      "1512/4000: train_loss: 3.21817070315592 train_error 23.88% test_error 32.50%\n",
      "================================1513===================================\n",
      "1513/4000: train_loss: 3.2173488057125357 train_error 23.75% test_error 32.50%\n",
      "================================1514===================================\n",
      "1514/4000: train_loss: 3.216528932200745 train_error 23.75% test_error 32.50%\n",
      "================================1515===================================\n",
      "1515/4000: train_loss: 3.2157111733406785 train_error 23.75% test_error 32.50%\n",
      "================================1516===================================\n",
      "1516/4000: train_loss: 3.2148954517720263 train_error 23.62% test_error 32.50%\n",
      "================================1517===================================\n",
      "1517/4000: train_loss: 3.21408188435249 train_error 23.62% test_error 32.50%\n",
      "================================1518===================================\n",
      "1518/4000: train_loss: 3.213270234689116 train_error 23.50% test_error 32.50%\n",
      "================================1519===================================\n",
      "1519/4000: train_loss: 3.2124596199253577 train_error 23.50% test_error 32.50%\n",
      "================================1520===================================\n",
      "1520/4000: train_loss: 3.211650355528109 train_error 23.50% test_error 32.50%\n",
      "================================1521===================================\n",
      "1521/4000: train_loss: 3.2108429038012396 train_error 23.50% test_error 32.50%\n",
      "================================1522===================================\n",
      "1522/4000: train_loss: 3.2100382210500533 train_error 23.50% test_error 32.50%\n",
      "================================1523===================================\n",
      "1523/4000: train_loss: 3.2092367841349914 train_error 23.50% test_error 32.50%\n",
      "================================1524===================================\n",
      "1524/4000: train_loss: 3.2084361480455845 train_error 23.62% test_error 32.50%\n",
      "================================1525===================================\n",
      "1525/4000: train_loss: 3.2076371430046855 train_error 23.62% test_error 32.50%\n",
      "================================1526===================================\n",
      "1526/4000: train_loss: 3.206839872905985 train_error 23.62% test_error 32.50%\n",
      "================================1527===================================\n",
      "1527/4000: train_loss: 3.2060439195344226 train_error 23.62% test_error 32.50%\n",
      "================================1528===================================\n",
      "1528/4000: train_loss: 3.2052495624590662 train_error 23.62% test_error 32.50%\n",
      "================================1529===================================\n",
      "1529/4000: train_loss: 3.2044566633785143 train_error 23.62% test_error 32.00%\n",
      "================================1530===================================\n",
      "1530/4000: train_loss: 3.203664967585355 train_error 23.62% test_error 32.00%\n",
      "================================1531===================================\n",
      "1531/4000: train_loss: 3.202874719835818 train_error 23.75% test_error 32.00%\n",
      "================================1532===================================\n",
      "1532/4000: train_loss: 3.2020861713774504 train_error 23.75% test_error 32.00%\n",
      "================================1533===================================\n",
      "1533/4000: train_loss: 3.201298077739775 train_error 23.75% test_error 32.00%\n",
      "================================1534===================================\n",
      "1534/4000: train_loss: 3.2005111365905035 train_error 23.62% test_error 32.00%\n",
      "================================1535===================================\n",
      "1535/4000: train_loss: 3.199726503840648 train_error 23.62% test_error 32.00%\n",
      "================================1536===================================\n",
      "1536/4000: train_loss: 3.19894261659123 train_error 23.62% test_error 32.00%\n",
      "================================1537===================================\n",
      "1537/4000: train_loss: 3.1981596665922556 train_error 23.62% test_error 32.00%\n",
      "================================1538===================================\n",
      "1538/4000: train_loss: 3.1973788252566004 train_error 23.62% test_error 31.50%\n",
      "================================1539===================================\n",
      "1539/4000: train_loss: 3.1965995027683674 train_error 23.50% test_error 31.50%\n",
      "================================1540===================================\n",
      "1540/4000: train_loss: 3.1958217367669564 train_error 23.62% test_error 31.50%\n",
      "================================1541===================================\n",
      "1541/4000: train_loss: 3.1950455420417714 train_error 23.62% test_error 31.50%\n",
      "================================1542===================================\n",
      "1542/4000: train_loss: 3.1942709162831306 train_error 23.62% test_error 31.50%\n",
      "================================1543===================================\n",
      "1543/4000: train_loss: 3.1934958009095866 train_error 23.62% test_error 31.50%\n",
      "================================1544===================================\n",
      "1544/4000: train_loss: 3.1927219958184283 train_error 23.50% test_error 31.50%\n",
      "================================1545===================================\n",
      "1545/4000: train_loss: 3.1919504511868584 train_error 23.62% test_error 31.50%\n",
      "================================1546===================================\n",
      "1546/4000: train_loss: 3.191181374778971 train_error 23.62% test_error 31.50%\n",
      "================================1547===================================\n",
      "1547/4000: train_loss: 3.190414669425227 train_error 23.50% test_error 31.50%\n",
      "================================1548===================================\n",
      "1548/4000: train_loss: 3.1896499829925595 train_error 23.50% test_error 31.50%\n",
      "================================1549===================================\n",
      "1549/4000: train_loss: 3.188887425321154 train_error 23.50% test_error 31.50%\n",
      "================================1550===================================\n",
      "1550/4000: train_loss: 3.1881264760438355 train_error 23.50% test_error 31.50%\n",
      "================================1551===================================\n",
      "1551/4000: train_loss: 3.187367292563431 train_error 23.50% test_error 31.50%\n",
      "================================1552===================================\n",
      "1552/4000: train_loss: 3.186610287204385 train_error 23.50% test_error 31.50%\n",
      "================================1553===================================\n",
      "1553/4000: train_loss: 3.1858555354038254 train_error 23.38% test_error 31.50%\n",
      "================================1554===================================\n",
      "1554/4000: train_loss: 3.1851025684131313 train_error 23.38% test_error 31.50%\n",
      "================================1555===================================\n",
      "1555/4000: train_loss: 3.184350784798153 train_error 23.50% test_error 31.50%\n",
      "================================1556===================================\n",
      "1556/4000: train_loss: 3.1836005764175206 train_error 23.50% test_error 31.50%\n",
      "================================1557===================================\n",
      "1557/4000: train_loss: 3.182850398980081 train_error 23.50% test_error 31.50%\n",
      "================================1558===================================\n",
      "1558/4000: train_loss: 3.1821014852030203 train_error 23.50% test_error 31.50%\n",
      "================================1559===================================\n",
      "1559/4000: train_loss: 3.1813537255674604 train_error 23.50% test_error 31.50%\n",
      "================================1560===================================\n",
      "1560/4000: train_loss: 3.180607448765077 train_error 23.50% test_error 31.50%\n",
      "================================1561===================================\n",
      "1561/4000: train_loss: 3.1798633060744033 train_error 23.50% test_error 31.50%\n",
      "================================1562===================================\n",
      "1562/4000: train_loss: 3.179121415922418 train_error 23.50% test_error 31.50%\n",
      "================================1563===================================\n",
      "1563/4000: train_loss: 3.1783817870356144 train_error 23.50% test_error 31.50%\n",
      "================================1564===================================\n",
      "1564/4000: train_loss: 3.1776438447786495 train_error 23.50% test_error 31.50%\n",
      "================================1565===================================\n",
      "1565/4000: train_loss: 3.1769075515493754 train_error 23.38% test_error 31.50%\n",
      "================================1566===================================\n",
      "1566/4000: train_loss: 3.1761731306882575 train_error 23.50% test_error 31.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1567===================================\n",
      "1567/4000: train_loss: 3.1754412829037757 train_error 23.50% test_error 31.50%\n",
      "================================1568===================================\n",
      "1568/4000: train_loss: 3.17471071720589 train_error 23.50% test_error 31.50%\n",
      "================================1569===================================\n",
      "1569/4000: train_loss: 3.173981612804346 train_error 23.50% test_error 31.50%\n",
      "================================1570===================================\n",
      "1570/4000: train_loss: 3.173253837591037 train_error 23.50% test_error 31.50%\n",
      "================================1571===================================\n",
      "1571/4000: train_loss: 3.172527033286169 train_error 23.50% test_error 31.50%\n",
      "================================1572===================================\n",
      "1572/4000: train_loss: 3.1718013194156813 train_error 23.50% test_error 31.50%\n",
      "================================1573===================================\n",
      "1573/4000: train_loss: 3.1710777284391223 train_error 23.62% test_error 31.50%\n",
      "================================1574===================================\n",
      "1574/4000: train_loss: 3.1703561944747345 train_error 23.62% test_error 31.50%\n",
      "================================1575===================================\n",
      "1575/4000: train_loss: 3.1696364084538073 train_error 23.62% test_error 31.50%\n",
      "================================1576===================================\n",
      "1576/4000: train_loss: 3.1689186042686925 train_error 23.62% test_error 31.50%\n",
      "================================1577===================================\n",
      "1577/4000: train_loss: 3.168202601503581 train_error 23.50% test_error 31.50%\n",
      "================================1578===================================\n",
      "1578/4000: train_loss: 3.167487864312716 train_error 23.50% test_error 31.50%\n",
      "================================1579===================================\n",
      "1579/4000: train_loss: 3.1667748406901954 train_error 23.50% test_error 31.50%\n",
      "================================1580===================================\n",
      "1580/4000: train_loss: 3.166063306010328 train_error 23.50% test_error 31.50%\n",
      "================================1581===================================\n",
      "1581/4000: train_loss: 3.1653526143264026 train_error 23.50% test_error 31.50%\n",
      "================================1582===================================\n",
      "1582/4000: train_loss: 3.164643804095686 train_error 23.62% test_error 31.50%\n",
      "================================1583===================================\n",
      "1583/4000: train_loss: 3.1639378675958145 train_error 23.62% test_error 31.50%\n",
      "================================1584===================================\n",
      "1584/4000: train_loss: 3.163235517302528 train_error 23.62% test_error 31.50%\n",
      "================================1585===================================\n",
      "1585/4000: train_loss: 3.1625365707976743 train_error 23.62% test_error 31.50%\n",
      "================================1586===================================\n",
      "1586/4000: train_loss: 3.161839892822318 train_error 23.62% test_error 31.50%\n",
      "================================1587===================================\n",
      "1587/4000: train_loss: 3.161145156500861 train_error 23.62% test_error 31.50%\n",
      "================================1588===================================\n",
      "1588/4000: train_loss: 3.160452565192245 train_error 23.50% test_error 31.50%\n",
      "================================1589===================================\n",
      "1589/4000: train_loss: 3.1597621376859024 train_error 23.50% test_error 32.00%\n",
      "================================1590===================================\n",
      "1590/4000: train_loss: 3.159073488852009 train_error 23.50% test_error 32.00%\n",
      "================================1591===================================\n",
      "1591/4000: train_loss: 3.1583863711962477 train_error 23.50% test_error 32.00%\n",
      "================================1592===================================\n",
      "1592/4000: train_loss: 3.157700515091419 train_error 23.50% test_error 32.00%\n",
      "================================1593===================================\n",
      "1593/4000: train_loss: 3.157015730482526 train_error 23.50% test_error 32.00%\n",
      "================================1594===================================\n",
      "1594/4000: train_loss: 3.1563320983527228 train_error 23.50% test_error 32.00%\n",
      "================================1595===================================\n",
      "1595/4000: train_loss: 3.155649963505566 train_error 23.50% test_error 32.00%\n",
      "================================1596===================================\n",
      "1596/4000: train_loss: 3.1549692382011565 train_error 23.50% test_error 32.00%\n",
      "================================1597===================================\n",
      "1597/4000: train_loss: 3.1542903323005884 train_error 23.50% test_error 32.00%\n",
      "================================1598===================================\n",
      "1598/4000: train_loss: 3.1536132484674453 train_error 23.62% test_error 32.00%\n",
      "================================1599===================================\n",
      "1599/4000: train_loss: 3.152939500212669 train_error 23.62% test_error 32.00%\n",
      "================================1600===================================\n",
      "1600/4000: train_loss: 3.1522678105859088 train_error 23.62% test_error 32.00%\n",
      "================================1601===================================\n",
      "1601/4000: train_loss: 3.1515985130658377 train_error 23.62% test_error 32.00%\n",
      "================================1602===================================\n",
      "1602/4000: train_loss: 3.1509314187057313 train_error 23.62% test_error 32.00%\n",
      "================================1603===================================\n",
      "1603/4000: train_loss: 3.1502649280568584 train_error 23.62% test_error 32.00%\n",
      "================================1604===================================\n",
      "1604/4000: train_loss: 3.149599274965003 train_error 23.50% test_error 32.00%\n",
      "================================1605===================================\n",
      "1605/4000: train_loss: 3.1489348179381342 train_error 23.75% test_error 32.00%\n",
      "================================1606===================================\n",
      "1606/4000: train_loss: 3.148272207337431 train_error 23.75% test_error 32.00%\n",
      "================================1607===================================\n",
      "1607/4000: train_loss: 3.147611463582143 train_error 23.75% test_error 32.00%\n",
      "================================1608===================================\n",
      "1608/4000: train_loss: 3.146953726387583 train_error 23.75% test_error 32.00%\n",
      "================================1609===================================\n",
      "1609/4000: train_loss: 3.146296219481155 train_error 23.75% test_error 32.00%\n",
      "================================1610===================================\n",
      "1610/4000: train_loss: 3.1456397388316693 train_error 23.75% test_error 32.00%\n",
      "================================1611===================================\n",
      "1611/4000: train_loss: 3.1449844698049128 train_error 23.75% test_error 32.00%\n",
      "================================1612===================================\n",
      "1612/4000: train_loss: 3.144329689042643 train_error 23.88% test_error 31.50%\n",
      "================================1613===================================\n",
      "1613/4000: train_loss: 3.1436758722597733 train_error 23.88% test_error 31.50%\n",
      "================================1614===================================\n",
      "1614/4000: train_loss: 3.143023105948232 train_error 23.88% test_error 31.50%\n",
      "================================1615===================================\n",
      "1615/4000: train_loss: 3.1423719020327554 train_error 23.75% test_error 31.50%\n",
      "================================1616===================================\n",
      "1616/4000: train_loss: 3.1417220691451804 train_error 23.75% test_error 31.50%\n",
      "================================1617===================================\n",
      "1617/4000: train_loss: 3.1410726413317027 train_error 23.88% test_error 31.50%\n",
      "================================1618===================================\n",
      "1618/4000: train_loss: 3.140424700845033 train_error 23.88% test_error 31.50%\n",
      "================================1619===================================\n",
      "1619/4000: train_loss: 3.1397783381165936 train_error 23.88% test_error 31.50%\n",
      "================================1620===================================\n",
      "1620/4000: train_loss: 3.139133905591443 train_error 23.88% test_error 31.50%\n",
      "================================1621===================================\n",
      "1621/4000: train_loss: 3.1384916655346755 train_error 23.88% test_error 31.50%\n",
      "================================1622===================================\n",
      "1622/4000: train_loss: 3.137852009953931 train_error 23.88% test_error 31.50%\n",
      "================================1623===================================\n",
      "1623/4000: train_loss: 3.1372131397482006 train_error 23.88% test_error 31.50%\n",
      "================================1624===================================\n",
      "1624/4000: train_loss: 3.1365764358825983 train_error 23.88% test_error 31.50%\n",
      "================================1625===================================\n",
      "1625/4000: train_loss: 3.1359420755226166 train_error 23.88% test_error 31.50%\n",
      "================================1626===================================\n",
      "1626/4000: train_loss: 3.135309466440231 train_error 23.88% test_error 31.50%\n",
      "================================1627===================================\n",
      "1627/4000: train_loss: 3.1346785674523563 train_error 23.88% test_error 31.50%\n",
      "================================1628===================================\n",
      "1628/4000: train_loss: 3.1340505999885497 train_error 23.88% test_error 31.50%\n",
      "================================1629===================================\n",
      "1629/4000: train_loss: 3.1334228900074956 train_error 23.75% test_error 31.50%\n",
      "================================1630===================================\n",
      "1630/4000: train_loss: 3.132797407931648 train_error 23.75% test_error 31.50%\n",
      "================================1631===================================\n",
      "1631/4000: train_loss: 3.132171700987965 train_error 23.88% test_error 31.50%\n",
      "================================1632===================================\n",
      "1632/4000: train_loss: 3.131547322487459 train_error 23.88% test_error 31.50%\n",
      "================================1633===================================\n",
      "1633/4000: train_loss: 3.1309242888819426 train_error 24.00% test_error 31.50%\n",
      "================================1634===================================\n",
      "1634/4000: train_loss: 3.1302995182899758 train_error 24.00% test_error 31.50%\n",
      "================================1635===================================\n",
      "1635/4000: train_loss: 3.1296739214472473 train_error 24.00% test_error 31.50%\n",
      "================================1636===================================\n",
      "1636/4000: train_loss: 3.1290501183271404 train_error 24.00% test_error 31.50%\n",
      "================================1637===================================\n",
      "1637/4000: train_loss: 3.1284290095744653 train_error 24.00% test_error 31.50%\n",
      "================================1638===================================\n",
      "1638/4000: train_loss: 3.127811841587536 train_error 24.00% test_error 31.50%\n",
      "================================1639===================================\n",
      "1639/4000: train_loss: 3.1271967474836857 train_error 24.00% test_error 31.50%\n",
      "================================1640===================================\n",
      "1640/4000: train_loss: 3.1265828015236186 train_error 24.12% test_error 31.50%\n",
      "================================1641===================================\n",
      "1641/4000: train_loss: 3.1259682506276296 train_error 24.12% test_error 31.50%\n",
      "================================1642===================================\n",
      "1642/4000: train_loss: 3.1253552864631637 train_error 24.12% test_error 31.50%\n",
      "================================1643===================================\n",
      "1643/4000: train_loss: 3.1247439043829215 train_error 24.12% test_error 31.50%\n",
      "================================1644===================================\n",
      "1644/4000: train_loss: 3.124135443083942 train_error 24.12% test_error 31.50%\n",
      "================================1645===================================\n",
      "1645/4000: train_loss: 3.1235304534807797 train_error 24.12% test_error 31.50%\n",
      "================================1646===================================\n",
      "1646/4000: train_loss: 3.122928415965289 train_error 24.12% test_error 31.50%\n",
      "================================1647===================================\n",
      "1647/4000: train_loss: 3.1223264371789994 train_error 24.25% test_error 31.50%\n",
      "================================1648===================================\n",
      "1648/4000: train_loss: 3.121723951343447 train_error 24.25% test_error 31.50%\n",
      "================================1649===================================\n",
      "1649/4000: train_loss: 3.121121094464324 train_error 24.25% test_error 31.50%\n",
      "================================1650===================================\n",
      "1650/4000: train_loss: 3.120519696418196 train_error 24.25% test_error 31.50%\n",
      "================================1651===================================\n",
      "1651/4000: train_loss: 3.1199191588349637 train_error 24.25% test_error 31.50%\n",
      "================================1652===================================\n",
      "1652/4000: train_loss: 3.119320132355206 train_error 24.25% test_error 31.50%\n",
      "================================1653===================================\n",
      "1653/4000: train_loss: 3.118722552293912 train_error 24.25% test_error 31.00%\n",
      "================================1654===================================\n",
      "1654/4000: train_loss: 3.1181265428103506 train_error 24.38% test_error 31.00%\n",
      "================================1655===================================\n",
      "1655/4000: train_loss: 3.117532438323833 train_error 24.38% test_error 31.00%\n",
      "================================1656===================================\n",
      "1656/4000: train_loss: 3.1169398836838083 train_error 24.38% test_error 31.00%\n",
      "================================1657===================================\n",
      "1657/4000: train_loss: 3.1163492712052534 train_error 24.38% test_error 31.00%\n",
      "================================1658===================================\n",
      "1658/4000: train_loss: 3.1157590932352472 train_error 24.38% test_error 31.00%\n",
      "================================1659===================================\n",
      "1659/4000: train_loss: 3.1151699731219558 train_error 24.38% test_error 31.00%\n",
      "================================1660===================================\n",
      "1660/4000: train_loss: 3.114582361630164 train_error 24.38% test_error 31.00%\n",
      "================================1661===================================\n",
      "1661/4000: train_loss: 3.1139956379076468 train_error 24.38% test_error 31.00%\n",
      "================================1662===================================\n",
      "1662/4000: train_loss: 3.11341034446843 train_error 24.38% test_error 31.00%\n",
      "================================1663===================================\n",
      "1663/4000: train_loss: 3.112826429810375 train_error 24.38% test_error 31.00%\n",
      "================================1664===================================\n",
      "1664/4000: train_loss: 3.112243641410023 train_error 24.38% test_error 31.00%\n",
      "================================1665===================================\n",
      "1665/4000: train_loss: 3.1116631337208673 train_error 24.38% test_error 31.00%\n",
      "================================1666===================================\n",
      "1666/4000: train_loss: 3.1110840892838314 train_error 24.38% test_error 31.00%\n",
      "================================1667===================================\n",
      "1667/4000: train_loss: 3.1105063671851525 train_error 24.38% test_error 31.00%\n",
      "================================1668===================================\n",
      "1668/4000: train_loss: 3.109930924358778 train_error 24.50% test_error 31.00%\n",
      "================================1669===================================\n",
      "1669/4000: train_loss: 3.1093577755894515 train_error 24.50% test_error 31.00%\n",
      "================================1670===================================\n",
      "1670/4000: train_loss: 3.1087856732867656 train_error 24.50% test_error 31.00%\n",
      "================================1671===================================\n",
      "1671/4000: train_loss: 3.1082132730819283 train_error 24.50% test_error 31.00%\n",
      "================================1672===================================\n",
      "1672/4000: train_loss: 3.107641802700236 train_error 24.50% test_error 31.00%\n",
      "================================1673===================================\n",
      "1673/4000: train_loss: 3.1070708641503004 train_error 24.38% test_error 31.00%\n",
      "================================1674===================================\n",
      "1674/4000: train_loss: 3.1065013423748313 train_error 24.38% test_error 31.00%\n",
      "================================1675===================================\n",
      "1675/4000: train_loss: 3.105933831152506 train_error 24.38% test_error 31.00%\n",
      "================================1676===================================\n",
      "1676/4000: train_loss: 3.1053681147051977 train_error 24.38% test_error 31.00%\n",
      "================================1677===================================\n",
      "1677/4000: train_loss: 3.104803329631686 train_error 24.38% test_error 31.00%\n",
      "================================1678===================================\n",
      "1678/4000: train_loss: 3.104240122190677 train_error 24.62% test_error 31.00%\n",
      "================================1679===================================\n",
      "1679/4000: train_loss: 3.1036780221387743 train_error 24.50% test_error 31.00%\n",
      "================================1680===================================\n",
      "1680/4000: train_loss: 3.1031168534746394 train_error 24.50% test_error 31.00%\n",
      "================================1681===================================\n",
      "1681/4000: train_loss: 3.1025573342479764 train_error 24.50% test_error 31.00%\n",
      "================================1682===================================\n",
      "1682/4000: train_loss: 3.1019985231896863 train_error 24.38% test_error 31.00%\n",
      "================================1683===================================\n",
      "1683/4000: train_loss: 3.101441460219212 train_error 24.50% test_error 31.00%\n",
      "================================1684===================================\n",
      "1684/4000: train_loss: 3.100887100938708 train_error 24.50% test_error 31.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1685===================================\n",
      "1685/4000: train_loss: 3.100334306424484 train_error 24.62% test_error 31.00%\n",
      "================================1686===================================\n",
      "1686/4000: train_loss: 3.0997836697008463 train_error 24.62% test_error 31.00%\n",
      "================================1687===================================\n",
      "1687/4000: train_loss: 3.0992322796257215 train_error 24.62% test_error 31.00%\n",
      "================================1688===================================\n",
      "1688/4000: train_loss: 3.098677598480135 train_error 24.62% test_error 31.00%\n",
      "================================1689===================================\n",
      "1689/4000: train_loss: 3.0981238214252516 train_error 24.62% test_error 31.00%\n",
      "================================1690===================================\n",
      "1690/4000: train_loss: 3.0975715379323807 train_error 24.62% test_error 31.00%\n",
      "================================1691===================================\n",
      "1691/4000: train_loss: 3.0970208577159792 train_error 24.62% test_error 31.00%\n",
      "================================1692===================================\n",
      "1692/4000: train_loss: 3.096470945701003 train_error 24.50% test_error 31.00%\n",
      "================================1693===================================\n",
      "1693/4000: train_loss: 3.0959228197811175 train_error 24.50% test_error 31.00%\n",
      "================================1694===================================\n",
      "1694/4000: train_loss: 3.0953768169879914 train_error 24.62% test_error 31.00%\n",
      "================================1695===================================\n",
      "1695/4000: train_loss: 3.0948326694173742 train_error 24.62% test_error 31.00%\n",
      "================================1696===================================\n",
      "1696/4000: train_loss: 3.094289792501368 train_error 24.62% test_error 31.00%\n",
      "================================1697===================================\n",
      "1697/4000: train_loss: 3.093747678622604 train_error 24.62% test_error 31.00%\n",
      "================================1698===================================\n",
      "1698/4000: train_loss: 3.0932047939673066 train_error 24.50% test_error 31.00%\n",
      "================================1699===================================\n",
      "1699/4000: train_loss: 3.0926606245525186 train_error 24.50% test_error 31.00%\n",
      "================================1700===================================\n",
      "1700/4000: train_loss: 3.0921176779828965 train_error 24.50% test_error 31.00%\n",
      "================================1701===================================\n",
      "1701/4000: train_loss: 3.0915773300174627 train_error 24.50% test_error 31.00%\n",
      "================================1702===================================\n",
      "1702/4000: train_loss: 3.091039168536663 train_error 24.50% test_error 31.00%\n",
      "================================1703===================================\n",
      "1703/4000: train_loss: 3.0905023187864575 train_error 24.50% test_error 31.00%\n",
      "================================1704===================================\n",
      "1704/4000: train_loss: 3.0899671952147036 train_error 24.50% test_error 31.00%\n",
      "================================1705===================================\n",
      "1705/4000: train_loss: 3.0894340280815955 train_error 24.50% test_error 31.00%\n",
      "================================1706===================================\n",
      "1706/4000: train_loss: 3.088901680633426 train_error 24.50% test_error 31.00%\n",
      "================================1707===================================\n",
      "1707/4000: train_loss: 3.088371562305838 train_error 24.38% test_error 31.00%\n",
      "================================1708===================================\n",
      "1708/4000: train_loss: 3.0878421456273646 train_error 24.38% test_error 31.00%\n",
      "================================1709===================================\n",
      "1709/4000: train_loss: 3.087313044006005 train_error 24.38% test_error 31.00%\n",
      "================================1710===================================\n",
      "1710/4000: train_loss: 3.0867835709638896 train_error 24.38% test_error 31.00%\n",
      "================================1711===================================\n",
      "1711/4000: train_loss: 3.0862542752642184 train_error 24.50% test_error 31.00%\n",
      "================================1712===================================\n",
      "1712/4000: train_loss: 3.085726038878784 train_error 24.50% test_error 31.00%\n",
      "================================1713===================================\n",
      "1713/4000: train_loss: 3.0851987203024325 train_error 24.50% test_error 31.00%\n",
      "================================1714===================================\n",
      "1714/4000: train_loss: 3.084674405725673 train_error 24.50% test_error 31.00%\n",
      "================================1715===================================\n",
      "1715/4000: train_loss: 3.0841518841776994 train_error 24.50% test_error 31.00%\n",
      "================================1716===================================\n",
      "1716/4000: train_loss: 3.0836304477509113 train_error 24.50% test_error 31.00%\n",
      "================================1717===================================\n",
      "1717/4000: train_loss: 3.0831094764359293 train_error 24.50% test_error 31.00%\n",
      "================================1718===================================\n",
      "1718/4000: train_loss: 3.0825887677446007 train_error 24.50% test_error 31.00%\n",
      "================================1719===================================\n",
      "1719/4000: train_loss: 3.082068342715502 train_error 24.50% test_error 31.00%\n",
      "================================1720===================================\n",
      "1720/4000: train_loss: 3.0815489499643443 train_error 24.50% test_error 31.00%\n",
      "================================1721===================================\n",
      "1721/4000: train_loss: 3.08103045691736 train_error 24.50% test_error 31.00%\n",
      "================================1722===================================\n",
      "1722/4000: train_loss: 3.080513009913266 train_error 24.50% test_error 31.00%\n",
      "================================1723===================================\n",
      "1723/4000: train_loss: 3.0799968993756917 train_error 24.62% test_error 31.00%\n",
      "================================1724===================================\n",
      "1724/4000: train_loss: 3.0794827128481117 train_error 24.62% test_error 31.00%\n",
      "================================1725===================================\n",
      "1725/4000: train_loss: 3.0789685287233444 train_error 24.50% test_error 31.00%\n",
      "================================1726===================================\n",
      "1726/4000: train_loss: 3.0784541566390544 train_error 24.50% test_error 31.00%\n",
      "================================1727===================================\n",
      "1727/4000: train_loss: 3.0779406379628926 train_error 24.50% test_error 31.00%\n",
      "================================1728===================================\n",
      "1728/4000: train_loss: 3.0774281661398706 train_error 24.50% test_error 31.00%\n",
      "================================1729===================================\n",
      "1729/4000: train_loss: 3.076917182570323 train_error 24.50% test_error 31.50%\n",
      "================================1730===================================\n",
      "1730/4000: train_loss: 3.076407098826021 train_error 24.50% test_error 31.50%\n",
      "================================1731===================================\n",
      "1731/4000: train_loss: 3.0758982953801755 train_error 24.50% test_error 31.50%\n",
      "================================1732===================================\n",
      "1732/4000: train_loss: 3.075390462372452 train_error 24.50% test_error 31.50%\n",
      "================================1733===================================\n",
      "1733/4000: train_loss: 3.0748836077563464 train_error 24.50% test_error 31.00%\n",
      "================================1734===================================\n",
      "1734/4000: train_loss: 3.074378250148147 train_error 24.50% test_error 31.00%\n",
      "================================1735===================================\n",
      "1735/4000: train_loss: 3.073873673928902 train_error 24.50% test_error 31.00%\n",
      "================================1736===================================\n",
      "1736/4000: train_loss: 3.073369520194828 train_error 24.50% test_error 31.00%\n",
      "================================1737===================================\n",
      "1737/4000: train_loss: 3.0728655218705536 train_error 24.50% test_error 31.00%\n",
      "================================1738===================================\n",
      "1738/4000: train_loss: 3.0723620818182824 train_error 24.50% test_error 31.00%\n",
      "================================1739===================================\n",
      "1739/4000: train_loss: 3.071859290972352 train_error 24.50% test_error 31.00%\n",
      "================================1740===================================\n",
      "1740/4000: train_loss: 3.0713586441194636 train_error 24.50% test_error 31.00%\n",
      "================================1741===================================\n",
      "1741/4000: train_loss: 3.0708600858645516 train_error 24.50% test_error 31.00%\n",
      "================================1742===================================\n",
      "1742/4000: train_loss: 3.070364993182011 train_error 24.50% test_error 31.00%\n",
      "================================1743===================================\n",
      "1743/4000: train_loss: 3.0698709537461397 train_error 24.50% test_error 31.00%\n",
      "================================1744===================================\n",
      "1744/4000: train_loss: 3.0693779299315063 train_error 24.50% test_error 31.00%\n",
      "================================1745===================================\n",
      "1745/4000: train_loss: 3.0688855044683443 train_error 24.50% test_error 31.00%\n",
      "================================1746===================================\n",
      "1746/4000: train_loss: 3.0683938401145863 train_error 24.62% test_error 31.00%\n",
      "================================1747===================================\n",
      "1747/4000: train_loss: 3.0679038860742005 train_error 24.62% test_error 31.00%\n",
      "================================1748===================================\n",
      "1748/4000: train_loss: 3.0674148071743548 train_error 24.62% test_error 31.00%\n",
      "================================1749===================================\n",
      "1749/4000: train_loss: 3.066926914108917 train_error 24.62% test_error 31.50%\n",
      "================================1750===================================\n",
      "1750/4000: train_loss: 3.0664397259848193 train_error 24.62% test_error 31.50%\n",
      "================================1751===================================\n",
      "1751/4000: train_loss: 3.06595351556316 train_error 24.62% test_error 31.50%\n",
      "================================1752===================================\n",
      "1752/4000: train_loss: 3.0654694372508673 train_error 24.62% test_error 31.50%\n",
      "================================1753===================================\n",
      "1753/4000: train_loss: 3.064986425894312 train_error 24.62% test_error 31.50%\n",
      "================================1754===================================\n",
      "1754/4000: train_loss: 3.064504187176935 train_error 24.62% test_error 31.50%\n",
      "================================1755===================================\n",
      "1755/4000: train_loss: 3.0640206296835095 train_error 24.62% test_error 31.50%\n",
      "================================1756===================================\n",
      "1756/4000: train_loss: 3.063536380678415 train_error 24.62% test_error 31.50%\n",
      "================================1757===================================\n",
      "1757/4000: train_loss: 3.063052930128761 train_error 24.75% test_error 31.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1758===================================\n",
      "1758/4000: train_loss: 3.062569677014835 train_error 24.62% test_error 31.50%\n",
      "================================1759===================================\n",
      "1759/4000: train_loss: 3.0620874796668067 train_error 24.62% test_error 31.50%\n",
      "================================1760===================================\n",
      "1760/4000: train_loss: 3.061604369212873 train_error 24.62% test_error 31.50%\n",
      "================================1761===================================\n",
      "1761/4000: train_loss: 3.061122550982982 train_error 24.75% test_error 31.50%\n",
      "================================1762===================================\n",
      "1762/4000: train_loss: 3.0606418995838616 train_error 24.75% test_error 31.50%\n",
      "================================1763===================================\n",
      "1763/4000: train_loss: 3.0601621476793666 train_error 24.75% test_error 31.50%\n",
      "================================1764===================================\n",
      "1764/4000: train_loss: 3.059683054382913 train_error 24.75% test_error 31.50%\n",
      "================================1765===================================\n",
      "1765/4000: train_loss: 3.059204077785835 train_error 24.75% test_error 31.50%\n",
      "================================1766===================================\n",
      "1766/4000: train_loss: 3.0587263797177 train_error 24.75% test_error 31.00%\n",
      "================================1767===================================\n",
      "1767/4000: train_loss: 3.058246837113984 train_error 24.75% test_error 31.00%\n",
      "================================1768===================================\n",
      "1768/4000: train_loss: 3.057767324484885 train_error 24.75% test_error 31.00%\n",
      "================================1769===================================\n",
      "1769/4000: train_loss: 3.0572869513928893 train_error 24.75% test_error 31.00%\n",
      "================================1770===================================\n",
      "1770/4000: train_loss: 3.0568045428022743 train_error 24.62% test_error 31.00%\n",
      "================================1771===================================\n",
      "1771/4000: train_loss: 3.0563229363691056 train_error 24.62% test_error 31.00%\n",
      "================================1772===================================\n",
      "1772/4000: train_loss: 3.0558418652322143 train_error 24.62% test_error 31.00%\n",
      "================================1773===================================\n",
      "1773/4000: train_loss: 3.055362285268493 train_error 24.62% test_error 31.00%\n",
      "================================1774===================================\n",
      "1774/4000: train_loss: 3.054882091959007 train_error 24.50% test_error 31.00%\n",
      "================================1775===================================\n",
      "1775/4000: train_loss: 3.0544035491999235 train_error 24.50% test_error 31.00%\n",
      "================================1776===================================\n",
      "1776/4000: train_loss: 3.0539277083938945 train_error 24.50% test_error 31.00%\n",
      "================================1777===================================\n",
      "1777/4000: train_loss: 3.0534523243317384 train_error 24.50% test_error 30.50%\n",
      "================================1778===================================\n",
      "1778/4000: train_loss: 3.0529779805336146 train_error 24.50% test_error 30.50%\n",
      "================================1779===================================\n",
      "1779/4000: train_loss: 3.052504125321284 train_error 24.50% test_error 30.50%\n",
      "================================1780===================================\n",
      "1780/4000: train_loss: 3.0520311976689847 train_error 24.50% test_error 30.50%\n",
      "================================1781===================================\n",
      "1781/4000: train_loss: 3.051558775748126 train_error 24.50% test_error 30.00%\n",
      "================================1782===================================\n",
      "1782/4000: train_loss: 3.0510894802585247 train_error 24.50% test_error 30.00%\n",
      "================================1783===================================\n",
      "1783/4000: train_loss: 3.0506223414652047 train_error 24.50% test_error 30.00%\n",
      "================================1784===================================\n",
      "1784/4000: train_loss: 3.0501569636818022 train_error 24.50% test_error 30.00%\n",
      "================================1785===================================\n",
      "1785/4000: train_loss: 3.0496899389801544 train_error 24.50% test_error 30.00%\n",
      "================================1786===================================\n",
      "1786/4000: train_loss: 3.0492160639027133 train_error 24.62% test_error 30.00%\n",
      "================================1787===================================\n",
      "1787/4000: train_loss: 3.048743424676359 train_error 24.75% test_error 30.00%\n",
      "================================1788===================================\n",
      "1788/4000: train_loss: 3.048271020897664 train_error 24.75% test_error 30.00%\n",
      "================================1789===================================\n",
      "1789/4000: train_loss: 3.0477988507458944 train_error 24.62% test_error 30.00%\n",
      "================================1790===================================\n",
      "1790/4000: train_loss: 3.04732765102759 train_error 24.62% test_error 30.00%\n",
      "================================1791===================================\n",
      "1791/4000: train_loss: 3.046858484786935 train_error 24.62% test_error 30.00%\n",
      "================================1792===================================\n",
      "1792/4000: train_loss: 3.0463902645418424 train_error 24.62% test_error 30.00%\n",
      "================================1793===================================\n",
      "1793/4000: train_loss: 3.0459246297972276 train_error 24.62% test_error 30.00%\n",
      "================================1794===================================\n",
      "1794/4000: train_loss: 3.0454593628086153 train_error 24.62% test_error 30.00%\n",
      "================================1795===================================\n",
      "1795/4000: train_loss: 3.0449943853123114 train_error 24.38% test_error 30.00%\n",
      "================================1796===================================\n",
      "1796/4000: train_loss: 3.044529647473246 train_error 24.38% test_error 30.00%\n",
      "================================1797===================================\n",
      "1797/4000: train_loss: 3.044067427455448 train_error 24.38% test_error 30.00%\n",
      "================================1798===================================\n",
      "1798/4000: train_loss: 3.0436059391126036 train_error 24.38% test_error 30.00%\n",
      "================================1799===================================\n",
      "1799/4000: train_loss: 3.043147158524953 train_error 24.25% test_error 30.00%\n",
      "================================1800===================================\n",
      "1800/4000: train_loss: 3.0426900991285217 train_error 24.25% test_error 30.00%\n",
      "================================1801===================================\n",
      "1801/4000: train_loss: 3.0422336594574158 train_error 24.12% test_error 30.00%\n",
      "================================1802===================================\n",
      "1802/4000: train_loss: 3.04177742079366 train_error 24.25% test_error 30.00%\n",
      "================================1803===================================\n",
      "1803/4000: train_loss: 3.0413222034694627 train_error 24.25% test_error 30.00%\n",
      "================================1804===================================\n",
      "1804/4000: train_loss: 3.0408703865529967 train_error 24.25% test_error 30.00%\n",
      "================================1805===================================\n",
      "1805/4000: train_loss: 3.0404211862199007 train_error 24.25% test_error 30.00%\n",
      "================================1806===================================\n",
      "1806/4000: train_loss: 3.0399741605482995 train_error 24.25% test_error 30.00%\n",
      "================================1807===================================\n",
      "1807/4000: train_loss: 3.039527128883637 train_error 24.25% test_error 30.00%\n",
      "================================1808===================================\n",
      "1808/4000: train_loss: 3.0390801815548913 train_error 24.25% test_error 30.00%\n",
      "================================1809===================================\n",
      "1809/4000: train_loss: 3.03863633077126 train_error 24.25% test_error 30.00%\n",
      "================================1810===================================\n",
      "1810/4000: train_loss: 3.0381941781565547 train_error 24.12% test_error 30.00%\n",
      "================================1811===================================\n",
      "1811/4000: train_loss: 3.0377527436427774 train_error 24.12% test_error 30.00%\n",
      "================================1812===================================\n",
      "1812/4000: train_loss: 3.0373124387022106 train_error 24.12% test_error 29.50%\n",
      "================================1813===================================\n",
      "1813/4000: train_loss: 3.036873040571809 train_error 24.25% test_error 29.50%\n",
      "================================1814===================================\n",
      "1814/4000: train_loss: 3.036435403171927 train_error 24.25% test_error 29.50%\n",
      "================================1815===================================\n",
      "1815/4000: train_loss: 3.03599796933122 train_error 24.25% test_error 29.50%\n",
      "================================1816===================================\n",
      "1816/4000: train_loss: 3.035561762484722 train_error 24.25% test_error 29.50%\n",
      "================================1817===================================\n",
      "1817/4000: train_loss: 3.035128380768001 train_error 24.25% test_error 29.50%\n",
      "================================1818===================================\n",
      "1818/4000: train_loss: 3.034696167772636 train_error 24.25% test_error 29.50%\n",
      "================================1819===================================\n",
      "1819/4000: train_loss: 3.0342653365200385 train_error 24.25% test_error 29.50%\n",
      "================================1820===================================\n",
      "1820/4000: train_loss: 3.0338340950896967 train_error 24.25% test_error 29.50%\n",
      "================================1821===================================\n",
      "1821/4000: train_loss: 3.033403400001116 train_error 24.25% test_error 29.50%\n",
      "================================1822===================================\n",
      "1822/4000: train_loss: 3.0329735937388613 train_error 24.25% test_error 29.50%\n",
      "================================1823===================================\n",
      "1823/4000: train_loss: 3.032543111257255 train_error 24.25% test_error 29.50%\n",
      "================================1824===================================\n",
      "1824/4000: train_loss: 3.032112218290567 train_error 24.25% test_error 29.50%\n",
      "================================1825===================================\n",
      "1825/4000: train_loss: 3.031681822007522 train_error 24.12% test_error 29.50%\n",
      "================================1826===================================\n",
      "1826/4000: train_loss: 3.031252518030815 train_error 24.12% test_error 29.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1827===================================\n",
      "1827/4000: train_loss: 3.030823743352667 train_error 24.12% test_error 29.50%\n",
      "================================1828===================================\n",
      "1828/4000: train_loss: 3.030396241797134 train_error 24.12% test_error 29.50%\n",
      "================================1829===================================\n",
      "1829/4000: train_loss: 3.0299699202133343 train_error 24.12% test_error 29.50%\n",
      "================================1830===================================\n",
      "1830/4000: train_loss: 3.0295465579815213 train_error 24.12% test_error 29.50%\n",
      "================================1831===================================\n",
      "1831/4000: train_loss: 3.0291230179788546 train_error 24.25% test_error 29.50%\n",
      "================================1832===================================\n",
      "1832/4000: train_loss: 3.028697060025297 train_error 24.25% test_error 29.50%\n",
      "================================1833===================================\n",
      "1833/4000: train_loss: 3.0282710713800043 train_error 24.25% test_error 29.50%\n",
      "================================1834===================================\n",
      "1834/4000: train_loss: 3.0278451032238083 train_error 24.25% test_error 29.50%\n",
      "================================1835===================================\n",
      "1835/4000: train_loss: 3.0274208848644046 train_error 24.25% test_error 29.50%\n",
      "================================1836===================================\n",
      "1836/4000: train_loss: 3.0269993803603574 train_error 24.25% test_error 29.50%\n",
      "================================1837===================================\n",
      "1837/4000: train_loss: 3.0265815081167964 train_error 24.25% test_error 29.50%\n",
      "================================1838===================================\n",
      "1838/4000: train_loss: 3.026165004922077 train_error 24.25% test_error 29.50%\n",
      "================================1839===================================\n",
      "1839/4000: train_loss: 3.02575035110116 train_error 24.12% test_error 29.50%\n",
      "================================1840===================================\n",
      "1840/4000: train_loss: 3.0253373991698025 train_error 24.12% test_error 29.50%\n",
      "================================1841===================================\n",
      "1841/4000: train_loss: 3.0249242111388592 train_error 24.12% test_error 29.50%\n",
      "================================1842===================================\n",
      "1842/4000: train_loss: 3.024512231708504 train_error 24.12% test_error 29.00%\n",
      "================================1843===================================\n",
      "1843/4000: train_loss: 3.024100815956481 train_error 24.00% test_error 29.00%\n",
      "================================1844===================================\n",
      "1844/4000: train_loss: 3.023688426464796 train_error 24.00% test_error 29.00%\n",
      "================================1845===================================\n",
      "1845/4000: train_loss: 3.0232734043989327 train_error 23.88% test_error 29.00%\n",
      "================================1846===================================\n",
      "1846/4000: train_loss: 3.022859347877093 train_error 23.88% test_error 29.00%\n",
      "================================1847===================================\n",
      "1847/4000: train_loss: 3.022447705012746 train_error 24.00% test_error 29.00%\n",
      "================================1848===================================\n",
      "1848/4000: train_loss: 3.022037659571506 train_error 24.00% test_error 29.00%\n",
      "================================1849===================================\n",
      "1849/4000: train_loss: 3.02162837469019 train_error 24.00% test_error 29.00%\n",
      "================================1850===================================\n",
      "1850/4000: train_loss: 3.021218831492588 train_error 24.12% test_error 29.00%\n",
      "================================1851===================================\n",
      "1851/4000: train_loss: 3.020808072546497 train_error 24.25% test_error 29.00%\n",
      "================================1852===================================\n",
      "1852/4000: train_loss: 3.020398402567953 train_error 24.25% test_error 29.00%\n",
      "================================1853===================================\n",
      "1853/4000: train_loss: 3.019988506906666 train_error 24.25% test_error 29.00%\n",
      "================================1854===================================\n",
      "1854/4000: train_loss: 3.019578686286695 train_error 24.12% test_error 29.00%\n",
      "================================1855===================================\n",
      "1855/4000: train_loss: 3.01917029208038 train_error 24.12% test_error 29.00%\n",
      "================================1856===================================\n",
      "1856/4000: train_loss: 3.018763192044571 train_error 24.12% test_error 29.00%\n",
      "================================1857===================================\n",
      "1857/4000: train_loss: 3.0183567232079804 train_error 24.00% test_error 29.00%\n",
      "================================1858===================================\n",
      "1858/4000: train_loss: 3.017950815632939 train_error 24.00% test_error 29.00%\n",
      "================================1859===================================\n",
      "1859/4000: train_loss: 3.0175446542771533 train_error 24.00% test_error 29.00%\n",
      "================================1860===================================\n",
      "1860/4000: train_loss: 3.0171398394275455 train_error 24.00% test_error 29.00%\n",
      "================================1861===================================\n",
      "1861/4000: train_loss: 3.016734184492379 train_error 24.00% test_error 29.00%\n",
      "================================1862===================================\n",
      "1862/4000: train_loss: 3.016329182302579 train_error 24.00% test_error 29.00%\n",
      "================================1863===================================\n",
      "1863/4000: train_loss: 3.0159250967856495 train_error 24.00% test_error 29.00%\n",
      "================================1864===================================\n",
      "1864/4000: train_loss: 3.015521939191967 train_error 24.00% test_error 29.00%\n",
      "================================1865===================================\n",
      "1865/4000: train_loss: 3.0151171119045466 train_error 24.00% test_error 29.00%\n",
      "================================1866===================================\n",
      "1866/4000: train_loss: 3.0147022807737813 train_error 23.88% test_error 29.00%\n",
      "================================1867===================================\n",
      "1867/4000: train_loss: 3.014287874158472 train_error 23.88% test_error 29.00%\n",
      "================================1868===================================\n",
      "1868/4000: train_loss: 3.013873474057764 train_error 23.75% test_error 29.00%\n",
      "================================1869===================================\n",
      "1869/4000: train_loss: 3.0134588803118096 train_error 23.62% test_error 29.00%\n",
      "================================1870===================================\n",
      "1870/4000: train_loss: 3.013044581436552 train_error 23.62% test_error 29.00%\n",
      "================================1871===================================\n",
      "1871/4000: train_loss: 3.0126294141355903 train_error 23.62% test_error 29.00%\n",
      "================================1872===================================\n",
      "1872/4000: train_loss: 3.012214724784717 train_error 23.62% test_error 29.00%\n",
      "================================1873===================================\n",
      "1873/4000: train_loss: 3.011800405220129 train_error 23.75% test_error 29.00%\n",
      "================================1874===================================\n",
      "1874/4000: train_loss: 3.011386789800599 train_error 23.75% test_error 29.00%\n",
      "================================1875===================================\n",
      "1875/4000: train_loss: 3.010973341600038 train_error 23.75% test_error 29.00%\n",
      "================================1876===================================\n",
      "1876/4000: train_loss: 3.0105597027111797 train_error 23.75% test_error 29.00%\n",
      "================================1877===================================\n",
      "1877/4000: train_loss: 3.0101470634387804 train_error 23.75% test_error 29.00%\n",
      "================================1878===================================\n",
      "1878/4000: train_loss: 3.009735063742846 train_error 23.88% test_error 29.00%\n",
      "================================1879===================================\n",
      "1879/4000: train_loss: 3.009323463048786 train_error 23.88% test_error 28.50%\n",
      "================================1880===================================\n",
      "1880/4000: train_loss: 3.0089156683767215 train_error 23.75% test_error 28.00%\n",
      "================================1881===================================\n",
      "1881/4000: train_loss: 3.0085068658785894 train_error 23.75% test_error 28.00%\n",
      "================================1882===================================\n",
      "1882/4000: train_loss: 3.008099454706535 train_error 23.62% test_error 27.50%\n",
      "================================1883===================================\n",
      "1883/4000: train_loss: 3.007692740042694 train_error 23.50% test_error 27.50%\n",
      "================================1884===================================\n",
      "1884/4000: train_loss: 3.007286785012111 train_error 23.50% test_error 27.50%\n",
      "================================1885===================================\n",
      "1885/4000: train_loss: 3.006881253561005 train_error 23.50% test_error 27.50%\n",
      "================================1886===================================\n",
      "1886/4000: train_loss: 3.0064759416133167 train_error 23.50% test_error 27.50%\n",
      "================================1887===================================\n",
      "1887/4000: train_loss: 3.006071000443771 train_error 23.50% test_error 27.50%\n",
      "================================1888===================================\n",
      "1888/4000: train_loss: 3.0056662135431544 train_error 23.50% test_error 27.50%\n",
      "================================1889===================================\n",
      "1889/4000: train_loss: 3.0052609933260825 train_error 23.50% test_error 27.50%\n",
      "================================1890===================================\n",
      "1890/4000: train_loss: 3.0048546961229294 train_error 23.50% test_error 27.50%\n",
      "================================1891===================================\n",
      "1891/4000: train_loss: 3.0044481221958996 train_error 23.50% test_error 27.50%\n",
      "================================1892===================================\n",
      "1892/4000: train_loss: 3.0040350629435855 train_error 23.50% test_error 27.50%\n",
      "================================1893===================================\n",
      "1893/4000: train_loss: 3.0036196899972856 train_error 23.50% test_error 27.50%\n",
      "================================1894===================================\n",
      "1894/4000: train_loss: 3.0032031856011603 train_error 23.50% test_error 27.50%\n",
      "================================1895===================================\n",
      "1895/4000: train_loss: 3.0027862344682217 train_error 23.50% test_error 27.00%\n",
      "================================1896===================================\n",
      "1896/4000: train_loss: 3.002367883394472 train_error 23.38% test_error 27.00%\n",
      "================================1897===================================\n",
      "1897/4000: train_loss: 3.001951752910391 train_error 23.38% test_error 27.00%\n",
      "================================1898===================================\n",
      "1898/4000: train_loss: 3.0015368750551716 train_error 23.38% test_error 27.00%\n",
      "================================1899===================================\n",
      "1899/4000: train_loss: 3.001122068450786 train_error 23.38% test_error 27.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1900===================================\n",
      "1900/4000: train_loss: 3.000708816437982 train_error 23.38% test_error 27.00%\n",
      "================================1901===================================\n",
      "1901/4000: train_loss: 3.000296199750155 train_error 23.38% test_error 27.00%\n",
      "================================1902===================================\n",
      "1902/4000: train_loss: 2.9998815307067708 train_error 23.38% test_error 27.50%\n",
      "================================1903===================================\n",
      "1903/4000: train_loss: 2.9994675210956485 train_error 23.38% test_error 27.50%\n",
      "================================1904===================================\n",
      "1904/4000: train_loss: 2.9990557323163376 train_error 23.38% test_error 27.50%\n",
      "================================1905===================================\n",
      "1905/4000: train_loss: 2.9986455624550583 train_error 23.38% test_error 27.50%\n",
      "================================1906===================================\n",
      "1906/4000: train_loss: 2.998235339149833 train_error 23.38% test_error 27.50%\n",
      "================================1907===================================\n",
      "1907/4000: train_loss: 2.9978246150305496 train_error 23.38% test_error 27.00%\n",
      "================================1908===================================\n",
      "1908/4000: train_loss: 2.997413756633177 train_error 23.25% test_error 27.00%\n",
      "================================1909===================================\n",
      "1909/4000: train_loss: 2.9970040834462273 train_error 23.25% test_error 27.00%\n",
      "================================1910===================================\n",
      "1910/4000: train_loss: 2.996595575343817 train_error 23.38% test_error 27.00%\n",
      "================================1911===================================\n",
      "1911/4000: train_loss: 2.9961882500816137 train_error 23.38% test_error 27.00%\n",
      "================================1912===================================\n",
      "1912/4000: train_loss: 2.9957816482847557 train_error 23.38% test_error 27.00%\n",
      "================================1913===================================\n",
      "1913/4000: train_loss: 2.9953795399656515 train_error 23.38% test_error 27.00%\n",
      "================================1914===================================\n",
      "1914/4000: train_loss: 2.9949762048199773 train_error 23.50% test_error 27.00%\n",
      "================================1915===================================\n",
      "1915/4000: train_loss: 2.9945740401605145 train_error 23.50% test_error 27.00%\n",
      "================================1916===================================\n",
      "1916/4000: train_loss: 2.994173072655685 train_error 23.50% test_error 27.00%\n",
      "================================1917===================================\n",
      "1917/4000: train_loss: 2.993772586071864 train_error 23.50% test_error 27.00%\n",
      "================================1918===================================\n",
      "1918/4000: train_loss: 2.9933717979025096 train_error 23.50% test_error 27.00%\n",
      "================================1919===================================\n",
      "1919/4000: train_loss: 2.9929697507480157 train_error 23.50% test_error 27.00%\n",
      "================================1920===================================\n",
      "1920/4000: train_loss: 2.9925670650368557 train_error 23.50% test_error 27.00%\n",
      "================================1921===================================\n",
      "1921/4000: train_loss: 2.992165184663609 train_error 23.50% test_error 27.00%\n",
      "================================1922===================================\n",
      "1922/4000: train_loss: 2.9917644355306403 train_error 23.38% test_error 27.50%\n",
      "================================1923===================================\n",
      "1923/4000: train_loss: 2.9913642241992053 train_error 23.38% test_error 27.50%\n",
      "================================1924===================================\n",
      "1924/4000: train_loss: 2.9909648591838778 train_error 23.38% test_error 27.50%\n",
      "================================1925===================================\n",
      "1925/4000: train_loss: 2.9905655608978123 train_error 23.62% test_error 27.50%\n",
      "================================1926===================================\n",
      "1926/4000: train_loss: 2.9901661970699207 train_error 23.75% test_error 27.50%\n",
      "================================1927===================================\n",
      "1927/4000: train_loss: 2.989767727414146 train_error 23.75% test_error 27.00%\n",
      "================================1928===================================\n",
      "1928/4000: train_loss: 2.989369638012722 train_error 23.62% test_error 27.00%\n",
      "================================1929===================================\n",
      "1929/4000: train_loss: 2.9889715824741874 train_error 23.50% test_error 27.00%\n",
      "================================1930===================================\n",
      "1930/4000: train_loss: 2.9885725017217917 train_error 23.50% test_error 27.00%\n",
      "================================1931===================================\n",
      "1931/4000: train_loss: 2.9881734278472143 train_error 23.25% test_error 27.00%\n",
      "================================1932===================================\n",
      "1932/4000: train_loss: 2.9877747795311733 train_error 23.25% test_error 27.00%\n",
      "================================1933===================================\n",
      "1933/4000: train_loss: 2.9873760212259364 train_error 23.25% test_error 27.00%\n",
      "================================1934===================================\n",
      "1934/4000: train_loss: 2.9869763255724684 train_error 23.25% test_error 27.00%\n",
      "================================1935===================================\n",
      "1935/4000: train_loss: 2.986580151086673 train_error 23.25% test_error 27.00%\n",
      "================================1936===================================\n",
      "1936/4000: train_loss: 2.986183999329805 train_error 23.38% test_error 27.00%\n",
      "================================1937===================================\n",
      "1937/4000: train_loss: 2.9857879262138156 train_error 23.38% test_error 27.00%\n",
      "================================1938===================================\n",
      "1938/4000: train_loss: 2.985391399487853 train_error 23.38% test_error 26.50%\n",
      "================================1939===================================\n",
      "1939/4000: train_loss: 2.984994429876097 train_error 23.38% test_error 26.50%\n",
      "================================1940===================================\n",
      "1940/4000: train_loss: 2.984597722524777 train_error 23.38% test_error 26.50%\n",
      "================================1941===================================\n",
      "1941/4000: train_loss: 2.9842015421576797 train_error 23.38% test_error 26.50%\n",
      "================================1942===================================\n",
      "1942/4000: train_loss: 2.9838059089751914 train_error 23.38% test_error 26.50%\n",
      "================================1943===================================\n",
      "1943/4000: train_loss: 2.9834112884895876 train_error 23.38% test_error 26.00%\n",
      "================================1944===================================\n",
      "1944/4000: train_loss: 2.983019476667978 train_error 23.38% test_error 25.50%\n",
      "================================1945===================================\n",
      "1945/4000: train_loss: 2.982628243882209 train_error 23.25% test_error 25.50%\n",
      "================================1946===================================\n",
      "1946/4000: train_loss: 2.982237685332075 train_error 23.25% test_error 25.50%\n",
      "================================1947===================================\n",
      "1947/4000: train_loss: 2.9818451161729174 train_error 23.25% test_error 25.50%\n",
      "================================1948===================================\n",
      "1948/4000: train_loss: 2.9814526427024974 train_error 23.25% test_error 25.50%\n",
      "================================1949===================================\n",
      "1949/4000: train_loss: 2.981060188463889 train_error 23.25% test_error 25.50%\n",
      "================================1950===================================\n",
      "1950/4000: train_loss: 2.98066868620459 train_error 23.25% test_error 25.50%\n",
      "================================1951===================================\n",
      "1951/4000: train_loss: 2.980279865558259 train_error 23.25% test_error 25.50%\n",
      "================================1952===================================\n",
      "1952/4000: train_loss: 2.9798921772744507 train_error 23.38% test_error 25.50%\n",
      "================================1953===================================\n",
      "1953/4000: train_loss: 2.979507786845789 train_error 23.38% test_error 25.00%\n",
      "================================1954===================================\n",
      "1954/4000: train_loss: 2.9791232291283083 train_error 23.38% test_error 25.00%\n",
      "================================1955===================================\n",
      "1955/4000: train_loss: 2.978737947354093 train_error 23.38% test_error 25.00%\n",
      "================================1956===================================\n",
      "1956/4000: train_loss: 2.978352590696886 train_error 23.38% test_error 25.00%\n",
      "================================1957===================================\n",
      "1957/4000: train_loss: 2.97796871278435 train_error 23.38% test_error 25.00%\n",
      "================================1958===================================\n",
      "1958/4000: train_loss: 2.9775846849335355 train_error 23.38% test_error 25.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1959===================================\n",
      "1959/4000: train_loss: 2.9772009568475184 train_error 23.38% test_error 25.50%\n",
      "================================1960===================================\n",
      "1960/4000: train_loss: 2.976817264282145 train_error 23.38% test_error 25.50%\n",
      "================================1961===================================\n",
      "1961/4000: train_loss: 2.97643523984123 train_error 23.50% test_error 25.00%\n",
      "================================1962===================================\n",
      "1962/4000: train_loss: 2.9760540379630402 train_error 23.38% test_error 25.00%\n",
      "================================1963===================================\n",
      "1963/4000: train_loss: 2.9756730049382893 train_error 23.38% test_error 25.00%\n",
      "================================1964===================================\n",
      "1964/4000: train_loss: 2.9752923342073334 train_error 23.38% test_error 25.00%\n",
      "================================1965===================================\n",
      "1965/4000: train_loss: 2.974911210923456 train_error 23.38% test_error 25.00%\n",
      "================================1966===================================\n",
      "1966/4000: train_loss: 2.974529734114185 train_error 23.50% test_error 25.00%\n",
      "================================1967===================================\n",
      "1967/4000: train_loss: 2.9741491671931 train_error 23.50% test_error 25.00%\n",
      "================================1968===================================\n",
      "1968/4000: train_loss: 2.973768673851155 train_error 23.50% test_error 25.00%\n",
      "================================1969===================================\n",
      "1969/4000: train_loss: 2.9733894647611305 train_error 23.50% test_error 25.00%\n",
      "================================1970===================================\n",
      "1970/4000: train_loss: 2.9730081863841042 train_error 23.50% test_error 25.00%\n",
      "================================1971===================================\n",
      "1971/4000: train_loss: 2.9726231514755637 train_error 23.50% test_error 25.00%\n",
      "================================1972===================================\n",
      "1972/4000: train_loss: 2.972235786980018 train_error 23.50% test_error 25.00%\n",
      "================================1973===================================\n",
      "1973/4000: train_loss: 2.9718450791295616 train_error 23.50% test_error 25.00%\n",
      "================================1974===================================\n",
      "1974/4000: train_loss: 2.971451420891099 train_error 23.38% test_error 25.00%\n",
      "================================1975===================================\n",
      "1975/4000: train_loss: 2.971048306203447 train_error 23.25% test_error 25.00%\n",
      "================================1976===================================\n",
      "1976/4000: train_loss: 2.970641269814223 train_error 23.12% test_error 25.00%\n",
      "================================1977===================================\n",
      "1977/4000: train_loss: 2.9702334279380738 train_error 23.12% test_error 25.00%\n",
      "================================1978===================================\n",
      "1978/4000: train_loss: 2.969825201490894 train_error 23.12% test_error 25.00%\n",
      "================================1979===================================\n",
      "1979/4000: train_loss: 2.9694170851120725 train_error 23.12% test_error 25.00%\n",
      "================================1980===================================\n",
      "1980/4000: train_loss: 2.9690101605514068 train_error 23.12% test_error 25.00%\n",
      "================================1981===================================\n",
      "1981/4000: train_loss: 2.9686059526726605 train_error 23.12% test_error 25.00%\n",
      "================================1982===================================\n",
      "1982/4000: train_loss: 2.968204898061231 train_error 23.12% test_error 25.00%\n",
      "================================1983===================================\n",
      "1983/4000: train_loss: 2.9678052462264897 train_error 23.12% test_error 25.00%\n",
      "================================1984===================================\n",
      "1984/4000: train_loss: 2.9674048956763 train_error 23.12% test_error 25.00%\n",
      "================================1985===================================\n",
      "1985/4000: train_loss: 2.9670045715896416 train_error 23.12% test_error 25.00%\n",
      "================================1986===================================\n",
      "1986/4000: train_loss: 2.9666032575210557 train_error 23.12% test_error 25.00%\n",
      "================================1987===================================\n",
      "1987/4000: train_loss: 2.966202954463661 train_error 23.00% test_error 25.00%\n",
      "================================1988===================================\n",
      "1988/4000: train_loss: 2.965800218642689 train_error 23.00% test_error 25.00%\n",
      "================================1989===================================\n",
      "1989/4000: train_loss: 2.965395980766043 train_error 23.00% test_error 25.00%\n",
      "================================1990===================================\n",
      "1990/4000: train_loss: 2.964990338124335 train_error 23.00% test_error 25.00%\n",
      "================================1991===================================\n",
      "1991/4000: train_loss: 2.964585192734376 train_error 22.88% test_error 25.00%\n",
      "================================1992===================================\n",
      "1992/4000: train_loss: 2.9641821436258033 train_error 22.88% test_error 25.00%\n",
      "================================1993===================================\n",
      "1993/4000: train_loss: 2.963776152748615 train_error 22.88% test_error 25.00%\n",
      "================================1994===================================\n",
      "1994/4000: train_loss: 2.9633651025034484 train_error 23.00% test_error 25.00%\n",
      "================================1995===================================\n",
      "1995/4000: train_loss: 2.962954137967899 train_error 23.00% test_error 25.50%\n",
      "================================1996===================================\n",
      "1996/4000: train_loss: 2.9625434032548217 train_error 23.12% test_error 25.50%\n",
      "================================1997===================================\n",
      "1997/4000: train_loss: 2.9621318045444784 train_error 23.12% test_error 25.50%\n",
      "================================1998===================================\n",
      "1998/4000: train_loss: 2.961718073706143 train_error 23.12% test_error 25.50%\n",
      "================================1999===================================\n",
      "1999/4000: train_loss: 2.961306209545582 train_error 23.25% test_error 25.50%\n",
      "================================2000===================================\n",
      "2000/4000: train_loss: 2.9608937058318405 train_error 23.25% test_error 25.50%\n",
      "================================2001===================================\n",
      "2001/4000: train_loss: 2.9604816296463836 train_error 23.25% test_error 25.50%\n",
      "================================2002===================================\n",
      "2002/4000: train_loss: 2.9600637821108107 train_error 23.25% test_error 25.50%\n",
      "================================2003===================================\n",
      "2003/4000: train_loss: 2.9596417939662936 train_error 23.25% test_error 25.50%\n",
      "================================2004===================================\n",
      "2004/4000: train_loss: 2.959221273497678 train_error 23.25% test_error 25.50%\n",
      "================================2005===================================\n",
      "2005/4000: train_loss: 2.9588007437158375 train_error 23.25% test_error 25.50%\n",
      "================================2006===================================\n",
      "2006/4000: train_loss: 2.9583815217902885 train_error 23.25% test_error 25.50%\n",
      "================================2007===================================\n",
      "2007/4000: train_loss: 2.9579643434099854 train_error 23.25% test_error 25.00%\n",
      "================================2008===================================\n",
      "2008/4000: train_loss: 2.95754908086732 train_error 23.25% test_error 25.00%\n",
      "================================2009===================================\n",
      "2009/4000: train_loss: 2.9571345875784756 train_error 23.12% test_error 25.00%\n",
      "================================2010===================================\n",
      "2010/4000: train_loss: 2.956721694455482 train_error 23.25% test_error 25.00%\n",
      "================================2011===================================\n",
      "2011/4000: train_loss: 2.9563072778703643 train_error 23.25% test_error 25.00%\n",
      "================================2012===================================\n",
      "2012/4000: train_loss: 2.955892645944841 train_error 23.25% test_error 25.00%\n",
      "================================2013===================================\n",
      "2013/4000: train_loss: 2.9554772131657225 train_error 23.25% test_error 25.00%\n",
      "================================2014===================================\n",
      "2014/4000: train_loss: 2.955062108715065 train_error 23.25% test_error 25.50%\n",
      "================================2015===================================\n",
      "2015/4000: train_loss: 2.954647554610856 train_error 23.25% test_error 25.50%\n",
      "================================2016===================================\n",
      "2016/4000: train_loss: 2.9542325995350254 train_error 23.25% test_error 25.50%\n",
      "================================2017===================================\n",
      "2017/4000: train_loss: 2.9538186304783447 train_error 23.25% test_error 25.50%\n",
      "================================2018===================================\n",
      "2018/4000: train_loss: 2.9534042313927786 train_error 23.25% test_error 25.50%\n",
      "================================2019===================================\n",
      "2019/4000: train_loss: 2.952989629013464 train_error 23.25% test_error 25.50%\n",
      "================================2020===================================\n",
      "2020/4000: train_loss: 2.9525747593957927 train_error 23.25% test_error 25.50%\n",
      "================================2021===================================\n",
      "2021/4000: train_loss: 2.9521585170598703 train_error 23.38% test_error 25.50%\n",
      "================================2022===================================\n",
      "2022/4000: train_loss: 2.951742705008946 train_error 23.25% test_error 25.50%\n",
      "================================2023===================================\n",
      "2023/4000: train_loss: 2.9513265111623332 train_error 23.12% test_error 25.50%\n",
      "================================2024===================================\n",
      "2024/4000: train_loss: 2.950910255620256 train_error 23.12% test_error 25.50%\n",
      "================================2025===================================\n",
      "2025/4000: train_loss: 2.9504952935175974 train_error 23.12% test_error 25.50%\n",
      "================================2026===================================\n",
      "2026/4000: train_loss: 2.9500829435698686 train_error 23.12% test_error 25.50%\n",
      "================================2027===================================\n",
      "2027/4000: train_loss: 2.9496724440390247 train_error 23.12% test_error 25.50%\n",
      "================================2028===================================\n",
      "2028/4000: train_loss: 2.949260549554601 train_error 23.12% test_error 25.50%\n",
      "================================2029===================================\n",
      "2029/4000: train_loss: 2.948849583049305 train_error 23.12% test_error 25.50%\n",
      "================================2030===================================\n",
      "2030/4000: train_loss: 2.948441247208975 train_error 23.00% test_error 25.50%\n",
      "================================2031===================================\n",
      "2031/4000: train_loss: 2.9480343515705316 train_error 23.00% test_error 25.50%\n",
      "================================2032===================================\n",
      "2032/4000: train_loss: 2.947628428861499 train_error 23.12% test_error 25.50%\n",
      "================================2033===================================\n",
      "2033/4000: train_loss: 2.9472233121469618 train_error 23.00% test_error 25.50%\n",
      "================================2034===================================\n",
      "2034/4000: train_loss: 2.946819155779667 train_error 23.00% test_error 25.50%\n",
      "================================2035===================================\n",
      "2035/4000: train_loss: 2.946413924829103 train_error 23.00% test_error 25.50%\n",
      "================================2036===================================\n",
      "2036/4000: train_loss: 2.9460057550668717 train_error 23.00% test_error 25.50%\n",
      "================================2037===================================\n",
      "2037/4000: train_loss: 2.945597692709416 train_error 23.12% test_error 25.50%\n",
      "================================2038===================================\n",
      "2038/4000: train_loss: 2.9451923787640406 train_error 23.00% test_error 25.50%\n",
      "================================2039===================================\n",
      "2039/4000: train_loss: 2.9447887998772786 train_error 22.88% test_error 25.50%\n",
      "================================2040===================================\n",
      "2040/4000: train_loss: 2.9443857444170862 train_error 22.88% test_error 25.50%\n",
      "================================2041===================================\n",
      "2041/4000: train_loss: 2.9439815298235046 train_error 22.88% test_error 25.50%\n",
      "================================2042===================================\n",
      "2042/4000: train_loss: 2.943576274216175 train_error 22.88% test_error 25.50%\n",
      "================================2043===================================\n",
      "2043/4000: train_loss: 2.943169825766235 train_error 22.88% test_error 25.50%\n",
      "================================2044===================================\n",
      "2044/4000: train_loss: 2.9427619386836885 train_error 22.88% test_error 25.50%\n",
      "================================2045===================================\n",
      "2045/4000: train_loss: 2.9423533969977873 train_error 22.88% test_error 25.50%\n",
      "================================2046===================================\n",
      "2046/4000: train_loss: 2.941943225422874 train_error 22.75% test_error 25.50%\n",
      "================================2047===================================\n",
      "2047/4000: train_loss: 2.941533475993201 train_error 22.75% test_error 25.50%\n",
      "================================2048===================================\n",
      "2048/4000: train_loss: 2.941123733557761 train_error 22.62% test_error 25.50%\n",
      "================================2049===================================\n",
      "2049/4000: train_loss: 2.9407145035313444 train_error 22.62% test_error 25.50%\n",
      "================================2050===================================\n",
      "2050/4000: train_loss: 2.9403045753808694 train_error 22.62% test_error 25.50%\n",
      "================================2051===================================\n",
      "2051/4000: train_loss: 2.939894409952685 train_error 22.62% test_error 25.50%\n",
      "================================2052===================================\n",
      "2052/4000: train_loss: 2.93948385396041 train_error 22.75% test_error 25.50%\n",
      "================================2053===================================\n",
      "2053/4000: train_loss: 2.9390714938333256 train_error 22.75% test_error 25.50%\n",
      "================================2054===================================\n",
      "2054/4000: train_loss: 2.938659198153764 train_error 22.75% test_error 25.50%\n",
      "================================2055===================================\n",
      "2055/4000: train_loss: 2.9382497619837524 train_error 22.75% test_error 25.50%\n",
      "================================2056===================================\n",
      "2056/4000: train_loss: 2.93784278227482 train_error 22.50% test_error 25.50%\n",
      "================================2057===================================\n",
      "2057/4000: train_loss: 2.937436569952406 train_error 22.50% test_error 25.50%\n",
      "================================2058===================================\n",
      "2058/4000: train_loss: 2.937028258857317 train_error 22.50% test_error 25.50%\n",
      "================================2059===================================\n",
      "2059/4000: train_loss: 2.9366191170178353 train_error 22.50% test_error 25.50%\n",
      "================================2060===================================\n",
      "2060/4000: train_loss: 2.9362081244494767 train_error 22.50% test_error 25.50%\n",
      "================================2061===================================\n",
      "2061/4000: train_loss: 2.935803467105143 train_error 22.50% test_error 25.50%\n",
      "================================2062===================================\n",
      "2062/4000: train_loss: 2.9354002947406843 train_error 22.62% test_error 25.50%\n",
      "================================2063===================================\n",
      "2063/4000: train_loss: 2.9349929599184543 train_error 22.62% test_error 25.50%\n",
      "================================2064===================================\n",
      "2064/4000: train_loss: 2.9345758493803444 train_error 22.62% test_error 25.50%\n",
      "================================2065===================================\n",
      "2065/4000: train_loss: 2.934160223328509 train_error 22.62% test_error 25.50%\n",
      "================================2066===================================\n",
      "2066/4000: train_loss: 2.933744349996559 train_error 22.62% test_error 25.50%\n",
      "================================2067===================================\n",
      "2067/4000: train_loss: 2.9333284396585078 train_error 22.62% test_error 25.50%\n",
      "================================2068===================================\n",
      "2068/4000: train_loss: 2.932912311861292 train_error 22.50% test_error 25.50%\n",
      "================================2069===================================\n",
      "2069/4000: train_loss: 2.9324958217749373 train_error 22.62% test_error 25.50%\n",
      "================================2070===================================\n",
      "2070/4000: train_loss: 2.9320808937307445 train_error 22.62% test_error 25.50%\n",
      "================================2071===================================\n",
      "2071/4000: train_loss: 2.931667244341224 train_error 22.62% test_error 25.50%\n",
      "================================2072===================================\n",
      "2072/4000: train_loss: 2.93125362996012 train_error 22.62% test_error 25.50%\n",
      "================================2073===================================\n",
      "2073/4000: train_loss: 2.9308417247142637 train_error 22.62% test_error 25.50%\n",
      "================================2074===================================\n",
      "2074/4000: train_loss: 2.930430350084789 train_error 22.62% test_error 25.50%\n",
      "================================2075===================================\n",
      "2075/4000: train_loss: 2.9300191415846344 train_error 22.62% test_error 25.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2076===================================\n",
      "2076/4000: train_loss: 2.9296046299673617 train_error 22.62% test_error 25.00%\n",
      "================================2077===================================\n",
      "2077/4000: train_loss: 2.92919059954118 train_error 22.62% test_error 25.00%\n",
      "================================2078===================================\n",
      "2078/4000: train_loss: 2.9287759127840403 train_error 22.62% test_error 25.00%\n",
      "================================2079===================================\n",
      "2079/4000: train_loss: 2.928360049105249 train_error 22.62% test_error 25.00%\n",
      "================================2080===================================\n",
      "2080/4000: train_loss: 2.9279427682375534 train_error 22.62% test_error 25.00%\n",
      "================================2081===================================\n",
      "2081/4000: train_loss: 2.927522192322649 train_error 22.62% test_error 25.00%\n",
      "================================2082===================================\n",
      "2082/4000: train_loss: 2.9270985592808576 train_error 22.62% test_error 25.00%\n",
      "================================2083===================================\n",
      "2083/4000: train_loss: 2.9266702981665733 train_error 22.75% test_error 25.00%\n",
      "================================2084===================================\n",
      "2084/4000: train_loss: 2.9262352697737515 train_error 22.75% test_error 25.00%\n",
      "================================2085===================================\n",
      "2085/4000: train_loss: 2.925793214687146 train_error 22.75% test_error 25.00%\n",
      "================================2086===================================\n",
      "2086/4000: train_loss: 2.9253498438186942 train_error 22.75% test_error 25.00%\n",
      "================================2087===================================\n",
      "2087/4000: train_loss: 2.9249065625388178 train_error 22.75% test_error 25.00%\n",
      "================================2088===================================\n",
      "2088/4000: train_loss: 2.924461453403346 train_error 22.75% test_error 25.00%\n",
      "================================2089===================================\n",
      "2089/4000: train_loss: 2.9240182735398412 train_error 22.75% test_error 25.00%\n",
      "================================2090===================================\n",
      "2090/4000: train_loss: 2.9235746844764794 train_error 22.75% test_error 25.00%\n",
      "================================2091===================================\n",
      "2091/4000: train_loss: 2.9231327558215705 train_error 22.62% test_error 25.00%\n",
      "================================2092===================================\n",
      "2092/4000: train_loss: 2.9226900342665614 train_error 22.62% test_error 25.00%\n",
      "================================2093===================================\n",
      "2093/4000: train_loss: 2.9222474901657556 train_error 22.62% test_error 25.00%\n",
      "================================2094===================================\n",
      "2094/4000: train_loss: 2.921804403825663 train_error 22.62% test_error 25.00%\n",
      "================================2095===================================\n",
      "2095/4000: train_loss: 2.9213595703663304 train_error 22.62% test_error 25.00%\n",
      "================================2096===================================\n",
      "2096/4000: train_loss: 2.9209139844821763 train_error 22.62% test_error 25.00%\n",
      "================================2097===================================\n",
      "2097/4000: train_loss: 2.920469814296812 train_error 22.62% test_error 25.00%\n",
      "================================2098===================================\n",
      "2098/4000: train_loss: 2.9200296788290143 train_error 22.62% test_error 25.00%\n",
      "================================2099===================================\n",
      "2099/4000: train_loss: 2.9195918921055273 train_error 22.62% test_error 25.00%\n",
      "================================2100===================================\n",
      "2100/4000: train_loss: 2.919153984836303 train_error 22.62% test_error 25.00%\n",
      "================================2101===================================\n",
      "2101/4000: train_loss: 2.918711529378779 train_error 22.75% test_error 25.00%\n",
      "================================2102===================================\n",
      "2102/4000: train_loss: 2.9182702784845604 train_error 22.75% test_error 25.00%\n",
      "================================2103===================================\n",
      "2103/4000: train_loss: 2.9178257911000403 train_error 22.62% test_error 25.00%\n",
      "================================2104===================================\n",
      "2104/4000: train_loss: 2.917381168841384 train_error 22.62% test_error 25.00%\n",
      "================================2105===================================\n",
      "2105/4000: train_loss: 2.916936046928167 train_error 22.50% test_error 25.00%\n",
      "================================2106===================================\n",
      "2106/4000: train_loss: 2.916492838631384 train_error 22.50% test_error 25.00%\n",
      "================================2107===================================\n",
      "2107/4000: train_loss: 2.9160485563986 train_error 22.50% test_error 25.00%\n",
      "================================2108===================================\n",
      "2108/4000: train_loss: 2.915602659336291 train_error 22.38% test_error 25.00%\n",
      "================================2109===================================\n",
      "2109/4000: train_loss: 2.91515593778342 train_error 22.50% test_error 25.00%\n",
      "================================2110===================================\n",
      "2110/4000: train_loss: 2.9147033620765432 train_error 22.50% test_error 25.00%\n",
      "================================2111===================================\n",
      "2111/4000: train_loss: 2.9142506545828657 train_error 22.50% test_error 25.00%\n",
      "================================2112===================================\n",
      "2112/4000: train_loss: 2.913798160883598 train_error 22.50% test_error 24.50%\n",
      "================================2113===================================\n",
      "2113/4000: train_loss: 2.913342491793446 train_error 22.62% test_error 24.50%\n",
      "================================2114===================================\n",
      "2114/4000: train_loss: 2.9128858848009256 train_error 22.62% test_error 24.50%\n",
      "================================2115===================================\n",
      "2115/4000: train_loss: 2.9124283005436884 train_error 22.62% test_error 24.50%\n",
      "================================2116===================================\n",
      "2116/4000: train_loss: 2.9119714323105295 train_error 22.62% test_error 24.50%\n",
      "================================2117===================================\n",
      "2117/4000: train_loss: 2.911511750188656 train_error 22.62% test_error 24.50%\n",
      "================================2118===================================\n",
      "2118/4000: train_loss: 2.9110515185305847 train_error 22.50% test_error 24.50%\n",
      "================================2119===================================\n",
      "2119/4000: train_loss: 2.9105925889359785 train_error 22.50% test_error 24.50%\n",
      "================================2120===================================\n",
      "2120/4000: train_loss: 2.910132139734924 train_error 22.50% test_error 24.50%\n",
      "================================2121===================================\n",
      "2121/4000: train_loss: 2.9096712529566138 train_error 22.50% test_error 24.50%\n",
      "================================2122===================================\n",
      "2122/4000: train_loss: 2.9092101908801125 train_error 22.50% test_error 24.50%\n",
      "================================2123===================================\n",
      "2123/4000: train_loss: 2.9087481734342875 train_error 22.50% test_error 24.50%\n",
      "================================2124===================================\n",
      "2124/4000: train_loss: 2.9082841855194417 train_error 22.62% test_error 24.50%\n",
      "================================2125===================================\n",
      "2125/4000: train_loss: 2.907819936480373 train_error 22.62% test_error 24.50%\n",
      "================================2126===================================\n",
      "2126/4000: train_loss: 2.9073557401215657 train_error 22.62% test_error 24.50%\n",
      "================================2127===================================\n",
      "2127/4000: train_loss: 2.9068936623958868 train_error 22.62% test_error 24.50%\n",
      "================================2128===================================\n",
      "2128/4000: train_loss: 2.9064325259346515 train_error 22.62% test_error 24.50%\n",
      "================================2129===================================\n",
      "2129/4000: train_loss: 2.9059717008657753 train_error 22.62% test_error 25.00%\n",
      "================================2130===================================\n",
      "2130/4000: train_loss: 2.9055174637539314 train_error 22.62% test_error 25.00%\n",
      "================================2131===================================\n",
      "2131/4000: train_loss: 2.9050634381873537 train_error 22.62% test_error 25.00%\n",
      "================================2132===================================\n",
      "2132/4000: train_loss: 2.9046120332973078 train_error 22.62% test_error 25.00%\n",
      "================================2133===================================\n",
      "2133/4000: train_loss: 2.904157498334534 train_error 22.62% test_error 25.00%\n",
      "================================2134===================================\n",
      "2134/4000: train_loss: 2.90370446221903 train_error 22.62% test_error 25.00%\n",
      "================================2135===================================\n",
      "2135/4000: train_loss: 2.903251688554883 train_error 22.75% test_error 25.00%\n",
      "================================2136===================================\n",
      "2136/4000: train_loss: 2.902800662685186 train_error 22.75% test_error 25.00%\n",
      "================================2137===================================\n",
      "2137/4000: train_loss: 2.9023504662234334 train_error 22.75% test_error 25.00%\n",
      "================================2138===================================\n",
      "2138/4000: train_loss: 2.9019017347414042 train_error 22.75% test_error 25.00%\n",
      "================================2139===================================\n",
      "2139/4000: train_loss: 2.9014537580450996 train_error 22.75% test_error 25.00%\n",
      "================================2140===================================\n",
      "2140/4000: train_loss: 2.90100760165602 train_error 22.75% test_error 25.00%\n",
      "================================2141===================================\n",
      "2141/4000: train_loss: 2.900562001848593 train_error 22.75% test_error 25.00%\n",
      "================================2142===================================\n",
      "2142/4000: train_loss: 2.900116356136277 train_error 22.75% test_error 25.00%\n",
      "================================2143===================================\n",
      "2143/4000: train_loss: 2.8996698975889013 train_error 22.62% test_error 25.00%\n",
      "================================2144===================================\n",
      "2144/4000: train_loss: 2.8992235937342046 train_error 22.62% test_error 25.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2145===================================\n",
      "2145/4000: train_loss: 2.8987773941969497 train_error 22.62% test_error 25.00%\n",
      "================================2146===================================\n",
      "2146/4000: train_loss: 2.8983333510160447 train_error 22.75% test_error 25.00%\n",
      "================================2147===================================\n",
      "2147/4000: train_loss: 2.897889653835446 train_error 22.75% test_error 25.00%\n",
      "================================2148===================================\n",
      "2148/4000: train_loss: 2.897445391961374 train_error 22.75% test_error 25.00%\n",
      "================================2149===================================\n",
      "2149/4000: train_loss: 2.897001651213505 train_error 22.75% test_error 25.00%\n",
      "================================2150===================================\n",
      "2150/4000: train_loss: 2.8965583480754864 train_error 22.75% test_error 25.00%\n",
      "================================2151===================================\n",
      "2151/4000: train_loss: 2.896113149537705 train_error 22.75% test_error 25.00%\n",
      "================================2152===================================\n",
      "2152/4000: train_loss: 2.895669319694862 train_error 22.75% test_error 25.00%\n",
      "================================2153===================================\n",
      "2153/4000: train_loss: 2.8952251452114433 train_error 22.62% test_error 25.00%\n",
      "================================2154===================================\n",
      "2154/4000: train_loss: 2.894779626494274 train_error 22.62% test_error 25.00%\n",
      "================================2155===================================\n",
      "2155/4000: train_loss: 2.8943322453880684 train_error 22.75% test_error 25.00%\n",
      "================================2156===================================\n",
      "2156/4000: train_loss: 2.893885011509992 train_error 22.75% test_error 25.00%\n",
      "================================2157===================================\n",
      "2157/4000: train_loss: 2.893437165375799 train_error 22.75% test_error 25.00%\n",
      "================================2158===================================\n",
      "2158/4000: train_loss: 2.892988459416665 train_error 22.75% test_error 25.00%\n",
      "================================2159===================================\n",
      "2159/4000: train_loss: 2.8925391690805555 train_error 22.75% test_error 25.00%\n",
      "================================2160===================================\n",
      "2160/4000: train_loss: 2.8920893186191097 train_error 23.00% test_error 25.00%\n",
      "================================2161===================================\n",
      "2161/4000: train_loss: 2.8916398339299487 train_error 23.00% test_error 25.00%\n",
      "================================2162===================================\n",
      "2162/4000: train_loss: 2.891189828482456 train_error 23.00% test_error 25.00%\n",
      "================================2163===================================\n",
      "2163/4000: train_loss: 2.8907422564504666 train_error 23.00% test_error 25.00%\n",
      "================================2164===================================\n",
      "2164/4000: train_loss: 2.8902911324612797 train_error 23.00% test_error 25.00%\n",
      "================================2165===================================\n",
      "2165/4000: train_loss: 2.8898401243053375 train_error 23.00% test_error 25.00%\n",
      "================================2166===================================\n",
      "2166/4000: train_loss: 2.889387568477541 train_error 23.00% test_error 25.00%\n",
      "================================2167===================================\n",
      "2167/4000: train_loss: 2.888933049812913 train_error 23.00% test_error 25.00%\n",
      "================================2168===================================\n",
      "2168/4000: train_loss: 2.888481712336652 train_error 23.00% test_error 24.50%\n",
      "================================2169===================================\n",
      "2169/4000: train_loss: 2.888029892765917 train_error 23.00% test_error 24.50%\n",
      "================================2170===================================\n",
      "2170/4000: train_loss: 2.887575804158114 train_error 23.12% test_error 24.50%\n",
      "================================2171===================================\n",
      "2171/4000: train_loss: 2.8871209695981817 train_error 23.12% test_error 24.50%\n",
      "================================2172===================================\n",
      "2172/4000: train_loss: 2.8866649220045653 train_error 23.12% test_error 24.50%\n",
      "================================2173===================================\n",
      "2173/4000: train_loss: 2.8862107867654414 train_error 23.12% test_error 24.50%\n",
      "================================2174===================================\n",
      "2174/4000: train_loss: 2.8857568994676694 train_error 23.12% test_error 24.50%\n",
      "================================2175===================================\n",
      "2175/4000: train_loss: 2.8853020357247443 train_error 23.12% test_error 24.50%\n",
      "================================2176===================================\n",
      "2176/4000: train_loss: 2.884841019799933 train_error 23.25% test_error 24.50%\n",
      "================================2177===================================\n",
      "2177/4000: train_loss: 2.8843769562942905 train_error 23.25% test_error 24.50%\n",
      "================================2178===================================\n",
      "2178/4000: train_loss: 2.883913381043821 train_error 23.25% test_error 24.50%\n",
      "================================2179===================================\n",
      "2179/4000: train_loss: 2.8834499625256282 train_error 23.25% test_error 24.50%\n",
      "================================2180===================================\n",
      "2180/4000: train_loss: 2.8829863906838 train_error 23.25% test_error 24.50%\n",
      "================================2181===================================\n",
      "2181/4000: train_loss: 2.882523444420658 train_error 23.25% test_error 24.50%\n",
      "================================2182===================================\n",
      "2182/4000: train_loss: 2.8820589868118986 train_error 23.25% test_error 24.50%\n",
      "================================2183===================================\n",
      "2183/4000: train_loss: 2.881594068673439 train_error 23.25% test_error 24.50%\n",
      "================================2184===================================\n",
      "2184/4000: train_loss: 2.8811290490766988 train_error 23.25% test_error 24.50%\n",
      "================================2185===================================\n",
      "2185/4000: train_loss: 2.8806633769953622 train_error 23.25% test_error 24.50%\n",
      "================================2186===================================\n",
      "2186/4000: train_loss: 2.880195986670442 train_error 23.25% test_error 24.50%\n",
      "================================2187===================================\n",
      "2187/4000: train_loss: 2.8797279996983707 train_error 23.25% test_error 24.50%\n",
      "================================2188===================================\n",
      "2188/4000: train_loss: 2.8792610841523856 train_error 23.25% test_error 24.50%\n",
      "================================2189===================================\n",
      "2189/4000: train_loss: 2.878794982112013 train_error 23.25% test_error 24.50%\n",
      "================================2190===================================\n",
      "2190/4000: train_loss: 2.878330693007447 train_error 23.25% test_error 24.50%\n",
      "================================2191===================================\n",
      "2191/4000: train_loss: 2.8778701746556905 train_error 23.25% test_error 24.50%\n",
      "================================2192===================================\n",
      "2192/4000: train_loss: 2.8774092385079713 train_error 23.25% test_error 24.50%\n",
      "================================2193===================================\n",
      "2193/4000: train_loss: 2.8769470054470005 train_error 23.25% test_error 24.50%\n",
      "================================2194===================================\n",
      "2194/4000: train_loss: 2.876483885897324 train_error 23.25% test_error 24.50%\n",
      "================================2195===================================\n",
      "2195/4000: train_loss: 2.876019137012772 train_error 23.25% test_error 24.50%\n",
      "================================2196===================================\n",
      "2196/4000: train_loss: 2.8755520675703887 train_error 23.38% test_error 24.50%\n",
      "================================2197===================================\n",
      "2197/4000: train_loss: 2.8750802692747675 train_error 23.38% test_error 24.50%\n",
      "================================2198===================================\n",
      "2198/4000: train_loss: 2.8746089988294985 train_error 23.38% test_error 24.50%\n",
      "================================2199===================================\n",
      "2199/4000: train_loss: 2.874138028442394 train_error 23.38% test_error 24.50%\n",
      "================================2200===================================\n",
      "2200/4000: train_loss: 2.8736683550826276 train_error 23.25% test_error 24.50%\n",
      "================================2201===================================\n",
      "2201/4000: train_loss: 2.873199327497277 train_error 23.25% test_error 24.50%\n",
      "================================2202===================================\n",
      "2202/4000: train_loss: 2.872730113316793 train_error 23.25% test_error 24.50%\n",
      "================================2203===================================\n",
      "2203/4000: train_loss: 2.872261186160613 train_error 23.25% test_error 24.00%\n",
      "================================2204===================================\n",
      "2204/4000: train_loss: 2.8717899990454314 train_error 23.25% test_error 24.00%\n",
      "================================2205===================================\n",
      "2205/4000: train_loss: 2.87131737123942 train_error 23.25% test_error 24.00%\n",
      "================================2206===================================\n",
      "2206/4000: train_loss: 2.8708431506576018 train_error 23.25% test_error 24.00%\n",
      "================================2207===================================\n",
      "2207/4000: train_loss: 2.8703680939693004 train_error 23.25% test_error 24.00%\n",
      "================================2208===================================\n",
      "2208/4000: train_loss: 2.869892933466472 train_error 23.25% test_error 24.00%\n",
      "================================2209===================================\n",
      "2209/4000: train_loss: 2.869417419866659 train_error 23.25% test_error 24.00%\n",
      "================================2210===================================\n",
      "2210/4000: train_loss: 2.8689397612819447 train_error 23.25% test_error 24.00%\n",
      "================================2211===================================\n",
      "2211/4000: train_loss: 2.8684600086626597 train_error 23.25% test_error 24.00%\n",
      "================================2212===================================\n",
      "2212/4000: train_loss: 2.8679824139573613 train_error 23.25% test_error 24.00%\n",
      "================================2213===================================\n",
      "2213/4000: train_loss: 2.8675080756493845 train_error 23.25% test_error 24.00%\n",
      "================================2214===================================\n",
      "2214/4000: train_loss: 2.8670331896911376 train_error 23.25% test_error 24.00%\n",
      "================================2215===================================\n",
      "2215/4000: train_loss: 2.8665574917267076 train_error 23.25% test_error 24.00%\n",
      "================================2216===================================\n",
      "2216/4000: train_loss: 2.8660777363856322 train_error 23.25% test_error 24.00%\n",
      "================================2217===================================\n",
      "2217/4000: train_loss: 2.865597457401454 train_error 23.25% test_error 24.00%\n",
      "================================2218===================================\n",
      "2218/4000: train_loss: 2.8651159571134484 train_error 23.12% test_error 24.00%\n",
      "================================2219===================================\n",
      "2219/4000: train_loss: 2.864632529260125 train_error 23.12% test_error 24.00%\n",
      "================================2220===================================\n",
      "2220/4000: train_loss: 2.8641503865481353 train_error 23.12% test_error 24.00%\n",
      "================================2221===================================\n",
      "2221/4000: train_loss: 2.863667549977545 train_error 23.12% test_error 24.00%\n",
      "================================2222===================================\n",
      "2222/4000: train_loss: 2.8631845271796923 train_error 23.12% test_error 24.00%\n",
      "================================2223===================================\n",
      "2223/4000: train_loss: 2.8627023918437775 train_error 23.12% test_error 24.50%\n",
      "================================2224===================================\n",
      "2224/4000: train_loss: 2.862219376009889 train_error 23.12% test_error 24.50%\n",
      "================================2225===================================\n",
      "2225/4000: train_loss: 2.8617334792157636 train_error 23.12% test_error 24.50%\n",
      "================================2226===================================\n",
      "2226/4000: train_loss: 2.861244500607718 train_error 23.12% test_error 24.50%\n",
      "================================2227===================================\n",
      "2227/4000: train_loss: 2.8607538204197773 train_error 23.12% test_error 24.50%\n",
      "================================2228===================================\n",
      "2228/4000: train_loss: 2.8602582452725622 train_error 23.12% test_error 24.50%\n",
      "================================2229===================================\n",
      "2229/4000: train_loss: 2.8597522476851007 train_error 23.12% test_error 24.50%\n",
      "================================2230===================================\n",
      "2230/4000: train_loss: 2.859245171856601 train_error 23.12% test_error 24.50%\n",
      "================================2231===================================\n",
      "2231/4000: train_loss: 2.8587362965429204 train_error 23.12% test_error 24.50%\n",
      "================================2232===================================\n",
      "2232/4000: train_loss: 2.8582262538932266 train_error 23.12% test_error 24.50%\n",
      "================================2233===================================\n",
      "2233/4000: train_loss: 2.857715744304005 train_error 23.12% test_error 24.50%\n",
      "================================2234===================================\n",
      "2234/4000: train_loss: 2.8572048198105766 train_error 23.12% test_error 24.50%\n",
      "================================2235===================================\n",
      "2235/4000: train_loss: 2.856693281403277 train_error 23.12% test_error 24.50%\n",
      "================================2236===================================\n",
      "2236/4000: train_loss: 2.856180599178188 train_error 23.12% test_error 25.00%\n",
      "================================2237===================================\n",
      "2237/4000: train_loss: 2.8556696665799244 train_error 23.12% test_error 25.00%\n",
      "================================2238===================================\n",
      "2238/4000: train_loss: 2.855154128766153 train_error 23.12% test_error 25.00%\n",
      "================================2239===================================\n",
      "2239/4000: train_loss: 2.854637216292322 train_error 23.12% test_error 25.00%\n",
      "================================2240===================================\n",
      "2240/4000: train_loss: 2.8541193019016644 train_error 23.12% test_error 25.00%\n",
      "================================2241===================================\n",
      "2241/4000: train_loss: 2.853602048801258 train_error 23.12% test_error 25.00%\n",
      "================================2242===================================\n",
      "2242/4000: train_loss: 2.8530849457741714 train_error 23.12% test_error 25.00%\n",
      "================================2243===================================\n",
      "2243/4000: train_loss: 2.8525680905766784 train_error 23.00% test_error 25.00%\n",
      "================================2244===================================\n",
      "2244/4000: train_loss: 2.8520515791652725 train_error 23.00% test_error 25.00%\n",
      "================================2245===================================\n",
      "2245/4000: train_loss: 2.8515345985209573 train_error 23.00% test_error 25.00%\n",
      "================================2246===================================\n",
      "2246/4000: train_loss: 2.8510168894520027 train_error 23.00% test_error 25.00%\n",
      "================================2247===================================\n",
      "2247/4000: train_loss: 2.85049662434496 train_error 23.00% test_error 25.00%\n",
      "================================2248===================================\n",
      "2248/4000: train_loss: 2.849976418884471 train_error 23.00% test_error 25.00%\n",
      "================================2249===================================\n",
      "2249/4000: train_loss: 2.849456064088736 train_error 23.00% test_error 25.00%\n",
      "================================2250===================================\n",
      "2250/4000: train_loss: 2.8489395395759494 train_error 23.00% test_error 25.00%\n",
      "================================2251===================================\n",
      "2251/4000: train_loss: 2.8484214813052677 train_error 23.00% test_error 25.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2252===================================\n",
      "2252/4000: train_loss: 2.847901823304128 train_error 22.88% test_error 25.00%\n",
      "================================2253===================================\n",
      "2253/4000: train_loss: 2.847380984718911 train_error 22.75% test_error 25.00%\n",
      "================================2254===================================\n",
      "2254/4000: train_loss: 2.8468593318597413 train_error 22.75% test_error 25.00%\n",
      "================================2255===================================\n",
      "2255/4000: train_loss: 2.846337097599171 train_error 22.75% test_error 25.50%\n",
      "================================2256===================================\n",
      "2256/4000: train_loss: 2.845812400786672 train_error 22.75% test_error 25.50%\n",
      "================================2257===================================\n",
      "2257/4000: train_loss: 2.8452858941769223 train_error 22.75% test_error 25.50%\n",
      "================================2258===================================\n",
      "2258/4000: train_loss: 2.844758712747134 train_error 22.75% test_error 25.50%\n",
      "================================2259===================================\n",
      "2259/4000: train_loss: 2.8442295814165846 train_error 22.75% test_error 25.50%\n",
      "================================2260===================================\n",
      "2260/4000: train_loss: 2.8436964266886933 train_error 22.75% test_error 25.00%\n",
      "================================2261===================================\n",
      "2261/4000: train_loss: 2.8431658418802543 train_error 22.75% test_error 25.00%\n",
      "================================2262===================================\n",
      "2262/4000: train_loss: 2.8426335389795714 train_error 22.75% test_error 25.00%\n",
      "================================2263===================================\n",
      "2263/4000: train_loss: 2.8421049617114473 train_error 22.75% test_error 25.00%\n",
      "================================2264===================================\n",
      "2264/4000: train_loss: 2.841572286088485 train_error 22.75% test_error 25.00%\n",
      "================================2265===================================\n",
      "2265/4000: train_loss: 2.841038072735537 train_error 22.75% test_error 25.00%\n",
      "================================2266===================================\n",
      "2266/4000: train_loss: 2.8405037050973623 train_error 22.75% test_error 25.00%\n",
      "================================2267===================================\n",
      "2267/4000: train_loss: 2.839969636700116 train_error 22.62% test_error 24.50%\n",
      "================================2268===================================\n",
      "2268/4000: train_loss: 2.8394333489844574 train_error 22.62% test_error 24.50%\n",
      "================================2269===================================\n",
      "2269/4000: train_loss: 2.8388952630059796 train_error 22.50% test_error 24.50%\n",
      "================================2270===================================\n",
      "2270/4000: train_loss: 2.838352878007572 train_error 22.50% test_error 24.50%\n",
      "================================2271===================================\n",
      "2271/4000: train_loss: 2.8378090577805413 train_error 22.50% test_error 24.50%\n",
      "================================2272===================================\n",
      "2272/4000: train_loss: 2.837262737061828 train_error 22.50% test_error 24.50%\n",
      "================================2273===================================\n",
      "2273/4000: train_loss: 2.8367185037792657 train_error 22.50% test_error 24.50%\n",
      "================================2274===================================\n",
      "2274/4000: train_loss: 2.8361734748189336 train_error 22.50% test_error 24.50%\n",
      "================================2275===================================\n",
      "2275/4000: train_loss: 2.8356285730912356 train_error 22.50% test_error 24.50%\n",
      "================================2276===================================\n",
      "2276/4000: train_loss: 2.835079723172821 train_error 22.50% test_error 24.50%\n",
      "================================2277===================================\n",
      "2277/4000: train_loss: 2.8345275991316887 train_error 22.50% test_error 24.50%\n",
      "================================2278===================================\n",
      "2278/4000: train_loss: 2.8339734494755975 train_error 22.50% test_error 24.50%\n",
      "================================2279===================================\n",
      "2279/4000: train_loss: 2.8334116519615056 train_error 22.50% test_error 24.50%\n",
      "================================2280===================================\n",
      "2280/4000: train_loss: 2.8328460359456953 train_error 22.50% test_error 24.50%\n",
      "================================2281===================================\n",
      "2281/4000: train_loss: 2.832280267626047 train_error 22.50% test_error 24.50%\n",
      "================================2282===================================\n",
      "2282/4000: train_loss: 2.831711935708299 train_error 22.50% test_error 24.50%\n",
      "================================2283===================================\n",
      "2283/4000: train_loss: 2.8311401817318984 train_error 22.50% test_error 24.50%\n",
      "================================2284===================================\n",
      "2284/4000: train_loss: 2.8305660514556803 train_error 22.38% test_error 24.00%\n",
      "================================2285===================================\n",
      "2285/4000: train_loss: 2.8299917346891017 train_error 22.38% test_error 24.00%\n",
      "================================2286===================================\n",
      "2286/4000: train_loss: 2.829417889930774 train_error 22.38% test_error 24.00%\n",
      "================================2287===================================\n",
      "2287/4000: train_loss: 2.8288456504163335 train_error 22.50% test_error 24.00%\n",
      "================================2288===================================\n",
      "2288/4000: train_loss: 2.8282739422703163 train_error 22.50% test_error 24.00%\n",
      "================================2289===================================\n",
      "2289/4000: train_loss: 2.8277045291895044 train_error 22.62% test_error 24.00%\n",
      "================================2290===================================\n",
      "2290/4000: train_loss: 2.8271349349850787 train_error 22.62% test_error 24.00%\n",
      "================================2291===================================\n",
      "2291/4000: train_loss: 2.826564722652547 train_error 22.62% test_error 24.00%\n",
      "================================2292===================================\n",
      "2292/4000: train_loss: 2.82599237217335 train_error 22.62% test_error 24.00%\n",
      "================================2293===================================\n",
      "2293/4000: train_loss: 2.825419542272575 train_error 22.62% test_error 24.00%\n",
      "================================2294===================================\n",
      "2294/4000: train_loss: 2.824844679667149 train_error 22.62% test_error 24.00%\n",
      "================================2295===================================\n",
      "2295/4000: train_loss: 2.8242687613959423 train_error 22.62% test_error 24.00%\n",
      "================================2296===================================\n",
      "2296/4000: train_loss: 2.8236927305767314 train_error 22.62% test_error 24.00%\n",
      "================================2297===================================\n",
      "2297/4000: train_loss: 2.823115812414326 train_error 22.62% test_error 24.00%\n",
      "================================2298===================================\n",
      "2298/4000: train_loss: 2.8225365298683753 train_error 22.62% test_error 24.00%\n",
      "================================2299===================================\n",
      "2299/4000: train_loss: 2.8219629133143465 train_error 22.62% test_error 24.00%\n",
      "================================2300===================================\n",
      "2300/4000: train_loss: 2.8213884965167377 train_error 22.62% test_error 24.00%\n",
      "================================2301===================================\n",
      "2301/4000: train_loss: 2.820811309174169 train_error 22.62% test_error 24.00%\n",
      "================================2302===================================\n",
      "2302/4000: train_loss: 2.820232250888366 train_error 22.62% test_error 24.00%\n",
      "================================2303===================================\n",
      "2303/4000: train_loss: 2.819652026749682 train_error 22.50% test_error 24.00%\n",
      "================================2304===================================\n",
      "2304/4000: train_loss: 2.8190696873585694 train_error 22.50% test_error 24.00%\n",
      "================================2305===================================\n",
      "2305/4000: train_loss: 2.8184849945642054 train_error 22.50% test_error 24.00%\n",
      "================================2306===================================\n",
      "2306/4000: train_loss: 2.817899466268718 train_error 22.50% test_error 24.00%\n",
      "================================2307===================================\n",
      "2307/4000: train_loss: 2.8172959954012184 train_error 22.50% test_error 24.00%\n",
      "================================2308===================================\n",
      "2308/4000: train_loss: 2.816688182465732 train_error 22.50% test_error 24.00%\n",
      "================================2309===================================\n",
      "2309/4000: train_loss: 2.816082841102034 train_error 22.50% test_error 23.50%\n",
      "================================2310===================================\n",
      "2310/4000: train_loss: 2.815477329979185 train_error 22.50% test_error 23.50%\n",
      "================================2311===================================\n",
      "2311/4000: train_loss: 2.8148712601233274 train_error 22.50% test_error 23.50%\n",
      "================================2312===================================\n",
      "2312/4000: train_loss: 2.814264841610566 train_error 22.50% test_error 23.50%\n",
      "================================2313===================================\n",
      "2313/4000: train_loss: 2.8136589180445295 train_error 22.50% test_error 23.50%\n",
      "================================2314===================================\n",
      "2314/4000: train_loss: 2.8130524477455765 train_error 22.50% test_error 23.50%\n",
      "================================2315===================================\n",
      "2315/4000: train_loss: 2.8124445459316485 train_error 22.50% test_error 23.50%\n",
      "================================2316===================================\n",
      "2316/4000: train_loss: 2.8118360695987943 train_error 22.50% test_error 23.50%\n",
      "================================2317===================================\n",
      "2317/4000: train_loss: 2.8112299921200607 train_error 22.50% test_error 23.50%\n",
      "================================2318===================================\n",
      "2318/4000: train_loss: 2.8106246542162263 train_error 22.50% test_error 23.50%\n",
      "================================2319===================================\n",
      "2319/4000: train_loss: 2.810019694310613 train_error 22.50% test_error 23.50%\n",
      "================================2320===================================\n",
      "2320/4000: train_loss: 2.809414246289525 train_error 22.50% test_error 23.50%\n",
      "================================2321===================================\n",
      "2321/4000: train_loss: 2.8088080410449767 train_error 22.50% test_error 23.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2322===================================\n",
      "2322/4000: train_loss: 2.808201874643564 train_error 22.62% test_error 23.50%\n",
      "================================2323===================================\n",
      "2323/4000: train_loss: 2.8075929167424327 train_error 22.62% test_error 23.50%\n",
      "================================2324===================================\n",
      "2324/4000: train_loss: 2.806978226234205 train_error 22.62% test_error 23.50%\n",
      "================================2325===================================\n",
      "2325/4000: train_loss: 2.806364443607163 train_error 22.62% test_error 23.50%\n",
      "================================2326===================================\n",
      "2326/4000: train_loss: 2.805752270917874 train_error 22.62% test_error 23.50%\n",
      "================================2327===================================\n",
      "2327/4000: train_loss: 2.805141224707477 train_error 22.62% test_error 23.50%\n",
      "================================2328===================================\n",
      "2328/4000: train_loss: 2.804526232383214 train_error 22.62% test_error 24.00%\n",
      "================================2329===================================\n",
      "2329/4000: train_loss: 2.803908929368481 train_error 22.75% test_error 24.00%\n",
      "================================2330===================================\n",
      "2330/4000: train_loss: 2.80329089225037 train_error 22.75% test_error 24.00%\n",
      "================================2331===================================\n",
      "2331/4000: train_loss: 2.8026723078731446 train_error 22.75% test_error 24.00%\n",
      "================================2332===================================\n",
      "2332/4000: train_loss: 2.802055032064673 train_error 22.75% test_error 24.00%\n",
      "================================2333===================================\n",
      "2333/4000: train_loss: 2.801437264683191 train_error 22.62% test_error 24.00%\n",
      "================================2334===================================\n",
      "2334/4000: train_loss: 2.800819230475463 train_error 22.62% test_error 24.00%\n",
      "================================2335===================================\n",
      "2335/4000: train_loss: 2.800199052232783 train_error 22.62% test_error 24.00%\n",
      "================================2336===================================\n",
      "2336/4000: train_loss: 2.7995795117551463 train_error 22.62% test_error 24.00%\n",
      "================================2337===================================\n",
      "2337/4000: train_loss: 2.798962118490599 train_error 22.62% test_error 24.00%\n",
      "================================2338===================================\n",
      "2338/4000: train_loss: 2.798347385642119 train_error 22.62% test_error 24.50%\n",
      "================================2339===================================\n",
      "2339/4000: train_loss: 2.797735305172391 train_error 22.62% test_error 24.50%\n",
      "================================2340===================================\n",
      "2340/4000: train_loss: 2.7971253493172115 train_error 22.62% test_error 24.50%\n",
      "================================2341===================================\n",
      "2341/4000: train_loss: 2.796516583219636 train_error 22.62% test_error 24.50%\n",
      "================================2342===================================\n",
      "2342/4000: train_loss: 2.7959071709029377 train_error 22.62% test_error 24.50%\n",
      "================================2343===================================\n",
      "2343/4000: train_loss: 2.795296496553347 train_error 22.50% test_error 24.50%\n",
      "================================2344===================================\n",
      "2344/4000: train_loss: 2.794684718309436 train_error 22.50% test_error 24.50%\n",
      "================================2345===================================\n",
      "2345/4000: train_loss: 2.7940723128500395 train_error 22.62% test_error 24.50%\n",
      "================================2346===================================\n",
      "2346/4000: train_loss: 2.7934583086310885 train_error 22.62% test_error 24.50%\n",
      "================================2347===================================\n",
      "2347/4000: train_loss: 2.7928423899086194 train_error 22.50% test_error 24.50%\n",
      "================================2348===================================\n",
      "2348/4000: train_loss: 2.7922249211673624 train_error 22.50% test_error 24.50%\n",
      "================================2349===================================\n",
      "2349/4000: train_loss: 2.791606450721156 train_error 22.38% test_error 24.50%\n",
      "================================2350===================================\n",
      "2350/4000: train_loss: 2.790988480937667 train_error 22.38% test_error 24.50%\n",
      "================================2351===================================\n",
      "2351/4000: train_loss: 2.7903706886572763 train_error 22.38% test_error 24.50%\n",
      "================================2352===================================\n",
      "2352/4000: train_loss: 2.789751192338299 train_error 22.38% test_error 24.50%\n",
      "================================2353===================================\n",
      "2353/4000: train_loss: 2.7891320785903373 train_error 22.38% test_error 24.50%\n",
      "================================2354===================================\n",
      "2354/4000: train_loss: 2.7885141875455157 train_error 22.38% test_error 24.50%\n",
      "================================2355===================================\n",
      "2355/4000: train_loss: 2.7878982078819536 train_error 22.38% test_error 24.50%\n",
      "================================2356===================================\n",
      "2356/4000: train_loss: 2.7872821148415095 train_error 22.38% test_error 24.50%\n",
      "================================2357===================================\n",
      "2357/4000: train_loss: 2.786665282505565 train_error 22.12% test_error 24.50%\n",
      "================================2358===================================\n",
      "2358/4000: train_loss: 2.7860479990043676 train_error 22.12% test_error 24.50%\n",
      "================================2359===================================\n",
      "2359/4000: train_loss: 2.7854311446845528 train_error 22.12% test_error 24.50%\n",
      "================================2360===================================\n",
      "2360/4000: train_loss: 2.78481627203757 train_error 22.12% test_error 24.50%\n",
      "================================2361===================================\n",
      "2361/4000: train_loss: 2.784202038801741 train_error 22.12% test_error 24.50%\n",
      "================================2362===================================\n",
      "2362/4000: train_loss: 2.7835869889380414 train_error 22.12% test_error 24.50%\n",
      "================================2363===================================\n",
      "2363/4000: train_loss: 2.7829738190863282 train_error 22.12% test_error 24.50%\n",
      "================================2364===================================\n",
      "2364/4000: train_loss: 2.7823580063763074 train_error 22.12% test_error 24.50%\n",
      "================================2365===================================\n",
      "2365/4000: train_loss: 2.7817367475293575 train_error 22.12% test_error 24.00%\n",
      "================================2366===================================\n",
      "2366/4000: train_loss: 2.7811102655110878 train_error 22.12% test_error 24.00%\n",
      "================================2367===================================\n",
      "2367/4000: train_loss: 2.780480506392196 train_error 22.12% test_error 24.00%\n",
      "================================2368===================================\n",
      "2368/4000: train_loss: 2.7798507480300034 train_error 22.12% test_error 24.00%\n",
      "================================2369===================================\n",
      "2369/4000: train_loss: 2.7792205982771705 train_error 22.12% test_error 24.00%\n",
      "================================2370===================================\n",
      "2370/4000: train_loss: 2.778593058725819 train_error 22.12% test_error 24.00%\n",
      "================================2371===================================\n",
      "2371/4000: train_loss: 2.777960907018278 train_error 22.12% test_error 24.00%\n",
      "================================2372===================================\n",
      "2372/4000: train_loss: 2.7773183036362754 train_error 22.12% test_error 23.50%\n",
      "================================2373===================================\n",
      "2373/4000: train_loss: 2.776670667170547 train_error 22.25% test_error 23.50%\n",
      "================================2374===================================\n",
      "2374/4000: train_loss: 2.7760222926037383 train_error 22.25% test_error 23.50%\n",
      "================================2375===================================\n",
      "2375/4000: train_loss: 2.775374691174366 train_error 22.25% test_error 24.00%\n",
      "================================2376===================================\n",
      "2376/4000: train_loss: 2.7747247721953316 train_error 22.38% test_error 24.00%\n",
      "================================2377===================================\n",
      "2377/4000: train_loss: 2.7740743171772917 train_error 22.38% test_error 24.00%\n",
      "================================2378===================================\n",
      "2378/4000: train_loss: 2.77342341643991 train_error 22.25% test_error 24.00%\n",
      "================================2379===================================\n",
      "2379/4000: train_loss: 2.772769663960207 train_error 22.25% test_error 24.00%\n",
      "================================2380===================================\n",
      "2380/4000: train_loss: 2.772112844348885 train_error 22.25% test_error 24.00%\n",
      "================================2381===================================\n",
      "2381/4000: train_loss: 2.7714564702776263 train_error 22.25% test_error 24.00%\n",
      "================================2382===================================\n",
      "2382/4000: train_loss: 2.7708006353932433 train_error 22.25% test_error 24.00%\n",
      "================================2383===================================\n",
      "2383/4000: train_loss: 2.7701444060471845 train_error 22.12% test_error 24.00%\n",
      "================================2384===================================\n",
      "2384/4000: train_loss: 2.769488568478264 train_error 22.12% test_error 24.00%\n",
      "================================2385===================================\n",
      "2385/4000: train_loss: 2.768837409808766 train_error 22.12% test_error 24.00%\n",
      "================================2386===================================\n",
      "2386/4000: train_loss: 2.7681869676429782 train_error 22.12% test_error 24.00%\n",
      "================================2387===================================\n",
      "2387/4000: train_loss: 2.767537797621917 train_error 22.12% test_error 24.00%\n",
      "================================2388===================================\n",
      "2388/4000: train_loss: 2.7668873229040765 train_error 22.12% test_error 24.00%\n",
      "================================2389===================================\n",
      "2389/4000: train_loss: 2.7662369998171927 train_error 22.00% test_error 24.00%\n",
      "================================2390===================================\n",
      "2390/4000: train_loss: 2.7655880826432258 train_error 22.00% test_error 24.50%\n",
      "================================2391===================================\n",
      "2391/4000: train_loss: 2.764938207911327 train_error 22.00% test_error 24.50%\n",
      "================================2392===================================\n",
      "2392/4000: train_loss: 2.764288290359546 train_error 22.00% test_error 24.50%\n",
      "================================2393===================================\n",
      "2393/4000: train_loss: 2.763638866306283 train_error 22.00% test_error 24.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2394===================================\n",
      "2394/4000: train_loss: 2.7629911223100496 train_error 21.88% test_error 24.50%\n",
      "================================2395===================================\n",
      "2395/4000: train_loss: 2.762347571789287 train_error 21.88% test_error 24.50%\n",
      "================================2396===================================\n",
      "2396/4000: train_loss: 2.7617032406316135 train_error 21.88% test_error 24.50%\n",
      "================================2397===================================\n",
      "2397/4000: train_loss: 2.761057107478846 train_error 22.00% test_error 24.50%\n",
      "================================2398===================================\n",
      "2398/4000: train_loss: 2.760413256196771 train_error 22.00% test_error 24.50%\n",
      "================================2399===================================\n",
      "2399/4000: train_loss: 2.7597649248782545 train_error 22.00% test_error 24.50%\n",
      "================================2400===================================\n",
      "2400/4000: train_loss: 2.7591176413954237 train_error 21.88% test_error 24.50%\n",
      "================================2401===================================\n",
      "2401/4000: train_loss: 2.758468121672049 train_error 21.88% test_error 24.50%\n",
      "================================2402===================================\n",
      "2402/4000: train_loss: 2.7578192802309056 train_error 21.88% test_error 24.50%\n",
      "================================2403===================================\n",
      "2403/4000: train_loss: 2.7571707462752237 train_error 22.00% test_error 24.50%\n",
      "================================2404===================================\n",
      "2404/4000: train_loss: 2.756521588105243 train_error 22.00% test_error 24.50%\n",
      "================================2405===================================\n",
      "2405/4000: train_loss: 2.755871960152872 train_error 22.00% test_error 25.00%\n",
      "================================2406===================================\n",
      "2406/4000: train_loss: 2.755224046476651 train_error 22.00% test_error 25.00%\n",
      "================================2407===================================\n",
      "2407/4000: train_loss: 2.754577989957761 train_error 22.00% test_error 25.00%\n",
      "================================2408===================================\n",
      "2408/4000: train_loss: 2.753929843539372 train_error 22.00% test_error 25.00%\n",
      "================================2409===================================\n",
      "2409/4000: train_loss: 2.753281607495155 train_error 22.00% test_error 25.00%\n",
      "================================2410===================================\n",
      "2410/4000: train_loss: 2.7526341085298918 train_error 22.00% test_error 25.00%\n",
      "================================2411===================================\n",
      "2411/4000: train_loss: 2.7519910233304836 train_error 22.00% test_error 25.00%\n",
      "================================2412===================================\n",
      "2412/4000: train_loss: 2.751351642485242 train_error 22.00% test_error 25.00%\n",
      "================================2413===================================\n",
      "2413/4000: train_loss: 2.750708169552963 train_error 22.12% test_error 25.00%\n",
      "================================2414===================================\n",
      "2414/4000: train_loss: 2.750063119244296 train_error 22.12% test_error 25.00%\n",
      "================================2415===================================\n",
      "2415/4000: train_loss: 2.749418928758241 train_error 22.00% test_error 25.00%\n",
      "================================2416===================================\n",
      "2416/4000: train_loss: 2.7487789870356214 train_error 22.00% test_error 25.00%\n",
      "================================2417===================================\n",
      "2417/4000: train_loss: 2.7481450506369582 train_error 22.00% test_error 25.00%\n",
      "================================2418===================================\n",
      "2418/4000: train_loss: 2.747511030642781 train_error 21.88% test_error 25.00%\n",
      "================================2419===================================\n",
      "2419/4000: train_loss: 2.746877013144549 train_error 22.00% test_error 25.00%\n",
      "================================2420===================================\n",
      "2420/4000: train_loss: 2.7462424390995874 train_error 22.00% test_error 25.00%\n",
      "================================2421===================================\n",
      "2421/4000: train_loss: 2.745607594579924 train_error 22.00% test_error 25.00%\n",
      "================================2422===================================\n",
      "2422/4000: train_loss: 2.7449724101228634 train_error 22.00% test_error 25.00%\n",
      "================================2423===================================\n",
      "2423/4000: train_loss: 2.7443353887205015 train_error 21.88% test_error 25.00%\n",
      "================================2424===================================\n",
      "2424/4000: train_loss: 2.7436980160255917 train_error 21.88% test_error 25.00%\n",
      "================================2425===================================\n",
      "2425/4000: train_loss: 2.7430602950090544 train_error 21.88% test_error 25.00%\n",
      "================================2426===================================\n",
      "2426/4000: train_loss: 2.7424227899545803 train_error 21.88% test_error 25.00%\n",
      "================================2427===================================\n",
      "2427/4000: train_loss: 2.7417875606240703 train_error 21.75% test_error 25.00%\n",
      "================================2428===================================\n",
      "2428/4000: train_loss: 2.7411510345642456 train_error 21.75% test_error 25.00%\n",
      "================================2429===================================\n",
      "2429/4000: train_loss: 2.7405155299673787 train_error 21.75% test_error 25.00%\n",
      "================================2430===================================\n",
      "2430/4000: train_loss: 2.7398794699972497 train_error 21.75% test_error 25.00%\n",
      "================================2431===================================\n",
      "2431/4000: train_loss: 2.7392417938262223 train_error 21.75% test_error 25.00%\n",
      "================================2432===================================\n",
      "2432/4000: train_loss: 2.738604604077991 train_error 21.62% test_error 25.00%\n",
      "================================2433===================================\n",
      "2433/4000: train_loss: 2.737967697905842 train_error 21.62% test_error 24.50%\n",
      "================================2434===================================\n",
      "2434/4000: train_loss: 2.737332676409278 train_error 21.75% test_error 24.50%\n",
      "================================2435===================================\n",
      "2435/4000: train_loss: 2.7366953130881297 train_error 21.75% test_error 24.50%\n",
      "================================2436===================================\n",
      "2436/4000: train_loss: 2.7360565198701803 train_error 21.62% test_error 24.50%\n",
      "================================2437===================================\n",
      "2437/4000: train_loss: 2.7354162988020105 train_error 21.62% test_error 24.50%\n",
      "================================2438===================================\n",
      "2438/4000: train_loss: 2.734776919814758 train_error 21.62% test_error 24.50%\n",
      "================================2439===================================\n",
      "2439/4000: train_loss: 2.734137198547833 train_error 21.62% test_error 24.50%\n",
      "================================2440===================================\n",
      "2440/4000: train_loss: 2.7334991529234687 train_error 21.62% test_error 24.50%\n",
      "================================2441===================================\n",
      "2441/4000: train_loss: 2.7328648848575536 train_error 21.62% test_error 24.50%\n",
      "================================2442===================================\n",
      "2442/4000: train_loss: 2.7322333473037 train_error 21.62% test_error 24.50%\n",
      "================================2443===================================\n",
      "2443/4000: train_loss: 2.7316022153873925 train_error 21.62% test_error 24.50%\n",
      "================================2444===================================\n",
      "2444/4000: train_loss: 2.7309695998393 train_error 21.62% test_error 24.00%\n",
      "================================2445===================================\n",
      "2445/4000: train_loss: 2.7303404782293366 train_error 21.50% test_error 24.00%\n",
      "================================2446===================================\n",
      "2446/4000: train_loss: 2.7297129722707902 train_error 21.50% test_error 24.00%\n",
      "================================2447===================================\n",
      "2447/4000: train_loss: 2.7290923721436413 train_error 21.50% test_error 24.00%\n",
      "================================2448===================================\n",
      "2448/4000: train_loss: 2.728471924280748 train_error 21.38% test_error 23.50%\n",
      "================================2449===================================\n",
      "2449/4000: train_loss: 2.727852276032791 train_error 21.38% test_error 23.50%\n",
      "================================2450===================================\n",
      "2450/4000: train_loss: 2.72723339520162 train_error 21.38% test_error 23.50%\n",
      "================================2451===================================\n",
      "2451/4000: train_loss: 2.7266133087291387 train_error 21.25% test_error 23.50%\n",
      "================================2452===================================\n",
      "2452/4000: train_loss: 2.725990010332316 train_error 21.25% test_error 23.50%\n",
      "================================2453===================================\n",
      "2453/4000: train_loss: 2.7253700199653395 train_error 21.00% test_error 23.50%\n",
      "================================2454===================================\n",
      "2454/4000: train_loss: 2.7247505378583448 train_error 21.00% test_error 23.50%\n",
      "================================2455===================================\n",
      "2455/4000: train_loss: 2.7241307632159444 train_error 21.00% test_error 23.50%\n",
      "================================2456===================================\n",
      "2456/4000: train_loss: 2.723511252119206 train_error 21.00% test_error 23.50%\n",
      "================================2457===================================\n",
      "2457/4000: train_loss: 2.722895316577051 train_error 21.00% test_error 23.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2458===================================\n",
      "2458/4000: train_loss: 2.7222791376616806 train_error 20.88% test_error 23.50%\n",
      "================================2459===================================\n",
      "2459/4000: train_loss: 2.7216586219950116 train_error 20.88% test_error 23.50%\n",
      "================================2460===================================\n",
      "2460/4000: train_loss: 2.7210383390192874 train_error 20.88% test_error 23.50%\n",
      "================================2461===================================\n",
      "2461/4000: train_loss: 2.720420041834004 train_error 20.88% test_error 23.50%\n",
      "================================2462===================================\n",
      "2462/4000: train_loss: 2.71979653903516 train_error 20.88% test_error 23.50%\n",
      "================================2463===================================\n",
      "2463/4000: train_loss: 2.7191714575106745 train_error 20.88% test_error 23.00%\n",
      "================================2464===================================\n",
      "2464/4000: train_loss: 2.7185484803933653 train_error 20.88% test_error 23.00%\n",
      "================================2465===================================\n",
      "2465/4000: train_loss: 2.717925238040043 train_error 20.75% test_error 23.00%\n",
      "================================2466===================================\n",
      "2466/4000: train_loss: 2.7172991545114202 train_error 20.75% test_error 23.00%\n",
      "================================2467===================================\n",
      "2467/4000: train_loss: 2.7166724232432897 train_error 20.75% test_error 23.00%\n",
      "================================2468===================================\n",
      "2468/4000: train_loss: 2.7160453778284137 train_error 20.75% test_error 23.00%\n",
      "================================2469===================================\n",
      "2469/4000: train_loss: 2.715415864867391 train_error 20.75% test_error 23.00%\n",
      "================================2470===================================\n",
      "2470/4000: train_loss: 2.714787386992248 train_error 20.75% test_error 23.00%\n",
      "================================2471===================================\n",
      "2471/4000: train_loss: 2.7141626475960945 train_error 20.75% test_error 23.00%\n",
      "================================2472===================================\n",
      "2472/4000: train_loss: 2.713543224617606 train_error 20.75% test_error 23.00%\n",
      "================================2473===================================\n",
      "2473/4000: train_loss: 2.712928471398773 train_error 20.75% test_error 23.00%\n",
      "================================2474===================================\n",
      "2474/4000: train_loss: 2.7123190364416225 train_error 20.75% test_error 23.00%\n",
      "================================2475===================================\n",
      "2475/4000: train_loss: 2.7117145791091026 train_error 20.75% test_error 23.00%\n",
      "================================2476===================================\n",
      "2476/4000: train_loss: 2.7111142011894844 train_error 20.88% test_error 23.00%\n",
      "================================2477===================================\n",
      "2477/4000: train_loss: 2.7105142608715687 train_error 20.88% test_error 22.50%\n",
      "================================2478===================================\n",
      "2478/4000: train_loss: 2.709914566606749 train_error 20.88% test_error 22.50%\n",
      "================================2479===================================\n",
      "2479/4000: train_loss: 2.7093150881899057 train_error 20.88% test_error 22.50%\n",
      "================================2480===================================\n",
      "2480/4000: train_loss: 2.7087154315400404 train_error 20.88% test_error 22.00%\n",
      "================================2481===================================\n",
      "2481/4000: train_loss: 2.7081154861487446 train_error 20.88% test_error 22.00%\n",
      "================================2482===================================\n",
      "2482/4000: train_loss: 2.707516177380458 train_error 20.75% test_error 22.00%\n",
      "================================2483===================================\n",
      "2483/4000: train_loss: 2.7069173521746412 train_error 20.75% test_error 22.00%\n",
      "================================2484===================================\n",
      "2484/4000: train_loss: 2.7063189326808788 train_error 20.75% test_error 22.00%\n",
      "================================2485===================================\n",
      "2485/4000: train_loss: 2.7057152127812154 train_error 20.75% test_error 22.00%\n",
      "================================2486===================================\n",
      "2486/4000: train_loss: 2.7051144271530214 train_error 20.75% test_error 22.00%\n",
      "================================2487===================================\n",
      "2487/4000: train_loss: 2.7045151221798736 train_error 20.75% test_error 22.00%\n",
      "================================2488===================================\n",
      "2488/4000: train_loss: 2.703916998158675 train_error 20.75% test_error 22.00%\n",
      "================================2489===================================\n",
      "2489/4000: train_loss: 2.703318268185249 train_error 20.75% test_error 22.00%\n",
      "================================2490===================================\n",
      "2490/4000: train_loss: 2.7027212194015737 train_error 20.88% test_error 22.00%\n",
      "================================2491===================================\n",
      "2491/4000: train_loss: 2.702124417474261 train_error 21.00% test_error 22.00%\n",
      "================================2492===================================\n",
      "2492/4000: train_loss: 2.70153169428464 train_error 21.00% test_error 22.00%\n",
      "================================2493===================================\n",
      "2493/4000: train_loss: 2.700940089708893 train_error 21.00% test_error 22.00%\n",
      "================================2494===================================\n",
      "2494/4000: train_loss: 2.700349116679281 train_error 21.00% test_error 22.00%\n",
      "================================2495===================================\n",
      "2495/4000: train_loss: 2.6997605649579786 train_error 21.00% test_error 22.00%\n",
      "================================2496===================================\n",
      "2496/4000: train_loss: 2.699172033496434 train_error 21.00% test_error 22.00%\n",
      "================================2497===================================\n",
      "2497/4000: train_loss: 2.6985812374122906 train_error 21.12% test_error 22.00%\n",
      "================================2498===================================\n",
      "2498/4000: train_loss: 2.6979904636531136 train_error 21.12% test_error 22.00%\n",
      "================================2499===================================\n",
      "2499/4000: train_loss: 2.6974000369873834 train_error 21.12% test_error 22.00%\n",
      "================================2500===================================\n",
      "2500/4000: train_loss: 2.6968095954845195 train_error 21.12% test_error 22.00%\n",
      "================================2501===================================\n",
      "2501/4000: train_loss: 2.6962208671239205 train_error 21.25% test_error 22.00%\n",
      "================================2502===================================\n",
      "2502/4000: train_loss: 2.695633605525363 train_error 21.25% test_error 22.00%\n",
      "================================2503===================================\n",
      "2503/4000: train_loss: 2.6950440226774663 train_error 21.25% test_error 22.00%\n",
      "================================2504===================================\n",
      "2504/4000: train_loss: 2.6944545606523755 train_error 21.25% test_error 22.00%\n",
      "================================2505===================================\n",
      "2505/4000: train_loss: 2.6938683051883707 train_error 21.25% test_error 22.00%\n",
      "================================2506===================================\n",
      "2506/4000: train_loss: 2.6932856160227674 train_error 21.25% test_error 22.00%\n",
      "================================2507===================================\n",
      "2507/4000: train_loss: 2.6927043110737574 train_error 21.25% test_error 22.00%\n",
      "================================2508===================================\n",
      "2508/4000: train_loss: 2.6921247604140084 train_error 21.25% test_error 22.00%\n",
      "================================2509===================================\n",
      "2509/4000: train_loss: 2.6915489027672446 train_error 21.25% test_error 22.00%\n",
      "================================2510===================================\n",
      "2510/4000: train_loss: 2.690974158913596 train_error 21.38% test_error 22.00%\n",
      "================================2511===================================\n",
      "2511/4000: train_loss: 2.6903999545460104 train_error 21.25% test_error 22.00%\n",
      "================================2512===================================\n",
      "2512/4000: train_loss: 2.6898252078762743 train_error 21.25% test_error 22.00%\n",
      "================================2513===================================\n",
      "2513/4000: train_loss: 2.6892501953197643 train_error 21.25% test_error 22.00%\n",
      "================================2514===================================\n",
      "2514/4000: train_loss: 2.688673346338328 train_error 21.12% test_error 22.00%\n",
      "================================2515===================================\n",
      "2515/4000: train_loss: 2.6880965753959027 train_error 21.12% test_error 22.00%\n",
      "================================2516===================================\n",
      "2516/4000: train_loss: 2.6875201782141813 train_error 21.12% test_error 22.00%\n",
      "================================2517===================================\n",
      "2517/4000: train_loss: 2.6869387858978007 train_error 21.12% test_error 22.00%\n",
      "================================2518===================================\n",
      "2518/4000: train_loss: 2.686353632651735 train_error 21.12% test_error 22.00%\n",
      "================================2519===================================\n",
      "2519/4000: train_loss: 2.6857754267647396 train_error 21.12% test_error 22.00%\n",
      "================================2520===================================\n",
      "2520/4000: train_loss: 2.685198594951071 train_error 21.00% test_error 22.00%\n",
      "================================2521===================================\n",
      "2521/4000: train_loss: 2.6846222920797302 train_error 21.00% test_error 22.00%\n",
      "================================2522===================================\n",
      "2522/4000: train_loss: 2.684050284054829 train_error 21.00% test_error 22.00%\n",
      "================================2523===================================\n",
      "2523/4000: train_loss: 2.6834838949120607 train_error 21.00% test_error 22.00%\n",
      "================================2524===================================\n",
      "2524/4000: train_loss: 2.6829191297467334 train_error 21.00% test_error 22.00%\n",
      "================================2525===================================\n",
      "2525/4000: train_loss: 2.6823547503259038 train_error 21.00% test_error 22.00%\n",
      "================================2526===================================\n",
      "2526/4000: train_loss: 2.681788884263951 train_error 20.88% test_error 22.00%\n",
      "================================2527===================================\n",
      "2527/4000: train_loss: 2.6812252145353703 train_error 20.88% test_error 22.00%\n",
      "================================2528===================================\n",
      "2528/4000: train_loss: 2.680662238036748 train_error 20.88% test_error 22.00%\n",
      "================================2529===================================\n",
      "2529/4000: train_loss: 2.6800992409931497 train_error 20.88% test_error 22.00%\n",
      "================================2530===================================\n",
      "2530/4000: train_loss: 2.679534806861775 train_error 20.88% test_error 22.00%\n",
      "================================2531===================================\n",
      "2531/4000: train_loss: 2.678968954348238 train_error 20.88% test_error 22.00%\n",
      "================================2532===================================\n",
      "2532/4000: train_loss: 2.678405998587841 train_error 20.88% test_error 22.00%\n",
      "================================2533===================================\n",
      "2533/4000: train_loss: 2.677845370718278 train_error 20.88% test_error 22.00%\n",
      "================================2534===================================\n",
      "2534/4000: train_loss: 2.6772832966654097 train_error 20.88% test_error 22.00%\n",
      "================================2535===================================\n",
      "2535/4000: train_loss: 2.6767236698674974 train_error 20.88% test_error 22.00%\n",
      "================================2536===================================\n",
      "2536/4000: train_loss: 2.6761676084715873 train_error 20.88% test_error 22.00%\n",
      "================================2537===================================\n",
      "2537/4000: train_loss: 2.675608675770927 train_error 20.88% test_error 22.00%\n",
      "================================2538===================================\n",
      "2538/4000: train_loss: 2.675046216417104 train_error 20.88% test_error 22.00%\n",
      "================================2539===================================\n",
      "2539/4000: train_loss: 2.674484500472899 train_error 20.75% test_error 22.00%\n",
      "================================2540===================================\n",
      "2540/4000: train_loss: 2.673921039644629 train_error 20.75% test_error 22.00%\n",
      "================================2541===================================\n",
      "2541/4000: train_loss: 2.673354812251637 train_error 20.75% test_error 22.00%\n",
      "================================2542===================================\n",
      "2542/4000: train_loss: 2.6727856524277014 train_error 20.75% test_error 22.00%\n",
      "================================2543===================================\n",
      "2543/4000: train_loss: 2.6722173402656337 train_error 20.75% test_error 22.00%\n",
      "================================2544===================================\n",
      "2544/4000: train_loss: 2.671647602932062 train_error 20.75% test_error 22.00%\n",
      "================================2545===================================\n",
      "2545/4000: train_loss: 2.6710730686842004 train_error 20.50% test_error 22.00%\n",
      "================================2546===================================\n",
      "2546/4000: train_loss: 2.6704893690568863 train_error 20.50% test_error 22.00%\n",
      "================================2547===================================\n",
      "2547/4000: train_loss: 2.6699014373810495 train_error 20.50% test_error 22.00%\n",
      "================================2548===================================\n",
      "2548/4000: train_loss: 2.6693106602097396 train_error 20.50% test_error 22.00%\n",
      "================================2549===================================\n",
      "2549/4000: train_loss: 2.668720663090935 train_error 20.50% test_error 22.00%\n",
      "================================2550===================================\n",
      "2550/4000: train_loss: 2.6681307262170595 train_error 20.50% test_error 22.00%\n",
      "================================2551===================================\n",
      "2551/4000: train_loss: 2.6675389595760497 train_error 20.38% test_error 22.00%\n",
      "================================2552===================================\n",
      "2552/4000: train_loss: 2.666947270834353 train_error 20.38% test_error 22.00%\n",
      "================================2553===================================\n",
      "2553/4000: train_loss: 2.6663592382881323 train_error 20.25% test_error 22.00%\n",
      "================================2554===================================\n",
      "2554/4000: train_loss: 2.6657737190974875 train_error 20.25% test_error 22.00%\n",
      "================================2555===================================\n",
      "2555/4000: train_loss: 2.6651871095842217 train_error 20.25% test_error 22.00%\n",
      "================================2556===================================\n",
      "2556/4000: train_loss: 2.664599957478931 train_error 20.25% test_error 22.00%\n",
      "================================2557===================================\n",
      "2557/4000: train_loss: 2.664013100862503 train_error 20.25% test_error 21.50%\n",
      "================================2558===================================\n",
      "2558/4000: train_loss: 2.6634271504322538 train_error 20.00% test_error 21.50%\n",
      "================================2559===================================\n",
      "2559/4000: train_loss: 2.6628434521832967 train_error 20.00% test_error 21.50%\n",
      "================================2560===================================\n",
      "2560/4000: train_loss: 2.662264057530556 train_error 20.00% test_error 21.50%\n",
      "================================2561===================================\n",
      "2561/4000: train_loss: 2.661685868249042 train_error 20.12% test_error 21.50%\n",
      "================================2562===================================\n",
      "2562/4000: train_loss: 2.661113319817232 train_error 20.12% test_error 21.50%\n",
      "================================2563===================================\n",
      "2563/4000: train_loss: 2.660543460127665 train_error 20.12% test_error 21.50%\n",
      "================================2564===================================\n",
      "2564/4000: train_loss: 2.659972656770842 train_error 20.12% test_error 21.50%\n",
      "================================2565===================================\n",
      "2565/4000: train_loss: 2.6593965497356837 train_error 20.12% test_error 21.50%\n",
      "================================2566===================================\n",
      "2566/4000: train_loss: 2.65882030747598 train_error 20.00% test_error 21.50%\n",
      "================================2567===================================\n",
      "2567/4000: train_loss: 2.658247003336437 train_error 20.00% test_error 22.00%\n",
      "================================2568===================================\n",
      "2568/4000: train_loss: 2.6576735304167958 train_error 20.00% test_error 22.50%\n",
      "================================2569===================================\n",
      "2569/4000: train_loss: 2.657096666973084 train_error 20.00% test_error 22.50%\n",
      "================================2570===================================\n",
      "2570/4000: train_loss: 2.6565227720513938 train_error 20.00% test_error 22.50%\n",
      "================================2571===================================\n",
      "2571/4000: train_loss: 2.6559503794112245 train_error 20.00% test_error 22.50%\n",
      "================================2572===================================\n",
      "2572/4000: train_loss: 2.6553791043988895 train_error 20.00% test_error 22.50%\n",
      "================================2573===================================\n",
      "2573/4000: train_loss: 2.6547996261657683 train_error 19.88% test_error 22.50%\n",
      "================================2574===================================\n",
      "2574/4000: train_loss: 2.654216375905089 train_error 19.88% test_error 22.50%\n",
      "================================2575===================================\n",
      "2575/4000: train_loss: 2.653636807855219 train_error 19.88% test_error 22.50%\n",
      "================================2576===================================\n",
      "2576/4000: train_loss: 2.653055985782994 train_error 19.88% test_error 22.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2577===================================\n",
      "2577/4000: train_loss: 2.652476025869837 train_error 19.88% test_error 22.50%\n",
      "================================2578===================================\n",
      "2578/4000: train_loss: 2.6518997575493994 train_error 19.75% test_error 22.50%\n",
      "================================2579===================================\n",
      "2579/4000: train_loss: 2.6513216083811133 train_error 19.75% test_error 22.50%\n",
      "================================2580===================================\n",
      "2580/4000: train_loss: 2.6507433653250336 train_error 19.75% test_error 22.50%\n",
      "================================2581===================================\n",
      "2581/4000: train_loss: 2.650169645471033 train_error 19.75% test_error 22.50%\n",
      "================================2582===================================\n",
      "2582/4000: train_loss: 2.6495967586396727 train_error 19.75% test_error 22.50%\n",
      "================================2583===================================\n",
      "2583/4000: train_loss: 2.64902462429367 train_error 19.75% test_error 22.50%\n",
      "================================2584===================================\n",
      "2584/4000: train_loss: 2.6484525369724725 train_error 19.62% test_error 22.50%\n",
      "================================2585===================================\n",
      "2585/4000: train_loss: 2.647873077918775 train_error 19.62% test_error 22.00%\n",
      "================================2586===================================\n",
      "2586/4000: train_loss: 2.6472925059380943 train_error 19.62% test_error 22.00%\n",
      "================================2587===================================\n",
      "2587/4000: train_loss: 2.6467086821771226 train_error 19.62% test_error 22.00%\n",
      "================================2588===================================\n",
      "2588/4000: train_loss: 2.646125182424439 train_error 19.62% test_error 22.00%\n",
      "================================2589===================================\n",
      "2589/4000: train_loss: 2.6455453275202307 train_error 19.62% test_error 22.00%\n",
      "================================2590===================================\n",
      "2590/4000: train_loss: 2.6449663247854915 train_error 19.62% test_error 22.00%\n",
      "================================2591===================================\n",
      "2591/4000: train_loss: 2.6443877340166364 train_error 19.62% test_error 22.00%\n",
      "================================2592===================================\n",
      "2592/4000: train_loss: 2.6438097026746252 train_error 19.62% test_error 22.00%\n",
      "================================2593===================================\n",
      "2593/4000: train_loss: 2.6432374267047267 train_error 19.62% test_error 22.00%\n",
      "================================2594===================================\n",
      "2594/4000: train_loss: 2.6426780405989847 train_error 19.62% test_error 22.00%\n",
      "================================2595===================================\n",
      "2595/4000: train_loss: 2.642120824299054 train_error 19.62% test_error 22.00%\n",
      "================================2596===================================\n",
      "2596/4000: train_loss: 2.6415660944627595 train_error 19.62% test_error 22.00%\n",
      "================================2597===================================\n",
      "2597/4000: train_loss: 2.641012217012467 train_error 19.62% test_error 22.00%\n",
      "================================2598===================================\n",
      "2598/4000: train_loss: 2.640457638736116 train_error 19.62% test_error 22.00%\n",
      "================================2599===================================\n",
      "2599/4000: train_loss: 2.6399011488782707 train_error 19.62% test_error 22.00%\n",
      "================================2600===================================\n",
      "2600/4000: train_loss: 2.6393434226047248 train_error 19.62% test_error 22.00%\n",
      "================================2601===================================\n",
      "2601/4000: train_loss: 2.638785471726442 train_error 19.38% test_error 22.00%\n",
      "================================2602===================================\n",
      "2602/4000: train_loss: 2.6382260542002043 train_error 19.25% test_error 22.00%\n",
      "================================2603===================================\n",
      "2603/4000: train_loss: 2.6376670092495624 train_error 19.25% test_error 22.00%\n",
      "================================2604===================================\n",
      "2604/4000: train_loss: 2.6371056586748454 train_error 19.25% test_error 22.00%\n",
      "================================2605===================================\n",
      "2605/4000: train_loss: 2.6365452140476555 train_error 19.25% test_error 22.50%\n",
      "================================2606===================================\n",
      "2606/4000: train_loss: 2.6359893960796765 train_error 19.25% test_error 22.50%\n",
      "================================2607===================================\n",
      "2607/4000: train_loss: 2.6354297474666963 train_error 19.12% test_error 22.50%\n",
      "================================2608===================================\n",
      "2608/4000: train_loss: 2.634870148914633 train_error 19.12% test_error 22.50%\n",
      "================================2609===================================\n",
      "2609/4000: train_loss: 2.6343105436442418 train_error 19.25% test_error 22.50%\n",
      "================================2610===================================\n",
      "2610/4000: train_loss: 2.633750480040908 train_error 19.38% test_error 22.50%\n",
      "================================2611===================================\n",
      "2611/4000: train_loss: 2.6331919691583607 train_error 19.38% test_error 22.50%\n",
      "================================2612===================================\n",
      "2612/4000: train_loss: 2.6326400958630254 train_error 19.38% test_error 22.50%\n",
      "================================2613===================================\n",
      "2613/4000: train_loss: 2.632089968675282 train_error 19.38% test_error 22.50%\n",
      "================================2614===================================\n",
      "2614/4000: train_loss: 2.6315418494690674 train_error 19.38% test_error 22.50%\n",
      "================================2615===================================\n",
      "2615/4000: train_loss: 2.6309947737772017 train_error 19.38% test_error 22.50%\n",
      "================================2616===================================\n",
      "2616/4000: train_loss: 2.6304469960404093 train_error 19.38% test_error 22.50%\n",
      "================================2617===================================\n",
      "2617/4000: train_loss: 2.6298996536701456 train_error 19.25% test_error 22.50%\n",
      "================================2618===================================\n",
      "2618/4000: train_loss: 2.6293549537856595 train_error 19.25% test_error 22.50%\n",
      "================================2619===================================\n",
      "2619/4000: train_loss: 2.6288113575417085 train_error 19.25% test_error 22.50%\n",
      "================================2620===================================\n",
      "2620/4000: train_loss: 2.6282678875990677 train_error 19.25% test_error 22.50%\n",
      "================================2621===================================\n",
      "2621/4000: train_loss: 2.6277233233256263 train_error 19.25% test_error 22.50%\n",
      "================================2622===================================\n",
      "2622/4000: train_loss: 2.6271834302158092 train_error 19.25% test_error 22.50%\n",
      "================================2623===================================\n",
      "2623/4000: train_loss: 2.626644976773532 train_error 19.25% test_error 22.50%\n",
      "================================2624===================================\n",
      "2624/4000: train_loss: 2.6261074382427614 train_error 19.25% test_error 22.50%\n",
      "================================2625===================================\n",
      "2625/4000: train_loss: 2.625570216251072 train_error 19.25% test_error 22.50%\n",
      "================================2626===================================\n",
      "2626/4000: train_loss: 2.6250304643879647 train_error 19.25% test_error 22.50%\n",
      "================================2627===================================\n",
      "2627/4000: train_loss: 2.62449261833448 train_error 19.25% test_error 22.50%\n",
      "================================2628===================================\n",
      "2628/4000: train_loss: 2.623957586992765 train_error 19.38% test_error 22.50%\n",
      "================================2629===================================\n",
      "2629/4000: train_loss: 2.6234195097582416 train_error 19.38% test_error 22.50%\n",
      "================================2630===================================\n",
      "2630/4000: train_loss: 2.6228811202757063 train_error 19.25% test_error 22.50%\n",
      "================================2631===================================\n",
      "2631/4000: train_loss: 2.6223435283417347 train_error 19.25% test_error 22.50%\n",
      "================================2632===================================\n",
      "2632/4000: train_loss: 2.6218068535474592 train_error 19.25% test_error 22.50%\n",
      "================================2633===================================\n",
      "2633/4000: train_loss: 2.6212662593787535 train_error 19.25% test_error 22.50%\n",
      "================================2634===================================\n",
      "2634/4000: train_loss: 2.620728022108087 train_error 19.25% test_error 22.50%\n",
      "================================2635===================================\n",
      "2635/4000: train_loss: 2.620192226455547 train_error 19.25% test_error 22.50%\n",
      "================================2636===================================\n",
      "2636/4000: train_loss: 2.6196564037562347 train_error 19.25% test_error 22.50%\n",
      "================================2637===================================\n",
      "2637/4000: train_loss: 2.619113235468976 train_error 19.25% test_error 22.50%\n",
      "================================2638===================================\n",
      "2638/4000: train_loss: 2.6185653102782087 train_error 19.25% test_error 22.50%\n",
      "================================2639===================================\n",
      "2639/4000: train_loss: 2.6180173269042277 train_error 19.12% test_error 22.50%\n",
      "================================2640===================================\n",
      "2640/4000: train_loss: 2.617470336840488 train_error 19.12% test_error 22.50%\n",
      "================================2641===================================\n",
      "2641/4000: train_loss: 2.6169197478191926 train_error 19.12% test_error 22.50%\n",
      "================================2642===================================\n",
      "2642/4000: train_loss: 2.616365482794354 train_error 19.12% test_error 22.50%\n",
      "================================2643===================================\n",
      "2643/4000: train_loss: 2.615811246309895 train_error 19.12% test_error 22.50%\n",
      "================================2644===================================\n",
      "2644/4000: train_loss: 2.6152565645845605 train_error 19.12% test_error 22.50%\n",
      "================================2645===================================\n",
      "2645/4000: train_loss: 2.61470469139982 train_error 19.12% test_error 22.50%\n",
      "================================2646===================================\n",
      "2646/4000: train_loss: 2.614152459704783 train_error 19.12% test_error 22.50%\n",
      "================================2647===================================\n",
      "2647/4000: train_loss: 2.6136042102822103 train_error 19.25% test_error 22.50%\n",
      "================================2648===================================\n",
      "2648/4000: train_loss: 2.613053223150782 train_error 19.25% test_error 22.50%\n",
      "================================2649===================================\n",
      "2649/4000: train_loss: 2.6125036378647204 train_error 19.25% test_error 22.50%\n",
      "================================2650===================================\n",
      "2650/4000: train_loss: 2.611959390137345 train_error 19.25% test_error 22.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2651===================================\n",
      "2651/4000: train_loss: 2.6114165069174486 train_error 19.25% test_error 22.50%\n",
      "================================2652===================================\n",
      "2652/4000: train_loss: 2.610869577646954 train_error 19.25% test_error 22.50%\n",
      "================================2653===================================\n",
      "2653/4000: train_loss: 2.6103200525662396 train_error 19.25% test_error 22.50%\n",
      "================================2654===================================\n",
      "2654/4000: train_loss: 2.6097655591194053 train_error 19.25% test_error 22.50%\n",
      "================================2655===================================\n",
      "2655/4000: train_loss: 2.6092087611928583 train_error 19.25% test_error 22.50%\n",
      "================================2656===================================\n",
      "2656/4000: train_loss: 2.6086524650757204 train_error 19.25% test_error 22.50%\n",
      "================================2657===================================\n",
      "2657/4000: train_loss: 2.6080953378404956 train_error 19.38% test_error 22.50%\n",
      "================================2658===================================\n",
      "2658/4000: train_loss: 2.6075345486972945 train_error 19.50% test_error 22.50%\n",
      "================================2659===================================\n",
      "2659/4000: train_loss: 2.6069725397543517 train_error 19.50% test_error 22.50%\n",
      "================================2660===================================\n",
      "2660/4000: train_loss: 2.606408047005534 train_error 19.50% test_error 22.50%\n",
      "================================2661===================================\n",
      "2661/4000: train_loss: 2.605844882936217 train_error 19.50% test_error 22.50%\n",
      "================================2662===================================\n",
      "2662/4000: train_loss: 2.605280514534097 train_error 19.50% test_error 22.50%\n",
      "================================2663===================================\n",
      "2663/4000: train_loss: 2.6047098992590327 train_error 19.50% test_error 22.50%\n",
      "================================2664===================================\n",
      "2664/4000: train_loss: 2.6041388100304173 train_error 19.50% test_error 22.50%\n",
      "================================2665===================================\n",
      "2665/4000: train_loss: 2.6035719014203647 train_error 19.50% test_error 22.50%\n",
      "================================2666===================================\n",
      "2666/4000: train_loss: 2.603006911048433 train_error 19.50% test_error 22.50%\n",
      "================================2667===================================\n",
      "2667/4000: train_loss: 2.602441338043427 train_error 19.50% test_error 22.50%\n",
      "================================2668===================================\n",
      "2668/4000: train_loss: 2.6018779609154445 train_error 19.50% test_error 22.00%\n",
      "================================2669===================================\n",
      "2669/4000: train_loss: 2.6013158464781005 train_error 19.50% test_error 22.00%\n",
      "================================2670===================================\n",
      "2670/4000: train_loss: 2.6007536590087694 train_error 19.50% test_error 22.00%\n",
      "================================2671===================================\n",
      "2671/4000: train_loss: 2.600193416059483 train_error 19.50% test_error 22.00%\n",
      "================================2672===================================\n",
      "2672/4000: train_loss: 2.599627347540809 train_error 19.50% test_error 22.00%\n",
      "================================2673===================================\n",
      "2673/4000: train_loss: 2.5990645671228414 train_error 19.50% test_error 22.00%\n",
      "================================2674===================================\n",
      "2674/4000: train_loss: 2.598500650090864 train_error 19.50% test_error 22.00%\n",
      "================================2675===================================\n",
      "2675/4000: train_loss: 2.597933711393271 train_error 19.50% test_error 22.00%\n",
      "================================2676===================================\n",
      "2676/4000: train_loss: 2.5973673096683343 train_error 19.62% test_error 22.00%\n",
      "================================2677===================================\n",
      "2677/4000: train_loss: 2.596799034946598 train_error 19.75% test_error 22.00%\n",
      "================================2678===================================\n",
      "2678/4000: train_loss: 2.596231892394135 train_error 19.75% test_error 22.00%\n",
      "================================2679===================================\n",
      "2679/4000: train_loss: 2.595662225986598 train_error 19.75% test_error 22.00%\n",
      "================================2680===================================\n",
      "2680/4000: train_loss: 2.595094100405695 train_error 19.88% test_error 22.00%\n",
      "================================2681===================================\n",
      "2681/4000: train_loss: 2.594527908150339 train_error 19.88% test_error 22.00%\n",
      "================================2682===================================\n",
      "2682/4000: train_loss: 2.593962861862965 train_error 19.88% test_error 22.00%\n",
      "================================2683===================================\n",
      "2683/4000: train_loss: 2.5934018221043518 train_error 19.88% test_error 21.50%\n",
      "================================2684===================================\n",
      "2684/4000: train_loss: 2.592845170156797 train_error 19.88% test_error 21.50%\n",
      "================================2685===================================\n",
      "2685/4000: train_loss: 2.5922896574961487 train_error 19.88% test_error 21.50%\n",
      "================================2686===================================\n",
      "2686/4000: train_loss: 2.591738404056523 train_error 19.88% test_error 21.50%\n",
      "================================2687===================================\n",
      "2687/4000: train_loss: 2.5911815178522373 train_error 19.88% test_error 21.50%\n",
      "================================2688===================================\n",
      "2688/4000: train_loss: 2.590619913570117 train_error 19.88% test_error 21.50%\n",
      "================================2689===================================\n",
      "2689/4000: train_loss: 2.5900648629222998 train_error 19.88% test_error 21.50%\n",
      "================================2690===================================\n",
      "2690/4000: train_loss: 2.5895119824050923 train_error 20.00% test_error 21.50%\n",
      "================================2691===================================\n",
      "2691/4000: train_loss: 2.588957850610605 train_error 20.00% test_error 21.50%\n",
      "================================2692===================================\n",
      "2692/4000: train_loss: 2.5884037730435376 train_error 20.00% test_error 21.00%\n",
      "================================2693===================================\n",
      "2693/4000: train_loss: 2.587852076366544 train_error 20.00% test_error 21.00%\n",
      "================================2694===================================\n",
      "2694/4000: train_loss: 2.587307921446627 train_error 20.00% test_error 21.00%\n",
      "================================2695===================================\n",
      "2695/4000: train_loss: 2.5867692459980027 train_error 20.00% test_error 21.00%\n",
      "================================2696===================================\n",
      "2696/4000: train_loss: 2.5862294969405046 train_error 20.00% test_error 21.00%\n",
      "================================2697===================================\n",
      "2697/4000: train_loss: 2.5856789996346925 train_error 20.00% test_error 21.00%\n",
      "================================2698===================================\n",
      "2698/4000: train_loss: 2.5851297935191546 train_error 20.00% test_error 21.00%\n",
      "================================2699===================================\n",
      "2699/4000: train_loss: 2.5845807943295225 train_error 20.00% test_error 21.00%\n",
      "================================2700===================================\n",
      "2700/4000: train_loss: 2.584032730202889 train_error 20.00% test_error 21.00%\n",
      "================================2701===================================\n",
      "2701/4000: train_loss: 2.5834799178224057 train_error 20.00% test_error 21.00%\n",
      "================================2702===================================\n",
      "2702/4000: train_loss: 2.582925826651044 train_error 20.00% test_error 21.00%\n",
      "================================2703===================================\n",
      "2703/4000: train_loss: 2.5823728606523946 train_error 20.00% test_error 21.00%\n",
      "================================2704===================================\n",
      "2704/4000: train_loss: 2.581819270616397 train_error 19.75% test_error 21.00%\n",
      "================================2705===================================\n",
      "2705/4000: train_loss: 2.581263832175173 train_error 19.75% test_error 21.00%\n",
      "================================2706===================================\n",
      "2706/4000: train_loss: 2.580706589095062 train_error 19.75% test_error 21.00%\n",
      "================================2707===================================\n",
      "2707/4000: train_loss: 2.5801527583657298 train_error 19.75% test_error 21.00%\n",
      "================================2708===================================\n",
      "2708/4000: train_loss: 2.579602485560463 train_error 19.75% test_error 21.00%\n",
      "================================2709===================================\n",
      "2709/4000: train_loss: 2.579051451688865 train_error 19.75% test_error 21.00%\n",
      "================================2710===================================\n",
      "2710/4000: train_loss: 2.578502722978592 train_error 19.75% test_error 21.00%\n",
      "================================2711===================================\n",
      "2711/4000: train_loss: 2.57795522687491 train_error 19.75% test_error 21.00%\n",
      "================================2712===================================\n",
      "2712/4000: train_loss: 2.5774092923797434 train_error 19.75% test_error 21.00%\n",
      "================================2713===================================\n",
      "2713/4000: train_loss: 2.576867158333189 train_error 19.75% test_error 21.00%\n",
      "================================2714===================================\n",
      "2714/4000: train_loss: 2.5763279864547073 train_error 19.75% test_error 21.00%\n",
      "================================2715===================================\n",
      "2715/4000: train_loss: 2.5757818990654777 train_error 19.75% test_error 21.00%\n",
      "================================2716===================================\n",
      "2716/4000: train_loss: 2.5752315182756864 train_error 19.75% test_error 21.00%\n",
      "================================2717===================================\n",
      "2717/4000: train_loss: 2.574681716361083 train_error 19.75% test_error 21.00%\n",
      "================================2718===================================\n",
      "2718/4000: train_loss: 2.5741387057426617 train_error 19.75% test_error 21.00%\n",
      "================================2719===================================\n",
      "2719/4000: train_loss: 2.5735969232959905 train_error 19.75% test_error 21.00%\n",
      "================================2720===================================\n",
      "2720/4000: train_loss: 2.573059042551322 train_error 19.75% test_error 21.00%\n",
      "================================2721===================================\n",
      "2721/4000: train_loss: 2.5725180222681954 train_error 19.75% test_error 21.00%\n",
      "================================2722===================================\n",
      "2722/4000: train_loss: 2.5719793776096775 train_error 19.75% test_error 21.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2723===================================\n",
      "2723/4000: train_loss: 2.5714395302627233 train_error 19.88% test_error 21.00%\n",
      "================================2724===================================\n",
      "2724/4000: train_loss: 2.5708984607836465 train_error 19.88% test_error 21.00%\n",
      "================================2725===================================\n",
      "2725/4000: train_loss: 2.5703604747983624 train_error 19.88% test_error 20.50%\n",
      "================================2726===================================\n",
      "2726/4000: train_loss: 2.569826603477122 train_error 19.75% test_error 20.50%\n",
      "================================2727===================================\n",
      "2727/4000: train_loss: 2.5692919711844295 train_error 19.75% test_error 20.50%\n",
      "================================2728===================================\n",
      "2728/4000: train_loss: 2.5687636408646357 train_error 19.75% test_error 20.50%\n",
      "================================2729===================================\n",
      "2729/4000: train_loss: 2.5682354836014563 train_error 19.75% test_error 20.50%\n",
      "================================2730===================================\n",
      "2730/4000: train_loss: 2.5677115197101372 train_error 19.75% test_error 20.50%\n",
      "================================2731===================================\n",
      "2731/4000: train_loss: 2.5671885197685334 train_error 19.75% test_error 20.50%\n",
      "================================2732===================================\n",
      "2732/4000: train_loss: 2.5666622945992277 train_error 19.75% test_error 20.50%\n",
      "================================2733===================================\n",
      "2733/4000: train_loss: 2.5661392086738486 train_error 19.62% test_error 20.50%\n",
      "================================2734===================================\n",
      "2734/4000: train_loss: 2.5656196430680573 train_error 19.62% test_error 20.50%\n",
      "================================2735===================================\n",
      "2735/4000: train_loss: 2.565101364203729 train_error 19.62% test_error 20.50%\n",
      "================================2736===================================\n",
      "2736/4000: train_loss: 2.5645820200617893 train_error 19.62% test_error 20.50%\n",
      "================================2737===================================\n",
      "2737/4000: train_loss: 2.5640653223521075 train_error 19.62% test_error 20.50%\n",
      "================================2738===================================\n",
      "2738/4000: train_loss: 2.563558455500752 train_error 19.62% test_error 20.50%\n",
      "================================2739===================================\n",
      "2739/4000: train_loss: 2.5630587219836887 train_error 19.62% test_error 20.50%\n",
      "================================2740===================================\n",
      "2740/4000: train_loss: 2.5625588246760893 train_error 19.50% test_error 20.50%\n",
      "================================2741===================================\n",
      "2741/4000: train_loss: 2.562065363700385 train_error 19.50% test_error 20.50%\n",
      "================================2742===================================\n",
      "2742/4000: train_loss: 2.561573976042564 train_error 19.50% test_error 20.50%\n",
      "================================2743===================================\n",
      "2743/4000: train_loss: 2.561084232001449 train_error 19.50% test_error 20.50%\n",
      "================================2744===================================\n",
      "2744/4000: train_loss: 2.5606007628998486 train_error 19.50% test_error 20.50%\n",
      "================================2745===================================\n",
      "2745/4000: train_loss: 2.5601186648447767 train_error 19.50% test_error 20.50%\n",
      "================================2746===================================\n",
      "2746/4000: train_loss: 2.559638518328429 train_error 19.50% test_error 20.50%\n",
      "================================2747===================================\n",
      "2747/4000: train_loss: 2.5591586206760257 train_error 19.50% test_error 20.50%\n",
      "================================2748===================================\n",
      "2748/4000: train_loss: 2.558681420790963 train_error 19.50% test_error 20.50%\n",
      "================================2749===================================\n",
      "2749/4000: train_loss: 2.5582056315534283 train_error 19.50% test_error 20.50%\n",
      "================================2750===================================\n",
      "2750/4000: train_loss: 2.557733974107541 train_error 19.62% test_error 20.50%\n",
      "================================2751===================================\n",
      "2751/4000: train_loss: 2.557261007046327 train_error 19.62% test_error 20.50%\n",
      "================================2752===================================\n",
      "2752/4000: train_loss: 2.5567880351841454 train_error 19.62% test_error 20.50%\n",
      "================================2753===================================\n",
      "2753/4000: train_loss: 2.556315550515428 train_error 19.62% test_error 20.50%\n",
      "================================2754===================================\n",
      "2754/4000: train_loss: 2.5558529750275194 train_error 19.62% test_error 20.50%\n",
      "================================2755===================================\n",
      "2755/4000: train_loss: 2.555394419734366 train_error 19.62% test_error 20.50%\n",
      "================================2756===================================\n",
      "2756/4000: train_loss: 2.55492994218308 train_error 19.62% test_error 20.50%\n",
      "================================2757===================================\n",
      "2757/4000: train_loss: 2.554466547386255 train_error 19.62% test_error 20.50%\n",
      "================================2758===================================\n",
      "2758/4000: train_loss: 2.5540027937752896 train_error 19.62% test_error 20.50%\n",
      "================================2759===================================\n",
      "2759/4000: train_loss: 2.553540398594341 train_error 19.62% test_error 20.50%\n",
      "================================2760===================================\n",
      "2760/4000: train_loss: 2.553069911235361 train_error 19.50% test_error 20.50%\n",
      "================================2761===================================\n",
      "2761/4000: train_loss: 2.5525975586840652 train_error 19.38% test_error 20.50%\n",
      "================================2762===================================\n",
      "2762/4000: train_loss: 2.5521245240449204 train_error 19.38% test_error 20.50%\n",
      "================================2763===================================\n",
      "2763/4000: train_loss: 2.5516528351709713 train_error 19.38% test_error 20.50%\n",
      "================================2764===================================\n",
      "2764/4000: train_loss: 2.551182576533174 train_error 19.38% test_error 20.50%\n",
      "================================2765===================================\n",
      "2765/4000: train_loss: 2.5507144225487717 train_error 19.38% test_error 20.50%\n",
      "================================2766===================================\n",
      "2766/4000: train_loss: 2.550246944553801 train_error 19.38% test_error 20.50%\n",
      "================================2767===================================\n",
      "2767/4000: train_loss: 2.5497800135653232 train_error 19.38% test_error 20.50%\n",
      "================================2768===================================\n",
      "2768/4000: train_loss: 2.5493160683102905 train_error 19.38% test_error 20.50%\n",
      "================================2769===================================\n",
      "2769/4000: train_loss: 2.5488556908944155 train_error 19.38% test_error 20.50%\n",
      "================================2770===================================\n",
      "2770/4000: train_loss: 2.5483963352197314 train_error 19.38% test_error 20.50%\n",
      "================================2771===================================\n",
      "2771/4000: train_loss: 2.547941067922511 train_error 19.38% test_error 20.50%\n",
      "================================2772===================================\n",
      "2772/4000: train_loss: 2.547493078979314 train_error 19.38% test_error 20.50%\n",
      "================================2773===================================\n",
      "2773/4000: train_loss: 2.5470477338385535 train_error 19.38% test_error 20.50%\n",
      "================================2774===================================\n",
      "2774/4000: train_loss: 2.546604969984619 train_error 19.38% test_error 20.50%\n",
      "================================2775===================================\n",
      "2775/4000: train_loss: 2.546163993973751 train_error 19.38% test_error 20.50%\n",
      "================================2776===================================\n",
      "2776/4000: train_loss: 2.545723112130072 train_error 19.38% test_error 20.50%\n",
      "================================2777===================================\n",
      "2777/4000: train_loss: 2.5452772642602213 train_error 19.25% test_error 20.50%\n",
      "================================2778===================================\n",
      "2778/4000: train_loss: 2.5448325259867124 train_error 19.25% test_error 20.50%\n",
      "================================2779===================================\n",
      "2779/4000: train_loss: 2.544390396552626 train_error 19.25% test_error 20.50%\n",
      "================================2780===================================\n",
      "2780/4000: train_loss: 2.5439496314065764 train_error 19.25% test_error 20.50%\n",
      "================================2781===================================\n",
      "2781/4000: train_loss: 2.5435153397673274 train_error 19.25% test_error 20.50%\n",
      "================================2782===================================\n",
      "2782/4000: train_loss: 2.543083889114787 train_error 19.25% test_error 20.50%\n",
      "================================2783===================================\n",
      "2783/4000: train_loss: 2.5426529227371795 train_error 19.12% test_error 20.50%\n",
      "================================2784===================================\n",
      "2784/4000: train_loss: 2.542222847676603 train_error 19.12% test_error 20.50%\n",
      "================================2785===================================\n",
      "2785/4000: train_loss: 2.541794123923755 train_error 19.12% test_error 20.50%\n",
      "================================2786===================================\n",
      "2786/4000: train_loss: 2.5413688376988284 train_error 19.25% test_error 20.50%\n",
      "================================2787===================================\n",
      "2787/4000: train_loss: 2.540947634219774 train_error 19.25% test_error 20.50%\n",
      "================================2788===================================\n",
      "2788/4000: train_loss: 2.5405282570340204 train_error 19.25% test_error 20.50%\n",
      "================================2789===================================\n",
      "2789/4000: train_loss: 2.540109855547198 train_error 19.25% test_error 20.50%\n",
      "================================2790===================================\n",
      "2790/4000: train_loss: 2.53969383540214 train_error 19.25% test_error 20.50%\n",
      "================================2791===================================\n",
      "2791/4000: train_loss: 2.5392788777389796 train_error 19.25% test_error 20.50%\n",
      "================================2792===================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2792/4000: train_loss: 2.5388643280044194 train_error 19.25% test_error 20.50%\n",
      "================================2793===================================\n",
      "2793/4000: train_loss: 2.538450044966885 train_error 19.25% test_error 20.50%\n",
      "================================2794===================================\n",
      "2794/4000: train_loss: 2.5380352214025335 train_error 19.25% test_error 20.50%\n",
      "================================2795===================================\n",
      "2795/4000: train_loss: 2.537623123928788 train_error 19.25% test_error 20.50%\n",
      "================================2796===================================\n",
      "2796/4000: train_loss: 2.537214732848806 train_error 19.25% test_error 20.50%\n",
      "================================2797===================================\n",
      "2797/4000: train_loss: 2.5368037037190514 train_error 19.12% test_error 20.50%\n",
      "================================2798===================================\n",
      "2798/4000: train_loss: 2.5363877868413693 train_error 19.12% test_error 20.50%\n",
      "================================2799===================================\n",
      "2799/4000: train_loss: 2.5359673090802968 train_error 19.00% test_error 20.50%\n",
      "================================2800===================================\n",
      "2800/4000: train_loss: 2.535548607572564 train_error 19.00% test_error 20.50%\n",
      "================================2801===================================\n",
      "2801/4000: train_loss: 2.5351323521026643 train_error 19.00% test_error 20.50%\n",
      "================================2802===================================\n",
      "2802/4000: train_loss: 2.5347163391194774 train_error 19.00% test_error 20.50%\n",
      "================================2803===================================\n",
      "2803/4000: train_loss: 2.5342996806732847 train_error 19.00% test_error 20.50%\n",
      "================================2804===================================\n",
      "2804/4000: train_loss: 2.533884168580407 train_error 19.00% test_error 20.50%\n",
      "================================2805===================================\n",
      "2805/4000: train_loss: 2.5334713379101594 train_error 19.00% test_error 20.50%\n",
      "================================2806===================================\n",
      "2806/4000: train_loss: 2.5330595350067595 train_error 19.00% test_error 20.50%\n",
      "================================2807===================================\n",
      "2807/4000: train_loss: 2.5326464026788016 train_error 19.00% test_error 20.50%\n",
      "================================2808===================================\n",
      "2808/4000: train_loss: 2.5322289048944366 train_error 18.88% test_error 20.50%\n",
      "================================2809===================================\n",
      "2809/4000: train_loss: 2.5318126834061694 train_error 18.88% test_error 20.50%\n",
      "================================2810===================================\n",
      "2810/4000: train_loss: 2.531399303858052 train_error 18.88% test_error 20.50%\n",
      "================================2811===================================\n",
      "2811/4000: train_loss: 2.530992200089968 train_error 18.88% test_error 20.50%\n",
      "================================2812===================================\n",
      "2812/4000: train_loss: 2.5305858859291765 train_error 18.88% test_error 21.00%\n",
      "================================2813===================================\n",
      "2813/4000: train_loss: 2.530180229922989 train_error 18.88% test_error 21.00%\n",
      "================================2814===================================\n",
      "2814/4000: train_loss: 2.529774694854859 train_error 18.88% test_error 21.00%\n",
      "================================2815===================================\n",
      "2815/4000: train_loss: 2.5293716927809875 train_error 18.88% test_error 21.00%\n",
      "================================2816===================================\n",
      "2816/4000: train_loss: 2.5289714714948786 train_error 18.88% test_error 21.00%\n",
      "================================2817===================================\n",
      "2817/4000: train_loss: 2.528569541815086 train_error 18.75% test_error 21.00%\n",
      "================================2818===================================\n",
      "2818/4000: train_loss: 2.528164795303019 train_error 18.75% test_error 21.00%\n",
      "================================2819===================================\n",
      "2819/4000: train_loss: 2.5277596333262045 train_error 18.75% test_error 21.00%\n",
      "================================2820===================================\n",
      "2820/4000: train_loss: 2.527355849679443 train_error 18.75% test_error 21.00%\n",
      "================================2821===================================\n",
      "2821/4000: train_loss: 2.5269509725010724 train_error 18.75% test_error 21.00%\n",
      "================================2822===================================\n",
      "2822/4000: train_loss: 2.526545615636278 train_error 18.75% test_error 21.00%\n",
      "================================2823===================================\n",
      "2823/4000: train_loss: 2.526138480625232 train_error 18.75% test_error 21.00%\n",
      "================================2824===================================\n",
      "2824/4000: train_loss: 2.525731377542834 train_error 18.62% test_error 21.00%\n",
      "================================2825===================================\n",
      "2825/4000: train_loss: 2.5253259766765406 train_error 18.62% test_error 21.00%\n",
      "================================2826===================================\n",
      "2826/4000: train_loss: 2.524926938096178 train_error 18.62% test_error 21.00%\n",
      "================================2827===================================\n",
      "2827/4000: train_loss: 2.524528889607172 train_error 18.62% test_error 21.00%\n",
      "================================2828===================================\n",
      "2828/4000: train_loss: 2.5241319110029146 train_error 18.62% test_error 21.00%\n",
      "================================2829===================================\n",
      "2829/4000: train_loss: 2.5237393068976233 train_error 18.62% test_error 21.00%\n",
      "================================2830===================================\n",
      "2830/4000: train_loss: 2.5233499252656477 train_error 18.62% test_error 21.00%\n",
      "================================2831===================================\n",
      "2831/4000: train_loss: 2.5229652272415115 train_error 18.62% test_error 21.00%\n",
      "================================2832===================================\n",
      "2832/4000: train_loss: 2.5225816203927387 train_error 18.62% test_error 21.00%\n",
      "================================2833===================================\n",
      "2833/4000: train_loss: 2.522199311981676 train_error 18.50% test_error 21.00%\n",
      "================================2834===================================\n",
      "2834/4000: train_loss: 2.5218165258248337 train_error 18.50% test_error 21.00%\n",
      "================================2835===================================\n",
      "2835/4000: train_loss: 2.52143162528635 train_error 18.50% test_error 21.00%\n",
      "================================2836===================================\n",
      "2836/4000: train_loss: 2.521047222526395 train_error 18.50% test_error 21.00%\n",
      "================================2837===================================\n",
      "2837/4000: train_loss: 2.520665111688431 train_error 18.50% test_error 21.00%\n",
      "================================2838===================================\n",
      "2838/4000: train_loss: 2.520289323324105 train_error 18.50% test_error 21.00%\n",
      "================================2839===================================\n",
      "2839/4000: train_loss: 2.519915220872499 train_error 18.50% test_error 21.00%\n",
      "================================2840===================================\n",
      "2840/4000: train_loss: 2.5195421570073813 train_error 18.50% test_error 21.00%\n",
      "================================2841===================================\n",
      "2841/4000: train_loss: 2.519164481151383 train_error 18.50% test_error 21.00%\n",
      "================================2842===================================\n",
      "2842/4000: train_loss: 2.5187868767103647 train_error 18.38% test_error 21.00%\n",
      "================================2843===================================\n",
      "2843/4000: train_loss: 2.5184144187386845 train_error 18.25% test_error 20.50%\n",
      "================================2844===================================\n",
      "2844/4000: train_loss: 2.5180430309812074 train_error 18.12% test_error 20.50%\n",
      "================================2845===================================\n",
      "2845/4000: train_loss: 2.517674081826117 train_error 18.12% test_error 20.50%\n",
      "================================2846===================================\n",
      "2846/4000: train_loss: 2.517300652746926 train_error 18.12% test_error 20.50%\n",
      "================================2847===================================\n",
      "2847/4000: train_loss: 2.5169254832778822 train_error 18.12% test_error 20.50%\n",
      "================================2848===================================\n",
      "2848/4000: train_loss: 2.5165492051298495 train_error 18.12% test_error 20.50%\n",
      "================================2849===================================\n",
      "2849/4000: train_loss: 2.5161706996103748 train_error 18.12% test_error 20.50%\n",
      "================================2850===================================\n",
      "2850/4000: train_loss: 2.515794441772741 train_error 18.12% test_error 20.50%\n",
      "================================2851===================================\n",
      "2851/4000: train_loss: 2.515417791570071 train_error 18.12% test_error 20.50%\n",
      "================================2852===================================\n",
      "2852/4000: train_loss: 2.515040551693528 train_error 18.12% test_error 20.50%\n",
      "================================2853===================================\n",
      "2853/4000: train_loss: 2.514667070613359 train_error 18.25% test_error 20.50%\n",
      "================================2854===================================\n",
      "2854/4000: train_loss: 2.514296773984097 train_error 18.25% test_error 20.50%\n",
      "================================2855===================================\n",
      "2855/4000: train_loss: 2.513927102303714 train_error 18.25% test_error 20.50%\n",
      "================================2856===================================\n",
      "2856/4000: train_loss: 2.513559094510856 train_error 18.25% test_error 20.50%\n",
      "================================2857===================================\n",
      "2857/4000: train_loss: 2.5131924406666077 train_error 18.25% test_error 20.50%\n",
      "================================2858===================================\n",
      "2858/4000: train_loss: 2.5128281533380505 train_error 18.25% test_error 20.50%\n",
      "================================2859===================================\n",
      "2859/4000: train_loss: 2.5124660127825336 train_error 18.25% test_error 20.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2860===================================\n",
      "2860/4000: train_loss: 2.512108461043681 train_error 18.25% test_error 20.50%\n",
      "================================2861===================================\n",
      "2861/4000: train_loss: 2.511751832802547 train_error 18.25% test_error 20.50%\n",
      "================================2862===================================\n",
      "2862/4000: train_loss: 2.511395659765112 train_error 18.25% test_error 20.50%\n",
      "================================2863===================================\n",
      "2863/4000: train_loss: 2.511037902049138 train_error 18.25% test_error 20.50%\n",
      "================================2864===================================\n",
      "2864/4000: train_loss: 2.510683544503409 train_error 18.25% test_error 20.50%\n",
      "================================2865===================================\n",
      "2865/4000: train_loss: 2.510328163356171 train_error 18.25% test_error 20.50%\n",
      "================================2866===================================\n",
      "2866/4000: train_loss: 2.509971695289132 train_error 18.25% test_error 20.50%\n",
      "================================2867===================================\n",
      "2867/4000: train_loss: 2.509610994217801 train_error 18.25% test_error 20.50%\n",
      "================================2868===================================\n",
      "2868/4000: train_loss: 2.5092534599133067 train_error 18.25% test_error 20.50%\n",
      "================================2869===================================\n",
      "2869/4000: train_loss: 2.5088965406129136 train_error 18.25% test_error 20.50%\n",
      "================================2870===================================\n",
      "2870/4000: train_loss: 2.5085392125876385 train_error 18.25% test_error 20.50%\n",
      "================================2871===================================\n",
      "2871/4000: train_loss: 2.508184235992958 train_error 18.38% test_error 20.50%\n",
      "================================2872===================================\n",
      "2872/4000: train_loss: 2.507830117008416 train_error 18.38% test_error 20.50%\n",
      "================================2873===================================\n",
      "2873/4000: train_loss: 2.5074782048474296 train_error 18.50% test_error 20.50%\n",
      "================================2874===================================\n",
      "2874/4000: train_loss: 2.50712696649367 train_error 18.50% test_error 20.50%\n",
      "================================2875===================================\n",
      "2875/4000: train_loss: 2.5067777617968385 train_error 18.50% test_error 20.50%\n",
      "================================2876===================================\n",
      "2876/4000: train_loss: 2.5064302741276334 train_error 18.50% test_error 20.50%\n",
      "================================2877===================================\n",
      "2877/4000: train_loss: 2.5060798980208348 train_error 18.50% test_error 20.50%\n",
      "================================2878===================================\n",
      "2878/4000: train_loss: 2.5057301783462753 train_error 18.50% test_error 20.50%\n",
      "================================2879===================================\n",
      "2879/4000: train_loss: 2.50538207174337 train_error 18.50% test_error 20.50%\n",
      "================================2880===================================\n",
      "2880/4000: train_loss: 2.505035558512318 train_error 18.50% test_error 20.50%\n",
      "================================2881===================================\n",
      "2881/4000: train_loss: 2.5046891728101763 train_error 18.50% test_error 20.50%\n",
      "================================2882===================================\n",
      "2882/4000: train_loss: 2.504347983016632 train_error 18.50% test_error 20.50%\n",
      "================================2883===================================\n",
      "2883/4000: train_loss: 2.5040102404268687 train_error 18.50% test_error 20.50%\n",
      "================================2884===================================\n",
      "2884/4000: train_loss: 2.503675383678055 train_error 18.50% test_error 20.50%\n",
      "================================2885===================================\n",
      "2885/4000: train_loss: 2.5033434149273672 train_error 18.50% test_error 20.50%\n",
      "================================2886===================================\n",
      "2886/4000: train_loss: 2.5030152733321303 train_error 18.50% test_error 20.50%\n",
      "================================2887===================================\n",
      "2887/4000: train_loss: 2.502687774010701 train_error 18.50% test_error 20.50%\n",
      "================================2888===================================\n",
      "2888/4000: train_loss: 2.5023609441443115 train_error 18.50% test_error 20.50%\n",
      "================================2889===================================\n",
      "2889/4000: train_loss: 2.502038357447018 train_error 18.50% test_error 20.50%\n",
      "================================2890===================================\n",
      "2890/4000: train_loss: 2.5017194225208366 train_error 18.50% test_error 20.50%\n",
      "================================2891===================================\n",
      "2891/4000: train_loss: 2.5014006713579873 train_error 18.50% test_error 20.50%\n",
      "================================2892===================================\n",
      "2892/4000: train_loss: 2.501081927710329 train_error 18.50% test_error 20.50%\n",
      "================================2893===================================\n",
      "2893/4000: train_loss: 2.5007665856508536 train_error 18.62% test_error 20.50%\n",
      "================================2894===================================\n",
      "2894/4000: train_loss: 2.5004510998522163 train_error 18.62% test_error 20.50%\n",
      "================================2895===================================\n",
      "2895/4000: train_loss: 2.500134222492925 train_error 18.62% test_error 20.50%\n",
      "================================2896===================================\n",
      "2896/4000: train_loss: 2.4998153851332607 train_error 18.62% test_error 20.50%\n",
      "================================2897===================================\n",
      "2897/4000: train_loss: 2.4994985332747457 train_error 18.62% test_error 20.50%\n",
      "================================2898===================================\n",
      "2898/4000: train_loss: 2.4991828644368796 train_error 18.62% test_error 20.50%\n",
      "================================2899===================================\n",
      "2899/4000: train_loss: 2.4988686373282687 train_error 18.62% test_error 20.50%\n",
      "================================2900===================================\n",
      "2900/4000: train_loss: 2.498554520838661 train_error 18.75% test_error 20.50%\n",
      "================================2901===================================\n",
      "2901/4000: train_loss: 2.4982416383351667 train_error 18.62% test_error 20.50%\n",
      "================================2902===================================\n",
      "2902/4000: train_loss: 2.497929632664309 train_error 18.62% test_error 20.50%\n",
      "================================2903===================================\n",
      "2903/4000: train_loss: 2.497618123097927 train_error 18.62% test_error 20.50%\n",
      "================================2904===================================\n",
      "2904/4000: train_loss: 2.497307765923324 train_error 18.62% test_error 20.50%\n",
      "================================2905===================================\n",
      "2905/4000: train_loss: 2.496997409937321 train_error 18.62% test_error 20.50%\n",
      "================================2906===================================\n",
      "2906/4000: train_loss: 2.496685780067928 train_error 18.62% test_error 20.50%\n",
      "================================2907===================================\n",
      "2907/4000: train_loss: 2.496374875236652 train_error 18.62% test_error 20.50%\n",
      "================================2908===================================\n",
      "2908/4000: train_loss: 2.4960640814958603 train_error 18.75% test_error 20.50%\n",
      "================================2909===================================\n",
      "2909/4000: train_loss: 2.495753737495397 train_error 18.62% test_error 20.50%\n",
      "================================2910===================================\n",
      "2910/4000: train_loss: 2.495445656038937 train_error 18.62% test_error 20.50%\n",
      "================================2911===================================\n",
      "2911/4000: train_loss: 2.4951378349005244 train_error 18.62% test_error 20.50%\n",
      "================================2912===================================\n",
      "2912/4000: train_loss: 2.4948311904259026 train_error 18.62% test_error 20.50%\n",
      "================================2913===================================\n",
      "2913/4000: train_loss: 2.4945257971878165 train_error 18.62% test_error 20.50%\n",
      "================================2914===================================\n",
      "2914/4000: train_loss: 2.4942195156769595 train_error 18.62% test_error 20.50%\n",
      "================================2915===================================\n",
      "2915/4000: train_loss: 2.4939131874073066 train_error 18.75% test_error 20.50%\n",
      "================================2916===================================\n",
      "2916/4000: train_loss: 2.4936083702603358 train_error 18.75% test_error 20.50%\n",
      "================================2917===================================\n",
      "2917/4000: train_loss: 2.4933037697291005 train_error 18.75% test_error 20.50%\n",
      "================================2918===================================\n",
      "2918/4000: train_loss: 2.492999376226799 train_error 18.75% test_error 20.50%\n",
      "================================2919===================================\n",
      "2919/4000: train_loss: 2.492694561419194 train_error 18.75% test_error 20.50%\n",
      "================================2920===================================\n",
      "2920/4000: train_loss: 2.4923912996664876 train_error 18.75% test_error 20.50%\n",
      "================================2921===================================\n",
      "2921/4000: train_loss: 2.492088327804813 train_error 18.75% test_error 20.50%\n",
      "================================2922===================================\n",
      "2922/4000: train_loss: 2.4917888144805325 train_error 18.75% test_error 20.50%\n",
      "================================2923===================================\n",
      "2923/4000: train_loss: 2.4914873084053397 train_error 18.75% test_error 20.50%\n",
      "================================2924===================================\n",
      "2924/4000: train_loss: 2.491187632874935 train_error 18.75% test_error 20.50%\n",
      "================================2925===================================\n",
      "2925/4000: train_loss: 2.4908885062177433 train_error 18.75% test_error 20.50%\n",
      "================================2926===================================\n",
      "2926/4000: train_loss: 2.4905939318129096 train_error 18.75% test_error 20.50%\n",
      "================================2927===================================\n",
      "2927/4000: train_loss: 2.4903013049194125 train_error 18.75% test_error 20.50%\n",
      "================================2928===================================\n",
      "2928/4000: train_loss: 2.490010010722326 train_error 18.75% test_error 20.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2929===================================\n",
      "2929/4000: train_loss: 2.4897213248314802 train_error 18.75% test_error 20.00%\n",
      "================================2930===================================\n",
      "2930/4000: train_loss: 2.4894326793320944 train_error 18.75% test_error 20.00%\n",
      "================================2931===================================\n",
      "2931/4000: train_loss: 2.4891441636747915 train_error 18.75% test_error 20.00%\n",
      "================================2932===================================\n",
      "2932/4000: train_loss: 2.4888542644068363 train_error 18.75% test_error 20.00%\n",
      "================================2933===================================\n",
      "2933/4000: train_loss: 2.488564844735665 train_error 18.75% test_error 20.00%\n",
      "================================2934===================================\n",
      "2934/4000: train_loss: 2.488275754836504 train_error 18.75% test_error 20.00%\n",
      "================================2935===================================\n",
      "2935/4000: train_loss: 2.487987241340452 train_error 18.75% test_error 20.00%\n",
      "================================2936===================================\n",
      "2936/4000: train_loss: 2.487699287669966 train_error 18.75% test_error 20.00%\n",
      "================================2937===================================\n",
      "2937/4000: train_loss: 2.487409746098565 train_error 18.75% test_error 20.00%\n",
      "================================2938===================================\n",
      "2938/4000: train_loss: 2.4871217621525283 train_error 18.75% test_error 20.00%\n",
      "================================2939===================================\n",
      "2939/4000: train_loss: 2.486834537573741 train_error 18.75% test_error 20.00%\n",
      "================================2940===================================\n",
      "2940/4000: train_loss: 2.4865477987972553 train_error 18.75% test_error 20.00%\n",
      "================================2941===================================\n",
      "2941/4000: train_loss: 2.4862605838052696 train_error 18.75% test_error 20.00%\n",
      "================================2942===================================\n",
      "2942/4000: train_loss: 2.485976119424449 train_error 18.62% test_error 20.00%\n",
      "================================2943===================================\n",
      "2943/4000: train_loss: 2.4856926299887707 train_error 18.62% test_error 20.00%\n",
      "================================2944===================================\n",
      "2944/4000: train_loss: 2.485403457397479 train_error 18.62% test_error 20.00%\n",
      "================================2945===================================\n",
      "2945/4000: train_loss: 2.4851130309578733 train_error 18.62% test_error 20.00%\n",
      "================================2946===================================\n",
      "2946/4000: train_loss: 2.484812558934791 train_error 18.62% test_error 20.00%\n",
      "================================2947===================================\n",
      "2947/4000: train_loss: 2.484515778013156 train_error 18.62% test_error 20.00%\n",
      "================================2948===================================\n",
      "2948/4000: train_loss: 2.48421890576079 train_error 18.62% test_error 20.00%\n",
      "================================2949===================================\n",
      "2949/4000: train_loss: 2.4839223631483036 train_error 18.62% test_error 20.00%\n",
      "================================2950===================================\n",
      "2950/4000: train_loss: 2.483626583411242 train_error 18.62% test_error 20.00%\n",
      "================================2951===================================\n",
      "2951/4000: train_loss: 2.4833332878566576 train_error 18.62% test_error 20.00%\n",
      "================================2952===================================\n",
      "2952/4000: train_loss: 2.4830404996330615 train_error 18.62% test_error 20.00%\n",
      "================================2953===================================\n",
      "2953/4000: train_loss: 2.482747906205477 train_error 18.62% test_error 20.00%\n",
      "================================2954===================================\n",
      "2954/4000: train_loss: 2.4824566928134297 train_error 18.62% test_error 20.00%\n",
      "================================2955===================================\n",
      "2955/4000: train_loss: 2.48216710567649 train_error 18.62% test_error 20.00%\n",
      "================================2956===================================\n",
      "2956/4000: train_loss: 2.481879376383731 train_error 18.62% test_error 20.00%\n",
      "================================2957===================================\n",
      "2957/4000: train_loss: 2.481590902581229 train_error 18.62% test_error 20.00%\n",
      "================================2958===================================\n",
      "2958/4000: train_loss: 2.4813042286830025 train_error 18.62% test_error 20.00%\n",
      "================================2959===================================\n",
      "2959/4000: train_loss: 2.481018092134618 train_error 18.62% test_error 20.00%\n",
      "================================2960===================================\n",
      "2960/4000: train_loss: 2.4807329080341147 train_error 18.50% test_error 20.00%\n",
      "================================2961===================================\n",
      "2961/4000: train_loss: 2.4804489693354115 train_error 18.50% test_error 20.00%\n",
      "================================2962===================================\n",
      "2962/4000: train_loss: 2.4801676794246306 train_error 18.50% test_error 20.00%\n",
      "================================2963===================================\n",
      "2963/4000: train_loss: 2.4798886285338084 train_error 18.50% test_error 20.00%\n",
      "================================2964===================================\n",
      "2964/4000: train_loss: 2.479609014810994 train_error 18.50% test_error 20.00%\n",
      "================================2965===================================\n",
      "2965/4000: train_loss: 2.479329308817978 train_error 18.50% test_error 20.00%\n",
      "================================2966===================================\n",
      "2966/4000: train_loss: 2.4790490407246395 train_error 18.50% test_error 20.00%\n",
      "================================2967===================================\n",
      "2967/4000: train_loss: 2.478767671576934 train_error 18.50% test_error 20.00%\n",
      "================================2968===================================\n",
      "2968/4000: train_loss: 2.4784842525277053 train_error 18.50% test_error 20.00%\n",
      "================================2969===================================\n",
      "2969/4000: train_loss: 2.478201259590569 train_error 18.50% test_error 20.00%\n",
      "================================2970===================================\n",
      "2970/4000: train_loss: 2.477919508969644 train_error 18.50% test_error 20.00%\n",
      "================================2971===================================\n",
      "2971/4000: train_loss: 2.477639061626978 train_error 18.50% test_error 20.00%\n",
      "================================2972===================================\n",
      "2972/4000: train_loss: 2.4773612670926375 train_error 18.50% test_error 20.00%\n",
      "================================2973===================================\n",
      "2973/4000: train_loss: 2.477085527909803 train_error 18.50% test_error 20.00%\n",
      "================================2974===================================\n",
      "2974/4000: train_loss: 2.476811080619809 train_error 18.50% test_error 20.00%\n",
      "================================2975===================================\n",
      "2975/4000: train_loss: 2.4765345527778844 train_error 18.38% test_error 20.00%\n",
      "================================2976===================================\n",
      "2976/4000: train_loss: 2.4762544119189265 train_error 18.38% test_error 20.00%\n",
      "================================2977===================================\n",
      "2977/4000: train_loss: 2.4759774060169 train_error 18.38% test_error 20.00%\n",
      "================================2978===================================\n",
      "2978/4000: train_loss: 2.475701486688922 train_error 18.38% test_error 20.00%\n",
      "================================2979===================================\n",
      "2979/4000: train_loss: 2.4754278776393037 train_error 18.38% test_error 20.00%\n",
      "================================2980===================================\n",
      "2980/4000: train_loss: 2.4751562280824873 train_error 18.38% test_error 20.00%\n",
      "================================2981===================================\n",
      "2981/4000: train_loss: 2.474888361186022 train_error 18.25% test_error 20.00%\n",
      "================================2982===================================\n",
      "2982/4000: train_loss: 2.4746219701087098 train_error 18.25% test_error 20.00%\n",
      "================================2983===================================\n",
      "2983/4000: train_loss: 2.474356491123908 train_error 18.25% test_error 20.00%\n",
      "================================2984===================================\n",
      "2984/4000: train_loss: 2.4740924556052777 train_error 18.25% test_error 20.00%\n",
      "================================2985===================================\n",
      "2985/4000: train_loss: 2.473829169005039 train_error 18.25% test_error 20.00%\n",
      "================================2986===================================\n",
      "2986/4000: train_loss: 2.4735666854772713 train_error 18.25% test_error 20.00%\n",
      "================================2987===================================\n",
      "2987/4000: train_loss: 2.4733050559356347 train_error 18.25% test_error 20.00%\n",
      "================================2988===================================\n",
      "2988/4000: train_loss: 2.4730428840377137 train_error 18.25% test_error 20.00%\n",
      "================================2989===================================\n",
      "2989/4000: train_loss: 2.472780281286105 train_error 18.25% test_error 20.00%\n",
      "================================2990===================================\n",
      "2990/4000: train_loss: 2.4725180921162244 train_error 18.25% test_error 20.00%\n",
      "================================2991===================================\n",
      "2991/4000: train_loss: 2.4722538393520517 train_error 18.12% test_error 20.00%\n",
      "================================2992===================================\n",
      "2992/4000: train_loss: 2.471990212012315 train_error 18.12% test_error 20.00%\n",
      "================================2993===================================\n",
      "2993/4000: train_loss: 2.4717293846281247 train_error 18.12% test_error 20.00%\n",
      "================================2994===================================\n",
      "2994/4000: train_loss: 2.4714686665340557 train_error 18.12% test_error 20.00%\n",
      "================================2995===================================\n",
      "2995/4000: train_loss: 2.4712088655686237 train_error 18.12% test_error 20.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2996===================================\n",
      "2996/4000: train_loss: 2.47094983461313 train_error 18.12% test_error 20.00%\n",
      "================================2997===================================\n",
      "2997/4000: train_loss: 2.470691841740627 train_error 18.12% test_error 20.00%\n",
      "================================2998===================================\n",
      "2998/4000: train_loss: 2.4704345967643895 train_error 18.12% test_error 20.00%\n",
      "================================2999===================================\n",
      "2999/4000: train_loss: 2.4701774657331406 train_error 18.12% test_error 20.00%\n",
      "================================3000===================================\n",
      "3000/4000: train_loss: 2.4699217533983755 train_error 18.12% test_error 20.00%\n",
      "================================3001===================================\n",
      "3001/4000: train_loss: 2.4696673857065616 train_error 18.12% test_error 20.00%\n",
      "================================3002===================================\n",
      "3002/4000: train_loss: 2.4694145326688886 train_error 18.12% test_error 20.00%\n",
      "================================3003===================================\n",
      "3003/4000: train_loss: 2.469162735672435 train_error 18.12% test_error 20.00%\n",
      "================================3004===================================\n",
      "3004/4000: train_loss: 2.4689090965414655 train_error 18.12% test_error 20.00%\n",
      "================================3005===================================\n",
      "3005/4000: train_loss: 2.4686531210062097 train_error 18.12% test_error 20.00%\n",
      "================================3006===================================\n",
      "3006/4000: train_loss: 2.4683980358787814 train_error 18.12% test_error 20.00%\n",
      "================================3007===================================\n",
      "3007/4000: train_loss: 2.4681403814884835 train_error 18.12% test_error 20.00%\n",
      "================================3008===================================\n",
      "3008/4000: train_loss: 2.4678868701017924 train_error 18.12% test_error 20.00%\n",
      "================================3009===================================\n",
      "3009/4000: train_loss: 2.4676352651976052 train_error 18.00% test_error 20.00%\n",
      "================================3010===================================\n",
      "3010/4000: train_loss: 2.467383514754474 train_error 18.00% test_error 20.00%\n",
      "================================3011===================================\n",
      "3011/4000: train_loss: 2.46713255054201 train_error 18.00% test_error 20.00%\n",
      "================================3012===================================\n",
      "3012/4000: train_loss: 2.4668777829338797 train_error 18.00% test_error 20.00%\n",
      "================================3013===================================\n",
      "3013/4000: train_loss: 2.466619914209587 train_error 18.00% test_error 20.00%\n",
      "================================3014===================================\n",
      "3014/4000: train_loss: 2.466362245621858 train_error 18.00% test_error 20.00%\n",
      "================================3015===================================\n",
      "3015/4000: train_loss: 2.466105024228454 train_error 18.00% test_error 20.00%\n",
      "================================3016===================================\n",
      "3016/4000: train_loss: 2.4658440901956054 train_error 18.00% test_error 20.00%\n",
      "================================3017===================================\n",
      "3017/4000: train_loss: 2.4655806696426588 train_error 18.00% test_error 20.00%\n",
      "================================3018===================================\n",
      "3018/4000: train_loss: 2.4653167924855373 train_error 18.00% test_error 20.00%\n",
      "================================3019===================================\n",
      "3019/4000: train_loss: 2.4650502273847814 train_error 18.00% test_error 20.00%\n",
      "================================3020===================================\n",
      "3020/4000: train_loss: 2.464784457818605 train_error 18.00% test_error 20.00%\n",
      "================================3021===================================\n",
      "3021/4000: train_loss: 2.464518841559766 train_error 18.00% test_error 20.00%\n",
      "================================3022===================================\n",
      "3022/4000: train_loss: 2.4642505777726185 train_error 18.00% test_error 20.00%\n",
      "================================3023===================================\n",
      "3023/4000: train_loss: 2.4639825312903847 train_error 18.00% test_error 20.00%\n",
      "================================3024===================================\n",
      "3024/4000: train_loss: 2.4637108325579904 train_error 18.00% test_error 20.00%\n",
      "================================3025===================================\n",
      "3025/4000: train_loss: 2.4634393257234475 train_error 18.00% test_error 20.00%\n",
      "================================3026===================================\n",
      "3026/4000: train_loss: 2.4631681854790077 train_error 18.00% test_error 20.00%\n",
      "================================3027===================================\n",
      "3027/4000: train_loss: 2.4628954772499854 train_error 18.00% test_error 20.00%\n",
      "================================3028===================================\n",
      "3028/4000: train_loss: 2.4626250467106003 train_error 18.00% test_error 20.00%\n",
      "================================3029===================================\n",
      "3029/4000: train_loss: 2.462355854100897 train_error 18.00% test_error 20.00%\n",
      "================================3030===================================\n",
      "3030/4000: train_loss: 2.462088404871174 train_error 18.00% test_error 20.00%\n",
      "================================3031===================================\n",
      "3031/4000: train_loss: 2.4618195735948394 train_error 18.00% test_error 20.00%\n",
      "================================3032===================================\n",
      "3032/4000: train_loss: 2.4615446852182505 train_error 18.00% test_error 20.00%\n",
      "================================3033===================================\n",
      "3033/4000: train_loss: 2.4612680326978444 train_error 18.00% test_error 20.00%\n",
      "================================3034===================================\n",
      "3034/4000: train_loss: 2.4609919315256414 train_error 18.00% test_error 20.00%\n",
      "================================3035===================================\n",
      "3035/4000: train_loss: 2.460715110789751 train_error 18.00% test_error 20.00%\n",
      "================================3036===================================\n",
      "3036/4000: train_loss: 2.4604365992796375 train_error 18.00% test_error 20.00%\n",
      "================================3037===================================\n",
      "3037/4000: train_loss: 2.4601593504106862 train_error 18.00% test_error 20.00%\n",
      "================================3038===================================\n",
      "3038/4000: train_loss: 2.4598838399490344 train_error 18.00% test_error 20.00%\n",
      "================================3039===================================\n",
      "3039/4000: train_loss: 2.4596109325799627 train_error 18.00% test_error 20.00%\n",
      "================================3040===================================\n",
      "3040/4000: train_loss: 2.4593358279252424 train_error 18.00% test_error 20.00%\n",
      "================================3041===================================\n",
      "3041/4000: train_loss: 2.459060235145735 train_error 18.00% test_error 20.00%\n",
      "================================3042===================================\n",
      "3042/4000: train_loss: 2.458785532076727 train_error 18.00% test_error 20.00%\n",
      "================================3043===================================\n",
      "3043/4000: train_loss: 2.4585114570573205 train_error 18.00% test_error 20.00%\n",
      "================================3044===================================\n",
      "3044/4000: train_loss: 2.4582383070484504 train_error 18.00% test_error 20.00%\n",
      "================================3045===================================\n",
      "3045/4000: train_loss: 2.457966345701716 train_error 18.00% test_error 20.00%\n",
      "================================3046===================================\n",
      "3046/4000: train_loss: 2.457688559910748 train_error 18.00% test_error 20.00%\n",
      "================================3047===================================\n",
      "3047/4000: train_loss: 2.4574111442541473 train_error 18.00% test_error 20.00%\n",
      "================================3048===================================\n",
      "3048/4000: train_loss: 2.4571335901354905 train_error 18.00% test_error 20.00%\n",
      "================================3049===================================\n",
      "3049/4000: train_loss: 2.4568575925769984 train_error 18.00% test_error 20.00%\n",
      "================================3050===================================\n",
      "3050/4000: train_loss: 2.456576881396468 train_error 18.00% test_error 20.00%\n",
      "================================3051===================================\n",
      "3051/4000: train_loss: 2.4562931114051025 train_error 18.00% test_error 20.00%\n",
      "================================3052===================================\n",
      "3052/4000: train_loss: 2.4560098546033258 train_error 18.00% test_error 20.00%\n",
      "================================3053===================================\n",
      "3053/4000: train_loss: 2.4557269628037464 train_error 17.88% test_error 20.00%\n",
      "================================3054===================================\n",
      "3054/4000: train_loss: 2.4554486859444298 train_error 17.88% test_error 20.00%\n",
      "================================3055===================================\n",
      "3055/4000: train_loss: 2.4551768044807245 train_error 17.88% test_error 20.00%\n",
      "================================3056===================================\n",
      "3056/4000: train_loss: 2.454909333437099 train_error 17.88% test_error 20.00%\n",
      "================================3057===================================\n",
      "3057/4000: train_loss: 2.4546429173229263 train_error 17.88% test_error 20.00%\n",
      "================================3058===================================\n",
      "3058/4000: train_loss: 2.454377972793882 train_error 17.88% test_error 20.00%\n",
      "================================3059===================================\n",
      "3059/4000: train_loss: 2.4541116507659897 train_error 17.88% test_error 20.00%\n",
      "================================3060===================================\n",
      "3060/4000: train_loss: 2.4538423614652127 train_error 17.88% test_error 20.00%\n",
      "================================3061===================================\n",
      "3061/4000: train_loss: 2.453573818233563 train_error 17.88% test_error 20.00%\n",
      "================================3062===================================\n",
      "3062/4000: train_loss: 2.453306633410975 train_error 17.88% test_error 20.00%\n",
      "================================3063===================================\n",
      "3063/4000: train_loss: 2.453037468361435 train_error 17.88% test_error 20.00%\n",
      "================================3064===================================\n",
      "3064/4000: train_loss: 2.452769013051293 train_error 18.00% test_error 20.00%\n",
      "================================3065===================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3065/4000: train_loss: 2.4525002430606397 train_error 18.00% test_error 20.50%\n",
      "================================3066===================================\n",
      "3066/4000: train_loss: 2.4522301244310802 train_error 18.00% test_error 20.50%\n",
      "================================3067===================================\n",
      "3067/4000: train_loss: 2.4519590843189505 train_error 18.00% test_error 20.50%\n",
      "================================3068===================================\n",
      "3068/4000: train_loss: 2.4516899268922865 train_error 18.00% test_error 20.50%\n",
      "================================3069===================================\n",
      "3069/4000: train_loss: 2.4514221074205125 train_error 18.00% test_error 20.50%\n",
      "================================3070===================================\n",
      "3070/4000: train_loss: 2.4511554429651006 train_error 17.88% test_error 21.00%\n",
      "================================3071===================================\n",
      "3071/4000: train_loss: 2.4508879515907025 train_error 17.88% test_error 21.00%\n",
      "================================3072===================================\n",
      "3072/4000: train_loss: 2.4506190945929847 train_error 17.88% test_error 21.00%\n",
      "================================3073===================================\n",
      "3073/4000: train_loss: 2.4503547086869366 train_error 17.88% test_error 21.00%\n",
      "================================3074===================================\n",
      "3074/4000: train_loss: 2.4500916349334876 train_error 17.88% test_error 21.00%\n",
      "================================3075===================================\n",
      "3075/4000: train_loss: 2.4498321587778626 train_error 17.88% test_error 21.00%\n",
      "================================3076===================================\n",
      "3076/4000: train_loss: 2.449567742187646 train_error 17.88% test_error 21.00%\n",
      "================================3077===================================\n",
      "3077/4000: train_loss: 2.4493056733568666 train_error 17.88% test_error 21.00%\n",
      "================================3078===================================\n",
      "3078/4000: train_loss: 2.4490405627695147 train_error 17.88% test_error 21.00%\n",
      "================================3079===================================\n",
      "3079/4000: train_loss: 2.4487747885443967 train_error 17.88% test_error 21.00%\n",
      "================================3080===================================\n",
      "3080/4000: train_loss: 2.448509572129697 train_error 17.88% test_error 21.00%\n",
      "================================3081===================================\n",
      "3081/4000: train_loss: 2.448247344501433 train_error 18.00% test_error 21.00%\n",
      "================================3082===================================\n",
      "3082/4000: train_loss: 2.4479853550466943 train_error 18.00% test_error 21.00%\n",
      "================================3083===================================\n",
      "3083/4000: train_loss: 2.4477250714495313 train_error 18.00% test_error 21.00%\n",
      "================================3084===================================\n",
      "3084/4000: train_loss: 2.447469475926482 train_error 18.00% test_error 21.00%\n",
      "================================3085===================================\n",
      "3085/4000: train_loss: 2.447211904498399 train_error 18.00% test_error 21.00%\n",
      "================================3086===================================\n",
      "3086/4000: train_loss: 2.4469575820781753 train_error 18.00% test_error 21.00%\n",
      "================================3087===================================\n",
      "3087/4000: train_loss: 2.446704614082118 train_error 18.00% test_error 21.50%\n",
      "================================3088===================================\n",
      "3088/4000: train_loss: 2.446453147827997 train_error 18.00% test_error 21.50%\n",
      "================================3089===================================\n",
      "3089/4000: train_loss: 2.4462020417291206 train_error 18.00% test_error 21.50%\n",
      "================================3090===================================\n",
      "3090/4000: train_loss: 2.445951596452505 train_error 18.00% test_error 21.50%\n",
      "================================3091===================================\n",
      "3091/4000: train_loss: 2.445701963212341 train_error 18.00% test_error 21.50%\n",
      "================================3092===================================\n",
      "3092/4000: train_loss: 2.4454531708831198 train_error 18.00% test_error 21.50%\n",
      "================================3093===================================\n",
      "3093/4000: train_loss: 2.4452057403884826 train_error 18.00% test_error 21.50%\n",
      "================================3094===================================\n",
      "3094/4000: train_loss: 2.444957649296848 train_error 18.00% test_error 21.50%\n",
      "================================3095===================================\n",
      "3095/4000: train_loss: 2.444704347194638 train_error 18.00% test_error 21.50%\n",
      "================================3096===================================\n",
      "3096/4000: train_loss: 2.444453430303256 train_error 18.00% test_error 21.50%\n",
      "================================3097===================================\n",
      "3097/4000: train_loss: 2.4441976564709327 train_error 18.00% test_error 21.50%\n",
      "================================3098===================================\n",
      "3098/4000: train_loss: 2.4439453970926115 train_error 18.00% test_error 21.50%\n",
      "================================3099===================================\n",
      "3099/4000: train_loss: 2.4436950753233395 train_error 18.00% test_error 21.50%\n",
      "================================3100===================================\n",
      "3100/4000: train_loss: 2.4434480549080764 train_error 18.00% test_error 21.50%\n",
      "================================3101===================================\n",
      "3101/4000: train_loss: 2.4432010708830783 train_error 18.00% test_error 21.50%\n",
      "================================3102===================================\n",
      "3102/4000: train_loss: 2.4429557175020458 train_error 18.00% test_error 21.50%\n",
      "================================3103===================================\n",
      "3103/4000: train_loss: 2.442710609361529 train_error 18.00% test_error 21.50%\n",
      "================================3104===================================\n",
      "3104/4000: train_loss: 2.4424668290512637 train_error 18.00% test_error 21.50%\n",
      "================================3105===================================\n",
      "3105/4000: train_loss: 2.442224423623993 train_error 18.00% test_error 21.50%\n",
      "================================3106===================================\n",
      "3106/4000: train_loss: 2.4419831904611784 train_error 18.00% test_error 21.50%\n",
      "================================3107===================================\n",
      "3107/4000: train_loss: 2.4417424367257627 train_error 18.00% test_error 21.50%\n",
      "================================3108===================================\n",
      "3108/4000: train_loss: 2.4414992774638815 train_error 18.00% test_error 21.50%\n",
      "================================3109===================================\n",
      "3109/4000: train_loss: 2.4412576675519815 train_error 18.00% test_error 21.50%\n",
      "================================3110===================================\n",
      "3110/4000: train_loss: 2.441017977132287 train_error 18.00% test_error 21.50%\n",
      "================================3111===================================\n",
      "3111/4000: train_loss: 2.440778358473617 train_error 18.00% test_error 21.50%\n",
      "================================3112===================================\n",
      "3112/4000: train_loss: 2.4405372622353028 train_error 18.00% test_error 21.50%\n",
      "================================3113===================================\n",
      "3113/4000: train_loss: 2.4402931009893654 train_error 18.00% test_error 21.50%\n",
      "================================3114===================================\n",
      "3114/4000: train_loss: 2.440048554451205 train_error 18.00% test_error 21.50%\n",
      "================================3115===================================\n",
      "3115/4000: train_loss: 2.439801662880927 train_error 18.00% test_error 21.50%\n",
      "================================3116===================================\n",
      "3116/4000: train_loss: 2.4395555071622947 train_error 18.00% test_error 21.50%\n",
      "================================3117===================================\n",
      "3117/4000: train_loss: 2.4393071595614306 train_error 18.00% test_error 21.50%\n",
      "================================3118===================================\n",
      "3118/4000: train_loss: 2.439053528392397 train_error 18.00% test_error 21.50%\n",
      "================================3119===================================\n",
      "3119/4000: train_loss: 2.4387959864430013 train_error 18.00% test_error 21.50%\n",
      "================================3120===================================\n",
      "3120/4000: train_loss: 2.4385400114496587 train_error 18.00% test_error 21.50%\n",
      "================================3121===================================\n",
      "3121/4000: train_loss: 2.438286602035805 train_error 18.00% test_error 21.50%\n",
      "================================3122===================================\n",
      "3122/4000: train_loss: 2.438034107189451 train_error 18.00% test_error 21.50%\n",
      "================================3123===================================\n",
      "3123/4000: train_loss: 2.4377830380829986 train_error 18.00% test_error 21.50%\n",
      "================================3124===================================\n",
      "3124/4000: train_loss: 2.437527533319371 train_error 17.88% test_error 21.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3125===================================\n",
      "3125/4000: train_loss: 2.4372725602102583 train_error 17.88% test_error 21.50%\n",
      "================================3126===================================\n",
      "3126/4000: train_loss: 2.4370172835674024 train_error 17.88% test_error 21.50%\n",
      "================================3127===================================\n",
      "3127/4000: train_loss: 2.4367630333441777 train_error 17.88% test_error 21.50%\n",
      "================================3128===================================\n",
      "3128/4000: train_loss: 2.436509168835764 train_error 17.88% test_error 21.50%\n",
      "================================3129===================================\n",
      "3129/4000: train_loss: 2.4362548701785274 train_error 17.88% test_error 21.50%\n",
      "================================3130===================================\n",
      "3130/4000: train_loss: 2.4360026537149677 train_error 17.88% test_error 21.50%\n",
      "================================3131===================================\n",
      "3131/4000: train_loss: 2.4357529440135117 train_error 17.88% test_error 21.50%\n",
      "================================3132===================================\n",
      "3132/4000: train_loss: 2.4355006370451884 train_error 17.88% test_error 21.50%\n",
      "================================3133===================================\n",
      "3133/4000: train_loss: 2.4352461739932187 train_error 17.88% test_error 21.50%\n",
      "================================3134===================================\n",
      "3134/4000: train_loss: 2.434985041419277 train_error 17.88% test_error 21.50%\n",
      "================================3135===================================\n",
      "3135/4000: train_loss: 2.434725763976458 train_error 17.88% test_error 21.50%\n",
      "================================3136===================================\n",
      "3136/4000: train_loss: 2.434466319579515 train_error 17.88% test_error 21.50%\n",
      "================================3137===================================\n",
      "3137/4000: train_loss: 2.434207970488933 train_error 17.88% test_error 21.50%\n",
      "================================3138===================================\n",
      "3138/4000: train_loss: 2.4339504318160468 train_error 17.88% test_error 21.00%\n",
      "================================3139===================================\n",
      "3139/4000: train_loss: 2.433694821111276 train_error 17.88% test_error 21.00%\n",
      "================================3140===================================\n",
      "3140/4000: train_loss: 2.4334395593951923 train_error 17.88% test_error 21.00%\n",
      "================================3141===================================\n",
      "3141/4000: train_loss: 2.4331843172656953 train_error 17.88% test_error 21.00%\n",
      "================================3142===================================\n",
      "3142/4000: train_loss: 2.4329297502787086 train_error 17.88% test_error 21.00%\n",
      "================================3143===================================\n",
      "3143/4000: train_loss: 2.4326761323335813 train_error 17.88% test_error 21.00%\n",
      "================================3144===================================\n",
      "3144/4000: train_loss: 2.4324238380021415 train_error 17.88% test_error 21.00%\n",
      "================================3145===================================\n",
      "3145/4000: train_loss: 2.4321729840597257 train_error 17.88% test_error 21.00%\n",
      "================================3146===================================\n",
      "3146/4000: train_loss: 2.4319228359701808 train_error 17.88% test_error 21.00%\n",
      "================================3147===================================\n",
      "3147/4000: train_loss: 2.43167099548009 train_error 17.88% test_error 21.00%\n",
      "================================3148===================================\n",
      "3148/4000: train_loss: 2.431421670426498 train_error 17.88% test_error 21.00%\n",
      "================================3149===================================\n",
      "3149/4000: train_loss: 2.4311772480953366 train_error 17.88% test_error 21.00%\n",
      "================================3150===================================\n",
      "3150/4000: train_loss: 2.430933332000568 train_error 17.88% test_error 21.00%\n",
      "================================3151===================================\n",
      "3151/4000: train_loss: 2.4306929294299335 train_error 17.88% test_error 21.00%\n",
      "================================3152===================================\n",
      "3152/4000: train_loss: 2.430453314528568 train_error 17.88% test_error 21.00%\n",
      "================================3153===================================\n",
      "3153/4000: train_loss: 2.430213560196571 train_error 17.88% test_error 21.00%\n",
      "================================3154===================================\n",
      "3154/4000: train_loss: 2.429972123001062 train_error 17.88% test_error 21.00%\n",
      "================================3155===================================\n",
      "3155/4000: train_loss: 2.429732169424824 train_error 17.88% test_error 21.00%\n",
      "================================3156===================================\n",
      "3156/4000: train_loss: 2.429493375766906 train_error 17.88% test_error 21.00%\n",
      "================================3157===================================\n",
      "3157/4000: train_loss: 2.429255493778328 train_error 17.88% test_error 21.00%\n",
      "================================3158===================================\n",
      "3158/4000: train_loss: 2.4290183945710306 train_error 17.88% test_error 21.00%\n",
      "================================3159===================================\n",
      "3159/4000: train_loss: 2.4287819682221743 train_error 17.88% test_error 21.00%\n",
      "================================3160===================================\n",
      "3160/4000: train_loss: 2.4285482632240747 train_error 17.88% test_error 21.00%\n",
      "================================3161===================================\n",
      "3161/4000: train_loss: 2.4283176303448273 train_error 17.88% test_error 21.00%\n",
      "================================3162===================================\n",
      "3162/4000: train_loss: 2.4280891617844462 train_error 17.88% test_error 21.00%\n",
      "================================3163===================================\n",
      "3163/4000: train_loss: 2.4278628281049897 train_error 17.88% test_error 21.00%\n",
      "================================3164===================================\n",
      "3164/4000: train_loss: 2.427639491662558 train_error 17.88% test_error 21.00%\n",
      "================================3165===================================\n",
      "3165/4000: train_loss: 2.427415342457534 train_error 17.88% test_error 21.00%\n",
      "================================3166===================================\n",
      "3166/4000: train_loss: 2.427191096516617 train_error 17.88% test_error 21.00%\n",
      "================================3167===================================\n",
      "3167/4000: train_loss: 2.426968168579915 train_error 17.88% test_error 21.00%\n",
      "================================3168===================================\n",
      "3168/4000: train_loss: 2.426748132328794 train_error 17.88% test_error 21.00%\n",
      "================================3169===================================\n",
      "3169/4000: train_loss: 2.426531020886905 train_error 17.88% test_error 21.00%\n",
      "================================3170===================================\n",
      "3170/4000: train_loss: 2.426317214728624 train_error 17.88% test_error 21.00%\n",
      "================================3171===================================\n",
      "3171/4000: train_loss: 2.4261043012485604 train_error 17.88% test_error 21.00%\n",
      "================================3172===================================\n",
      "3172/4000: train_loss: 2.4258930491196224 train_error 17.88% test_error 21.00%\n",
      "================================3173===================================\n",
      "3173/4000: train_loss: 2.425683492970129 train_error 17.88% test_error 21.00%\n",
      "================================3174===================================\n",
      "3174/4000: train_loss: 2.4254755966170345 train_error 17.88% test_error 21.00%\n",
      "================================3175===================================\n",
      "3175/4000: train_loss: 2.4252664072540937 train_error 17.88% test_error 21.00%\n",
      "================================3176===================================\n",
      "3176/4000: train_loss: 2.425054109001649 train_error 17.88% test_error 21.00%\n",
      "================================3177===================================\n",
      "3177/4000: train_loss: 2.4248434157803422 train_error 17.88% test_error 21.00%\n",
      "================================3178===================================\n",
      "3178/4000: train_loss: 2.4246330598535133 train_error 17.88% test_error 21.00%\n",
      "================================3179===================================\n",
      "3179/4000: train_loss: 2.4244224907443277 train_error 17.88% test_error 21.00%\n",
      "================================3180===================================\n",
      "3180/4000: train_loss: 2.4242125345664682 train_error 17.88% test_error 21.50%\n",
      "================================3181===================================\n",
      "3181/4000: train_loss: 2.424000418812211 train_error 17.88% test_error 21.50%\n",
      "================================3182===================================\n",
      "3182/4000: train_loss: 2.423785999479587 train_error 17.88% test_error 21.50%\n",
      "================================3183===================================\n",
      "3183/4000: train_loss: 2.4235669438325567 train_error 17.88% test_error 21.00%\n",
      "================================3184===================================\n",
      "3184/4000: train_loss: 2.4233514849099445 train_error 17.88% test_error 21.00%\n",
      "================================3185===================================\n",
      "3185/4000: train_loss: 2.423137531313405 train_error 17.88% test_error 21.00%\n",
      "================================3186===================================\n",
      "3186/4000: train_loss: 2.42293042649253 train_error 17.88% test_error 21.00%\n",
      "================================3187===================================\n",
      "3187/4000: train_loss: 2.422727017941652 train_error 17.88% test_error 21.00%\n",
      "================================3188===================================\n",
      "3188/4000: train_loss: 2.422523160215351 train_error 17.88% test_error 21.00%\n",
      "================================3189===================================\n",
      "3189/4000: train_loss: 2.4223147735738895 train_error 17.88% test_error 21.00%\n",
      "================================3190===================================\n",
      "3190/4000: train_loss: 2.422111670625163 train_error 17.88% test_error 21.00%\n",
      "================================3191===================================\n",
      "3191/4000: train_loss: 2.42191000124265 train_error 17.88% test_error 21.00%\n",
      "================================3192===================================\n",
      "3192/4000: train_loss: 2.4217089993163246 train_error 17.88% test_error 21.00%\n",
      "================================3193===================================\n",
      "3193/4000: train_loss: 2.4215089225742847 train_error 17.88% test_error 21.00%\n",
      "================================3194===================================\n",
      "3194/4000: train_loss: 2.4213056031567977 train_error 18.00% test_error 21.00%\n",
      "================================3195===================================\n",
      "3195/4000: train_loss: 2.4210991554998325 train_error 18.00% test_error 21.00%\n",
      "================================3196===================================\n",
      "3196/4000: train_loss: 2.4208919976782637 train_error 18.00% test_error 21.00%\n",
      "================================3197===================================\n",
      "3197/4000: train_loss: 2.4206846850449804 train_error 18.00% test_error 21.00%\n",
      "================================3198===================================\n",
      "3198/4000: train_loss: 2.4204790727604997 train_error 18.00% test_error 21.00%\n",
      "================================3199===================================\n",
      "3199/4000: train_loss: 2.420274906166596 train_error 18.00% test_error 21.00%\n",
      "================================3200===================================\n",
      "3200/4000: train_loss: 2.420075212598604 train_error 18.12% test_error 21.00%\n",
      "================================3201===================================\n",
      "3201/4000: train_loss: 2.419877867147152 train_error 18.12% test_error 21.00%\n",
      "================================3202===================================\n",
      "3202/4000: train_loss: 2.419680986882595 train_error 18.12% test_error 21.00%\n",
      "================================3203===================================\n",
      "3203/4000: train_loss: 2.4194855829584414 train_error 18.12% test_error 21.00%\n",
      "================================3204===================================\n",
      "3204/4000: train_loss: 2.4192908228974557 train_error 18.12% test_error 21.00%\n",
      "================================3205===================================\n",
      "3205/4000: train_loss: 2.419097644124122 train_error 18.12% test_error 21.00%\n",
      "================================3206===================================\n",
      "3206/4000: train_loss: 2.4189054150204172 train_error 18.12% test_error 21.00%\n",
      "================================3207===================================\n",
      "3207/4000: train_loss: 2.418716181573982 train_error 18.12% test_error 21.00%\n",
      "================================3208===================================\n",
      "3208/4000: train_loss: 2.418528665660997 train_error 18.12% test_error 21.00%\n",
      "================================3209===================================\n",
      "3209/4000: train_loss: 2.4183415836925266 train_error 18.00% test_error 21.00%\n",
      "================================3210===================================\n",
      "3210/4000: train_loss: 2.4181561838102064 train_error 18.00% test_error 21.00%\n",
      "================================3211===================================\n",
      "3211/4000: train_loss: 2.417971301235957 train_error 18.00% test_error 21.00%\n",
      "================================3212===================================\n",
      "3212/4000: train_loss: 2.4177873395429925 train_error 18.00% test_error 21.00%\n",
      "================================3213===================================\n",
      "3213/4000: train_loss: 2.4176072716811907 train_error 18.00% test_error 21.00%\n",
      "================================3214===================================\n",
      "3214/4000: train_loss: 2.4174290018290048 train_error 17.88% test_error 21.00%\n",
      "================================3215===================================\n",
      "3215/4000: train_loss: 2.4172554310469425 train_error 17.88% test_error 21.00%\n",
      "================================3216===================================\n",
      "3216/4000: train_loss: 2.417089328173897 train_error 17.88% test_error 21.00%\n",
      "================================3217===================================\n",
      "3217/4000: train_loss: 2.416927205337852 train_error 17.88% test_error 21.00%\n",
      "================================3218===================================\n",
      "3218/4000: train_loss: 2.416758916070103 train_error 17.88% test_error 21.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3219===================================\n",
      "3219/4000: train_loss: 2.416594392223633 train_error 17.88% test_error 21.00%\n",
      "================================3220===================================\n",
      "3220/4000: train_loss: 2.4164279813520264 train_error 17.88% test_error 21.00%\n",
      "================================3221===================================\n",
      "3221/4000: train_loss: 2.4162584628225887 train_error 17.88% test_error 21.00%\n",
      "================================3222===================================\n",
      "3222/4000: train_loss: 2.416090977398708 train_error 17.88% test_error 21.00%\n",
      "================================3223===================================\n",
      "3223/4000: train_loss: 2.4159240876222614 train_error 17.88% test_error 21.00%\n",
      "================================3224===================================\n",
      "3224/4000: train_loss: 2.4157568418447046 train_error 18.00% test_error 21.00%\n",
      "================================3225===================================\n",
      "3225/4000: train_loss: 2.4155898970436827 train_error 18.00% test_error 21.00%\n",
      "================================3226===================================\n",
      "3226/4000: train_loss: 2.4154223593704227 train_error 18.00% test_error 21.00%\n",
      "================================3227===================================\n",
      "3227/4000: train_loss: 2.415255412070401 train_error 18.00% test_error 21.00%\n",
      "================================3228===================================\n",
      "3228/4000: train_loss: 2.4150887883716496 train_error 18.00% test_error 21.00%\n",
      "================================3229===================================\n",
      "3229/4000: train_loss: 2.4149212834591163 train_error 18.00% test_error 21.00%\n",
      "================================3230===================================\n",
      "3230/4000: train_loss: 2.4147525869242963 train_error 18.00% test_error 21.00%\n",
      "================================3231===================================\n",
      "3231/4000: train_loss: 2.4145823226963694 train_error 18.00% test_error 21.00%\n",
      "================================3232===================================\n",
      "3232/4000: train_loss: 2.4144142286869466 train_error 18.00% test_error 21.00%\n",
      "================================3233===================================\n",
      "3233/4000: train_loss: 2.414244640944671 train_error 18.00% test_error 21.00%\n",
      "================================3234===================================\n",
      "3234/4000: train_loss: 2.414074841632537 train_error 18.00% test_error 21.00%\n",
      "================================3235===================================\n",
      "3235/4000: train_loss: 2.4139059284147515 train_error 18.00% test_error 21.00%\n",
      "================================3236===================================\n",
      "3236/4000: train_loss: 2.4137360230382185 train_error 18.00% test_error 21.00%\n",
      "================================3237===================================\n",
      "3237/4000: train_loss: 2.413566622005747 train_error 18.00% test_error 21.00%\n",
      "================================3238===================================\n",
      "3238/4000: train_loss: 2.413399963386473 train_error 17.88% test_error 21.00%\n",
      "================================3239===================================\n",
      "3239/4000: train_loss: 2.413234102710703 train_error 17.88% test_error 21.00%\n",
      "================================3240===================================\n",
      "3240/4000: train_loss: 2.41306818158002 train_error 17.88% test_error 21.00%\n",
      "================================3241===================================\n",
      "3241/4000: train_loss: 2.4129013506832417 train_error 17.88% test_error 21.00%\n",
      "================================3242===================================\n",
      "3242/4000: train_loss: 2.4127412178684606 train_error 17.88% test_error 21.00%\n",
      "================================3243===================================\n",
      "3243/4000: train_loss: 2.4125854944449387 train_error 17.88% test_error 21.00%\n",
      "================================3244===================================\n",
      "3244/4000: train_loss: 2.4124305602027745 train_error 17.88% test_error 21.00%\n",
      "================================3245===================================\n",
      "3245/4000: train_loss: 2.4122796276587177 train_error 17.88% test_error 21.00%\n",
      "================================3246===================================\n",
      "3246/4000: train_loss: 2.412135355345381 train_error 17.88% test_error 21.00%\n",
      "================================3247===================================\n",
      "3247/4000: train_loss: 2.4119985995987374 train_error 17.88% test_error 21.00%\n",
      "================================3248===================================\n",
      "3248/4000: train_loss: 2.4118692924326752 train_error 17.88% test_error 21.00%\n",
      "================================3249===================================\n",
      "3249/4000: train_loss: 2.4117409061717625 train_error 17.88% test_error 21.00%\n",
      "================================3250===================================\n",
      "3250/4000: train_loss: 2.4116111495705264 train_error 17.88% test_error 21.00%\n",
      "================================3251===================================\n",
      "3251/4000: train_loss: 2.411483795578679 train_error 17.88% test_error 21.00%\n",
      "================================3252===================================\n",
      "3252/4000: train_loss: 2.4113576017743616 train_error 17.88% test_error 21.00%\n",
      "================================3253===================================\n",
      "3253/4000: train_loss: 2.411231168833765 train_error 17.88% test_error 21.00%\n",
      "================================3254===================================\n",
      "3254/4000: train_loss: 2.411102186199714 train_error 17.88% test_error 21.00%\n",
      "================================3255===================================\n",
      "3255/4000: train_loss: 2.410972602636466 train_error 17.88% test_error 21.00%\n",
      "================================3256===================================\n",
      "3256/4000: train_loss: 2.410845267361292 train_error 18.00% test_error 21.00%\n",
      "================================3257===================================\n",
      "3257/4000: train_loss: 2.4107194102162612 train_error 18.00% test_error 21.00%\n",
      "================================3258===================================\n",
      "3258/4000: train_loss: 2.4105927181894367 train_error 18.00% test_error 21.00%\n",
      "================================3259===================================\n",
      "3259/4000: train_loss: 2.4104717057016387 train_error 18.00% test_error 21.00%\n",
      "================================3260===================================\n",
      "3260/4000: train_loss: 2.410352368084132 train_error 18.00% test_error 21.00%\n",
      "================================3261===================================\n",
      "3261/4000: train_loss: 2.41023537695728 train_error 18.00% test_error 21.00%\n",
      "================================3262===================================\n",
      "3262/4000: train_loss: 2.41011769711753 train_error 18.00% test_error 21.00%\n",
      "================================3263===================================\n",
      "3263/4000: train_loss: 2.410000601083011 train_error 18.00% test_error 21.00%\n",
      "================================3264===================================\n",
      "3264/4000: train_loss: 2.409883881003043 train_error 18.12% test_error 21.00%\n",
      "================================3265===================================\n",
      "3265/4000: train_loss: 2.4097658039013914 train_error 18.12% test_error 21.00%\n",
      "================================3266===================================\n",
      "3266/4000: train_loss: 2.4096468070411357 train_error 18.12% test_error 21.00%\n",
      "================================3267===================================\n",
      "3267/4000: train_loss: 2.409531454298267 train_error 18.25% test_error 21.00%\n",
      "================================3268===================================\n",
      "3268/4000: train_loss: 2.409415795376408 train_error 18.25% test_error 21.00%\n",
      "================================3269===================================\n",
      "3269/4000: train_loss: 2.409299469536054 train_error 18.25% test_error 21.00%\n",
      "================================3270===================================\n",
      "3270/4000: train_loss: 2.409183566357533 train_error 18.25% test_error 20.50%\n",
      "================================3271===================================\n",
      "3271/4000: train_loss: 2.409069672415644 train_error 18.25% test_error 20.50%\n",
      "================================3272===================================\n",
      "3272/4000: train_loss: 2.408959650103934 train_error 18.25% test_error 20.50%\n",
      "================================3273===================================\n",
      "3273/4000: train_loss: 2.408852301272418 train_error 18.25% test_error 20.50%\n",
      "================================3274===================================\n",
      "3274/4000: train_loss: 2.408744505250215 train_error 18.25% test_error 20.50%\n",
      "================================3275===================================\n",
      "3275/4000: train_loss: 2.4086378422591954 train_error 18.25% test_error 20.50%\n",
      "================================3276===================================\n",
      "3276/4000: train_loss: 2.4085337411414365 train_error 18.25% test_error 20.50%\n",
      "================================3277===================================\n",
      "3277/4000: train_loss: 2.408431523362087 train_error 18.25% test_error 20.50%\n",
      "================================3278===================================\n",
      "3278/4000: train_loss: 2.4083283994009257 train_error 18.25% test_error 21.00%\n",
      "================================3279===================================\n",
      "3279/4000: train_loss: 2.408225606608903 train_error 18.25% test_error 21.00%\n",
      "================================3280===================================\n",
      "3280/4000: train_loss: 2.4081288533018963 train_error 18.25% test_error 21.00%\n",
      "================================3281===================================\n",
      "3281/4000: train_loss: 2.40803546154144 train_error 18.25% test_error 21.00%\n",
      "================================3282===================================\n",
      "3282/4000: train_loss: 2.407941471779486 train_error 18.25% test_error 21.00%\n",
      "================================3283===================================\n",
      "3283/4000: train_loss: 2.407847720617574 train_error 18.38% test_error 21.00%\n",
      "================================3284===================================\n",
      "3284/4000: train_loss: 2.4077542777798953 train_error 18.38% test_error 21.00%\n",
      "================================3285===================================\n",
      "3285/4000: train_loss: 2.4076612560577635 train_error 18.25% test_error 21.00%\n",
      "================================3286===================================\n",
      "3286/4000: train_loss: 2.407568562263332 train_error 18.25% test_error 21.00%\n",
      "================================3287===================================\n",
      "3287/4000: train_loss: 2.4074760338148917 train_error 18.38% test_error 21.00%\n",
      "================================3288===================================\n",
      "3288/4000: train_loss: 2.407383949335781 train_error 18.38% test_error 21.00%\n",
      "================================3289===================================\n",
      "3289/4000: train_loss: 2.407291042707366 train_error 18.38% test_error 21.00%\n",
      "================================3290===================================\n",
      "3290/4000: train_loss: 2.4072019443417956 train_error 18.38% test_error 21.00%\n",
      "================================3291===================================\n",
      "3291/4000: train_loss: 2.4071139742073138 train_error 18.38% test_error 21.00%\n",
      "================================3292===================================\n",
      "3292/4000: train_loss: 2.4070260193712603 train_error 18.38% test_error 21.00%\n",
      "================================3293===================================\n",
      "3293/4000: train_loss: 2.406938810674037 train_error 18.38% test_error 21.00%\n",
      "================================3294===================================\n",
      "3294/4000: train_loss: 2.4068500503859833 train_error 18.38% test_error 21.00%\n",
      "================================3295===================================\n",
      "3295/4000: train_loss: 2.406759308769106 train_error 18.38% test_error 21.00%\n",
      "================================3296===================================\n",
      "3296/4000: train_loss: 2.4066708773598657 train_error 18.38% test_error 21.00%\n",
      "================================3297===================================\n",
      "3297/4000: train_loss: 2.4065823185975024 train_error 18.38% test_error 21.00%\n",
      "================================3298===================================\n",
      "3298/4000: train_loss: 2.406494052078924 train_error 18.25% test_error 21.00%\n",
      "================================3299===================================\n",
      "3299/4000: train_loss: 2.4064078826920015 train_error 18.25% test_error 21.00%\n",
      "================================3300===================================\n",
      "3300/4000: train_loss: 2.4063227486312098 train_error 18.25% test_error 21.00%\n",
      "================================3301===================================\n",
      "3301/4000: train_loss: 2.4062369498326737 train_error 18.25% test_error 21.00%\n",
      "================================3302===================================\n",
      "3302/4000: train_loss: 2.4061510901826844 train_error 18.25% test_error 21.00%\n",
      "================================3303===================================\n",
      "3303/4000: train_loss: 2.406066506006173 train_error 18.25% test_error 21.00%\n",
      "================================3304===================================\n",
      "3304/4000: train_loss: 2.405980382559792 train_error 18.38% test_error 21.00%\n",
      "================================3305===================================\n",
      "3305/4000: train_loss: 2.4058942891701007 train_error 18.38% test_error 21.00%\n",
      "================================3306===================================\n",
      "3306/4000: train_loss: 2.405806162934896 train_error 18.38% test_error 21.00%\n",
      "================================3307===================================\n",
      "3307/4000: train_loss: 2.4057176675669325 train_error 18.38% test_error 21.00%\n",
      "================================3308===================================\n",
      "3308/4000: train_loss: 2.405629674185329 train_error 18.38% test_error 21.00%\n",
      "================================3309===================================\n",
      "3309/4000: train_loss: 2.4055419654400607 train_error 18.38% test_error 21.00%\n",
      "================================3310===================================\n",
      "3310/4000: train_loss: 2.405457290484483 train_error 18.38% test_error 21.00%\n",
      "================================3311===================================\n",
      "3311/4000: train_loss: 2.4053737421112604 train_error 18.38% test_error 21.00%\n",
      "================================3312===================================\n",
      "3312/4000: train_loss: 2.4052921925182456 train_error 18.50% test_error 21.00%\n",
      "================================3313===================================\n",
      "3313/4000: train_loss: 2.405211509950168 train_error 18.50% test_error 21.00%\n",
      "================================3314===================================\n",
      "3314/4000: train_loss: 2.4051319881029483 train_error 18.50% test_error 21.00%\n",
      "================================3315===================================\n",
      "3315/4000: train_loss: 2.4050564545929958 train_error 18.50% test_error 21.00%\n",
      "================================3316===================================\n",
      "3316/4000: train_loss: 2.404981252153229 train_error 18.50% test_error 21.00%\n",
      "================================3317===================================\n",
      "3317/4000: train_loss: 2.4049060233168715 train_error 18.50% test_error 21.00%\n",
      "================================3318===================================\n",
      "3318/4000: train_loss: 2.4048312859689758 train_error 18.50% test_error 21.00%\n",
      "================================3319===================================\n",
      "3319/4000: train_loss: 2.404756230906496 train_error 18.50% test_error 21.00%\n",
      "================================3320===================================\n",
      "3320/4000: train_loss: 2.4046806269646916 train_error 18.50% test_error 21.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3321===================================\n",
      "3321/4000: train_loss: 2.4046048236761997 train_error 18.50% test_error 21.00%\n",
      "================================3322===================================\n",
      "3322/4000: train_loss: 2.4045267070621774 train_error 18.50% test_error 21.00%\n",
      "================================3323===================================\n",
      "3323/4000: train_loss: 2.4044436000977294 train_error 18.50% test_error 21.00%\n",
      "================================3324===================================\n",
      "3324/4000: train_loss: 2.404362822029798 train_error 18.50% test_error 21.00%\n",
      "================================3325===================================\n",
      "3325/4000: train_loss: 2.4042834509264503 train_error 18.50% test_error 21.00%\n",
      "================================3326===================================\n",
      "3326/4000: train_loss: 2.4042062552433343 train_error 18.50% test_error 21.00%\n",
      "================================3327===================================\n",
      "3327/4000: train_loss: 2.404130598107731 train_error 18.50% test_error 21.00%\n",
      "================================3328===================================\n",
      "3328/4000: train_loss: 2.404057956951583 train_error 18.50% test_error 21.00%\n",
      "================================3329===================================\n",
      "3329/4000: train_loss: 2.403986058356677 train_error 18.50% test_error 21.00%\n",
      "================================3330===================================\n",
      "3330/4000: train_loss: 2.403912412431091 train_error 18.50% test_error 21.00%\n",
      "================================3331===================================\n",
      "3331/4000: train_loss: 2.4038376515207345 train_error 18.50% test_error 21.00%\n",
      "================================3332===================================\n",
      "3332/4000: train_loss: 2.403763261641434 train_error 18.50% test_error 21.00%\n",
      "================================3333===================================\n",
      "3333/4000: train_loss: 2.4036890482832676 train_error 18.50% test_error 21.00%\n",
      "================================3334===================================\n",
      "3334/4000: train_loss: 2.4036100598178747 train_error 18.50% test_error 21.00%\n",
      "================================3335===================================\n",
      "3335/4000: train_loss: 2.403528046550637 train_error 18.50% test_error 21.00%\n",
      "================================3336===================================\n",
      "3336/4000: train_loss: 2.403445424844831 train_error 18.50% test_error 21.00%\n",
      "================================3337===================================\n",
      "3337/4000: train_loss: 2.4033624930311634 train_error 18.50% test_error 21.00%\n",
      "================================3338===================================\n",
      "3338/4000: train_loss: 2.4032820293819532 train_error 18.50% test_error 21.00%\n",
      "================================3339===================================\n",
      "3339/4000: train_loss: 2.403202230126481 train_error 18.50% test_error 21.00%\n",
      "================================3340===================================\n",
      "3340/4000: train_loss: 2.40312335967712 train_error 18.50% test_error 21.00%\n",
      "================================3341===================================\n",
      "3341/4000: train_loss: 2.4030400921705586 train_error 18.50% test_error 21.00%\n",
      "================================3342===================================\n",
      "3342/4000: train_loss: 2.402957893543353 train_error 18.50% test_error 21.00%\n",
      "================================3343===================================\n",
      "3343/4000: train_loss: 2.402875735976122 train_error 18.38% test_error 21.00%\n",
      "================================3344===================================\n",
      "3344/4000: train_loss: 2.4027933850807313 train_error 18.38% test_error 21.00%\n",
      "================================3345===================================\n",
      "3345/4000: train_loss: 2.4027110816448114 train_error 18.38% test_error 21.00%\n",
      "================================3346===================================\n",
      "3346/4000: train_loss: 2.402629708206805 train_error 18.38% test_error 21.00%\n",
      "================================3347===================================\n",
      "3347/4000: train_loss: 2.4025473627317115 train_error 18.38% test_error 21.00%\n",
      "================================3348===================================\n",
      "3348/4000: train_loss: 2.40246745649376 train_error 18.38% test_error 21.00%\n",
      "================================3349===================================\n",
      "3349/4000: train_loss: 2.4023860188617254 train_error 18.38% test_error 21.00%\n",
      "================================3350===================================\n",
      "3350/4000: train_loss: 2.402298495729483 train_error 18.38% test_error 21.00%\n",
      "================================3351===================================\n",
      "3351/4000: train_loss: 2.402212736038928 train_error 18.38% test_error 21.00%\n",
      "================================3352===================================\n",
      "3352/4000: train_loss: 2.4021270471632308 train_error 18.38% test_error 21.00%\n",
      "================================3353===================================\n",
      "3353/4000: train_loss: 2.4020412689047226 train_error 18.38% test_error 21.00%\n",
      "================================3354===================================\n",
      "3354/4000: train_loss: 2.401954235500816 train_error 18.38% test_error 21.00%\n",
      "================================3355===================================\n",
      "3355/4000: train_loss: 2.4018669252860128 train_error 18.38% test_error 21.00%\n",
      "================================3356===================================\n",
      "3356/4000: train_loss: 2.4017796258083397 train_error 18.38% test_error 21.00%\n",
      "================================3357===================================\n",
      "3357/4000: train_loss: 2.4016951524405155 train_error 18.38% test_error 21.00%\n",
      "================================3358===================================\n",
      "3358/4000: train_loss: 2.401610893368925 train_error 18.38% test_error 21.00%\n",
      "================================3359===================================\n",
      "3359/4000: train_loss: 2.4015293538924016 train_error 18.38% test_error 21.00%\n",
      "================================3360===================================\n",
      "3360/4000: train_loss: 2.4014459937178616 train_error 18.38% test_error 21.00%\n",
      "================================3361===================================\n",
      "3361/4000: train_loss: 2.401367487487514 train_error 18.38% test_error 21.00%\n",
      "================================3362===================================\n",
      "3362/4000: train_loss: 2.401289343855387 train_error 18.38% test_error 21.00%\n",
      "================================3363===================================\n",
      "3363/4000: train_loss: 2.401211490966816 train_error 18.38% test_error 21.00%\n",
      "================================3364===================================\n",
      "3364/4000: train_loss: 2.401134018958328 train_error 18.38% test_error 21.50%\n",
      "================================3365===================================\n",
      "3365/4000: train_loss: 2.401056695951047 train_error 18.50% test_error 21.50%\n",
      "================================3366===================================\n",
      "3366/4000: train_loss: 2.4009793451311268 train_error 18.50% test_error 21.50%\n",
      "================================3367===================================\n",
      "3367/4000: train_loss: 2.400900866222437 train_error 18.50% test_error 21.50%\n",
      "================================3368===================================\n",
      "3368/4000: train_loss: 2.400823794579046 train_error 18.50% test_error 21.50%\n",
      "================================3369===================================\n",
      "3369/4000: train_loss: 2.400745194016563 train_error 18.62% test_error 21.50%\n",
      "================================3370===================================\n",
      "3370/4000: train_loss: 2.4006668150579933 train_error 18.62% test_error 21.50%\n",
      "================================3371===================================\n",
      "3371/4000: train_loss: 2.4005921633826075 train_error 18.62% test_error 21.50%\n",
      "================================3372===================================\n",
      "3372/4000: train_loss: 2.4005218336638063 train_error 18.62% test_error 21.50%\n",
      "================================3373===================================\n",
      "3373/4000: train_loss: 2.400453532260653 train_error 18.62% test_error 21.50%\n",
      "================================3374===================================\n",
      "3374/4000: train_loss: 2.400384518000501 train_error 18.62% test_error 21.50%\n",
      "================================3375===================================\n",
      "3375/4000: train_loss: 2.400319227132713 train_error 18.62% test_error 21.50%\n",
      "================================3376===================================\n",
      "3376/4000: train_loss: 2.4002593003135555 train_error 18.62% test_error 21.50%\n",
      "================================3377===================================\n",
      "3377/4000: train_loss: 2.400199217256304 train_error 18.62% test_error 21.50%\n",
      "================================3378===================================\n",
      "3378/4000: train_loss: 2.4001387038538815 train_error 18.62% test_error 21.50%\n",
      "================================3379===================================\n",
      "3379/4000: train_loss: 2.4000755434115124 train_error 18.62% test_error 21.50%\n",
      "================================3380===================================\n",
      "3380/4000: train_loss: 2.4000117240573307 train_error 18.62% test_error 21.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3381===================================\n",
      "3381/4000: train_loss: 2.399949649066621 train_error 18.62% test_error 21.50%\n",
      "================================3382===================================\n",
      "3382/4000: train_loss: 2.399888832483848 train_error 18.62% test_error 21.50%\n",
      "================================3383===================================\n",
      "3383/4000: train_loss: 2.399828006651369 train_error 18.62% test_error 21.50%\n",
      "================================3384===================================\n",
      "3384/4000: train_loss: 2.3997662553305417 train_error 18.62% test_error 21.50%\n",
      "================================3385===================================\n",
      "3385/4000: train_loss: 2.3997049688833068 train_error 18.62% test_error 21.50%\n",
      "================================3386===================================\n",
      "3386/4000: train_loss: 2.399640961723562 train_error 18.62% test_error 21.50%\n",
      "================================3387===================================\n",
      "3387/4000: train_loss: 2.3995787634597945 train_error 18.62% test_error 21.50%\n",
      "================================3388===================================\n",
      "3388/4000: train_loss: 2.3995166374607653 train_error 18.62% test_error 21.50%\n",
      "================================3389===================================\n",
      "3389/4000: train_loss: 2.399454518323328 train_error 18.62% test_error 21.50%\n",
      "================================3390===================================\n",
      "3390/4000: train_loss: 2.3993935291925297 train_error 18.62% test_error 21.50%\n",
      "================================3391===================================\n",
      "3391/4000: train_loss: 2.399332930809687 train_error 18.62% test_error 21.50%\n",
      "================================3392===================================\n",
      "3392/4000: train_loss: 2.39927645407246 train_error 18.62% test_error 21.50%\n",
      "================================3393===================================\n",
      "3393/4000: train_loss: 2.399220449059867 train_error 18.62% test_error 21.50%\n",
      "================================3394===================================\n",
      "3394/4000: train_loss: 2.3991656826456165 train_error 18.62% test_error 21.50%\n",
      "================================3395===================================\n",
      "3395/4000: train_loss: 2.399111129206867 train_error 18.62% test_error 21.50%\n",
      "================================3396===================================\n",
      "3396/4000: train_loss: 2.399062881693244 train_error 18.62% test_error 21.50%\n",
      "================================3397===================================\n",
      "3397/4000: train_loss: 2.39901740022935 train_error 18.62% test_error 21.50%\n",
      "================================3398===================================\n",
      "3398/4000: train_loss: 2.3989716808959924 train_error 18.50% test_error 22.00%\n",
      "================================3399===================================\n",
      "3399/4000: train_loss: 2.3989250043580252 train_error 18.50% test_error 22.00%\n",
      "================================3400===================================\n",
      "3400/4000: train_loss: 2.3988796735149664 train_error 18.50% test_error 22.00%\n",
      "================================3401===================================\n",
      "3401/4000: train_loss: 2.3988352459052837 train_error 18.50% test_error 22.00%\n",
      "================================3402===================================\n",
      "3402/4000: train_loss: 2.398793536204248 train_error 18.50% test_error 22.00%\n",
      "================================3403===================================\n",
      "3403/4000: train_loss: 2.398753345027799 train_error 18.50% test_error 22.00%\n",
      "================================3404===================================\n",
      "3404/4000: train_loss: 2.398713138975436 train_error 18.50% test_error 22.00%\n",
      "================================3405===================================\n",
      "3405/4000: train_loss: 2.398673224643062 train_error 18.50% test_error 22.00%\n",
      "================================3406===================================\n",
      "3406/4000: train_loss: 2.3986327358413835 train_error 18.50% test_error 22.00%\n",
      "================================3407===================================\n",
      "3407/4000: train_loss: 2.398585583490276 train_error 18.50% test_error 22.00%\n",
      "================================3408===================================\n",
      "3408/4000: train_loss: 2.3985373976396662 train_error 18.50% test_error 22.00%\n",
      "================================3409===================================\n",
      "3409/4000: train_loss: 2.3984896058215965 train_error 18.50% test_error 22.00%\n",
      "================================3410===================================\n",
      "3410/4000: train_loss: 2.3984416944249096 train_error 18.38% test_error 22.00%\n",
      "================================3411===================================\n",
      "3411/4000: train_loss: 2.398396333464116 train_error 18.38% test_error 22.00%\n",
      "================================3412===================================\n",
      "3412/4000: train_loss: 2.3983479516028456 train_error 18.25% test_error 22.00%\n",
      "================================3413===================================\n",
      "3413/4000: train_loss: 2.3983003054509027 train_error 18.25% test_error 22.00%\n",
      "================================3414===================================\n",
      "3414/4000: train_loss: 2.3982511402800446 train_error 18.25% test_error 22.00%\n",
      "================================3415===================================\n",
      "3415/4000: train_loss: 2.3982075047210674 train_error 18.25% test_error 22.00%\n",
      "================================3416===================================\n",
      "3416/4000: train_loss: 2.398162199206345 train_error 18.25% test_error 22.00%\n",
      "================================3417===================================\n",
      "3417/4000: train_loss: 2.3981171429136885 train_error 18.38% test_error 22.00%\n",
      "================================3418===================================\n",
      "3418/4000: train_loss: 2.398072054281365 train_error 18.38% test_error 22.00%\n",
      "================================3419===================================\n",
      "3419/4000: train_loss: 2.398022667000332 train_error 18.38% test_error 22.00%\n",
      "================================3420===================================\n",
      "3420/4000: train_loss: 2.397972270103492 train_error 18.38% test_error 22.00%\n",
      "================================3421===================================\n",
      "3421/4000: train_loss: 2.397916562862083 train_error 18.38% test_error 22.00%\n",
      "================================3422===================================\n",
      "3422/4000: train_loss: 2.397858862201174 train_error 18.38% test_error 22.00%\n",
      "================================3423===================================\n",
      "3423/4000: train_loss: 2.3978016065917473 train_error 18.38% test_error 22.00%\n",
      "================================3424===================================\n",
      "3424/4000: train_loss: 2.397744717794267 train_error 18.38% test_error 22.00%\n",
      "================================3425===================================\n",
      "3425/4000: train_loss: 2.397687340666307 train_error 18.38% test_error 22.00%\n",
      "================================3426===================================\n",
      "3426/4000: train_loss: 2.3976240913121 train_error 18.25% test_error 22.00%\n",
      "================================3427===================================\n",
      "3427/4000: train_loss: 2.3975628181909268 train_error 18.25% test_error 22.00%\n",
      "================================3428===================================\n",
      "3428/4000: train_loss: 2.3975024276776824 train_error 18.25% test_error 22.00%\n",
      "================================3429===================================\n",
      "3429/4000: train_loss: 2.3974429034056812 train_error 18.25% test_error 22.00%\n",
      "================================3430===================================\n",
      "3430/4000: train_loss: 2.397387013008629 train_error 18.25% test_error 22.00%\n",
      "================================3431===================================\n",
      "3431/4000: train_loss: 2.397331258856357 train_error 18.25% test_error 22.00%\n",
      "================================3432===================================\n",
      "3432/4000: train_loss: 2.397275192134912 train_error 18.25% test_error 22.00%\n",
      "================================3433===================================\n",
      "3433/4000: train_loss: 2.39721921311364 train_error 18.25% test_error 22.00%\n",
      "================================3434===================================\n",
      "3434/4000: train_loss: 2.3971633135902812 train_error 18.25% test_error 22.00%\n",
      "================================3435===================================\n",
      "3435/4000: train_loss: 2.3971068008586007 train_error 18.25% test_error 22.00%\n",
      "================================3436===================================\n",
      "3436/4000: train_loss: 2.397052961687004 train_error 18.25% test_error 22.00%\n",
      "================================3437===================================\n",
      "3437/4000: train_loss: 2.397002460121803 train_error 18.25% test_error 22.00%\n",
      "================================3438===================================\n",
      "3438/4000: train_loss: 2.3969497771366877 train_error 18.25% test_error 22.00%\n",
      "================================3439===================================\n",
      "3439/4000: train_loss: 2.3968968837537976 train_error 18.25% test_error 22.00%\n",
      "================================3440===================================\n",
      "3440/4000: train_loss: 2.3968439991833295 train_error 18.25% test_error 22.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3441===================================\n",
      "3441/4000: train_loss: 2.396791501592379 train_error 18.25% test_error 22.00%\n",
      "================================3442===================================\n",
      "3442/4000: train_loss: 2.3967437052857714 train_error 18.25% test_error 22.00%\n",
      "================================3443===================================\n",
      "3443/4000: train_loss: 2.3966960943875892 train_error 18.25% test_error 22.00%\n",
      "================================3444===================================\n",
      "3444/4000: train_loss: 2.3966470472943184 train_error 18.25% test_error 22.00%\n",
      "================================3445===================================\n",
      "3445/4000: train_loss: 2.396596420075875 train_error 18.25% test_error 22.00%\n",
      "================================3446===================================\n",
      "3446/4000: train_loss: 2.396544902833411 train_error 18.25% test_error 22.00%\n",
      "================================3447===================================\n",
      "3447/4000: train_loss: 2.396496431323685 train_error 18.25% test_error 22.00%\n",
      "================================3448===================================\n",
      "3448/4000: train_loss: 2.3964460675173176 train_error 18.25% test_error 22.00%\n",
      "================================3449===================================\n",
      "3449/4000: train_loss: 2.3963912930824884 train_error 18.25% test_error 21.50%\n",
      "================================3450===================================\n",
      "3450/4000: train_loss: 2.396338544586615 train_error 18.25% test_error 21.50%\n",
      "================================3451===================================\n",
      "3451/4000: train_loss: 2.396287452337419 train_error 18.25% test_error 21.50%\n",
      "================================3452===================================\n",
      "3452/4000: train_loss: 2.39623539182081 train_error 18.25% test_error 22.00%\n",
      "================================3453===================================\n",
      "3453/4000: train_loss: 2.39618299843547 train_error 18.25% test_error 22.00%\n",
      "================================3454===================================\n",
      "3454/4000: train_loss: 2.39613062161603 train_error 18.25% test_error 22.00%\n",
      "================================3455===================================\n",
      "3455/4000: train_loss: 2.3960788016917647 train_error 18.25% test_error 22.00%\n",
      "================================3456===================================\n",
      "3456/4000: train_loss: 2.396027912747595 train_error 18.25% test_error 22.00%\n",
      "================================3457===================================\n",
      "3457/4000: train_loss: 2.395978606034842 train_error 18.25% test_error 22.00%\n",
      "================================3458===================================\n",
      "3458/4000: train_loss: 2.3959331594107063 train_error 18.25% test_error 22.00%\n",
      "================================3459===================================\n",
      "3459/4000: train_loss: 2.395888128926599 train_error 18.25% test_error 22.00%\n",
      "================================3460===================================\n",
      "3460/4000: train_loss: 2.3958452381323876 train_error 18.25% test_error 22.00%\n",
      "================================3461===================================\n",
      "3461/4000: train_loss: 2.395802243182552 train_error 18.25% test_error 22.00%\n",
      "================================3462===================================\n",
      "3462/4000: train_loss: 2.3957596374333665 train_error 18.25% test_error 22.00%\n",
      "================================3463===================================\n",
      "3463/4000: train_loss: 2.395718693002491 train_error 18.25% test_error 22.00%\n",
      "================================3464===================================\n",
      "3464/4000: train_loss: 2.395676574840472 train_error 18.25% test_error 22.00%\n",
      "================================3465===================================\n",
      "3465/4000: train_loss: 2.395630754124577 train_error 18.25% test_error 22.00%\n",
      "================================3466===================================\n",
      "3466/4000: train_loss: 2.3955883278092736 train_error 18.12% test_error 22.00%\n",
      "================================3467===================================\n",
      "3467/4000: train_loss: 2.3955461873985042 train_error 18.12% test_error 22.00%\n",
      "================================3468===================================\n",
      "3468/4000: train_loss: 2.3955051372023806 train_error 18.12% test_error 22.00%\n",
      "================================3469===================================\n",
      "3469/4000: train_loss: 2.39546503879239 train_error 18.25% test_error 22.00%\n",
      "================================3470===================================\n",
      "3470/4000: train_loss: 2.3954230806580745 train_error 18.25% test_error 22.00%\n",
      "================================3471===================================\n",
      "3471/4000: train_loss: 2.3953815762049633 train_error 18.25% test_error 22.00%\n",
      "================================3472===================================\n",
      "3472/4000: train_loss: 2.39534018173621 train_error 18.25% test_error 22.00%\n",
      "================================3473===================================\n",
      "3473/4000: train_loss: 2.3952976956563727 train_error 18.25% test_error 22.00%\n",
      "================================3474===================================\n",
      "3474/4000: train_loss: 2.3952528686414007 train_error 18.25% test_error 22.00%\n",
      "================================3475===================================\n",
      "3475/4000: train_loss: 2.3952075996524944 train_error 18.25% test_error 22.00%\n",
      "================================3476===================================\n",
      "3476/4000: train_loss: 2.3951634083205136 train_error 18.25% test_error 22.00%\n",
      "================================3477===================================\n",
      "3477/4000: train_loss: 2.3951195891526003 train_error 18.25% test_error 22.00%\n",
      "================================3478===================================\n",
      "3478/4000: train_loss: 2.395076953938842 train_error 18.25% test_error 22.00%\n",
      "================================3479===================================\n",
      "3479/4000: train_loss: 2.395037895995265 train_error 18.25% test_error 22.00%\n",
      "================================3480===================================\n",
      "3480/4000: train_loss: 2.3949986053046453 train_error 18.25% test_error 22.00%\n",
      "================================3481===================================\n",
      "3481/4000: train_loss: 2.3949582606487456 train_error 18.25% test_error 22.00%\n",
      "================================3482===================================\n",
      "3482/4000: train_loss: 2.3949183837843884 train_error 18.25% test_error 22.00%\n",
      "================================3483===================================\n",
      "3483/4000: train_loss: 2.3948790630528674 train_error 18.25% test_error 22.00%\n",
      "================================3484===================================\n",
      "3484/4000: train_loss: 2.394839079974263 train_error 18.25% test_error 22.00%\n",
      "================================3485===================================\n",
      "3485/4000: train_loss: 2.3947998507908776 train_error 18.25% test_error 22.00%\n",
      "================================3486===================================\n",
      "3486/4000: train_loss: 2.394760547955084 train_error 18.25% test_error 22.00%\n",
      "================================3487===================================\n",
      "3487/4000: train_loss: 2.394721430016616 train_error 18.25% test_error 22.00%\n",
      "================================3488===================================\n",
      "3488/4000: train_loss: 2.394685069594125 train_error 18.25% test_error 22.00%\n",
      "================================3489===================================\n",
      "3489/4000: train_loss: 2.3946441452995715 train_error 18.25% test_error 22.00%\n",
      "================================3490===================================\n",
      "3490/4000: train_loss: 2.3946023102929397 train_error 18.25% test_error 22.00%\n",
      "================================3491===================================\n",
      "3491/4000: train_loss: 2.3945602959428287 train_error 18.25% test_error 22.00%\n",
      "================================3492===================================\n",
      "3492/4000: train_loss: 2.3945127638154005 train_error 18.25% test_error 22.00%\n",
      "================================3493===================================\n",
      "3493/4000: train_loss: 2.394464577110375 train_error 18.25% test_error 22.00%\n",
      "================================3494===================================\n",
      "3494/4000: train_loss: 2.394415934571116 train_error 18.25% test_error 22.00%\n",
      "================================3495===================================\n",
      "3495/4000: train_loss: 2.394365150436024 train_error 18.25% test_error 22.00%\n",
      "================================3496===================================\n",
      "3496/4000: train_loss: 2.394313944652895 train_error 18.25% test_error 22.00%\n",
      "================================3497===================================\n",
      "3497/4000: train_loss: 2.394263905956686 train_error 18.25% test_error 22.00%\n",
      "================================3498===================================\n",
      "3498/4000: train_loss: 2.394216421336096 train_error 18.38% test_error 22.00%\n",
      "================================3499===================================\n",
      "3499/4000: train_loss: 2.3941660351467 train_error 18.38% test_error 22.00%\n",
      "================================3500===================================\n",
      "3500/4000: train_loss: 2.3941160863889674 train_error 18.50% test_error 22.00%\n",
      "================================3501===================================\n",
      "3501/4000: train_loss: 2.3940678223277794 train_error 18.50% test_error 22.00%\n",
      "================================3502===================================\n",
      "3502/4000: train_loss: 2.394019811786202 train_error 18.50% test_error 22.00%\n",
      "================================3503===================================\n",
      "3503/4000: train_loss: 2.393971717059576 train_error 18.50% test_error 22.00%\n",
      "================================3504===================================\n",
      "3504/4000: train_loss: 2.393924267087459 train_error 18.50% test_error 22.00%\n",
      "================================3505===================================\n",
      "3505/4000: train_loss: 2.39388164389944 train_error 18.50% test_error 22.50%\n",
      "================================3506===================================\n",
      "3506/4000: train_loss: 2.393841670557376 train_error 18.50% test_error 22.50%\n",
      "================================3507===================================\n",
      "3507/4000: train_loss: 2.393802692733298 train_error 18.50% test_error 22.50%\n",
      "================================3508===================================\n",
      "3508/4000: train_loss: 2.3937611132247913 train_error 18.50% test_error 22.50%\n",
      "================================3509===================================\n",
      "3509/4000: train_loss: 2.3937204316012863 train_error 18.50% test_error 22.50%\n",
      "================================3510===================================\n",
      "3510/4000: train_loss: 2.393680708667234 train_error 18.38% test_error 22.50%\n",
      "================================3511===================================\n",
      "3511/4000: train_loss: 2.393640799312452 train_error 18.38% test_error 22.50%\n",
      "================================3512===================================\n",
      "3512/4000: train_loss: 2.3935953044598497 train_error 18.38% test_error 22.50%\n",
      "================================3513===================================\n",
      "3513/4000: train_loss: 2.3935506234148125 train_error 18.38% test_error 22.50%\n",
      "================================3514===================================\n",
      "3514/4000: train_loss: 2.3935077094260486 train_error 18.38% test_error 22.50%\n",
      "================================3515===================================\n",
      "3515/4000: train_loss: 2.393464863837362 train_error 18.38% test_error 22.50%\n",
      "================================3516===================================\n",
      "3516/4000: train_loss: 2.3934221774597613 train_error 18.38% test_error 22.50%\n",
      "================================3517===================================\n",
      "3517/4000: train_loss: 2.393379842064096 train_error 18.38% test_error 22.50%\n",
      "================================3518===================================\n",
      "3518/4000: train_loss: 2.3933374057400942 train_error 18.38% test_error 22.50%\n",
      "================================3519===================================\n",
      "3519/4000: train_loss: 2.3932950786615765 train_error 18.38% test_error 22.50%\n",
      "================================3520===================================\n",
      "3520/4000: train_loss: 2.393252782431409 train_error 18.38% test_error 22.50%\n",
      "================================3521===================================\n",
      "3521/4000: train_loss: 2.393203357850325 train_error 18.25% test_error 22.50%\n",
      "================================3522===================================\n",
      "3522/4000: train_loss: 2.3931530584072243 train_error 18.25% test_error 22.50%\n",
      "================================3523===================================\n",
      "3523/4000: train_loss: 2.393103765469423 train_error 18.25% test_error 22.50%\n",
      "================================3524===================================\n",
      "3524/4000: train_loss: 2.3930572008566013 train_error 18.25% test_error 22.50%\n",
      "================================3525===================================\n",
      "3525/4000: train_loss: 2.3930118987923197 train_error 18.25% test_error 22.50%\n",
      "================================3526===================================\n",
      "3526/4000: train_loss: 2.392965887521823 train_error 18.25% test_error 22.50%\n",
      "================================3527===================================\n",
      "3527/4000: train_loss: 2.392917533447435 train_error 18.25% test_error 22.50%\n",
      "================================3528===================================\n",
      "3528/4000: train_loss: 2.3928690323227055 train_error 18.25% test_error 22.50%\n",
      "================================3529===================================\n",
      "3529/4000: train_loss: 2.392821129640506 train_error 18.25% test_error 22.50%\n",
      "================================3530===================================\n",
      "3530/4000: train_loss: 2.392775915008897 train_error 18.38% test_error 22.50%\n",
      "================================3531===================================\n",
      "3531/4000: train_loss: 2.3927288192034757 train_error 18.38% test_error 22.50%\n",
      "================================3532===================================\n",
      "3532/4000: train_loss: 2.39268060768045 train_error 18.38% test_error 22.50%\n",
      "================================3533===================================\n",
      "3533/4000: train_loss: 2.3926287524330108 train_error 18.38% test_error 23.00%\n",
      "================================3534===================================\n",
      "3534/4000: train_loss: 2.3925770063366874 train_error 18.38% test_error 23.00%\n",
      "================================3535===================================\n",
      "3535/4000: train_loss: 2.392527182929589 train_error 18.38% test_error 23.00%\n",
      "================================3536===================================\n",
      "3536/4000: train_loss: 2.3924783393671167 train_error 18.38% test_error 23.00%\n",
      "================================3537===================================\n",
      "3537/4000: train_loss: 2.392426604915163 train_error 18.38% test_error 23.00%\n",
      "================================3538===================================\n",
      "3538/4000: train_loss: 2.3923741430295555 train_error 18.38% test_error 23.00%\n",
      "================================3539===================================\n",
      "3539/4000: train_loss: 2.392321671820718 train_error 18.50% test_error 22.50%\n",
      "================================3540===================================\n",
      "3540/4000: train_loss: 2.3922696898586215 train_error 18.62% test_error 22.50%\n",
      "================================3541===================================\n",
      "3541/4000: train_loss: 2.3922150837730443 train_error 18.62% test_error 22.50%\n",
      "================================3542===================================\n",
      "3542/4000: train_loss: 2.392156620477399 train_error 18.62% test_error 22.50%\n",
      "================================3543===================================\n",
      "3543/4000: train_loss: 2.392098490734388 train_error 18.62% test_error 22.50%\n",
      "================================3544===================================\n",
      "3544/4000: train_loss: 2.3920406312739577 train_error 18.62% test_error 22.50%\n",
      "================================3545===================================\n",
      "3545/4000: train_loss: 2.391982158391511 train_error 18.62% test_error 22.50%\n",
      "================================3546===================================\n",
      "3546/4000: train_loss: 2.391923816247072 train_error 18.62% test_error 22.50%\n",
      "================================3547===================================\n",
      "3547/4000: train_loss: 2.391865153424951 train_error 18.62% test_error 22.50%\n",
      "================================3548===================================\n",
      "3548/4000: train_loss: 2.391805834007864 train_error 18.62% test_error 22.50%\n",
      "================================3549===================================\n",
      "3549/4000: train_loss: 2.391744880593396 train_error 18.62% test_error 22.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3550===================================\n",
      "3550/4000: train_loss: 2.391683994889427 train_error 18.62% test_error 22.50%\n",
      "================================3551===================================\n",
      "3551/4000: train_loss: 2.3916216204785083 train_error 18.62% test_error 22.50%\n",
      "================================3552===================================\n",
      "3552/4000: train_loss: 2.391556693475031 train_error 18.62% test_error 22.50%\n",
      "================================3553===================================\n",
      "3553/4000: train_loss: 2.3914898559239735 train_error 18.62% test_error 22.50%\n",
      "================================3554===================================\n",
      "3554/4000: train_loss: 2.391422495167426 train_error 18.62% test_error 22.50%\n",
      "================================3555===================================\n",
      "3555/4000: train_loss: 2.3913550145352565 train_error 18.62% test_error 22.50%\n",
      "================================3556===================================\n",
      "3556/4000: train_loss: 2.3912874837520577 train_error 18.62% test_error 22.50%\n",
      "================================3557===================================\n",
      "3557/4000: train_loss: 2.3912199776438863 train_error 18.62% test_error 22.50%\n",
      "================================3558===================================\n",
      "3558/4000: train_loss: 2.3911528600428937 train_error 18.62% test_error 22.50%\n",
      "================================3559===================================\n",
      "3559/4000: train_loss: 2.3910860197151123 train_error 18.62% test_error 22.50%\n",
      "================================3560===================================\n",
      "3560/4000: train_loss: 2.3910190811972276 train_error 18.62% test_error 22.50%\n",
      "================================3561===================================\n",
      "3561/4000: train_loss: 2.3909522587574976 train_error 18.62% test_error 22.50%\n",
      "================================3562===================================\n",
      "3562/4000: train_loss: 2.390885556419962 train_error 18.62% test_error 22.50%\n",
      "================================3563===================================\n",
      "3563/4000: train_loss: 2.39081944855905 train_error 18.62% test_error 22.50%\n",
      "================================3564===================================\n",
      "3564/4000: train_loss: 2.390754110894195 train_error 18.62% test_error 22.50%\n",
      "================================3565===================================\n",
      "3565/4000: train_loss: 2.390686566420081 train_error 18.62% test_error 22.50%\n",
      "================================3566===================================\n",
      "3566/4000: train_loss: 2.390617856181816 train_error 18.62% test_error 22.50%\n",
      "================================3567===================================\n",
      "3567/4000: train_loss: 2.3905494109664507 train_error 18.62% test_error 22.50%\n",
      "================================3568===================================\n",
      "3568/4000: train_loss: 2.390481519580644 train_error 18.62% test_error 22.50%\n",
      "================================3569===================================\n",
      "3569/4000: train_loss: 2.3904134215577866 train_error 18.62% test_error 22.50%\n",
      "================================3570===================================\n",
      "3570/4000: train_loss: 2.3903452323004966 train_error 18.62% test_error 22.50%\n",
      "================================3571===================================\n",
      "3571/4000: train_loss: 2.390276939126379 train_error 18.62% test_error 22.50%\n",
      "================================3572===================================\n",
      "3572/4000: train_loss: 2.390206326091902 train_error 18.62% test_error 22.50%\n",
      "================================3573===================================\n",
      "3573/4000: train_loss: 2.3901338809493247 train_error 18.62% test_error 22.50%\n",
      "================================3574===================================\n",
      "3574/4000: train_loss: 2.3900606200154653 train_error 18.62% test_error 22.50%\n",
      "================================3575===================================\n",
      "3575/4000: train_loss: 2.3899871348634765 train_error 18.62% test_error 22.50%\n",
      "================================3576===================================\n",
      "3576/4000: train_loss: 2.389914479078252 train_error 18.62% test_error 22.50%\n",
      "================================3577===================================\n",
      "3577/4000: train_loss: 2.3898416493358488 train_error 18.62% test_error 22.50%\n",
      "================================3578===================================\n",
      "3578/4000: train_loss: 2.3897700866198646 train_error 18.62% test_error 22.50%\n",
      "================================3579===================================\n",
      "3579/4000: train_loss: 2.3896992347170816 train_error 18.62% test_error 22.50%\n",
      "================================3580===================================\n",
      "3580/4000: train_loss: 2.389627236554388 train_error 18.62% test_error 22.50%\n",
      "================================3581===================================\n",
      "3581/4000: train_loss: 2.389554495121374 train_error 18.62% test_error 22.50%\n",
      "================================3582===================================\n",
      "3582/4000: train_loss: 2.3894820983606406 train_error 18.62% test_error 22.50%\n",
      "================================3583===================================\n",
      "3583/4000: train_loss: 2.3894082125492244 train_error 18.62% test_error 22.50%\n",
      "================================3584===================================\n",
      "3584/4000: train_loss: 2.3893334005749054 train_error 18.62% test_error 22.50%\n",
      "================================3585===================================\n",
      "3585/4000: train_loss: 2.3892606373847776 train_error 18.62% test_error 22.50%\n",
      "================================3586===================================\n",
      "3586/4000: train_loss: 2.389189518804942 train_error 18.62% test_error 22.50%\n",
      "================================3587===================================\n",
      "3587/4000: train_loss: 2.38911846621113 train_error 18.62% test_error 22.50%\n",
      "================================3588===================================\n",
      "3588/4000: train_loss: 2.3890467617589457 train_error 18.62% test_error 22.50%\n",
      "================================3589===================================\n",
      "3589/4000: train_loss: 2.3889786507327337 train_error 18.62% test_error 22.50%\n",
      "================================3590===================================\n",
      "3590/4000: train_loss: 2.388911195389119 train_error 18.62% test_error 22.50%\n",
      "================================3591===================================\n",
      "3591/4000: train_loss: 2.388840074605687 train_error 18.62% test_error 22.50%\n",
      "================================3592===================================\n",
      "3592/4000: train_loss: 2.388771571316902 train_error 18.62% test_error 22.50%\n",
      "================================3593===================================\n",
      "3593/4000: train_loss: 2.388704880292044 train_error 18.62% test_error 22.50%\n",
      "================================3594===================================\n",
      "3594/4000: train_loss: 2.3886400887302077 train_error 18.62% test_error 22.50%\n",
      "================================3595===================================\n",
      "3595/4000: train_loss: 2.38857961923537 train_error 18.62% test_error 22.50%\n",
      "================================3596===================================\n",
      "3596/4000: train_loss: 2.3885202369912077 train_error 18.50% test_error 22.50%\n",
      "================================3597===================================\n",
      "3597/4000: train_loss: 2.3884611215020595 train_error 18.50% test_error 22.50%\n",
      "================================3598===================================\n",
      "3598/4000: train_loss: 2.388403167414926 train_error 18.50% test_error 23.00%\n",
      "================================3599===================================\n",
      "3599/4000: train_loss: 2.3883449350266712 train_error 18.50% test_error 23.00%\n",
      "================================3600===================================\n",
      "3600/4000: train_loss: 2.3882851124696938 train_error 18.50% test_error 23.00%\n",
      "================================3601===================================\n",
      "3601/4000: train_loss: 2.3882251552795424 train_error 18.50% test_error 23.00%\n",
      "================================3602===================================\n",
      "3602/4000: train_loss: 2.3881658464991053 train_error 18.50% test_error 23.00%\n",
      "================================3603===================================\n",
      "3603/4000: train_loss: 2.3881065026987196 train_error 18.50% test_error 23.00%\n",
      "================================3604===================================\n",
      "3604/4000: train_loss: 2.388047230754091 train_error 18.50% test_error 23.00%\n",
      "================================3605===================================\n",
      "3605/4000: train_loss: 2.3879878598474713 train_error 18.50% test_error 23.00%\n",
      "================================3606===================================\n",
      "3606/4000: train_loss: 2.387928646598721 train_error 18.50% test_error 23.00%\n",
      "================================3607===================================\n",
      "3607/4000: train_loss: 2.3878652249894547 train_error 18.50% test_error 23.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3608===================================\n",
      "3608/4000: train_loss: 2.387799062806444 train_error 18.50% test_error 23.00%\n",
      "================================3609===================================\n",
      "3609/4000: train_loss: 2.3877329086148347 train_error 18.50% test_error 23.00%\n",
      "================================3610===================================\n",
      "3610/4000: train_loss: 2.387667678188573 train_error 18.50% test_error 23.00%\n",
      "================================3611===================================\n",
      "3611/4000: train_loss: 2.3876036829144685 train_error 18.50% test_error 23.00%\n",
      "================================3612===================================\n",
      "3612/4000: train_loss: 2.387537937717407 train_error 18.50% test_error 23.00%\n",
      "================================3613===================================\n",
      "3613/4000: train_loss: 2.387472385026922 train_error 18.50% test_error 23.00%\n",
      "================================3614===================================\n",
      "3614/4000: train_loss: 2.387406876845489 train_error 18.38% test_error 23.00%\n",
      "================================3615===================================\n",
      "3615/4000: train_loss: 2.3873435698903633 train_error 18.38% test_error 23.00%\n",
      "================================3616===================================\n",
      "3616/4000: train_loss: 2.3872801421514303 train_error 18.38% test_error 23.00%\n",
      "================================3617===================================\n",
      "3617/4000: train_loss: 2.3872115576441866 train_error 18.38% test_error 23.00%\n",
      "================================3618===================================\n",
      "3618/4000: train_loss: 2.38714325765779 train_error 18.38% test_error 23.00%\n",
      "================================3619===================================\n",
      "3619/4000: train_loss: 2.387072382389997 train_error 18.38% test_error 23.00%\n",
      "================================3620===================================\n",
      "3620/4000: train_loss: 2.3870014359333984 train_error 18.38% test_error 23.00%\n",
      "================================3621===================================\n",
      "3621/4000: train_loss: 2.3869304559706146 train_error 18.38% test_error 23.00%\n",
      "================================3622===================================\n",
      "3622/4000: train_loss: 2.3868595307737994 train_error 18.38% test_error 23.00%\n",
      "================================3623===================================\n",
      "3623/4000: train_loss: 2.3867881951994967 train_error 18.50% test_error 23.00%\n",
      "================================3624===================================\n",
      "3624/4000: train_loss: 2.3867136855971873 train_error 18.50% test_error 23.00%\n",
      "================================3625===================================\n",
      "3625/4000: train_loss: 2.3866377793637183 train_error 18.50% test_error 23.00%\n",
      "================================3626===================================\n",
      "3626/4000: train_loss: 2.3865622812320546 train_error 18.50% test_error 23.00%\n",
      "================================3627===================================\n",
      "3627/4000: train_loss: 2.3864877223030088 train_error 18.50% test_error 23.00%\n",
      "================================3628===================================\n",
      "3628/4000: train_loss: 2.3864128091610475 train_error 18.50% test_error 23.00%\n",
      "================================3629===================================\n",
      "3629/4000: train_loss: 2.3863377074808887 train_error 18.50% test_error 23.00%\n",
      "================================3630===================================\n",
      "3630/4000: train_loss: 2.386262653472004 train_error 18.50% test_error 23.00%\n",
      "================================3631===================================\n",
      "3631/4000: train_loss: 2.386187942767847 train_error 18.50% test_error 23.00%\n",
      "================================3632===================================\n",
      "3632/4000: train_loss: 2.386113286351119 train_error 18.50% test_error 23.00%\n",
      "================================3633===================================\n",
      "3633/4000: train_loss: 2.386038396386557 train_error 18.50% test_error 23.00%\n",
      "================================3634===================================\n",
      "3634/4000: train_loss: 2.3859642298988364 train_error 18.50% test_error 23.00%\n",
      "================================3635===================================\n",
      "3635/4000: train_loss: 2.3858900463334063 train_error 18.50% test_error 23.00%\n",
      "================================3636===================================\n",
      "3636/4000: train_loss: 2.385816369645072 train_error 18.50% test_error 23.00%\n",
      "================================3637===================================\n",
      "3637/4000: train_loss: 2.3857399997440374 train_error 18.50% test_error 23.00%\n",
      "================================3638===================================\n",
      "3638/4000: train_loss: 2.3856647084068756 train_error 18.50% test_error 23.00%\n",
      "================================3639===================================\n",
      "3639/4000: train_loss: 2.385590325515732 train_error 18.50% test_error 23.00%\n",
      "================================3640===================================\n",
      "3640/4000: train_loss: 2.3855177383793853 train_error 18.50% test_error 23.00%\n",
      "================================3641===================================\n",
      "3641/4000: train_loss: 2.3854493409155477 train_error 18.50% test_error 23.00%\n",
      "================================3642===================================\n",
      "3642/4000: train_loss: 2.385378010892782 train_error 18.50% test_error 22.50%\n",
      "================================3643===================================\n",
      "3643/4000: train_loss: 2.3853048399249204 train_error 18.50% test_error 22.50%\n",
      "================================3644===================================\n",
      "3644/4000: train_loss: 2.3852298232451905 train_error 18.50% test_error 22.50%\n",
      "================================3645===================================\n",
      "3645/4000: train_loss: 2.3851523778953196 train_error 18.50% test_error 22.50%\n",
      "================================3646===================================\n",
      "3646/4000: train_loss: 2.3850723395208115 train_error 18.50% test_error 22.50%\n",
      "================================3647===================================\n",
      "3647/4000: train_loss: 2.3849876045311067 train_error 18.50% test_error 22.50%\n",
      "================================3648===================================\n",
      "3648/4000: train_loss: 2.3849047868892375 train_error 18.50% test_error 22.50%\n",
      "================================3649===================================\n",
      "3649/4000: train_loss: 2.3848235365941766 train_error 18.50% test_error 22.50%\n",
      "================================3650===================================\n",
      "3650/4000: train_loss: 2.384740956197838 train_error 18.50% test_error 22.50%\n",
      "================================3651===================================\n",
      "3651/4000: train_loss: 2.384656513338232 train_error 18.50% test_error 22.50%\n",
      "================================3652===================================\n",
      "3652/4000: train_loss: 2.3845721135981695 train_error 18.50% test_error 22.50%\n",
      "================================3653===================================\n",
      "3653/4000: train_loss: 2.3844875244600736 train_error 18.50% test_error 22.50%\n",
      "================================3654===================================\n",
      "3654/4000: train_loss: 2.3844064194161367 train_error 18.50% test_error 22.50%\n",
      "================================3655===================================\n",
      "3655/4000: train_loss: 2.3843257630726296 train_error 18.50% test_error 22.50%\n",
      "================================3656===================================\n",
      "3656/4000: train_loss: 2.3842450352731976 train_error 18.50% test_error 22.50%\n",
      "================================3657===================================\n",
      "3657/4000: train_loss: 2.384160751812378 train_error 18.50% test_error 22.50%\n",
      "================================3658===================================\n",
      "3658/4000: train_loss: 2.3840712536355384 train_error 18.50% test_error 22.50%\n",
      "================================3659===================================\n",
      "3659/4000: train_loss: 2.3839808718921454 train_error 18.50% test_error 22.50%\n",
      "================================3660===================================\n",
      "3660/4000: train_loss: 2.383889840376887 train_error 18.50% test_error 22.50%\n",
      "================================3661===================================\n",
      "3661/4000: train_loss: 2.3837977660793697 train_error 18.38% test_error 22.50%\n",
      "================================3662===================================\n",
      "3662/4000: train_loss: 2.3837067789879622 train_error 18.38% test_error 22.50%\n",
      "================================3663===================================\n",
      "3663/4000: train_loss: 2.383617751622296 train_error 18.38% test_error 22.50%\n",
      "================================3664===================================\n",
      "3664/4000: train_loss: 2.3835284184399823 train_error 18.38% test_error 22.50%\n",
      "================================3665===================================\n",
      "3665/4000: train_loss: 2.383436604830276 train_error 18.38% test_error 22.50%\n",
      "================================3666===================================\n",
      "3666/4000: train_loss: 2.3833430371732356 train_error 18.38% test_error 22.50%\n",
      "================================3667===================================\n",
      "3667/4000: train_loss: 2.383249581051714 train_error 18.38% test_error 22.50%\n",
      "================================3668===================================\n",
      "3668/4000: train_loss: 2.383156253242596 train_error 18.38% test_error 22.50%\n",
      "================================3669===================================\n",
      "3669/4000: train_loss: 2.383063753860479 train_error 18.38% test_error 22.50%\n",
      "================================3670===================================\n",
      "3670/4000: train_loss: 2.3829703879604134 train_error 18.38% test_error 22.50%\n",
      "================================3671===================================\n",
      "3671/4000: train_loss: 2.3828758797272713 train_error 18.38% test_error 22.50%\n",
      "================================3672===================================\n",
      "3672/4000: train_loss: 2.382782646991509 train_error 18.38% test_error 22.50%\n",
      "================================3673===================================\n",
      "3673/4000: train_loss: 2.382689770033649 train_error 18.38% test_error 22.50%\n",
      "================================3674===================================\n",
      "3674/4000: train_loss: 2.382596933193872 train_error 18.38% test_error 22.50%\n",
      "================================3675===================================\n",
      "3675/4000: train_loss: 2.3825045292291 train_error 18.38% test_error 22.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3676===================================\n",
      "3676/4000: train_loss: 2.3824133982547027 train_error 18.38% test_error 22.50%\n",
      "================================3677===================================\n",
      "3677/4000: train_loss: 2.3823230506002617 train_error 18.38% test_error 22.50%\n",
      "================================3678===================================\n",
      "3678/4000: train_loss: 2.382233036305315 train_error 18.38% test_error 22.50%\n",
      "================================3679===================================\n",
      "3679/4000: train_loss: 2.382144787164543 train_error 18.38% test_error 22.50%\n",
      "================================3680===================================\n",
      "3680/4000: train_loss: 2.3820586874844416 train_error 18.38% test_error 22.50%\n",
      "================================3681===================================\n",
      "3681/4000: train_loss: 2.381972591741742 train_error 18.38% test_error 22.50%\n",
      "================================3682===================================\n",
      "3682/4000: train_loss: 2.381885544649103 train_error 18.38% test_error 22.50%\n",
      "================================3683===================================\n",
      "3683/4000: train_loss: 2.381795704482502 train_error 18.50% test_error 22.50%\n",
      "================================3684===================================\n",
      "3684/4000: train_loss: 2.3817057621302595 train_error 18.50% test_error 22.50%\n",
      "================================3685===================================\n",
      "3685/4000: train_loss: 2.3816156796925134 train_error 18.50% test_error 22.50%\n",
      "================================3686===================================\n",
      "3686/4000: train_loss: 2.381526168980909 train_error 18.50% test_error 22.50%\n",
      "================================3687===================================\n",
      "3687/4000: train_loss: 2.381439081179433 train_error 18.50% test_error 22.50%\n",
      "================================3688===================================\n",
      "3688/4000: train_loss: 2.3813504410763926 train_error 18.50% test_error 22.50%\n",
      "================================3689===================================\n",
      "3689/4000: train_loss: 2.3812620557669835 train_error 18.50% test_error 22.50%\n",
      "================================3690===================================\n",
      "3690/4000: train_loss: 2.381175198397177 train_error 18.50% test_error 22.50%\n",
      "================================3691===================================\n",
      "3691/4000: train_loss: 2.381087212598886 train_error 18.50% test_error 22.50%\n",
      "================================3692===================================\n",
      "3692/4000: train_loss: 2.3810002609850107 train_error 18.50% test_error 22.50%\n",
      "================================3693===================================\n",
      "3693/4000: train_loss: 2.380913685390178 train_error 18.50% test_error 22.50%\n",
      "================================3694===================================\n",
      "3694/4000: train_loss: 2.3808274046678255 train_error 18.50% test_error 22.50%\n",
      "================================3695===================================\n",
      "3695/4000: train_loss: 2.3807382636935293 train_error 18.50% test_error 22.50%\n",
      "================================3696===================================\n",
      "3696/4000: train_loss: 2.3806487917076087 train_error 18.50% test_error 22.50%\n",
      "================================3697===================================\n",
      "3697/4000: train_loss: 2.380559046569051 train_error 18.50% test_error 22.50%\n",
      "================================3698===================================\n",
      "3698/4000: train_loss: 2.3804710369105395 train_error 18.50% test_error 22.00%\n",
      "================================3699===================================\n",
      "3699/4000: train_loss: 2.380381726164833 train_error 18.50% test_error 22.00%\n",
      "================================3700===================================\n",
      "3700/4000: train_loss: 2.3802905159680994 train_error 18.50% test_error 22.00%\n",
      "================================3701===================================\n",
      "3701/4000: train_loss: 2.380198672425604 train_error 18.50% test_error 22.00%\n",
      "================================3702===================================\n",
      "3702/4000: train_loss: 2.3801070398669797 train_error 18.50% test_error 22.00%\n",
      "================================3703===================================\n",
      "3703/4000: train_loss: 2.380014510629544 train_error 18.50% test_error 22.00%\n",
      "================================3704===================================\n",
      "3704/4000: train_loss: 2.3799212830546366 train_error 18.50% test_error 22.00%\n",
      "================================3705===================================\n",
      "3705/4000: train_loss: 2.379828909368998 train_error 18.50% test_error 22.00%\n",
      "================================3706===================================\n",
      "3706/4000: train_loss: 2.3797378642124567 train_error 18.50% test_error 22.00%\n",
      "================================3707===================================\n",
      "3707/4000: train_loss: 2.3796475992816433 train_error 18.50% test_error 22.00%\n",
      "================================3708===================================\n",
      "3708/4000: train_loss: 2.379556050911742 train_error 18.50% test_error 22.00%\n",
      "================================3709===================================\n",
      "3709/4000: train_loss: 2.3794643939505478 train_error 18.50% test_error 22.00%\n",
      "================================3710===================================\n",
      "3710/4000: train_loss: 2.379372822180794 train_error 18.50% test_error 22.00%\n",
      "================================3711===================================\n",
      "3711/4000: train_loss: 2.379281355921721 train_error 18.50% test_error 21.50%\n",
      "================================3712===================================\n",
      "3712/4000: train_loss: 2.3791901841666094 train_error 18.50% test_error 21.50%\n",
      "================================3713===================================\n",
      "3713/4000: train_loss: 2.3790992693790214 train_error 18.50% test_error 21.50%\n",
      "================================3714===================================\n",
      "3714/4000: train_loss: 2.3790081736620685 train_error 18.38% test_error 21.50%\n",
      "================================3715===================================\n",
      "3715/4000: train_loss: 2.378919192047733 train_error 18.38% test_error 21.50%\n",
      "================================3716===================================\n",
      "3716/4000: train_loss: 2.378829915671695 train_error 18.38% test_error 21.50%\n",
      "================================3717===================================\n",
      "3717/4000: train_loss: 2.378739653677176 train_error 18.50% test_error 21.50%\n",
      "================================3718===================================\n",
      "3718/4000: train_loss: 2.378649626168726 train_error 18.50% test_error 21.50%\n",
      "================================3719===================================\n",
      "3719/4000: train_loss: 2.3785593655452884 train_error 18.50% test_error 21.50%\n",
      "================================3720===================================\n",
      "3720/4000: train_loss: 2.3784663389756773 train_error 18.38% test_error 21.50%\n",
      "================================3721===================================\n",
      "3721/4000: train_loss: 2.378372614613518 train_error 18.38% test_error 21.50%\n",
      "================================3722===================================\n",
      "3722/4000: train_loss: 2.3782815249161287 train_error 18.38% test_error 21.50%\n",
      "================================3723===================================\n",
      "3723/4000: train_loss: 2.378191407583945 train_error 18.38% test_error 21.50%\n",
      "================================3724===================================\n",
      "3724/4000: train_loss: 2.3780930007762526 train_error 18.38% test_error 21.50%\n",
      "================================3725===================================\n",
      "3725/4000: train_loss: 2.3779935933214986 train_error 18.38% test_error 21.50%\n",
      "================================3726===================================\n",
      "3726/4000: train_loss: 2.3778950428365806 train_error 18.38% test_error 21.50%\n",
      "================================3727===================================\n",
      "3727/4000: train_loss: 2.3777965812139064 train_error 18.38% test_error 21.50%\n",
      "================================3728===================================\n",
      "3728/4000: train_loss: 2.3776999917852026 train_error 18.38% test_error 21.50%\n",
      "================================3729===================================\n",
      "3729/4000: train_loss: 2.3776064434740416 train_error 18.38% test_error 21.50%\n",
      "================================3730===================================\n",
      "3730/4000: train_loss: 2.3775113782544666 train_error 18.38% test_error 21.50%\n",
      "================================3731===================================\n",
      "3731/4000: train_loss: 2.37741573593712 train_error 18.38% test_error 21.50%\n",
      "================================3732===================================\n",
      "3732/4000: train_loss: 2.377316696404732 train_error 18.38% test_error 21.50%\n",
      "================================3733===================================\n",
      "3733/4000: train_loss: 2.37721712292383 train_error 18.38% test_error 21.50%\n",
      "================================3734===================================\n",
      "3734/4000: train_loss: 2.37712021690636 train_error 18.38% test_error 21.50%\n",
      "================================3735===================================\n",
      "3735/4000: train_loss: 2.3770236188067884 train_error 18.38% test_error 21.50%\n",
      "================================3736===================================\n",
      "3736/4000: train_loss: 2.376927000773994 train_error 18.38% test_error 21.50%\n",
      "================================3737===================================\n",
      "3737/4000: train_loss: 2.376830188403228 train_error 18.38% test_error 21.50%\n",
      "================================3738===================================\n",
      "3738/4000: train_loss: 2.376734309250105 train_error 18.38% test_error 21.50%\n",
      "================================3739===================================\n",
      "3739/4000: train_loss: 2.3766423581018716 train_error 18.38% test_error 21.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3740===================================\n",
      "3740/4000: train_loss: 2.376549806978719 train_error 18.38% test_error 21.50%\n",
      "================================3741===================================\n",
      "3741/4000: train_loss: 2.376457931907826 train_error 18.38% test_error 21.50%\n",
      "================================3742===================================\n",
      "3742/4000: train_loss: 2.376369126970658 train_error 18.38% test_error 21.50%\n",
      "================================3743===================================\n",
      "3743/4000: train_loss: 2.3762809237161218 train_error 18.38% test_error 21.50%\n",
      "================================3744===================================\n",
      "3744/4000: train_loss: 2.376192544055757 train_error 18.38% test_error 21.50%\n",
      "================================3745===================================\n",
      "3745/4000: train_loss: 2.376103926294172 train_error 18.38% test_error 21.50%\n",
      "================================3746===================================\n",
      "3746/4000: train_loss: 2.3760152967247086 train_error 18.38% test_error 21.50%\n",
      "================================3747===================================\n",
      "3747/4000: train_loss: 2.3759258612856042 train_error 18.38% test_error 21.50%\n",
      "================================3748===================================\n",
      "3748/4000: train_loss: 2.3758365818478158 train_error 18.38% test_error 21.50%\n",
      "================================3749===================================\n",
      "3749/4000: train_loss: 2.375745409638885 train_error 18.38% test_error 21.50%\n",
      "================================3750===================================\n",
      "3750/4000: train_loss: 2.3756580614265297 train_error 18.38% test_error 21.50%\n",
      "================================3751===================================\n",
      "3751/4000: train_loss: 2.375570781469878 train_error 18.38% test_error 21.50%\n",
      "================================3752===================================\n",
      "3752/4000: train_loss: 2.3754834500170543 train_error 18.38% test_error 21.50%\n",
      "================================3753===================================\n",
      "3753/4000: train_loss: 2.3753967822787216 train_error 18.38% test_error 21.50%\n",
      "================================3754===================================\n",
      "3754/4000: train_loss: 2.375309939069084 train_error 18.38% test_error 21.50%\n",
      "================================3755===================================\n",
      "3755/4000: train_loss: 2.375222832755044 train_error 18.38% test_error 21.50%\n",
      "================================3756===================================\n",
      "3756/4000: train_loss: 2.3751309546535415 train_error 18.38% test_error 21.50%\n",
      "================================3757===================================\n",
      "3757/4000: train_loss: 2.3750399210374327 train_error 18.38% test_error 21.00%\n",
      "================================3758===================================\n",
      "3758/4000: train_loss: 2.374945795307576 train_error 18.38% test_error 21.00%\n",
      "================================3759===================================\n",
      "3759/4000: train_loss: 2.3748512194286198 train_error 18.38% test_error 21.00%\n",
      "================================3760===================================\n",
      "3760/4000: train_loss: 2.374754596282628 train_error 18.38% test_error 21.00%\n",
      "================================3761===================================\n",
      "3761/4000: train_loss: 2.3746578799228155 train_error 18.38% test_error 21.00%\n",
      "================================3762===================================\n",
      "3762/4000: train_loss: 2.374561600636116 train_error 18.38% test_error 21.00%\n",
      "================================3763===================================\n",
      "3763/4000: train_loss: 2.3744655660640457 train_error 18.38% test_error 21.00%\n",
      "================================3764===================================\n",
      "3764/4000: train_loss: 2.3743690931731636 train_error 18.38% test_error 21.00%\n",
      "================================3765===================================\n",
      "3765/4000: train_loss: 2.37427102190587 train_error 18.38% test_error 21.00%\n",
      "================================3766===================================\n",
      "3766/4000: train_loss: 2.3741753673268065 train_error 18.38% test_error 21.00%\n",
      "================================3767===================================\n",
      "3767/4000: train_loss: 2.3740812312789696 train_error 18.38% test_error 21.00%\n",
      "================================3768===================================\n",
      "3768/4000: train_loss: 2.373984001523486 train_error 18.38% test_error 21.00%\n",
      "================================3769===================================\n",
      "3769/4000: train_loss: 2.3738845603111347 train_error 18.38% test_error 21.00%\n",
      "================================3770===================================\n",
      "3770/4000: train_loss: 2.3737843696734036 train_error 18.38% test_error 21.00%\n",
      "================================3771===================================\n",
      "3771/4000: train_loss: 2.3736833994039626 train_error 18.38% test_error 20.50%\n",
      "================================3772===================================\n",
      "3772/4000: train_loss: 2.3735830759495546 train_error 18.38% test_error 20.50%\n",
      "================================3773===================================\n",
      "3773/4000: train_loss: 2.3734771989330237 train_error 18.38% test_error 20.50%\n",
      "================================3774===================================\n",
      "3774/4000: train_loss: 2.3733714702585984 train_error 18.38% test_error 20.50%\n",
      "================================3775===================================\n",
      "3775/4000: train_loss: 2.3732657237230157 train_error 18.38% test_error 20.50%\n",
      "================================3776===================================\n",
      "3776/4000: train_loss: 2.373161869800524 train_error 18.38% test_error 20.50%\n",
      "================================3777===================================\n",
      "3777/4000: train_loss: 2.37305932711417 train_error 18.38% test_error 20.50%\n",
      "================================3778===================================\n",
      "3778/4000: train_loss: 2.372955953829187 train_error 18.38% test_error 20.50%\n",
      "================================3779===================================\n",
      "3779/4000: train_loss: 2.372852594612614 train_error 18.38% test_error 20.50%\n",
      "================================3780===================================\n",
      "3780/4000: train_loss: 2.372748535337041 train_error 18.38% test_error 20.50%\n",
      "================================3781===================================\n",
      "3781/4000: train_loss: 2.372644447508601 train_error 18.38% test_error 20.50%\n",
      "================================3782===================================\n",
      "3782/4000: train_loss: 2.3725387838339884 train_error 18.38% test_error 20.50%\n",
      "================================3783===================================\n",
      "3783/4000: train_loss: 2.3724323023957092 train_error 18.38% test_error 20.50%\n",
      "================================3784===================================\n",
      "3784/4000: train_loss: 2.3723275015896887 train_error 18.38% test_error 20.50%\n",
      "================================3785===================================\n",
      "3785/4000: train_loss: 2.3722222931603754 train_error 18.38% test_error 20.50%\n",
      "================================3786===================================\n",
      "3786/4000: train_loss: 2.37211653309786 train_error 18.38% test_error 20.50%\n",
      "================================3787===================================\n",
      "3787/4000: train_loss: 2.3720106502919407 train_error 18.38% test_error 20.50%\n",
      "================================3788===================================\n",
      "3788/4000: train_loss: 2.371907344950787 train_error 18.38% test_error 20.50%\n",
      "================================3789===================================\n",
      "3789/4000: train_loss: 2.37180371388813 train_error 18.38% test_error 20.50%\n",
      "================================3790===================================\n",
      "3790/4000: train_loss: 2.3717024232978563 train_error 18.25% test_error 20.50%\n",
      "================================3791===================================\n",
      "3791/4000: train_loss: 2.3716006542496597 train_error 18.25% test_error 20.50%\n",
      "================================3792===================================\n",
      "3792/4000: train_loss: 2.3714990660407422 train_error 18.25% test_error 20.50%\n",
      "================================3793===================================\n",
      "3793/4000: train_loss: 2.371394825137677 train_error 18.25% test_error 20.50%\n",
      "================================3794===================================\n",
      "3794/4000: train_loss: 2.371290379138782 train_error 18.25% test_error 20.50%\n",
      "================================3795===================================\n",
      "3795/4000: train_loss: 2.371188187242578 train_error 18.25% test_error 20.50%\n",
      "================================3796===================================\n",
      "3796/4000: train_loss: 2.3710856352021255 train_error 18.25% test_error 20.50%\n",
      "================================3797===================================\n",
      "3797/4000: train_loss: 2.370978066027983 train_error 18.25% test_error 20.50%\n",
      "================================3798===================================\n",
      "3798/4000: train_loss: 2.370870481255461 train_error 18.25% test_error 20.50%\n",
      "================================3799===================================\n",
      "3799/4000: train_loss: 2.3707630042067738 train_error 18.25% test_error 20.50%\n",
      "================================3800===================================\n",
      "3800/4000: train_loss: 2.370655518206795 train_error 18.25% test_error 20.50%\n",
      "================================3801===================================\n",
      "3801/4000: train_loss: 2.3705476848612217 train_error 18.25% test_error 20.50%\n",
      "================================3802===================================\n",
      "3802/4000: train_loss: 2.370441146118019 train_error 18.25% test_error 20.50%\n",
      "================================3803===================================\n",
      "3803/4000: train_loss: 2.370334596298753 train_error 18.25% test_error 20.50%\n",
      "================================3804===================================\n",
      "3804/4000: train_loss: 2.37022800145327 train_error 18.25% test_error 20.50%\n",
      "================================3805===================================\n",
      "3805/4000: train_loss: 2.37012127072252 train_error 18.25% test_error 20.50%\n",
      "================================3806===================================\n",
      "3806/4000: train_loss: 2.3700150156278417 train_error 18.25% test_error 20.50%\n",
      "================================3807===================================\n",
      "3807/4000: train_loss: 2.369908366359587 train_error 18.25% test_error 20.50%\n",
      "================================3808===================================\n",
      "3808/4000: train_loss: 2.3698017767162853 train_error 18.25% test_error 20.50%\n",
      "================================3809===================================\n",
      "3809/4000: train_loss: 2.369695472668118 train_error 18.25% test_error 20.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3810===================================\n",
      "3810/4000: train_loss: 2.3695908375922317 train_error 18.25% test_error 20.50%\n",
      "================================3811===================================\n",
      "3811/4000: train_loss: 2.369487648679929 train_error 18.25% test_error 20.50%\n",
      "================================3812===================================\n",
      "3812/4000: train_loss: 2.3693822853488697 train_error 18.25% test_error 20.50%\n",
      "================================3813===================================\n",
      "3813/4000: train_loss: 2.3692762928981757 train_error 18.25% test_error 20.50%\n",
      "================================3814===================================\n",
      "3814/4000: train_loss: 2.369170716043345 train_error 18.25% test_error 20.50%\n",
      "================================3815===================================\n",
      "3815/4000: train_loss: 2.3690652092008806 train_error 18.25% test_error 20.50%\n",
      "================================3816===================================\n",
      "3816/4000: train_loss: 2.368959917968373 train_error 18.25% test_error 20.50%\n",
      "================================3817===================================\n",
      "3817/4000: train_loss: 2.3688541686124562 train_error 18.25% test_error 20.50%\n",
      "================================3818===================================\n",
      "3818/4000: train_loss: 2.368744135936663 train_error 18.25% test_error 20.50%\n",
      "================================3819===================================\n",
      "3819/4000: train_loss: 2.368635180462634 train_error 18.25% test_error 21.00%\n",
      "================================3820===================================\n",
      "3820/4000: train_loss: 2.3685278038902196 train_error 18.25% test_error 21.00%\n",
      "================================3821===================================\n",
      "3821/4000: train_loss: 2.3684201187942837 train_error 18.25% test_error 21.00%\n",
      "================================3822===================================\n",
      "3822/4000: train_loss: 2.3683127392027243 train_error 18.25% test_error 21.00%\n",
      "================================3823===================================\n",
      "3823/4000: train_loss: 2.3682057061276103 train_error 18.25% test_error 21.00%\n",
      "================================3824===================================\n",
      "3824/4000: train_loss: 2.368098746763094 train_error 18.25% test_error 21.00%\n",
      "================================3825===================================\n",
      "3825/4000: train_loss: 2.367992680430298 train_error 18.25% test_error 21.00%\n",
      "================================3826===================================\n",
      "3826/4000: train_loss: 2.3678872409111364 train_error 18.25% test_error 21.00%\n",
      "================================3827===================================\n",
      "3827/4000: train_loss: 2.3677825443697564 train_error 18.25% test_error 21.00%\n",
      "================================3828===================================\n",
      "3828/4000: train_loss: 2.367679603261072 train_error 18.25% test_error 21.00%\n",
      "================================3829===================================\n",
      "3829/4000: train_loss: 2.3675764701768234 train_error 18.25% test_error 21.00%\n",
      "================================3830===================================\n",
      "3830/4000: train_loss: 2.367466851517288 train_error 18.25% test_error 21.00%\n",
      "================================3831===================================\n",
      "3831/4000: train_loss: 2.367362674891137 train_error 18.25% test_error 21.00%\n",
      "================================3832===================================\n",
      "3832/4000: train_loss: 2.3672586247924663 train_error 18.25% test_error 21.00%\n",
      "================================3833===================================\n",
      "3833/4000: train_loss: 2.3671552122809545 train_error 18.25% test_error 21.00%\n",
      "================================3834===================================\n",
      "3834/4000: train_loss: 2.3670535402577433 train_error 18.25% test_error 21.00%\n",
      "================================3835===================================\n",
      "3835/4000: train_loss: 2.366948741840338 train_error 18.25% test_error 21.00%\n",
      "================================3836===================================\n",
      "3836/4000: train_loss: 2.3668433524659758 train_error 18.25% test_error 21.00%\n",
      "================================3837===================================\n",
      "3837/4000: train_loss: 2.3667384792761004 train_error 18.25% test_error 21.00%\n",
      "================================3838===================================\n",
      "3838/4000: train_loss: 2.366637338106393 train_error 18.38% test_error 21.00%\n",
      "================================3839===================================\n",
      "3839/4000: train_loss: 2.3665348192832516 train_error 18.38% test_error 21.00%\n",
      "================================3840===================================\n",
      "3840/4000: train_loss: 2.3664279799107275 train_error 18.38% test_error 21.00%\n",
      "================================3841===================================\n",
      "3841/4000: train_loss: 2.3663203745050216 train_error 18.38% test_error 21.00%\n",
      "================================3842===================================\n",
      "3842/4000: train_loss: 2.3662127030445212 train_error 18.38% test_error 21.00%\n",
      "================================3843===================================\n",
      "3843/4000: train_loss: 2.366105227621847 train_error 18.38% test_error 21.00%\n",
      "================================3844===================================\n",
      "3844/4000: train_loss: 2.3659946838145336 train_error 18.38% test_error 21.00%\n",
      "================================3845===================================\n",
      "3845/4000: train_loss: 2.3658827185148676 train_error 18.38% test_error 21.00%\n",
      "================================3846===================================\n",
      "3846/4000: train_loss: 2.3657723717625276 train_error 18.38% test_error 21.00%\n",
      "================================3847===================================\n",
      "3847/4000: train_loss: 2.365661921249507 train_error 18.38% test_error 21.00%\n",
      "================================3848===================================\n",
      "3848/4000: train_loss: 2.3655543605115463 train_error 18.38% test_error 21.00%\n",
      "================================3849===================================\n",
      "3849/4000: train_loss: 2.3654467255129203 train_error 18.38% test_error 21.00%\n",
      "================================3850===================================\n",
      "3850/4000: train_loss: 2.3653387969754522 train_error 18.38% test_error 21.00%\n",
      "================================3851===================================\n",
      "3851/4000: train_loss: 2.3652307553419862 train_error 18.25% test_error 21.00%\n",
      "================================3852===================================\n",
      "3852/4000: train_loss: 2.3651218792164537 train_error 18.25% test_error 21.00%\n",
      "================================3853===================================\n",
      "3853/4000: train_loss: 2.3650130793573 train_error 18.25% test_error 21.00%\n",
      "================================3854===================================\n",
      "3854/4000: train_loss: 2.36490393960632 train_error 18.25% test_error 21.00%\n",
      "================================3855===================================\n",
      "3855/4000: train_loss: 2.364796010758173 train_error 18.25% test_error 21.00%\n",
      "================================3856===================================\n",
      "3856/4000: train_loss: 2.3646903349793367 train_error 18.25% test_error 21.00%\n",
      "================================3857===================================\n",
      "3857/4000: train_loss: 2.3645819056854678 train_error 18.25% test_error 21.00%\n",
      "================================3858===================================\n",
      "3858/4000: train_loss: 2.3644710666010633 train_error 18.25% test_error 21.00%\n",
      "================================3859===================================\n",
      "3859/4000: train_loss: 2.364360878489374 train_error 18.25% test_error 21.00%\n",
      "================================3860===================================\n",
      "3860/4000: train_loss: 2.3642504607727464 train_error 18.25% test_error 21.00%\n",
      "================================3861===================================\n",
      "3861/4000: train_loss: 2.3641407783913566 train_error 18.25% test_error 21.00%\n",
      "================================3862===================================\n",
      "3862/4000: train_loss: 2.3640313340699595 train_error 18.25% test_error 21.00%\n",
      "================================3863===================================\n",
      "3863/4000: train_loss: 2.3639217320219954 train_error 18.25% test_error 21.00%\n",
      "================================3864===================================\n",
      "3864/4000: train_loss: 2.3638112520566343 train_error 18.25% test_error 21.00%\n",
      "================================3865===================================\n",
      "3865/4000: train_loss: 2.363700126810759 train_error 18.25% test_error 21.00%\n",
      "================================3866===================================\n",
      "3866/4000: train_loss: 2.3635894084167286 train_error 18.12% test_error 21.00%\n",
      "================================3867===================================\n",
      "3867/4000: train_loss: 2.3634789169203487 train_error 18.12% test_error 21.00%\n",
      "================================3868===================================\n",
      "3868/4000: train_loss: 2.3633674977977805 train_error 18.12% test_error 21.00%\n",
      "================================3869===================================\n",
      "3869/4000: train_loss: 2.3632558533473684 train_error 18.12% test_error 21.00%\n",
      "================================3870===================================\n",
      "3870/4000: train_loss: 2.3631445770458916 train_error 18.12% test_error 21.00%\n",
      "================================3871===================================\n",
      "3871/4000: train_loss: 2.3630332592529792 train_error 18.12% test_error 21.00%\n",
      "================================3872===================================\n",
      "3872/4000: train_loss: 2.3629222402950605 train_error 18.00% test_error 21.00%\n",
      "================================3873===================================\n",
      "3873/4000: train_loss: 2.362811202490284 train_error 18.00% test_error 21.00%\n",
      "================================3874===================================\n",
      "3874/4000: train_loss: 2.362700437078866 train_error 18.00% test_error 21.00%\n",
      "================================3875===================================\n",
      "3875/4000: train_loss: 2.3625897480909046 train_error 18.00% test_error 21.00%\n",
      "================================3876===================================\n",
      "3876/4000: train_loss: 2.3624797906054575 train_error 18.00% test_error 21.00%\n",
      "================================3877===================================\n",
      "3877/4000: train_loss: 2.3623626063223355 train_error 18.00% test_error 21.00%\n",
      "================================3878===================================\n",
      "3878/4000: train_loss: 2.3622478484104246 train_error 18.00% test_error 21.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3879===================================\n",
      "3879/4000: train_loss: 2.3621328973499067 train_error 18.00% test_error 21.00%\n",
      "================================3880===================================\n",
      "3880/4000: train_loss: 2.362018322772633 train_error 18.00% test_error 21.00%\n",
      "================================3881===================================\n",
      "3881/4000: train_loss: 2.361904253278076 train_error 18.00% test_error 21.00%\n",
      "================================3882===================================\n",
      "3882/4000: train_loss: 2.3617910055837457 train_error 18.00% test_error 21.00%\n",
      "================================3883===================================\n",
      "3883/4000: train_loss: 2.3616772759490505 train_error 18.00% test_error 21.00%\n",
      "================================3884===================================\n",
      "3884/4000: train_loss: 2.3615630109131054 train_error 18.00% test_error 21.00%\n",
      "================================3885===================================\n",
      "3885/4000: train_loss: 2.361449217673585 train_error 18.00% test_error 21.00%\n",
      "================================3886===================================\n",
      "3886/4000: train_loss: 2.361336154295964 train_error 18.00% test_error 21.00%\n",
      "================================3887===================================\n",
      "3887/4000: train_loss: 2.3612255940242948 train_error 18.00% test_error 21.00%\n",
      "================================3888===================================\n",
      "3888/4000: train_loss: 2.3611151354733875 train_error 18.00% test_error 21.00%\n",
      "================================3889===================================\n",
      "3889/4000: train_loss: 2.361005499516286 train_error 18.00% test_error 21.00%\n",
      "================================3890===================================\n",
      "3890/4000: train_loss: 2.3608964440047155 train_error 18.00% test_error 21.00%\n",
      "================================3891===================================\n",
      "3891/4000: train_loss: 2.360787190815072 train_error 18.00% test_error 21.00%\n",
      "================================3892===================================\n",
      "3892/4000: train_loss: 2.3606778596295497 train_error 18.00% test_error 21.00%\n",
      "================================3893===================================\n",
      "3893/4000: train_loss: 2.360568689797792 train_error 18.00% test_error 21.00%\n",
      "================================3894===================================\n",
      "3894/4000: train_loss: 2.360462341769262 train_error 18.00% test_error 21.00%\n",
      "================================3895===================================\n",
      "3895/4000: train_loss: 2.3603599438346827 train_error 18.00% test_error 21.00%\n",
      "================================3896===================================\n",
      "3896/4000: train_loss: 2.3602569429328013 train_error 18.00% test_error 21.00%\n",
      "================================3897===================================\n",
      "3897/4000: train_loss: 2.360153664966756 train_error 18.00% test_error 21.00%\n",
      "================================3898===================================\n",
      "3898/4000: train_loss: 2.3600458398452475 train_error 18.00% test_error 21.00%\n",
      "================================3899===================================\n",
      "3899/4000: train_loss: 2.359937525568321 train_error 18.00% test_error 21.00%\n",
      "================================3900===================================\n",
      "3900/4000: train_loss: 2.3598293643336277 train_error 18.00% test_error 21.00%\n",
      "================================3901===================================\n",
      "3901/4000: train_loss: 2.3597211021252953 train_error 18.00% test_error 21.00%\n",
      "================================3902===================================\n",
      "3902/4000: train_loss: 2.3596130745462007 train_error 18.00% test_error 21.00%\n",
      "================================3903===================================\n",
      "3903/4000: train_loss: 2.3595054439247587 train_error 18.00% test_error 21.00%\n",
      "================================3904===================================\n",
      "3904/4000: train_loss: 2.35939573514222 train_error 18.00% test_error 21.00%\n",
      "================================3905===================================\n",
      "3905/4000: train_loss: 2.359284384860507 train_error 18.00% test_error 21.00%\n",
      "================================3906===================================\n",
      "3906/4000: train_loss: 2.3591730715238013 train_error 18.00% test_error 21.00%\n",
      "================================3907===================================\n",
      "3907/4000: train_loss: 2.3590618618815826 train_error 18.00% test_error 21.00%\n",
      "================================3908===================================\n",
      "3908/4000: train_loss: 2.3589509248666944 train_error 18.00% test_error 21.00%\n",
      "================================3909===================================\n",
      "3909/4000: train_loss: 2.358839730266645 train_error 18.00% test_error 21.00%\n",
      "================================3910===================================\n",
      "3910/4000: train_loss: 2.3587279608451857 train_error 18.00% test_error 21.00%\n",
      "================================3911===================================\n",
      "3911/4000: train_loss: 2.3586168067081914 train_error 18.00% test_error 21.00%\n",
      "================================3912===================================\n",
      "3912/4000: train_loss: 2.3585054393572724 train_error 18.00% test_error 21.00%\n",
      "================================3913===================================\n",
      "3913/4000: train_loss: 2.3583957799526116 train_error 18.00% test_error 21.00%\n",
      "================================3914===================================\n",
      "3914/4000: train_loss: 2.3582876727488564 train_error 18.00% test_error 21.00%\n",
      "================================3915===================================\n",
      "3915/4000: train_loss: 2.358179631335811 train_error 18.00% test_error 21.00%\n",
      "================================3916===================================\n",
      "3916/4000: train_loss: 2.358069380222137 train_error 18.00% test_error 21.00%\n",
      "================================3917===================================\n",
      "3917/4000: train_loss: 2.357955689858395 train_error 18.00% test_error 21.00%\n",
      "================================3918===================================\n",
      "3918/4000: train_loss: 2.357842039556185 train_error 18.00% test_error 21.00%\n",
      "================================3919===================================\n",
      "3919/4000: train_loss: 2.357727694876085 train_error 18.00% test_error 21.00%\n",
      "================================3920===================================\n",
      "3920/4000: train_loss: 2.3576123655191394 train_error 18.00% test_error 21.00%\n",
      "================================3921===================================\n",
      "3921/4000: train_loss: 2.3574982451770525 train_error 18.00% test_error 21.00%\n",
      "================================3922===================================\n",
      "3922/4000: train_loss: 2.3573842192170744 train_error 18.00% test_error 21.00%\n",
      "================================3923===================================\n",
      "3923/4000: train_loss: 2.357271766629797 train_error 18.00% test_error 21.00%\n",
      "================================3924===================================\n",
      "3924/4000: train_loss: 2.3571554287858865 train_error 18.00% test_error 21.00%\n",
      "================================3925===================================\n",
      "3925/4000: train_loss: 2.3570416761410753 train_error 18.00% test_error 21.00%\n",
      "================================3926===================================\n",
      "3926/4000: train_loss: 2.3569290881005145 train_error 17.88% test_error 21.00%\n",
      "================================3927===================================\n",
      "3927/4000: train_loss: 2.3568164899722754 train_error 17.88% test_error 21.00%\n",
      "================================3928===================================\n",
      "3928/4000: train_loss: 2.356700382679146 train_error 17.88% test_error 21.00%\n",
      "================================3929===================================\n",
      "3929/4000: train_loss: 2.3565844789277346 train_error 17.88% test_error 21.00%\n",
      "================================3930===================================\n",
      "3930/4000: train_loss: 2.35646892490593 train_error 17.88% test_error 21.00%\n",
      "================================3931===================================\n",
      "3931/4000: train_loss: 2.356352915105035 train_error 17.88% test_error 21.00%\n",
      "================================3932===================================\n",
      "3932/4000: train_loss: 2.35623643832389 train_error 17.88% test_error 21.00%\n",
      "================================3933===================================\n",
      "3933/4000: train_loss: 2.3561200643552 train_error 18.00% test_error 21.00%\n",
      "================================3934===================================\n",
      "3934/4000: train_loss: 2.356003706465901 train_error 18.00% test_error 21.00%\n",
      "================================3935===================================\n",
      "3935/4000: train_loss: 2.3558872745343 train_error 18.00% test_error 21.00%\n",
      "================================3936===================================\n",
      "3936/4000: train_loss: 2.3557738736787157 train_error 18.12% test_error 21.00%\n",
      "================================3937===================================\n",
      "3937/4000: train_loss: 2.3556588635170854 train_error 18.12% test_error 21.00%\n",
      "================================3938===================================\n",
      "3938/4000: train_loss: 2.3555384563979693 train_error 18.12% test_error 21.00%\n",
      "================================3939===================================\n",
      "3939/4000: train_loss: 2.3554180246704983 train_error 18.12% test_error 21.00%\n",
      "================================3940===================================\n",
      "3940/4000: train_loss: 2.35529965689409 train_error 18.12% test_error 21.00%\n",
      "================================3941===================================\n",
      "3941/4000: train_loss: 2.355183250690011 train_error 18.12% test_error 21.00%\n",
      "================================3942===================================\n",
      "3942/4000: train_loss: 2.3550667371109606 train_error 18.12% test_error 21.00%\n",
      "================================3943===================================\n",
      "3943/4000: train_loss: 2.354947344868051 train_error 18.12% test_error 21.00%\n",
      "================================3944===================================\n",
      "3944/4000: train_loss: 2.3548264103847805 train_error 18.12% test_error 21.00%\n",
      "================================3945===================================\n",
      "3945/4000: train_loss: 2.354703090783798 train_error 18.12% test_error 21.00%\n",
      "================================3946===================================\n",
      "3946/4000: train_loss: 2.35458260789886 train_error 18.12% test_error 21.00%\n",
      "================================3947===================================\n",
      "3947/4000: train_loss: 2.354462195119031 train_error 18.12% test_error 21.00%\n",
      "================================3948===================================\n",
      "3948/4000: train_loss: 2.354342555297046 train_error 18.12% test_error 21.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3949===================================\n",
      "3949/4000: train_loss: 2.3542231936645246 train_error 18.12% test_error 21.00%\n",
      "================================3950===================================\n",
      "3950/4000: train_loss: 2.354104102490103 train_error 18.12% test_error 21.00%\n",
      "================================3951===================================\n",
      "3951/4000: train_loss: 2.3539831284202455 train_error 18.12% test_error 21.00%\n",
      "================================3952===================================\n",
      "3952/4000: train_loss: 2.3538645866923478 train_error 18.12% test_error 21.00%\n",
      "================================3953===================================\n",
      "3953/4000: train_loss: 2.3537472221224194 train_error 18.12% test_error 21.00%\n",
      "================================3954===================================\n",
      "3954/4000: train_loss: 2.3536299156364544 train_error 18.12% test_error 21.00%\n",
      "================================3955===================================\n",
      "3955/4000: train_loss: 2.3535146448606996 train_error 18.12% test_error 21.00%\n",
      "================================3956===================================\n",
      "3956/4000: train_loss: 2.353399600041296 train_error 18.12% test_error 21.00%\n",
      "================================3957===================================\n",
      "3957/4000: train_loss: 2.3532845595252936 train_error 18.12% test_error 21.00%\n",
      "================================3958===================================\n",
      "3958/4000: train_loss: 2.353170199938522 train_error 18.12% test_error 21.00%\n",
      "================================3959===================================\n",
      "3959/4000: train_loss: 2.353055438172812 train_error 18.12% test_error 21.00%\n",
      "================================3960===================================\n",
      "3960/4000: train_loss: 2.352941780772178 train_error 18.12% test_error 21.00%\n",
      "================================3961===================================\n",
      "3961/4000: train_loss: 2.352826182186966 train_error 18.12% test_error 21.00%\n",
      "================================3962===================================\n",
      "3962/4000: train_loss: 2.3527113862626243 train_error 18.12% test_error 21.50%\n",
      "================================3963===================================\n",
      "3963/4000: train_loss: 2.3525955839075094 train_error 18.12% test_error 21.50%\n",
      "================================3964===================================\n",
      "3964/4000: train_loss: 2.352476829069838 train_error 18.12% test_error 21.50%\n",
      "================================3965===================================\n",
      "3965/4000: train_loss: 2.352359704059877 train_error 18.12% test_error 21.50%\n",
      "================================3966===================================\n",
      "3966/4000: train_loss: 2.3522434138861517 train_error 18.12% test_error 21.50%\n",
      "================================3967===================================\n",
      "3967/4000: train_loss: 2.352127124643914 train_error 18.12% test_error 21.50%\n",
      "================================3968===================================\n",
      "3968/4000: train_loss: 2.352011576907837 train_error 18.12% test_error 21.50%\n",
      "================================3969===================================\n",
      "3969/4000: train_loss: 2.3518878898215894 train_error 18.12% test_error 21.50%\n",
      "================================3970===================================\n",
      "3970/4000: train_loss: 2.3517626403474656 train_error 18.12% test_error 21.50%\n",
      "================================3971===================================\n",
      "3971/4000: train_loss: 2.3516374707195835 train_error 18.12% test_error 21.50%\n",
      "================================3972===================================\n",
      "3972/4000: train_loss: 2.3515124677837207 train_error 18.12% test_error 21.50%\n",
      "================================3973===================================\n",
      "3973/4000: train_loss: 2.3513880035832813 train_error 18.12% test_error 21.50%\n",
      "================================3974===================================\n",
      "3974/4000: train_loss: 2.3512637435275225 train_error 18.12% test_error 21.50%\n",
      "================================3975===================================\n",
      "3975/4000: train_loss: 2.351140082483837 train_error 18.12% test_error 21.50%\n",
      "================================3976===================================\n",
      "3976/4000: train_loss: 2.3510120014795506 train_error 18.12% test_error 21.50%\n",
      "================================3977===================================\n",
      "3977/4000: train_loss: 2.35088568397061 train_error 18.12% test_error 21.50%\n",
      "================================3978===================================\n",
      "3978/4000: train_loss: 2.3507594145350437 train_error 18.12% test_error 21.50%\n",
      "================================3979===================================\n",
      "3979/4000: train_loss: 2.3506359450213634 train_error 18.12% test_error 21.50%\n",
      "================================3980===================================\n",
      "3980/4000: train_loss: 2.3505121408885294 train_error 18.12% test_error 21.50%\n",
      "================================3981===================================\n",
      "3981/4000: train_loss: 2.3503918128189047 train_error 18.12% test_error 21.50%\n",
      "================================3982===================================\n",
      "3982/4000: train_loss: 2.350272598255374 train_error 18.12% test_error 21.50%\n",
      "================================3983===================================\n",
      "3983/4000: train_loss: 2.350154067945323 train_error 18.12% test_error 21.50%\n",
      "================================3984===================================\n",
      "3984/4000: train_loss: 2.3500365164262598 train_error 18.12% test_error 21.50%\n",
      "================================3985===================================\n",
      "3985/4000: train_loss: 2.349920742274744 train_error 18.12% test_error 21.50%\n",
      "================================3986===================================\n",
      "3986/4000: train_loss: 2.3498044759304615 train_error 18.12% test_error 21.50%\n",
      "================================3987===================================\n",
      "3987/4000: train_loss: 2.3496854346439315 train_error 18.12% test_error 21.50%\n",
      "================================3988===================================\n",
      "3988/4000: train_loss: 2.3495654378002655 train_error 18.12% test_error 21.50%\n",
      "================================3989===================================\n",
      "3989/4000: train_loss: 2.349445815488627 train_error 18.12% test_error 21.50%\n",
      "================================3990===================================\n",
      "3990/4000: train_loss: 2.3493279340848723 train_error 18.12% test_error 21.50%\n",
      "================================3991===================================\n",
      "3991/4000: train_loss: 2.349209958298127 train_error 18.12% test_error 21.50%\n",
      "================================3992===================================\n",
      "3992/4000: train_loss: 2.3490916620932376 train_error 18.12% test_error 21.50%\n",
      "================================3993===================================\n",
      "3993/4000: train_loss: 2.3489729295369424 train_error 18.12% test_error 21.50%\n",
      "================================3994===================================\n",
      "3994/4000: train_loss: 2.348854504805877 train_error 18.12% test_error 21.50%\n",
      "================================3995===================================\n",
      "3995/4000: train_loss: 2.3487369785036094 train_error 18.12% test_error 21.50%\n",
      "================================3996===================================\n",
      "3996/4000: train_loss: 2.3486203410814803 train_error 18.12% test_error 21.50%\n",
      "================================3997===================================\n",
      "3997/4000: train_loss: 2.348503692308091 train_error 18.00% test_error 21.50%\n",
      "================================3998===================================\n",
      "3998/4000: train_loss: 2.3483879814957933 train_error 18.00% test_error 21.50%\n",
      "================================3999===================================\n",
      "3999/4000: train_loss: 2.348270604847437 train_error 18.00% test_error 21.50%\n"
     ]
    }
   ],
   "source": [
    "lr =  1e-3\n",
    "mini_batch_size = 200\n",
    "nb_epochs = 4000\n",
    "# modules = [Linear(2, 25), Relu(),Linear(25, 25),Relu(),Linear(25, 25),Relu(),Linear(25, 2), Tanh()]\n",
    "modules = [Linear(2, 25), Relu(),Linear(25, 2), Tanh()]\n",
    "model = Sequential(modules)\n",
    "\n",
    "train_input, train_target, test_input, test_target = data[0:800,], target[0:800,], data[800:,], target[800:,]\n",
    "\n",
    "train_model(model, train_input, train_target, test_input, test_target, nb_epochs, lr, mini_batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
