{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import Tensor \n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def forward(self, x):   \n",
    "        self.x = x.clone()\n",
    "        return x.clamp(min=0)\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        output = self.x.clone()\n",
    "        output[output > 0] = 1\n",
    "        output[output < 0] = 0\n",
    "#         print(\"forwarded x\")\n",
    "#         print(self.x[:5])\n",
    "#         print(\"output\")\n",
    "#         print(output[:5])\n",
    "#         print(\"dz come\")\n",
    "#         print(dz[:5])\n",
    "#         print(\"backwarded update\")\n",
    "#         print(dz.mul(output).shape)\n",
    "        return dz.mul(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x.clone()\n",
    "        self.output = Tensor.tanh(x)\n",
    "        return self.output;\n",
    "\n",
    "    def backward(self, dz):\n",
    "#         print(\"forwarded x\")\n",
    "#         print(self.x[:5])\n",
    "#         print(\"output\")\n",
    "#         print(self.output[:5])\n",
    "#         print(\"dz come\")\n",
    "#         print(dz[:5])\n",
    "#         print(\"backwarded update\")\n",
    "#         print(dz.mul(1.0 - Tensor.tanh(self.x).pow(2))[:5])\n",
    "        return dz.mul(1.0 - Tensor.tanh(self.x).pow(2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \n",
    "    def __init__(self, input_size ,hidden_nodes):    \n",
    "        \n",
    "        # Initialize weight, bias xavie initializer\n",
    "        stdv = 1. / math.sqrt(input_size)\n",
    "        self.w = Tensor(hidden_nodes, input_size).uniform_(-stdv, stdv)\n",
    "        self.b = Tensor(hidden_nodes).uniform_(-stdv, stdv) \n",
    "        self.dw = Tensor(self.w.size()).zero_()\n",
    "        self.db = Tensor(self.b.size()).zero_()\n",
    "#         self.db = Tensor(self.b.size()).normal_(-10,100)\n",
    "#         self.dw = Tensor(self.w.size()).normal_(-10,100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x.clone()\n",
    "        s = x.matmul(self.w.t()) + self.b\n",
    "        return s\n",
    "        \n",
    "    def backward(self, dz):\n",
    "        \n",
    "        dx = dz.matmul(self.w)\n",
    "        dw = self.x.t().matmul(dz)\n",
    "        db = dz.t().sum(1)\n",
    "        \n",
    "        self.dw += dw\n",
    "        self.db += db\n",
    "        \n",
    "        return dx\n",
    "        \n",
    "    def params(self):\n",
    "        return (self.w, self.b, self.dw,self.db)\n",
    "    \n",
    "    \n",
    "    def update_params(self, lambda_):\n",
    "        self.w -= lambda_ * self.dw\n",
    "        self.b -= lambda_ * self.db\n",
    "        \n",
    "    \n",
    "    def zero_gradient(self):\n",
    "        self.dw.zero_()\n",
    "        self.db.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossMSE: \n",
    "        \n",
    "    def forward(self, t, x):\n",
    "        self.t = t.clone()\n",
    "        self.x = x.clone()\n",
    "        self.output = (self.x - self.t).pow(2).mean()\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self):\n",
    "#         print(\"t\")\n",
    "#         print(self.t)\n",
    "#         print(\"x\")\n",
    "#         print(self.x)\n",
    "#         print(\"error\")\n",
    "#         print(self.output)\n",
    "        dloss = 2 * (self.t - self.x)/self.x.shape[0]/2\n",
    "#         print(self.x.shape)\n",
    "        return dloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    \n",
    "    def __init__(self, layer_modules):\n",
    "        self.layer_modules = layer_modules\n",
    "\n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        module_input = x_input.clone()\n",
    "        \n",
    "        # hidden layer\n",
    "        for i in range(len(self.layer_modules)): \n",
    "            module_output = self.layer_modules[i].forward(module_input)\n",
    "            module_input = module_output\n",
    "        return module_output\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        for i in range(len(self.layer_modules) - 1, -1, -1):\n",
    "            dz = self.layer_modules[i].backward(dz) \n",
    "    \n",
    "    def update_params(self, lambda_):\n",
    "        for m in self.layer_modules:\n",
    "            if isinstance(m, Linear): \n",
    "                m.update_params(lambda_);\n",
    "\n",
    "    \n",
    "    def zero_gradient(self):\n",
    "        for m in self.layer_modules:\n",
    "            if isinstance(m, Linear):\n",
    "                m.zero_gradient()\n",
    "    \n",
    "    def get_params(self):\n",
    "        for m in self.layer_modules:\n",
    "            print('{},{}'.format(m.params()[0], m.params()[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, test_input, test_target, nb_epochs, lr,mini_batch_size ):\n",
    "    \n",
    "    criterion = LossMSE()\n",
    "    \n",
    "    for m in range(nb_epochs):\n",
    "\n",
    "        total_loss = 0    \n",
    "        \n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model.forward(train_input.narrow(0, b, mini_batch_size))\n",
    "#             print(output)\n",
    "            total_loss  += criterion.forward(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_gradient()\n",
    "            dloss = criterion.backward()\n",
    "#             print(\"dloss\")\n",
    "#             print(dloss[:5])\n",
    "            model.backward(dloss)\n",
    "            model.update_params(lr)\n",
    "        \n",
    "        train_errors = compute_nb_errors(model, train_input, train_target)\n",
    "        test_errors = compute_nb_errors(model, test_input, test_target)\n",
    "        print(\"================================{}===================================\".format(m))\n",
    "        \n",
    "        print(  '{}/{}: train_loss: {} train_error {:.02f}% test_error {:.02f}%'.format(m , nb_epochs,total_loss,\n",
    "                train_errors/ train_input.size(0) * 100,\n",
    "                test_errors / test_input.size(0) * 100))  \n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model.forward(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(0, mini_batch_size):\n",
    "            if data_target[b + k][predicted_classes[k]]  < 0:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f305b2b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = torch.FloatTensor(1000,2).uniform_(0, 1) - 0.5\n",
    "distance = torch.sqrt(torch.pow(data[:, 0], 2) + torch.pow(data[:,1],2)).view(-1,1)\n",
    "radius = 1 / math.sqrt(2 * math.pi)\n",
    "inside = distance.clone().apply_(lambda x : 1 if x < radius else  -1)\n",
    "outside = distance.clone().apply_(lambda x : 1 if x > radius else  -1)\n",
    "\n",
    "target = torch.cat((inside, outside),1)\n",
    "\n",
    "\n",
    "data = (data - data.mean())/ data.std()\n",
    "# plt.scatter(data[:,0], data[:,1], c=inside)\n",
    "# plt.show()\n",
    "plt.scatter(data[:,0], data[:,1], c=inside.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheng-chun-epfl/anaconda3/lib/python3.6/site-packages/torch/tensor.py:309: UserWarning: other is not broadcastable to self, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return self.add_(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================0===================================\n",
      "0/10000: train_loss: 4.112853581309318 train_error 46.88% test_error 51.00%\n",
      "================================1===================================\n",
      "1/10000: train_loss: 4.112475614473223 train_error 46.88% test_error 51.00%\n",
      "================================2===================================\n",
      "2/10000: train_loss: 4.112099702432752 train_error 46.88% test_error 51.00%\n",
      "================================3===================================\n",
      "3/10000: train_loss: 4.111725694164633 train_error 46.88% test_error 51.00%\n",
      "================================4===================================\n",
      "4/10000: train_loss: 4.111353584378957 train_error 46.88% test_error 51.00%\n",
      "================================5===================================\n",
      "5/10000: train_loss: 4.110983426421881 train_error 46.88% test_error 51.00%\n",
      "================================6===================================\n",
      "6/10000: train_loss: 4.110615198537707 train_error 46.88% test_error 51.00%\n",
      "================================7===================================\n",
      "7/10000: train_loss: 4.110248958617449 train_error 46.88% test_error 51.00%\n",
      "================================8===================================\n",
      "8/10000: train_loss: 4.109884645193815 train_error 46.88% test_error 51.00%\n",
      "================================9===================================\n",
      "9/10000: train_loss: 4.109522250220179 train_error 46.88% test_error 51.00%\n",
      "================================10===================================\n",
      "10/10000: train_loss: 4.109161707237362 train_error 46.88% test_error 51.00%\n",
      "================================11===================================\n",
      "11/10000: train_loss: 4.108803111538291 train_error 46.88% test_error 51.00%\n",
      "================================12===================================\n",
      "12/10000: train_loss: 4.108446364104748 train_error 46.88% test_error 51.00%\n",
      "================================13===================================\n",
      "13/10000: train_loss: 4.108091474622488 train_error 46.88% test_error 51.00%\n",
      "================================14===================================\n",
      "14/10000: train_loss: 4.107738400027156 train_error 46.88% test_error 51.00%\n",
      "================================15===================================\n",
      "15/10000: train_loss: 4.107387200668454 train_error 46.88% test_error 51.00%\n",
      "================================16===================================\n",
      "16/10000: train_loss: 4.107037827372551 train_error 46.88% test_error 51.00%\n",
      "================================17===================================\n",
      "17/10000: train_loss: 4.106690349727869 train_error 46.88% test_error 51.00%\n",
      "================================18===================================\n",
      "18/10000: train_loss: 4.106344669461251 train_error 46.88% test_error 51.00%\n",
      "================================19===================================\n",
      "19/10000: train_loss: 4.106000815704465 train_error 46.88% test_error 51.00%\n",
      "================================20===================================\n",
      "20/10000: train_loss: 4.105658742934466 train_error 46.88% test_error 51.00%\n",
      "================================21===================================\n",
      "21/10000: train_loss: 4.105318445637822 train_error 46.88% test_error 51.00%\n",
      "================================22===================================\n",
      "22/10000: train_loss: 4.104979938417673 train_error 46.88% test_error 51.00%\n",
      "================================23===================================\n",
      "23/10000: train_loss: 4.104643263667822 train_error 46.88% test_error 51.00%\n",
      "================================24===================================\n",
      "24/10000: train_loss: 4.104308317154645 train_error 46.88% test_error 51.00%\n",
      "================================25===================================\n",
      "25/10000: train_loss: 4.103975135907531 train_error 46.88% test_error 51.00%\n",
      "================================26===================================\n",
      "26/10000: train_loss: 4.103643696084618 train_error 46.88% test_error 51.00%\n",
      "================================27===================================\n",
      "27/10000: train_loss: 4.103313941657543 train_error 46.88% test_error 51.00%\n",
      "================================28===================================\n",
      "28/10000: train_loss: 4.102985862419009 train_error 46.88% test_error 51.00%\n",
      "================================29===================================\n",
      "29/10000: train_loss: 4.10265950910747 train_error 46.88% test_error 51.00%\n",
      "================================30===================================\n",
      "30/10000: train_loss: 4.1023348569869995 train_error 46.88% test_error 51.00%\n",
      "================================31===================================\n",
      "31/10000: train_loss: 4.102011963799596 train_error 46.88% test_error 51.00%\n",
      "================================32===================================\n",
      "32/10000: train_loss: 4.101690751239657 train_error 46.88% test_error 51.00%\n",
      "================================33===================================\n",
      "33/10000: train_loss: 4.101371163204312 train_error 46.88% test_error 51.00%\n",
      "================================34===================================\n",
      "34/10000: train_loss: 4.101053170636296 train_error 46.88% test_error 51.00%\n",
      "================================35===================================\n",
      "35/10000: train_loss: 4.100736807137728 train_error 46.88% test_error 51.00%\n",
      "================================36===================================\n",
      "36/10000: train_loss: 4.10042202733457 train_error 46.88% test_error 51.00%\n",
      "================================37===================================\n",
      "37/10000: train_loss: 4.1001089046895505 train_error 46.88% test_error 51.00%\n",
      "================================38===================================\n",
      "38/10000: train_loss: 4.099797434583307 train_error 46.88% test_error 51.00%\n",
      "================================39===================================\n",
      "39/10000: train_loss: 4.09948757328093 train_error 46.88% test_error 51.00%\n",
      "================================40===================================\n",
      "40/10000: train_loss: 4.099179361537098 train_error 46.88% test_error 51.00%\n",
      "================================41===================================\n",
      "41/10000: train_loss: 4.098872739225627 train_error 46.88% test_error 51.00%\n",
      "================================42===================================\n",
      "42/10000: train_loss: 4.098567805364728 train_error 46.88% test_error 51.00%\n",
      "================================43===================================\n",
      "43/10000: train_loss: 4.098264547213912 train_error 46.88% test_error 51.00%\n",
      "================================44===================================\n",
      "44/10000: train_loss: 4.097962856441736 train_error 46.88% test_error 51.00%\n",
      "================================45===================================\n",
      "45/10000: train_loss: 4.097662727013231 train_error 46.88% test_error 51.00%\n",
      "================================46===================================\n",
      "46/10000: train_loss: 4.097364150881768 train_error 46.88% test_error 51.00%\n",
      "================================47===================================\n",
      "47/10000: train_loss: 4.097067187577486 train_error 46.88% test_error 51.00%\n",
      "================================48===================================\n",
      "48/10000: train_loss: 4.096771726384759 train_error 46.88% test_error 51.00%\n",
      "================================49===================================\n",
      "49/10000: train_loss: 4.0964778739959 train_error 46.88% test_error 51.00%\n",
      "================================50===================================\n",
      "50/10000: train_loss: 4.096185530647635 train_error 46.88% test_error 51.00%\n",
      "================================51===================================\n",
      "51/10000: train_loss: 4.095894745215774 train_error 46.88% test_error 51.00%\n",
      "================================52===================================\n",
      "52/10000: train_loss: 4.095605466812849 train_error 46.88% test_error 51.00%\n",
      "================================53===================================\n",
      "53/10000: train_loss: 4.095317736715079 train_error 46.88% test_error 51.00%\n",
      "================================54===================================\n",
      "54/10000: train_loss: 4.095031642690301 train_error 46.88% test_error 51.00%\n",
      "================================55===================================\n",
      "55/10000: train_loss: 4.0947470151633025 train_error 46.88% test_error 51.00%\n",
      "================================56===================================\n",
      "56/10000: train_loss: 4.094463890790939 train_error 46.88% test_error 51.00%\n",
      "================================57===================================\n",
      "57/10000: train_loss: 4.094182221442461 train_error 46.88% test_error 51.00%\n",
      "================================58===================================\n",
      "58/10000: train_loss: 4.093902087062597 train_error 46.88% test_error 51.00%\n",
      "================================59===================================\n",
      "59/10000: train_loss: 4.09362342223525 train_error 46.88% test_error 51.00%\n",
      "================================60===================================\n",
      "60/10000: train_loss: 4.093346185237169 train_error 46.88% test_error 51.00%\n",
      "================================61===================================\n",
      "61/10000: train_loss: 4.093070396780968 train_error 46.88% test_error 51.00%\n",
      "================================62===================================\n",
      "62/10000: train_loss: 4.092796023115516 train_error 46.88% test_error 51.00%\n",
      "================================63===================================\n",
      "63/10000: train_loss: 4.092523149698973 train_error 46.88% test_error 51.00%\n",
      "================================64===================================\n",
      "64/10000: train_loss: 4.092251682206989 train_error 46.88% test_error 51.00%\n",
      "================================65===================================\n",
      "65/10000: train_loss: 4.091981591507793 train_error 46.88% test_error 51.00%\n",
      "================================66===================================\n",
      "66/10000: train_loss: 4.091712852716446 train_error 46.88% test_error 51.00%\n",
      "================================67===================================\n",
      "67/10000: train_loss: 4.091445461660623 train_error 46.88% test_error 51.00%\n",
      "================================68===================================\n",
      "68/10000: train_loss: 4.0911794834584 train_error 46.88% test_error 51.00%\n",
      "================================69===================================\n",
      "69/10000: train_loss: 4.090914885923267 train_error 46.88% test_error 51.00%\n",
      "================================70===================================\n",
      "70/10000: train_loss: 4.090651700273156 train_error 46.88% test_error 51.00%\n",
      "================================71===================================\n",
      "71/10000: train_loss: 4.090389918759465 train_error 46.88% test_error 51.00%\n",
      "================================72===================================\n",
      "72/10000: train_loss: 4.090129506736994 train_error 46.88% test_error 51.00%\n",
      "================================73===================================\n",
      "73/10000: train_loss: 4.08987053476274 train_error 46.88% test_error 51.00%\n",
      "================================74===================================\n",
      "74/10000: train_loss: 4.0896129932254555 train_error 46.88% test_error 51.00%\n",
      "================================75===================================\n",
      "75/10000: train_loss: 4.089356843680144 train_error 46.88% test_error 51.00%\n",
      "================================76===================================\n",
      "76/10000: train_loss: 4.089102008044719 train_error 46.88% test_error 51.00%\n",
      "================================77===================================\n",
      "77/10000: train_loss: 4.088848505541682 train_error 46.88% test_error 51.00%\n",
      "================================78===================================\n",
      "78/10000: train_loss: 4.088596380650998 train_error 46.88% test_error 51.00%\n",
      "================================79===================================\n",
      "79/10000: train_loss: 4.088345587030053 train_error 46.88% test_error 51.00%\n",
      "================================80===================================\n",
      "80/10000: train_loss: 4.0880961385369305 train_error 46.88% test_error 51.00%\n",
      "================================81===================================\n",
      "81/10000: train_loss: 4.087848012521864 train_error 46.88% test_error 51.00%\n",
      "================================82===================================\n",
      "82/10000: train_loss: 4.087601212710142 train_error 46.88% test_error 51.00%\n",
      "================================83===================================\n",
      "83/10000: train_loss: 4.087355720698834 train_error 46.88% test_error 51.00%\n",
      "================================84===================================\n",
      "84/10000: train_loss: 4.087111576348543 train_error 46.88% test_error 51.00%\n",
      "================================85===================================\n",
      "85/10000: train_loss: 4.086868699789047 train_error 46.88% test_error 51.00%\n",
      "================================86===================================\n",
      "86/10000: train_loss: 4.086627160534262 train_error 46.88% test_error 51.00%\n",
      "================================87===================================\n",
      "87/10000: train_loss: 4.086386971399188 train_error 46.88% test_error 51.00%\n",
      "================================88===================================\n",
      "88/10000: train_loss: 4.086147999614477 train_error 46.88% test_error 51.00%\n",
      "================================89===================================\n",
      "89/10000: train_loss: 4.0859102708101265 train_error 46.88% test_error 51.00%\n",
      "================================90===================================\n",
      "90/10000: train_loss: 4.085673835873604 train_error 46.88% test_error 51.00%\n",
      "================================91===================================\n",
      "91/10000: train_loss: 4.0854387204349045 train_error 46.88% test_error 51.00%\n",
      "================================92===================================\n",
      "92/10000: train_loss: 4.08520487703383 train_error 46.88% test_error 51.00%\n",
      "================================93===================================\n",
      "93/10000: train_loss: 4.084972277507186 train_error 46.88% test_error 51.00%\n",
      "================================94===================================\n",
      "94/10000: train_loss: 4.084740926250815 train_error 46.88% test_error 51.00%\n",
      "================================95===================================\n",
      "95/10000: train_loss: 4.084510790929198 train_error 46.88% test_error 51.00%\n",
      "================================96===================================\n",
      "96/10000: train_loss: 4.084281858950854 train_error 46.88% test_error 51.00%\n",
      "================================97===================================\n",
      "97/10000: train_loss: 4.084054175615311 train_error 46.88% test_error 51.00%\n",
      "================================98===================================\n",
      "98/10000: train_loss: 4.083827691748738 train_error 46.88% test_error 51.00%\n",
      "================================99===================================\n",
      "99/10000: train_loss: 4.083602395132184 train_error 46.88% test_error 51.00%\n",
      "================================100===================================\n",
      "100/10000: train_loss: 4.083378289565444 train_error 46.88% test_error 51.00%\n",
      "================================101===================================\n",
      "101/10000: train_loss: 4.083155409768223 train_error 46.88% test_error 51.00%\n",
      "================================102===================================\n",
      "102/10000: train_loss: 4.082933742031455 train_error 46.88% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================103===================================\n",
      "103/10000: train_loss: 4.082713262960315 train_error 46.88% test_error 51.00%\n",
      "================================104===================================\n",
      "104/10000: train_loss: 4.082493897527456 train_error 46.88% test_error 51.00%\n",
      "================================105===================================\n",
      "105/10000: train_loss: 4.082275720089674 train_error 46.88% test_error 51.00%\n",
      "================================106===================================\n",
      "106/10000: train_loss: 4.0820586888492105 train_error 46.88% test_error 51.00%\n",
      "================================107===================================\n",
      "107/10000: train_loss: 4.081842848956585 train_error 46.88% test_error 51.00%\n",
      "================================108===================================\n",
      "108/10000: train_loss: 4.081628137081861 train_error 46.88% test_error 51.00%\n",
      "================================109===================================\n",
      "109/10000: train_loss: 4.081414559781551 train_error 46.88% test_error 51.00%\n",
      "================================110===================================\n",
      "110/10000: train_loss: 4.081202054396272 train_error 46.88% test_error 51.00%\n",
      "================================111===================================\n",
      "111/10000: train_loss: 4.0809907136112455 train_error 46.88% test_error 51.00%\n",
      "================================112===================================\n",
      "112/10000: train_loss: 4.080780499428511 train_error 46.88% test_error 51.00%\n",
      "================================113===================================\n",
      "113/10000: train_loss: 4.080571444034576 train_error 46.88% test_error 51.00%\n",
      "================================114===================================\n",
      "114/10000: train_loss: 4.080363526046277 train_error 46.88% test_error 51.00%\n",
      "================================115===================================\n",
      "115/10000: train_loss: 4.080156719610095 train_error 46.88% test_error 51.00%\n",
      "================================116===================================\n",
      "116/10000: train_loss: 4.079950987696648 train_error 46.88% test_error 51.00%\n",
      "================================117===================================\n",
      "117/10000: train_loss: 4.079746403470636 train_error 46.88% test_error 51.00%\n",
      "================================118===================================\n",
      "118/10000: train_loss: 4.079542893469333 train_error 46.88% test_error 51.00%\n",
      "================================119===================================\n",
      "119/10000: train_loss: 4.079340476989746 train_error 46.88% test_error 51.00%\n",
      "================================120===================================\n",
      "120/10000: train_loss: 4.079139250963927 train_error 46.88% test_error 51.00%\n",
      "================================121===================================\n",
      "121/10000: train_loss: 4.078939161598683 train_error 46.88% test_error 51.00%\n",
      "================================122===================================\n",
      "122/10000: train_loss: 4.078740192204714 train_error 46.88% test_error 51.00%\n",
      "================================123===================================\n",
      "123/10000: train_loss: 4.07854223035276 train_error 46.88% test_error 51.00%\n",
      "================================124===================================\n",
      "124/10000: train_loss: 4.078345315009356 train_error 46.88% test_error 51.00%\n",
      "================================125===================================\n",
      "125/10000: train_loss: 4.078149475604296 train_error 46.88% test_error 51.00%\n",
      "================================126===================================\n",
      "126/10000: train_loss: 4.077954659909009 train_error 46.88% test_error 51.00%\n",
      "================================127===================================\n",
      "127/10000: train_loss: 4.077760816812516 train_error 46.88% test_error 51.00%\n",
      "================================128===================================\n",
      "128/10000: train_loss: 4.077567981109023 train_error 46.88% test_error 51.00%\n",
      "================================129===================================\n",
      "129/10000: train_loss: 4.077376159951091 train_error 46.88% test_error 51.00%\n",
      "================================130===================================\n",
      "130/10000: train_loss: 4.077185411527753 train_error 46.88% test_error 51.00%\n",
      "================================131===================================\n",
      "131/10000: train_loss: 4.076995662376285 train_error 46.88% test_error 51.00%\n",
      "================================132===================================\n",
      "132/10000: train_loss: 4.076806948259473 train_error 46.88% test_error 51.00%\n",
      "================================133===================================\n",
      "133/10000: train_loss: 4.0766192515939474 train_error 46.88% test_error 51.00%\n",
      "================================134===================================\n",
      "134/10000: train_loss: 4.076432571262122 train_error 46.88% test_error 51.00%\n",
      "================================135===================================\n",
      "135/10000: train_loss: 4.076246916502715 train_error 46.88% test_error 51.00%\n",
      "================================136===================================\n",
      "136/10000: train_loss: 4.076062265112996 train_error 46.88% test_error 51.00%\n",
      "================================137===================================\n",
      "137/10000: train_loss: 4.075878549441695 train_error 46.88% test_error 51.00%\n",
      "================================138===================================\n",
      "138/10000: train_loss: 4.075695779621601 train_error 46.88% test_error 51.00%\n",
      "================================139===================================\n",
      "139/10000: train_loss: 4.075514040440321 train_error 46.88% test_error 51.00%\n",
      "================================140===================================\n",
      "140/10000: train_loss: 4.075333351120353 train_error 46.88% test_error 51.00%\n",
      "================================141===================================\n",
      "141/10000: train_loss: 4.075153751447797 train_error 46.88% test_error 51.00%\n",
      "================================142===================================\n",
      "142/10000: train_loss: 4.074975130558014 train_error 46.88% test_error 51.00%\n",
      "================================143===================================\n",
      "143/10000: train_loss: 4.074797476530075 train_error 46.88% test_error 51.00%\n",
      "================================144===================================\n",
      "144/10000: train_loss: 4.07462076112628 train_error 46.88% test_error 51.00%\n",
      "================================145===================================\n",
      "145/10000: train_loss: 4.074445049464703 train_error 46.88% test_error 51.00%\n",
      "================================146===================================\n",
      "146/10000: train_loss: 4.0742702884972095 train_error 46.88% test_error 51.00%\n",
      "================================147===================================\n",
      "147/10000: train_loss: 4.074096424430609 train_error 46.88% test_error 51.00%\n",
      "================================148===================================\n",
      "148/10000: train_loss: 4.073923472762107 train_error 46.88% test_error 51.00%\n",
      "================================149===================================\n",
      "149/10000: train_loss: 4.073751489967108 train_error 46.88% test_error 51.00%\n",
      "================================150===================================\n",
      "150/10000: train_loss: 4.073580424338579 train_error 46.88% test_error 51.00%\n",
      "================================151===================================\n",
      "151/10000: train_loss: 4.073410260081291 train_error 46.88% test_error 51.00%\n",
      "================================152===================================\n",
      "152/10000: train_loss: 4.073240994513035 train_error 46.88% test_error 51.00%\n",
      "================================153===================================\n",
      "153/10000: train_loss: 4.073072651326656 train_error 46.88% test_error 51.00%\n",
      "================================154===================================\n",
      "154/10000: train_loss: 4.072905234843493 train_error 46.88% test_error 51.00%\n",
      "================================155===================================\n",
      "155/10000: train_loss: 4.072738747149706 train_error 46.88% test_error 51.00%\n",
      "================================156===================================\n",
      "156/10000: train_loss: 4.0725732359290125 train_error 46.88% test_error 51.00%\n",
      "================================157===================================\n",
      "157/10000: train_loss: 4.072408594489097 train_error 46.88% test_error 51.00%\n",
      "================================158===================================\n",
      "158/10000: train_loss: 4.072244769632817 train_error 46.88% test_error 51.00%\n",
      "================================159===================================\n",
      "159/10000: train_loss: 4.072081894427537 train_error 46.88% test_error 51.00%\n",
      "================================160===================================\n",
      "160/10000: train_loss: 4.071919900178909 train_error 46.88% test_error 51.00%\n",
      "================================161===================================\n",
      "161/10000: train_loss: 4.071758840829134 train_error 46.88% test_error 51.00%\n",
      "================================162===================================\n",
      "162/10000: train_loss: 4.071598662137985 train_error 46.88% test_error 51.00%\n",
      "================================163===================================\n",
      "163/10000: train_loss: 4.071439359635114 train_error 46.88% test_error 51.00%\n",
      "================================164===================================\n",
      "164/10000: train_loss: 4.071281028240919 train_error 46.88% test_error 51.00%\n",
      "================================165===================================\n",
      "165/10000: train_loss: 4.071123576015234 train_error 46.88% test_error 51.00%\n",
      "================================166===================================\n",
      "166/10000: train_loss: 4.070967003256083 train_error 46.88% test_error 51.00%\n",
      "================================167===================================\n",
      "167/10000: train_loss: 4.070811279416084 train_error 46.88% test_error 51.00%\n",
      "================================168===================================\n",
      "168/10000: train_loss: 4.0706564466655255 train_error 46.88% test_error 51.00%\n",
      "================================169===================================\n",
      "169/10000: train_loss: 4.070502470433712 train_error 46.88% test_error 51.00%\n",
      "================================170===================================\n",
      "170/10000: train_loss: 4.070349299460649 train_error 46.88% test_error 51.00%\n",
      "================================171===================================\n",
      "171/10000: train_loss: 4.070196995288134 train_error 46.88% test_error 51.00%\n",
      "================================172===================================\n",
      "172/10000: train_loss: 4.070045514851809 train_error 46.88% test_error 51.00%\n",
      "================================173===================================\n",
      "173/10000: train_loss: 4.069894826561212 train_error 46.88% test_error 51.00%\n",
      "================================174===================================\n",
      "174/10000: train_loss: 4.069744979739189 train_error 46.88% test_error 51.00%\n",
      "================================175===================================\n",
      "175/10000: train_loss: 4.069595957547426 train_error 46.88% test_error 51.00%\n",
      "================================176===================================\n",
      "176/10000: train_loss: 4.069447779208422 train_error 46.88% test_error 51.00%\n",
      "================================177===================================\n",
      "177/10000: train_loss: 4.069300376772881 train_error 46.88% test_error 51.00%\n",
      "================================178===================================\n",
      "178/10000: train_loss: 4.069153734445572 train_error 46.88% test_error 51.00%\n",
      "================================179===================================\n",
      "179/10000: train_loss: 4.069007852971554 train_error 46.88% test_error 51.00%\n",
      "================================180===================================\n",
      "180/10000: train_loss: 4.06886278912425 train_error 46.88% test_error 51.00%\n",
      "================================181===================================\n",
      "181/10000: train_loss: 4.068718434870243 train_error 46.88% test_error 51.00%\n",
      "================================182===================================\n",
      "182/10000: train_loss: 4.068574822843075 train_error 46.88% test_error 51.00%\n",
      "================================183===================================\n",
      "183/10000: train_loss: 4.068431992083788 train_error 46.88% test_error 51.00%\n",
      "================================184===================================\n",
      "184/10000: train_loss: 4.068289979994297 train_error 46.88% test_error 51.00%\n",
      "================================185===================================\n",
      "185/10000: train_loss: 4.068148799240589 train_error 46.88% test_error 51.00%\n",
      "================================186===================================\n",
      "186/10000: train_loss: 4.068008462190628 train_error 46.88% test_error 51.00%\n",
      "================================187===================================\n",
      "187/10000: train_loss: 4.067868883907795 train_error 46.88% test_error 51.00%\n",
      "================================188===================================\n",
      "188/10000: train_loss: 4.06773007184267 train_error 46.88% test_error 51.00%\n",
      "================================189===================================\n",
      "189/10000: train_loss: 4.067592024803162 train_error 46.88% test_error 51.00%\n",
      "================================190===================================\n",
      "190/10000: train_loss: 4.067454816401005 train_error 46.88% test_error 51.00%\n",
      "================================191===================================\n",
      "191/10000: train_loss: 4.067318389266729 train_error 46.88% test_error 51.00%\n",
      "================================192===================================\n",
      "192/10000: train_loss: 4.067182802408934 train_error 46.88% test_error 51.00%\n",
      "================================193===================================\n",
      "193/10000: train_loss: 4.0670479452610016 train_error 46.88% test_error 51.00%\n",
      "================================194===================================\n",
      "194/10000: train_loss: 4.066913853883744 train_error 46.88% test_error 51.00%\n",
      "================================195===================================\n",
      "195/10000: train_loss: 4.066780532300472 train_error 46.88% test_error 51.00%\n",
      "================================196===================================\n",
      "196/10000: train_loss: 4.066647953093051 train_error 46.88% test_error 51.00%\n",
      "================================197===================================\n",
      "197/10000: train_loss: 4.066516111642121 train_error 46.88% test_error 51.00%\n",
      "================================198===================================\n",
      "198/10000: train_loss: 4.066385000795126 train_error 46.88% test_error 51.00%\n",
      "================================199===================================\n",
      "199/10000: train_loss: 4.066254629939794 train_error 46.88% test_error 51.00%\n",
      "================================200===================================\n",
      "200/10000: train_loss: 4.066124986708164 train_error 46.88% test_error 51.00%\n",
      "================================201===================================\n",
      "201/10000: train_loss: 4.065996064841747 train_error 46.88% test_error 51.00%\n",
      "================================202===================================\n",
      "202/10000: train_loss: 4.065867889076472 train_error 46.88% test_error 51.00%\n",
      "================================203===================================\n",
      "203/10000: train_loss: 4.065740430504084 train_error 46.88% test_error 51.00%\n",
      "================================204===================================\n",
      "204/10000: train_loss: 4.065613665133715 train_error 46.88% test_error 51.00%\n",
      "================================205===================================\n",
      "205/10000: train_loss: 4.065487593710422 train_error 46.88% test_error 51.00%\n",
      "================================206===================================\n",
      "206/10000: train_loss: 4.065362231135368 train_error 46.88% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================207===================================\n",
      "207/10000: train_loss: 4.06523753747344 train_error 46.88% test_error 51.00%\n",
      "================================208===================================\n",
      "208/10000: train_loss: 4.065113569945097 train_error 46.88% test_error 51.00%\n",
      "================================209===================================\n",
      "209/10000: train_loss: 4.064990279525519 train_error 46.88% test_error 51.00%\n",
      "================================210===================================\n",
      "210/10000: train_loss: 4.0648677167296405 train_error 46.88% test_error 51.00%\n",
      "================================211===================================\n",
      "211/10000: train_loss: 4.064745826870203 train_error 46.88% test_error 51.00%\n",
      "================================212===================================\n",
      "212/10000: train_loss: 4.064624583274126 train_error 46.88% test_error 51.00%\n",
      "================================213===================================\n",
      "213/10000: train_loss: 4.0645040261745455 train_error 46.88% test_error 51.00%\n",
      "================================214===================================\n",
      "214/10000: train_loss: 4.0643841336667546 train_error 46.88% test_error 51.00%\n",
      "================================215===================================\n",
      "215/10000: train_loss: 4.064264896959067 train_error 46.88% test_error 51.00%\n",
      "================================216===================================\n",
      "216/10000: train_loss: 4.064146309643984 train_error 46.88% test_error 51.00%\n",
      "================================217===================================\n",
      "217/10000: train_loss: 4.064028377234935 train_error 46.88% test_error 51.00%\n",
      "================================218===================================\n",
      "218/10000: train_loss: 4.063911121189594 train_error 46.88% test_error 51.00%\n",
      "================================219===================================\n",
      "219/10000: train_loss: 4.063794519454241 train_error 46.88% test_error 51.00%\n",
      "================================220===================================\n",
      "220/10000: train_loss: 4.063678575307131 train_error 46.88% test_error 51.00%\n",
      "================================221===================================\n",
      "221/10000: train_loss: 4.063563273996115 train_error 46.88% test_error 51.00%\n",
      "================================222===================================\n",
      "222/10000: train_loss: 4.063448608517647 train_error 46.88% test_error 51.00%\n",
      "================================223===================================\n",
      "223/10000: train_loss: 4.063334602713585 train_error 46.88% test_error 51.00%\n",
      "================================224===================================\n",
      "224/10000: train_loss: 4.063221249431372 train_error 46.88% test_error 51.00%\n",
      "================================225===================================\n",
      "225/10000: train_loss: 4.063108537942171 train_error 46.88% test_error 51.00%\n",
      "================================226===================================\n",
      "226/10000: train_loss: 4.062996455430985 train_error 46.88% test_error 51.00%\n",
      "================================227===================================\n",
      "227/10000: train_loss: 4.0628850290179255 train_error 46.88% test_error 51.00%\n",
      "================================228===================================\n",
      "228/10000: train_loss: 4.062774219959975 train_error 46.88% test_error 51.00%\n",
      "================================229===================================\n",
      "229/10000: train_loss: 4.062664071172476 train_error 46.88% test_error 51.00%\n",
      "================================230===================================\n",
      "230/10000: train_loss: 4.062554488331079 train_error 46.88% test_error 51.00%\n",
      "================================231===================================\n",
      "231/10000: train_loss: 4.062445475459099 train_error 46.88% test_error 51.00%\n",
      "================================232===================================\n",
      "232/10000: train_loss: 4.062337055057287 train_error 46.88% test_error 51.00%\n",
      "================================233===================================\n",
      "233/10000: train_loss: 4.062229226827621 train_error 46.88% test_error 51.00%\n",
      "================================234===================================\n",
      "234/10000: train_loss: 4.0621220321953295 train_error 46.88% test_error 51.00%\n",
      "================================235===================================\n",
      "235/10000: train_loss: 4.062015457451343 train_error 46.88% test_error 51.00%\n",
      "================================236===================================\n",
      "236/10000: train_loss: 4.06190948471427 train_error 46.88% test_error 51.00%\n",
      "================================237===================================\n",
      "237/10000: train_loss: 4.061804134845734 train_error 46.88% test_error 51.00%\n",
      "================================238===================================\n",
      "238/10000: train_loss: 4.061699351072312 train_error 46.88% test_error 51.00%\n",
      "================================239===================================\n",
      "239/10000: train_loss: 4.061595126837492 train_error 46.88% test_error 51.00%\n",
      "================================240===================================\n",
      "240/10000: train_loss: 4.06149145424366 train_error 46.88% test_error 51.00%\n",
      "================================241===================================\n",
      "241/10000: train_loss: 4.061388324350119 train_error 46.88% test_error 51.00%\n",
      "================================242===================================\n",
      "242/10000: train_loss: 4.061285756379366 train_error 46.88% test_error 51.00%\n",
      "================================243===================================\n",
      "243/10000: train_loss: 4.0611838127672675 train_error 46.88% test_error 51.00%\n",
      "================================244===================================\n",
      "244/10000: train_loss: 4.061082457005977 train_error 46.88% test_error 51.00%\n",
      "================================245===================================\n",
      "245/10000: train_loss: 4.060981682837009 train_error 46.88% test_error 51.00%\n",
      "================================246===================================\n",
      "246/10000: train_loss: 4.060881436318159 train_error 46.88% test_error 51.00%\n",
      "================================247===================================\n",
      "247/10000: train_loss: 4.060781728178263 train_error 46.88% test_error 51.00%\n",
      "================================248===================================\n",
      "248/10000: train_loss: 4.060682570487261 train_error 46.88% test_error 51.00%\n",
      "================================249===================================\n",
      "249/10000: train_loss: 4.0605839841067795 train_error 46.88% test_error 51.00%\n",
      "================================250===================================\n",
      "250/10000: train_loss: 4.06048596650362 train_error 46.88% test_error 51.00%\n",
      "================================251===================================\n",
      "251/10000: train_loss: 4.060388516485691 train_error 46.88% test_error 51.00%\n",
      "================================252===================================\n",
      "252/10000: train_loss: 4.060291629433632 train_error 46.88% test_error 51.00%\n",
      "================================253===================================\n",
      "253/10000: train_loss: 4.06019525140524 train_error 46.88% test_error 51.00%\n",
      "================================254===================================\n",
      "254/10000: train_loss: 4.060099391490222 train_error 46.88% test_error 51.00%\n",
      "================================255===================================\n",
      "255/10000: train_loss: 4.060004095882177 train_error 46.88% test_error 51.00%\n",
      "================================256===================================\n",
      "256/10000: train_loss: 4.059909363389016 train_error 46.88% test_error 51.00%\n",
      "================================257===================================\n",
      "257/10000: train_loss: 4.059815326780081 train_error 46.88% test_error 51.00%\n",
      "================================258===================================\n",
      "258/10000: train_loss: 4.059721768349409 train_error 46.88% test_error 51.00%\n",
      "================================259===================================\n",
      "259/10000: train_loss: 4.05962870657444 train_error 46.88% test_error 51.00%\n",
      "================================260===================================\n",
      "260/10000: train_loss: 4.059536217749119 train_error 46.88% test_error 51.00%\n",
      "================================261===================================\n",
      "261/10000: train_loss: 4.059444256424904 train_error 46.88% test_error 51.00%\n",
      "================================262===================================\n",
      "262/10000: train_loss: 4.059352828860282 train_error 46.88% test_error 51.00%\n",
      "================================263===================================\n",
      "263/10000: train_loss: 4.059261870533228 train_error 46.88% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================264===================================\n",
      "264/10000: train_loss: 4.059171454310417 train_error 46.88% test_error 51.00%\n",
      "================================265===================================\n",
      "265/10000: train_loss: 4.059081539511681 train_error 46.88% test_error 51.00%\n",
      "================================266===================================\n",
      "266/10000: train_loss: 4.058992156386375 train_error 46.88% test_error 51.00%\n",
      "================================267===================================\n",
      "267/10000: train_loss: 4.058903311789035 train_error 46.88% test_error 51.00%\n",
      "================================268===================================\n",
      "268/10000: train_loss: 4.058814935833216 train_error 46.88% test_error 51.00%\n",
      "================================269===================================\n",
      "269/10000: train_loss: 4.058727111369371 train_error 46.88% test_error 51.00%\n",
      "================================270===================================\n",
      "270/10000: train_loss: 4.05863977342844 train_error 46.88% test_error 51.00%\n",
      "================================271===================================\n",
      "271/10000: train_loss: 4.058552970439196 train_error 46.88% test_error 51.00%\n",
      "================================272===================================\n",
      "272/10000: train_loss: 4.058466727584601 train_error 46.88% test_error 51.00%\n",
      "================================273===================================\n",
      "273/10000: train_loss: 4.058381067067385 train_error 46.88% test_error 51.00%\n",
      "================================274===================================\n",
      "274/10000: train_loss: 4.058295870125294 train_error 46.88% test_error 51.00%\n",
      "================================275===================================\n",
      "275/10000: train_loss: 4.05821116656065 train_error 46.88% test_error 51.00%\n",
      "================================276===================================\n",
      "276/10000: train_loss: 4.058127000331878 train_error 46.88% test_error 51.00%\n",
      "================================277===================================\n",
      "277/10000: train_loss: 4.058043310642242 train_error 46.88% test_error 51.00%\n",
      "================================278===================================\n",
      "278/10000: train_loss: 4.057960115820169 train_error 46.88% test_error 51.00%\n",
      "================================279===================================\n",
      "279/10000: train_loss: 4.057877471148968 train_error 46.88% test_error 51.00%\n",
      "================================280===================================\n",
      "280/10000: train_loss: 4.0577953232824795 train_error 46.88% test_error 51.00%\n",
      "================================281===================================\n",
      "281/10000: train_loss: 4.0577136449515825 train_error 46.88% test_error 51.00%\n",
      "================================282===================================\n",
      "282/10000: train_loss: 4.057632457017899 train_error 46.88% test_error 51.00%\n",
      "================================283===================================\n",
      "283/10000: train_loss: 4.057551716268062 train_error 46.88% test_error 51.00%\n",
      "================================284===================================\n",
      "284/10000: train_loss: 4.057471464574337 train_error 46.88% test_error 51.00%\n",
      "================================285===================================\n",
      "285/10000: train_loss: 4.057391704618931 train_error 46.88% test_error 51.00%\n",
      "================================286===================================\n",
      "286/10000: train_loss: 4.057312406301499 train_error 46.88% test_error 51.00%\n",
      "================================287===================================\n",
      "287/10000: train_loss: 4.0572335878014565 train_error 46.88% test_error 51.00%\n",
      "================================288===================================\n",
      "288/10000: train_loss: 4.057155269384384 train_error 46.88% test_error 51.00%\n",
      "================================289===================================\n",
      "289/10000: train_loss: 4.05707740277052 train_error 46.88% test_error 51.00%\n",
      "================================290===================================\n",
      "290/10000: train_loss: 4.0570000475645065 train_error 46.88% test_error 51.00%\n",
      "================================291===================================\n",
      "291/10000: train_loss: 4.056923137158155 train_error 46.88% test_error 51.00%\n",
      "================================292===================================\n",
      "292/10000: train_loss: 4.056846619099378 train_error 46.88% test_error 51.00%\n",
      "================================293===================================\n",
      "293/10000: train_loss: 4.0567705783247945 train_error 46.88% test_error 51.00%\n",
      "================================294===================================\n",
      "294/10000: train_loss: 4.056695001125336 train_error 46.88% test_error 51.00%\n",
      "================================295===================================\n",
      "295/10000: train_loss: 4.056619970351457 train_error 46.88% test_error 51.00%\n",
      "================================296===================================\n",
      "296/10000: train_loss: 4.056545399278402 train_error 46.88% test_error 51.00%\n",
      "================================297===================================\n",
      "297/10000: train_loss: 4.056471329480409 train_error 46.88% test_error 51.00%\n",
      "================================298===================================\n",
      "298/10000: train_loss: 4.056397606730461 train_error 46.88% test_error 51.00%\n",
      "================================299===================================\n",
      "299/10000: train_loss: 4.056324296444654 train_error 46.88% test_error 51.00%\n",
      "================================300===================================\n",
      "300/10000: train_loss: 4.05625144764781 train_error 46.88% test_error 51.00%\n",
      "================================301===================================\n",
      "301/10000: train_loss: 4.056179028153419 train_error 46.88% test_error 51.00%\n",
      "================================302===================================\n",
      "302/10000: train_loss: 4.05610704228282 train_error 46.88% test_error 51.00%\n",
      "================================303===================================\n",
      "303/10000: train_loss: 4.056035496890545 train_error 46.88% test_error 51.00%\n",
      "================================304===================================\n",
      "304/10000: train_loss: 4.0559643319249155 train_error 46.88% test_error 51.00%\n",
      "================================305===================================\n",
      "305/10000: train_loss: 4.055893654823304 train_error 46.88% test_error 51.00%\n",
      "================================306===================================\n",
      "306/10000: train_loss: 4.055823395848274 train_error 46.88% test_error 51.00%\n",
      "================================307===================================\n",
      "307/10000: train_loss: 4.055753531455994 train_error 46.88% test_error 51.00%\n",
      "================================308===================================\n",
      "308/10000: train_loss: 4.055684190392494 train_error 46.88% test_error 51.00%\n",
      "================================309===================================\n",
      "309/10000: train_loss: 4.055615231394768 train_error 46.88% test_error 51.00%\n",
      "================================310===================================\n",
      "310/10000: train_loss: 4.0555467633903035 train_error 46.88% test_error 51.00%\n",
      "================================311===================================\n",
      "311/10000: train_loss: 4.055478661656379 train_error 46.88% test_error 51.00%\n",
      "================================312===================================\n",
      "312/10000: train_loss: 4.055410940945149 train_error 46.88% test_error 51.00%\n",
      "================================313===================================\n",
      "313/10000: train_loss: 4.055343668758869 train_error 46.88% test_error 51.00%\n",
      "================================314===================================\n",
      "314/10000: train_loss: 4.0552768303453925 train_error 46.88% test_error 51.00%\n",
      "================================315===================================\n",
      "315/10000: train_loss: 4.055210414528847 train_error 46.88% test_error 51.00%\n",
      "================================316===================================\n",
      "316/10000: train_loss: 4.055144384205342 train_error 46.88% test_error 51.00%\n",
      "================================317===================================\n",
      "317/10000: train_loss: 4.055078715384006 train_error 46.88% test_error 51.00%\n",
      "================================318===================================\n",
      "318/10000: train_loss: 4.0550134114921095 train_error 46.88% test_error 51.00%\n",
      "================================319===================================\n",
      "319/10000: train_loss: 4.054948512464762 train_error 46.88% test_error 51.00%\n",
      "================================320===================================\n",
      "320/10000: train_loss: 4.054884035438299 train_error 46.88% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================321===================================\n",
      "321/10000: train_loss: 4.054819932878017 train_error 46.88% test_error 51.00%\n",
      "================================322===================================\n",
      "322/10000: train_loss: 4.054756236225367 train_error 46.88% test_error 51.00%\n",
      "================================323===================================\n",
      "323/10000: train_loss: 4.054692936390638 train_error 46.88% test_error 51.00%\n",
      "================================324===================================\n",
      "324/10000: train_loss: 4.054630020409822 train_error 46.88% test_error 51.00%\n",
      "================================325===================================\n",
      "325/10000: train_loss: 4.054567504376173 train_error 46.88% test_error 51.00%\n",
      "================================326===================================\n",
      "326/10000: train_loss: 4.0545053726434706 train_error 46.88% test_error 51.00%\n",
      "================================327===================================\n",
      "327/10000: train_loss: 4.054443633705377 train_error 46.88% test_error 51.00%\n",
      "================================328===================================\n",
      "328/10000: train_loss: 4.054382242113352 train_error 46.88% test_error 51.00%\n",
      "================================329===================================\n",
      "329/10000: train_loss: 4.054321271181107 train_error 46.88% test_error 51.00%\n",
      "================================330===================================\n",
      "330/10000: train_loss: 4.054260707348585 train_error 46.88% test_error 51.00%\n",
      "================================331===================================\n",
      "331/10000: train_loss: 4.054200542718172 train_error 46.88% test_error 51.00%\n",
      "================================332===================================\n",
      "332/10000: train_loss: 4.054140746444464 train_error 46.88% test_error 51.00%\n",
      "================================333===================================\n",
      "333/10000: train_loss: 4.054081320017577 train_error 46.88% test_error 51.00%\n",
      "================================334===================================\n",
      "334/10000: train_loss: 4.054022211283446 train_error 46.88% test_error 51.00%\n",
      "================================335===================================\n",
      "335/10000: train_loss: 4.053963403105736 train_error 46.88% test_error 51.00%\n",
      "================================336===================================\n",
      "336/10000: train_loss: 4.053904981762171 train_error 46.88% test_error 51.00%\n",
      "================================337===================================\n",
      "337/10000: train_loss: 4.053846928477288 train_error 46.88% test_error 51.00%\n",
      "================================338===================================\n",
      "338/10000: train_loss: 4.053789244294167 train_error 46.88% test_error 51.00%\n",
      "================================339===================================\n",
      "339/10000: train_loss: 4.053731878995896 train_error 46.88% test_error 51.00%\n",
      "================================340===================================\n",
      "340/10000: train_loss: 4.05367486461997 train_error 46.88% test_error 51.00%\n",
      "================================341===================================\n",
      "341/10000: train_loss: 4.053618218898773 train_error 46.88% test_error 51.00%\n",
      "================================342===================================\n",
      "342/10000: train_loss: 4.0535619367659095 train_error 46.88% test_error 51.00%\n",
      "================================343===================================\n",
      "343/10000: train_loss: 4.053505997210741 train_error 46.88% test_error 51.00%\n",
      "================================344===================================\n",
      "344/10000: train_loss: 4.0534504064917565 train_error 46.88% test_error 51.00%\n",
      "================================345===================================\n",
      "345/10000: train_loss: 4.053395192921162 train_error 46.88% test_error 51.00%\n",
      "================================346===================================\n",
      "346/10000: train_loss: 4.05334032356739 train_error 46.88% test_error 51.00%\n",
      "================================347===================================\n",
      "347/10000: train_loss: 4.05328584343195 train_error 46.88% test_error 51.00%\n",
      "================================348===================================\n",
      "348/10000: train_loss: 4.053231713473797 train_error 46.88% test_error 51.00%\n",
      "================================349===================================\n",
      "349/10000: train_loss: 4.0531779649853705 train_error 46.88% test_error 51.00%\n",
      "================================350===================================\n",
      "350/10000: train_loss: 4.053124553710222 train_error 46.88% test_error 51.00%\n",
      "================================351===================================\n",
      "351/10000: train_loss: 4.053071504235268 train_error 46.88% test_error 51.00%\n",
      "================================352===================================\n",
      "352/10000: train_loss: 4.053018796145916 train_error 46.88% test_error 51.00%\n",
      "================================353===================================\n",
      "353/10000: train_loss: 4.0529664349555965 train_error 46.88% test_error 51.00%\n",
      "================================354===================================\n",
      "354/10000: train_loss: 4.052914422303438 train_error 46.88% test_error 51.00%\n",
      "================================355===================================\n",
      "355/10000: train_loss: 4.052862761318684 train_error 46.88% test_error 51.00%\n",
      "================================356===================================\n",
      "356/10000: train_loss: 4.052811385840177 train_error 46.88% test_error 51.00%\n",
      "================================357===================================\n",
      "357/10000: train_loss: 4.052760367691517 train_error 46.88% test_error 51.00%\n",
      "================================358===================================\n",
      "358/10000: train_loss: 4.0527097170054915 train_error 46.88% test_error 51.00%\n",
      "================================359===================================\n",
      "359/10000: train_loss: 4.052659374475478 train_error 46.88% test_error 51.00%\n",
      "================================360===================================\n",
      "360/10000: train_loss: 4.0526093192398545 train_error 46.88% test_error 51.00%\n",
      "================================361===================================\n",
      "361/10000: train_loss: 4.052559560835362 train_error 46.88% test_error 51.00%\n",
      "================================362===================================\n",
      "362/10000: train_loss: 4.0525101003050805 train_error 46.88% test_error 51.00%\n",
      "================================363===================================\n",
      "363/10000: train_loss: 4.052460998594761 train_error 46.88% test_error 51.00%\n",
      "================================364===================================\n",
      "364/10000: train_loss: 4.052412194311619 train_error 46.88% test_error 51.00%\n",
      "================================365===================================\n",
      "365/10000: train_loss: 4.052363731563091 train_error 46.88% test_error 51.00%\n",
      "================================366===================================\n",
      "366/10000: train_loss: 4.052315502017737 train_error 46.88% test_error 51.00%\n",
      "================================367===================================\n",
      "367/10000: train_loss: 4.052267571687699 train_error 46.88% test_error 51.00%\n",
      "================================368===================================\n",
      "368/10000: train_loss: 4.052219984829426 train_error 46.88% test_error 51.00%\n",
      "================================369===================================\n",
      "369/10000: train_loss: 4.052172677814961 train_error 46.88% test_error 51.00%\n",
      "================================370===================================\n",
      "370/10000: train_loss: 4.052125700265169 train_error 46.88% test_error 51.00%\n",
      "================================371===================================\n",
      "371/10000: train_loss: 4.052079059928656 train_error 46.88% test_error 51.00%\n",
      "================================372===================================\n",
      "372/10000: train_loss: 4.052032672464847 train_error 46.88% test_error 51.00%\n",
      "================================373===================================\n",
      "373/10000: train_loss: 4.051986550390721 train_error 46.88% test_error 51.00%\n",
      "================================374===================================\n",
      "374/10000: train_loss: 4.051940803825856 train_error 46.88% test_error 51.00%\n",
      "================================375===================================\n",
      "375/10000: train_loss: 4.051895344257355 train_error 46.88% test_error 51.00%\n",
      "================================376===================================\n",
      "376/10000: train_loss: 4.051850190907716 train_error 46.88% test_error 51.00%\n",
      "================================377===================================\n",
      "377/10000: train_loss: 4.051805341541767 train_error 46.88% test_error 51.00%\n",
      "================================378===================================\n",
      "378/10000: train_loss: 4.051760806292296 train_error 46.88% test_error 51.00%\n",
      "================================379===================================\n",
      "379/10000: train_loss: 4.051716580390931 train_error 46.88% test_error 51.00%\n",
      "================================380===================================\n",
      "380/10000: train_loss: 4.051672650426626 train_error 46.88% test_error 51.00%\n",
      "================================381===================================\n",
      "381/10000: train_loss: 4.051629012972116 train_error 46.88% test_error 51.00%\n",
      "================================382===================================\n",
      "382/10000: train_loss: 4.051585659235716 train_error 46.88% test_error 51.00%\n",
      "================================383===================================\n",
      "383/10000: train_loss: 4.051542598009108 train_error 46.88% test_error 51.00%\n",
      "================================384===================================\n",
      "384/10000: train_loss: 4.051499818265438 train_error 46.88% test_error 51.00%\n",
      "================================385===================================\n",
      "385/10000: train_loss: 4.051457297056913 train_error 46.88% test_error 51.00%\n",
      "================================386===================================\n",
      "386/10000: train_loss: 4.051415080577135 train_error 46.88% test_error 51.00%\n",
      "================================387===================================\n",
      "387/10000: train_loss: 4.051373223215341 train_error 46.88% test_error 51.00%\n",
      "================================388===================================\n",
      "388/10000: train_loss: 4.0513316516578195 train_error 46.88% test_error 51.00%\n",
      "================================389===================================\n",
      "389/10000: train_loss: 4.051290339678526 train_error 46.88% test_error 51.00%\n",
      "================================390===================================\n",
      "390/10000: train_loss: 4.051249273568391 train_error 46.88% test_error 51.00%\n",
      "================================391===================================\n",
      "391/10000: train_loss: 4.05120849058032 train_error 46.88% test_error 51.00%\n",
      "================================392===================================\n",
      "392/10000: train_loss: 4.05116800904274 train_error 46.88% test_error 51.00%\n",
      "================================393===================================\n",
      "393/10000: train_loss: 4.051127835214138 train_error 46.88% test_error 51.00%\n",
      "================================394===================================\n",
      "394/10000: train_loss: 4.0510880085825915 train_error 46.88% test_error 51.00%\n",
      "================================395===================================\n",
      "395/10000: train_loss: 4.051048406809568 train_error 46.88% test_error 51.00%\n",
      "================================396===================================\n",
      "396/10000: train_loss: 4.051009030491113 train_error 46.88% test_error 51.00%\n",
      "================================397===================================\n",
      "397/10000: train_loss: 4.050969941169024 train_error 46.88% test_error 51.00%\n",
      "================================398===================================\n",
      "398/10000: train_loss: 4.050931108593941 train_error 46.88% test_error 51.00%\n",
      "================================399===================================\n",
      "399/10000: train_loss: 4.050892568230628 train_error 46.88% test_error 51.00%\n",
      "================================400===================================\n",
      "400/10000: train_loss: 4.050854305773973 train_error 46.88% test_error 51.00%\n",
      "================================401===================================\n",
      "401/10000: train_loss: 4.050816330611706 train_error 46.88% test_error 51.00%\n",
      "================================402===================================\n",
      "402/10000: train_loss: 4.050778683423996 train_error 46.88% test_error 51.00%\n",
      "================================403===================================\n",
      "403/10000: train_loss: 4.0507412993907925 train_error 46.88% test_error 51.00%\n",
      "================================404===================================\n",
      "404/10000: train_loss: 4.050704136043787 train_error 46.88% test_error 51.00%\n",
      "================================405===================================\n",
      "405/10000: train_loss: 4.050667226463556 train_error 46.88% test_error 51.00%\n",
      "================================406===================================\n",
      "406/10000: train_loss: 4.050630613267423 train_error 46.88% test_error 51.00%\n",
      "================================407===================================\n",
      "407/10000: train_loss: 4.050594215393067 train_error 46.88% test_error 51.00%\n",
      "================================408===================================\n",
      "408/10000: train_loss: 4.050558067709208 train_error 46.88% test_error 51.00%\n",
      "================================409===================================\n",
      "409/10000: train_loss: 4.050522208660841 train_error 46.88% test_error 51.00%\n",
      "================================410===================================\n",
      "410/10000: train_loss: 4.050486586689949 train_error 46.88% test_error 51.00%\n",
      "================================411===================================\n",
      "411/10000: train_loss: 4.050451170802116 train_error 46.88% test_error 51.00%\n",
      "================================412===================================\n",
      "412/10000: train_loss: 4.050415966957807 train_error 46.88% test_error 51.00%\n",
      "================================413===================================\n",
      "413/10000: train_loss: 4.050381020754576 train_error 46.88% test_error 51.00%\n",
      "================================414===================================\n",
      "414/10000: train_loss: 4.050346329659224 train_error 46.88% test_error 51.00%\n",
      "================================415===================================\n",
      "415/10000: train_loss: 4.050311900824308 train_error 46.88% test_error 51.00%\n",
      "================================416===================================\n",
      "416/10000: train_loss: 4.050277709811926 train_error 46.88% test_error 51.00%\n",
      "================================417===================================\n",
      "417/10000: train_loss: 4.050243757814169 train_error 46.88% test_error 51.00%\n",
      "================================418===================================\n",
      "418/10000: train_loss: 4.05020998865366 train_error 46.88% test_error 51.00%\n",
      "================================419===================================\n",
      "419/10000: train_loss: 4.050176489800214 train_error 46.88% test_error 51.00%\n",
      "================================420===================================\n",
      "420/10000: train_loss: 4.050143240243196 train_error 46.88% test_error 51.00%\n",
      "================================421===================================\n",
      "421/10000: train_loss: 4.050110247731208 train_error 46.88% test_error 51.00%\n",
      "================================422===================================\n",
      "422/10000: train_loss: 4.050077495276928 train_error 46.88% test_error 51.00%\n",
      "================================423===================================\n",
      "423/10000: train_loss: 4.050044959336519 train_error 46.88% test_error 51.00%\n",
      "================================424===================================\n",
      "424/10000: train_loss: 4.050012699663639 train_error 46.88% test_error 51.00%\n",
      "================================425===================================\n",
      "425/10000: train_loss: 4.049980663061142 train_error 46.88% test_error 51.00%\n",
      "================================426===================================\n",
      "426/10000: train_loss: 4.049948870241643 train_error 46.88% test_error 51.00%\n",
      "================================427===================================\n",
      "427/10000: train_loss: 4.049917293190957 train_error 46.88% test_error 51.00%\n",
      "================================428===================================\n",
      "428/10000: train_loss: 4.049885941892862 train_error 46.88% test_error 51.00%\n",
      "================================429===================================\n",
      "429/10000: train_loss: 4.0498548276722435 train_error 46.88% test_error 51.00%\n",
      "================================430===================================\n",
      "430/10000: train_loss: 4.049823877066373 train_error 46.88% test_error 51.00%\n",
      "================================431===================================\n",
      "431/10000: train_loss: 4.04979312852025 train_error 46.88% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================432===================================\n",
      "432/10000: train_loss: 4.049762597233057 train_error 46.88% test_error 51.00%\n",
      "================================433===================================\n",
      "433/10000: train_loss: 4.049732238352299 train_error 46.88% test_error 51.00%\n",
      "================================434===================================\n",
      "434/10000: train_loss: 4.049702101349831 train_error 46.88% test_error 51.00%\n",
      "================================435===================================\n",
      "435/10000: train_loss: 4.049672219902277 train_error 46.88% test_error 51.00%\n",
      "================================436===================================\n",
      "436/10000: train_loss: 4.0496425610780715 train_error 46.88% test_error 51.00%\n",
      "================================437===================================\n",
      "437/10000: train_loss: 4.049613111317158 train_error 46.88% test_error 51.00%\n",
      "================================438===================================\n",
      "438/10000: train_loss: 4.049583891779184 train_error 46.88% test_error 51.00%\n",
      "================================439===================================\n",
      "439/10000: train_loss: 4.04955491900444 train_error 46.88% test_error 51.00%\n",
      "================================440===================================\n",
      "440/10000: train_loss: 4.049526167362928 train_error 46.88% test_error 51.00%\n",
      "================================441===================================\n",
      "441/10000: train_loss: 4.049497631788254 train_error 46.88% test_error 51.00%\n",
      "================================442===================================\n",
      "442/10000: train_loss: 4.049469309300184 train_error 46.88% test_error 51.00%\n",
      "================================443===================================\n",
      "443/10000: train_loss: 4.049441204965115 train_error 46.88% test_error 51.00%\n",
      "================================444===================================\n",
      "444/10000: train_loss: 4.04941334336996 train_error 46.88% test_error 51.00%\n",
      "================================445===================================\n",
      "445/10000: train_loss: 4.049385667443276 train_error 46.88% test_error 51.00%\n",
      "================================446===================================\n",
      "446/10000: train_loss: 4.049358261674643 train_error 46.88% test_error 51.00%\n",
      "================================447===================================\n",
      "447/10000: train_loss: 4.049331094026566 train_error 46.88% test_error 51.00%\n",
      "================================448===================================\n",
      "448/10000: train_loss: 4.049304168224334 train_error 46.88% test_error 51.00%\n",
      "================================449===================================\n",
      "449/10000: train_loss: 4.04927739188075 train_error 46.88% test_error 51.00%\n",
      "================================450===================================\n",
      "450/10000: train_loss: 4.0492507964372635 train_error 46.88% test_error 51.00%\n",
      "================================451===================================\n",
      "451/10000: train_loss: 4.049224375784397 train_error 46.88% test_error 51.00%\n",
      "================================452===================================\n",
      "452/10000: train_loss: 4.0491981123387815 train_error 46.88% test_error 51.00%\n",
      "================================453===================================\n",
      "453/10000: train_loss: 4.0491720716655255 train_error 46.88% test_error 51.00%\n",
      "================================454===================================\n",
      "454/10000: train_loss: 4.049146250933409 train_error 46.88% test_error 51.00%\n",
      "================================455===================================\n",
      "455/10000: train_loss: 4.04912070915103 train_error 46.88% test_error 51.00%\n",
      "================================456===================================\n",
      "456/10000: train_loss: 4.0490953762829305 train_error 46.88% test_error 51.00%\n",
      "================================457===================================\n",
      "457/10000: train_loss: 4.049070254266262 train_error 46.88% test_error 51.00%\n",
      "================================458===================================\n",
      "458/10000: train_loss: 4.049045352935791 train_error 46.88% test_error 51.00%\n",
      "================================459===================================\n",
      "459/10000: train_loss: 4.049020676612853 train_error 46.88% test_error 51.00%\n",
      "================================460===================================\n",
      "460/10000: train_loss: 4.048996245414019 train_error 46.88% test_error 51.00%\n",
      "================================461===================================\n",
      "461/10000: train_loss: 4.048972021490336 train_error 46.88% test_error 51.00%\n",
      "================================462===================================\n",
      "462/10000: train_loss: 4.048947979211807 train_error 46.88% test_error 51.00%\n",
      "================================463===================================\n",
      "463/10000: train_loss: 4.048924112170934 train_error 46.88% test_error 51.00%\n",
      "================================464===================================\n",
      "464/10000: train_loss: 4.048900453150273 train_error 46.88% test_error 51.00%\n",
      "================================465===================================\n",
      "465/10000: train_loss: 4.0488770079612735 train_error 46.88% test_error 51.00%\n",
      "================================466===================================\n",
      "466/10000: train_loss: 4.0488537392020225 train_error 46.88% test_error 51.00%\n",
      "================================467===================================\n",
      "467/10000: train_loss: 4.048830643445253 train_error 46.88% test_error 51.00%\n",
      "================================468===================================\n",
      "468/10000: train_loss: 4.048807672262192 train_error 46.88% test_error 51.00%\n",
      "================================469===================================\n",
      "469/10000: train_loss: 4.048784833401442 train_error 46.88% test_error 51.00%\n",
      "================================470===================================\n",
      "470/10000: train_loss: 4.0487621867656705 train_error 46.88% test_error 51.00%\n",
      "================================471===================================\n",
      "471/10000: train_loss: 4.048739751726389 train_error 46.88% test_error 51.00%\n",
      "================================472===================================\n",
      "472/10000: train_loss: 4.04871752679348 train_error 46.88% test_error 51.00%\n",
      "================================473===================================\n",
      "473/10000: train_loss: 4.048695503622294 train_error 46.88% test_error 51.00%\n",
      "================================474===================================\n",
      "474/10000: train_loss: 4.048673676550388 train_error 46.88% test_error 51.00%\n",
      "================================475===================================\n",
      "475/10000: train_loss: 4.04865203216672 train_error 46.88% test_error 51.00%\n",
      "================================476===================================\n",
      "476/10000: train_loss: 4.048630559295416 train_error 46.88% test_error 51.00%\n",
      "================================477===================================\n",
      "477/10000: train_loss: 4.048609283864499 train_error 46.88% test_error 51.00%\n",
      "================================478===================================\n",
      "478/10000: train_loss: 4.048588173538446 train_error 46.88% test_error 51.00%\n",
      "================================479===================================\n",
      "479/10000: train_loss: 4.048567273467779 train_error 46.88% test_error 51.00%\n",
      "================================480===================================\n",
      "480/10000: train_loss: 4.048546582311392 train_error 46.88% test_error 51.00%\n",
      "================================481===================================\n",
      "481/10000: train_loss: 4.048526102602482 train_error 46.88% test_error 51.00%\n",
      "================================482===================================\n",
      "482/10000: train_loss: 4.048505812138319 train_error 46.88% test_error 51.00%\n",
      "================================483===================================\n",
      "483/10000: train_loss: 4.048485712409019 train_error 46.88% test_error 51.00%\n",
      "================================484===================================\n",
      "484/10000: train_loss: 4.048465768098831 train_error 46.88% test_error 51.00%\n",
      "================================485===================================\n",
      "485/10000: train_loss: 4.048445947617293 train_error 46.88% test_error 51.00%\n",
      "================================486===================================\n",
      "486/10000: train_loss: 4.048426268100739 train_error 46.88% test_error 51.00%\n",
      "================================487===================================\n",
      "487/10000: train_loss: 4.048406792134046 train_error 46.88% test_error 51.00%\n",
      "================================488===================================\n",
      "488/10000: train_loss: 4.0483874496817585 train_error 46.88% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================489===================================\n",
      "489/10000: train_loss: 4.048368306457997 train_error 46.88% test_error 51.00%\n",
      "================================490===================================\n",
      "490/10000: train_loss: 4.048349299728871 train_error 46.88% test_error 51.00%\n",
      "================================491===================================\n",
      "491/10000: train_loss: 4.048330408185721 train_error 46.88% test_error 51.00%\n",
      "================================492===================================\n",
      "492/10000: train_loss: 4.048311676681042 train_error 46.88% test_error 51.00%\n",
      "================================493===================================\n",
      "493/10000: train_loss: 4.048293114602566 train_error 46.88% test_error 51.00%\n",
      "================================494===================================\n",
      "494/10000: train_loss: 4.048274713605642 train_error 46.88% test_error 51.00%\n",
      "================================495===================================\n",
      "495/10000: train_loss: 4.048256524652243 train_error 46.88% test_error 51.00%\n",
      "================================496===================================\n",
      "496/10000: train_loss: 4.04823851659894 train_error 46.88% test_error 51.00%\n",
      "================================497===================================\n",
      "497/10000: train_loss: 4.048220714330673 train_error 46.88% test_error 51.00%\n",
      "================================498===================================\n",
      "498/10000: train_loss: 4.048203096985817 train_error 46.88% test_error 51.00%\n",
      "================================499===================================\n",
      "499/10000: train_loss: 4.0481856344640255 train_error 46.88% test_error 51.00%\n",
      "================================500===================================\n",
      "500/10000: train_loss: 4.048168329894543 train_error 46.88% test_error 51.00%\n",
      "================================501===================================\n",
      "501/10000: train_loss: 4.048151175230741 train_error 46.88% test_error 51.00%\n",
      "================================502===================================\n",
      "502/10000: train_loss: 4.04813422113657 train_error 46.88% test_error 51.00%\n",
      "================================503===================================\n",
      "503/10000: train_loss: 4.048117411583662 train_error 46.88% test_error 51.00%\n",
      "================================504===================================\n",
      "504/10000: train_loss: 4.048100778013469 train_error 47.00% test_error 51.00%\n",
      "================================505===================================\n",
      "505/10000: train_loss: 4.04808431610465 train_error 47.00% test_error 51.00%\n",
      "================================506===================================\n",
      "506/10000: train_loss: 4.048068009465933 train_error 47.00% test_error 51.00%\n",
      "================================507===================================\n",
      "507/10000: train_loss: 4.048051865845919 train_error 47.00% test_error 51.00%\n",
      "================================508===================================\n",
      "508/10000: train_loss: 4.048035867959261 train_error 47.00% test_error 51.00%\n",
      "================================509===================================\n",
      "509/10000: train_loss: 4.04802006572485 train_error 47.00% test_error 51.00%\n",
      "================================510===================================\n",
      "510/10000: train_loss: 4.048004396557808 train_error 47.00% test_error 51.00%\n",
      "================================511===================================\n",
      "511/10000: train_loss: 4.047988871186972 train_error 47.00% test_error 51.00%\n",
      "================================512===================================\n",
      "512/10000: train_loss: 4.047973515987397 train_error 47.00% test_error 51.00%\n",
      "================================513===================================\n",
      "513/10000: train_loss: 4.047958298325539 train_error 47.00% test_error 51.00%\n",
      "================================514===================================\n",
      "514/10000: train_loss: 4.047943267971277 train_error 47.00% test_error 51.00%\n",
      "================================515===================================\n",
      "515/10000: train_loss: 4.047928378582001 train_error 47.00% test_error 51.00%\n",
      "================================516===================================\n",
      "516/10000: train_loss: 4.047913674116135 train_error 47.00% test_error 51.00%\n",
      "================================517===================================\n",
      "517/10000: train_loss: 4.04789910748601 train_error 47.00% test_error 51.00%\n",
      "================================518===================================\n",
      "518/10000: train_loss: 4.047884737849236 train_error 47.00% test_error 51.00%\n",
      "================================519===================================\n",
      "519/10000: train_loss: 4.047870599031448 train_error 47.00% test_error 51.00%\n",
      "================================520===================================\n",
      "520/10000: train_loss: 4.0478565713763235 train_error 47.00% test_error 51.00%\n",
      "================================521===================================\n",
      "521/10000: train_loss: 4.047842748463154 train_error 47.00% test_error 51.00%\n",
      "================================522===================================\n",
      "522/10000: train_loss: 4.04782905831933 train_error 47.00% test_error 51.00%\n",
      "================================523===================================\n",
      "523/10000: train_loss: 4.0478155279159544 train_error 47.00% test_error 51.00%\n",
      "================================524===================================\n",
      "524/10000: train_loss: 4.047802143990993 train_error 47.00% test_error 51.00%\n",
      "================================525===================================\n",
      "525/10000: train_loss: 4.047788859456778 train_error 47.00% test_error 51.00%\n",
      "================================526===================================\n",
      "526/10000: train_loss: 4.047775791883469 train_error 47.00% test_error 51.00%\n",
      "================================527===================================\n",
      "527/10000: train_loss: 4.04776290372014 train_error 47.00% test_error 51.00%\n",
      "================================528===================================\n",
      "528/10000: train_loss: 4.047750174552203 train_error 47.00% test_error 51.00%\n",
      "================================529===================================\n",
      "529/10000: train_loss: 4.047737598568201 train_error 47.00% test_error 51.00%\n",
      "================================530===================================\n",
      "530/10000: train_loss: 4.047725138515234 train_error 47.00% test_error 51.00%\n",
      "================================531===================================\n",
      "531/10000: train_loss: 4.047712812721729 train_error 47.00% test_error 51.00%\n",
      "================================532===================================\n",
      "532/10000: train_loss: 4.0477005867660045 train_error 47.00% test_error 51.00%\n",
      "================================533===================================\n",
      "533/10000: train_loss: 4.047688479125499 train_error 47.00% test_error 51.00%\n",
      "================================534===================================\n",
      "534/10000: train_loss: 4.047676472216844 train_error 47.00% test_error 51.00%\n",
      "================================535===================================\n",
      "535/10000: train_loss: 4.0476645952463155 train_error 47.00% test_error 51.00%\n",
      "================================536===================================\n",
      "536/10000: train_loss: 4.0476528477668765 train_error 47.00% test_error 51.00%\n",
      "================================537===================================\n",
      "537/10000: train_loss: 4.047641196548939 train_error 47.00% test_error 51.00%\n",
      "================================538===================================\n",
      "538/10000: train_loss: 4.047629670798778 train_error 47.00% test_error 51.00%\n",
      "================================539===================================\n",
      "539/10000: train_loss: 4.047618303149939 train_error 47.00% test_error 51.00%\n",
      "================================540===================================\n",
      "540/10000: train_loss: 4.047607052624226 train_error 47.00% test_error 51.00%\n",
      "================================541===================================\n",
      "541/10000: train_loss: 4.0475959195196625 train_error 47.00% test_error 51.00%\n",
      "================================542===================================\n",
      "542/10000: train_loss: 4.047584924697876 train_error 47.00% test_error 51.00%\n",
      "================================543===================================\n",
      "543/10000: train_loss: 4.0475740550458434 train_error 47.00% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================544===================================\n",
      "544/10000: train_loss: 4.047563292831183 train_error 47.00% test_error 51.00%\n",
      "================================545===================================\n",
      "545/10000: train_loss: 4.047552652359009 train_error 47.00% test_error 51.00%\n",
      "================================546===================================\n",
      "546/10000: train_loss: 4.04754217132926 train_error 47.00% test_error 51.00%\n",
      "================================547===================================\n",
      "547/10000: train_loss: 4.047531894743443 train_error 47.00% test_error 51.00%\n",
      "================================548===================================\n",
      "548/10000: train_loss: 4.047521732747555 train_error 47.00% test_error 51.00%\n",
      "================================549===================================\n",
      "549/10000: train_loss: 4.047511704862117 train_error 47.00% test_error 51.00%\n",
      "================================550===================================\n",
      "550/10000: train_loss: 4.047501788586378 train_error 47.00% test_error 51.00%\n",
      "================================551===================================\n",
      "551/10000: train_loss: 4.047492014765739 train_error 47.00% test_error 51.00%\n",
      "================================552===================================\n",
      "552/10000: train_loss: 4.047482368648052 train_error 47.00% test_error 51.00%\n",
      "================================553===================================\n",
      "553/10000: train_loss: 4.04747281730175 train_error 47.00% test_error 51.00%\n",
      "================================554===================================\n",
      "554/10000: train_loss: 4.0474633866548535 train_error 47.00% test_error 51.00%\n",
      "================================555===================================\n",
      "555/10000: train_loss: 4.047454079836608 train_error 47.00% test_error 51.00%\n",
      "================================556===================================\n",
      "556/10000: train_loss: 4.0474448829889305 train_error 47.00% test_error 51.00%\n",
      "================================557===================================\n",
      "557/10000: train_loss: 4.047435846626758 train_error 47.00% test_error 51.00%\n",
      "================================558===================================\n",
      "558/10000: train_loss: 4.047426938563586 train_error 47.00% test_error 51.00%\n",
      "================================559===================================\n",
      "559/10000: train_loss: 4.047418169826269 train_error 47.00% test_error 51.00%\n",
      "================================560===================================\n",
      "560/10000: train_loss: 4.0474094994366165 train_error 47.00% test_error 51.00%\n",
      "================================561===================================\n",
      "561/10000: train_loss: 4.047400962561369 train_error 47.00% test_error 51.00%\n",
      "================================562===================================\n",
      "562/10000: train_loss: 4.047392569631338 train_error 47.00% test_error 51.00%\n",
      "================================563===================================\n",
      "563/10000: train_loss: 4.047384281307458 train_error 47.00% test_error 51.00%\n",
      "================================564===================================\n",
      "564/10000: train_loss: 4.047376130819321 train_error 47.00% test_error 51.00%\n",
      "================================565===================================\n",
      "565/10000: train_loss: 4.047368103563786 train_error 47.00% test_error 51.00%\n",
      "================================566===================================\n",
      "566/10000: train_loss: 4.047360191047192 train_error 47.00% test_error 51.00%\n",
      "================================567===================================\n",
      "567/10000: train_loss: 4.0473523846268655 train_error 47.00% test_error 51.00%\n",
      "================================568===================================\n",
      "568/10000: train_loss: 4.0473447421193125 train_error 47.00% test_error 51.00%\n",
      "================================569===================================\n",
      "569/10000: train_loss: 4.047337206453085 train_error 47.00% test_error 51.00%\n",
      "================================570===================================\n",
      "570/10000: train_loss: 4.047329772561788 train_error 47.00% test_error 51.00%\n",
      "================================571===================================\n",
      "571/10000: train_loss: 4.047322480082512 train_error 47.00% test_error 51.00%\n",
      "================================572===================================\n",
      "572/10000: train_loss: 4.047315282076598 train_error 47.00% test_error 51.00%\n",
      "================================573===================================\n",
      "573/10000: train_loss: 4.04730821877718 train_error 47.00% test_error 51.00%\n",
      "================================574===================================\n",
      "574/10000: train_loss: 4.047301276028156 train_error 47.00% test_error 51.00%\n",
      "================================575===================================\n",
      "575/10000: train_loss: 4.047294443398714 train_error 47.00% test_error 51.00%\n",
      "================================576===================================\n",
      "576/10000: train_loss: 4.047287740856409 train_error 47.00% test_error 51.00%\n",
      "================================577===================================\n",
      "577/10000: train_loss: 4.0472811430692675 train_error 47.00% test_error 51.00%\n",
      "================================578===================================\n",
      "578/10000: train_loss: 4.047274653464556 train_error 47.00% test_error 51.00%\n",
      "================================579===================================\n",
      "579/10000: train_loss: 4.047268248945475 train_error 47.00% test_error 51.00%\n",
      "================================580===================================\n",
      "580/10000: train_loss: 4.047261889725923 train_error 47.00% test_error 51.00%\n",
      "================================581===================================\n",
      "581/10000: train_loss: 4.047255670577288 train_error 47.00% test_error 51.00%\n",
      "================================582===================================\n",
      "582/10000: train_loss: 4.0472495618462565 train_error 47.00% test_error 51.00%\n",
      "================================583===================================\n",
      "583/10000: train_loss: 4.047243626266718 train_error 47.00% test_error 51.00%\n",
      "================================584===================================\n",
      "584/10000: train_loss: 4.047237801551819 train_error 47.00% test_error 51.00%\n",
      "================================585===================================\n",
      "585/10000: train_loss: 4.047232121825218 train_error 47.00% test_error 51.00%\n",
      "================================586===================================\n",
      "586/10000: train_loss: 4.047226565331221 train_error 47.00% test_error 51.00%\n",
      "================================587===================================\n",
      "587/10000: train_loss: 4.047221097052097 train_error 47.00% test_error 51.00%\n",
      "================================588===================================\n",
      "588/10000: train_loss: 4.047215745300055 train_error 47.00% test_error 51.00%\n",
      "================================589===================================\n",
      "589/10000: train_loss: 4.047210488170386 train_error 47.00% test_error 51.00%\n",
      "================================590===================================\n",
      "590/10000: train_loss: 4.0472053511440755 train_error 47.00% test_error 51.00%\n",
      "================================591===================================\n",
      "591/10000: train_loss: 4.047200295180082 train_error 47.00% test_error 51.00%\n",
      "================================592===================================\n",
      "592/10000: train_loss: 4.047195344418287 train_error 47.00% test_error 51.00%\n",
      "================================593===================================\n",
      "593/10000: train_loss: 4.0471905185282235 train_error 47.00% test_error 51.00%\n",
      "================================594===================================\n",
      "594/10000: train_loss: 4.047185738980771 train_error 47.00% test_error 51.00%\n",
      "================================595===================================\n",
      "595/10000: train_loss: 4.04718108072877 train_error 47.00% test_error 51.00%\n",
      "================================596===================================\n",
      "596/10000: train_loss: 4.047176515311002 train_error 47.00% test_error 51.00%\n",
      "================================597===================================\n",
      "597/10000: train_loss: 4.047172045409679 train_error 47.00% test_error 51.00%\n",
      "================================598===================================\n",
      "598/10000: train_loss: 4.047167693972588 train_error 47.00% test_error 51.00%\n",
      "================================599===================================\n",
      "599/10000: train_loss: 4.047163426429034 train_error 47.00% test_error 51.00%\n",
      "================================600===================================\n",
      "600/10000: train_loss: 4.047159252017736 train_error 47.00% test_error 51.00%\n",
      "================================601===================================\n",
      "601/10000: train_loss: 4.047155190110207 train_error 47.12% test_error 51.00%\n",
      "================================602===================================\n",
      "602/10000: train_loss: 4.047151252180338 train_error 47.25% test_error 51.00%\n",
      "================================603===================================\n",
      "603/10000: train_loss: 4.047147390693427 train_error 47.25% test_error 51.00%\n",
      "================================604===================================\n",
      "604/10000: train_loss: 4.047143673747778 train_error 47.25% test_error 51.00%\n",
      "================================605===================================\n",
      "605/10000: train_loss: 4.047140013724565 train_error 47.25% test_error 51.00%\n",
      "================================606===================================\n",
      "606/10000: train_loss: 4.047136468887329 train_error 47.25% test_error 51.00%\n",
      "================================607===================================\n",
      "607/10000: train_loss: 4.047132997959852 train_error 47.25% test_error 51.00%\n",
      "================================608===================================\n",
      "608/10000: train_loss: 4.047129624933005 train_error 47.25% test_error 51.00%\n",
      "================================609===================================\n",
      "609/10000: train_loss: 4.047126349657773 train_error 47.25% test_error 51.00%\n",
      "================================610===================================\n",
      "610/10000: train_loss: 4.047123190462589 train_error 47.25% test_error 51.00%\n",
      "================================611===================================\n",
      "611/10000: train_loss: 4.0471201094985005 train_error 47.25% test_error 51.00%\n",
      "================================612===================================\n",
      "612/10000: train_loss: 4.047117120325566 train_error 47.25% test_error 51.00%\n",
      "================================613===================================\n",
      "613/10000: train_loss: 4.047114263921976 train_error 47.25% test_error 51.00%\n",
      "================================614===================================\n",
      "614/10000: train_loss: 4.047111539840698 train_error 47.25% test_error 51.00%\n",
      "================================615===================================\n",
      "615/10000: train_loss: 4.0471089324355125 train_error 47.25% test_error 51.00%\n",
      "================================616===================================\n",
      "616/10000: train_loss: 4.047106390744448 train_error 47.25% test_error 51.00%\n",
      "================================617===================================\n",
      "617/10000: train_loss: 4.047103939801454 train_error 47.25% test_error 51.00%\n",
      "================================618===================================\n",
      "618/10000: train_loss: 4.047101590931415 train_error 47.25% test_error 51.00%\n",
      "================================619===================================\n",
      "619/10000: train_loss: 4.047099340707064 train_error 47.25% test_error 51.00%\n",
      "================================620===================================\n",
      "620/10000: train_loss: 4.047097193300724 train_error 47.25% test_error 51.00%\n",
      "================================621===================================\n",
      "621/10000: train_loss: 4.04709513515234 train_error 47.25% test_error 51.00%\n",
      "================================622===================================\n",
      "622/10000: train_loss: 4.047093180865049 train_error 47.25% test_error 51.00%\n",
      "================================623===================================\n",
      "623/10000: train_loss: 4.0470912955701355 train_error 47.25% test_error 51.00%\n",
      "================================624===================================\n",
      "624/10000: train_loss: 4.047089519649744 train_error 47.25% test_error 51.00%\n",
      "================================625===================================\n",
      "625/10000: train_loss: 4.04708782017231 train_error 47.25% test_error 51.00%\n",
      "================================626===================================\n",
      "626/10000: train_loss: 4.04708622187376 train_error 47.25% test_error 51.00%\n",
      "================================627===================================\n",
      "627/10000: train_loss: 4.047084776014089 train_error 47.25% test_error 51.00%\n",
      "================================628===================================\n",
      "628/10000: train_loss: 4.047083442807198 train_error 47.25% test_error 51.00%\n",
      "================================629===================================\n",
      "629/10000: train_loss: 4.047082219719886 train_error 47.25% test_error 51.00%\n",
      "================================630===================================\n",
      "630/10000: train_loss: 4.047081089764833 train_error 47.25% test_error 51.00%\n",
      "================================631===================================\n",
      "631/10000: train_loss: 4.04708006054163 train_error 47.25% test_error 51.00%\n",
      "================================632===================================\n",
      "632/10000: train_loss: 4.047079093307256 train_error 47.25% test_error 51.00%\n",
      "================================633===================================\n",
      "633/10000: train_loss: 4.0470782536268235 train_error 47.25% test_error 51.00%\n",
      "================================634===================================\n",
      "634/10000: train_loss: 4.0470774877071385 train_error 47.25% test_error 51.00%\n",
      "================================635===================================\n",
      "635/10000: train_loss: 4.047076829969883 train_error 47.25% test_error 51.00%\n",
      "================================636===================================\n",
      "636/10000: train_loss: 4.047076232433319 train_error 47.25% test_error 51.00%\n",
      "================================637===================================\n",
      "637/10000: train_loss: 4.047075785845518 train_error 47.25% test_error 51.00%\n",
      "================================638===================================\n",
      "638/10000: train_loss: 4.047075399458408 train_error 47.25% test_error 51.00%\n",
      "================================639===================================\n",
      "639/10000: train_loss: 4.047075113356113 train_error 47.25% test_error 51.00%\n",
      "================================640===================================\n",
      "640/10000: train_loss: 4.0470749112963675 train_error 47.25% test_error 51.00%\n",
      "================================641===================================\n",
      "641/10000: train_loss: 4.047074864208699 train_error 47.25% test_error 51.00%\n",
      "================================642===================================\n",
      "642/10000: train_loss: 4.0470748987793925 train_error 47.25% test_error 51.00%\n",
      "================================643===================================\n",
      "643/10000: train_loss: 4.047075016498566 train_error 47.25% test_error 51.00%\n",
      "================================644===================================\n",
      "644/10000: train_loss: 4.047075197547674 train_error 47.25% test_error 51.00%\n",
      "================================645===================================\n",
      "645/10000: train_loss: 4.0470754301548 train_error 47.25% test_error 51.00%\n",
      "================================646===================================\n",
      "646/10000: train_loss: 4.0470756927132605 train_error 47.25% test_error 51.00%\n",
      "================================647===================================\n",
      "647/10000: train_loss: 4.0470759686827655 train_error 47.25% test_error 51.00%\n",
      "================================648===================================\n",
      "648/10000: train_loss: 4.047076270282268 train_error 47.25% test_error 51.00%\n",
      "================================649===================================\n",
      "649/10000: train_loss: 4.047076656520367 train_error 47.25% test_error 51.00%\n",
      "================================650===================================\n",
      "650/10000: train_loss: 4.047077185958624 train_error 47.25% test_error 51.00%\n",
      "================================651===================================\n",
      "651/10000: train_loss: 4.047077855765819 train_error 47.25% test_error 51.00%\n",
      "================================652===================================\n",
      "652/10000: train_loss: 4.047078591734171 train_error 47.25% test_error 51.00%\n",
      "================================653===================================\n",
      "653/10000: train_loss: 4.047079386562109 train_error 47.25% test_error 51.00%\n",
      "================================654===================================\n",
      "654/10000: train_loss: 4.047080292701722 train_error 47.25% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================655===================================\n",
      "655/10000: train_loss: 4.047081264257431 train_error 47.25% test_error 51.00%\n",
      "================================656===================================\n",
      "656/10000: train_loss: 4.047082354277372 train_error 47.25% test_error 51.00%\n",
      "================================657===================================\n",
      "657/10000: train_loss: 4.047083503007888 train_error 47.25% test_error 51.00%\n",
      "================================658===================================\n",
      "658/10000: train_loss: 4.04708474457264 train_error 47.25% test_error 51.00%\n",
      "================================659===================================\n",
      "659/10000: train_loss: 4.047086026519537 train_error 47.25% test_error 51.00%\n",
      "================================660===================================\n",
      "660/10000: train_loss: 4.047087395638227 train_error 47.25% test_error 51.00%\n",
      "================================661===================================\n",
      "661/10000: train_loss: 4.04708885639906 train_error 47.25% test_error 51.00%\n",
      "================================662===================================\n",
      "662/10000: train_loss: 4.047090377807617 train_error 47.25% test_error 51.00%\n",
      "================================663===================================\n",
      "663/10000: train_loss: 4.047091973274947 train_error 47.25% test_error 51.00%\n",
      "================================664===================================\n",
      "664/10000: train_loss: 4.047093646079302 train_error 47.25% test_error 51.00%\n",
      "================================665===================================\n",
      "665/10000: train_loss: 4.047095410376787 train_error 47.25% test_error 51.00%\n",
      "================================666===================================\n",
      "666/10000: train_loss: 4.047097321599722 train_error 47.25% test_error 51.00%\n",
      "================================667===================================\n",
      "667/10000: train_loss: 4.047099267244339 train_error 47.25% test_error 51.00%\n",
      "================================668===================================\n",
      "668/10000: train_loss: 4.047101285457611 train_error 47.25% test_error 51.00%\n",
      "================================669===================================\n",
      "669/10000: train_loss: 4.04710337921977 train_error 47.25% test_error 51.00%\n",
      "================================670===================================\n",
      "670/10000: train_loss: 4.047105548083782 train_error 47.25% test_error 51.00%\n",
      "================================671===================================\n",
      "671/10000: train_loss: 4.047107767611742 train_error 47.25% test_error 51.00%\n",
      "================================672===================================\n",
      "672/10000: train_loss: 4.047110051512718 train_error 47.25% test_error 51.00%\n",
      "================================673===================================\n",
      "673/10000: train_loss: 4.047112422436475 train_error 47.25% test_error 51.00%\n",
      "================================674===================================\n",
      "674/10000: train_loss: 4.047114870101213 train_error 47.25% test_error 51.00%\n",
      "================================675===================================\n",
      "675/10000: train_loss: 4.047117398828267 train_error 47.25% test_error 51.00%\n",
      "================================676===================================\n",
      "676/10000: train_loss: 4.047119989991188 train_error 47.25% test_error 51.00%\n",
      "================================677===================================\n",
      "677/10000: train_loss: 4.047122656255961 train_error 47.25% test_error 51.00%\n",
      "================================678===================================\n",
      "678/10000: train_loss: 4.0471254703402515 train_error 47.25% test_error 51.00%\n",
      "================================679===================================\n",
      "679/10000: train_loss: 4.047128360271454 train_error 47.38% test_error 51.00%\n",
      "================================680===================================\n",
      "680/10000: train_loss: 4.0471313317120075 train_error 47.38% test_error 51.00%\n",
      "================================681===================================\n",
      "681/10000: train_loss: 4.047134293168783 train_error 47.38% test_error 51.00%\n",
      "================================682===================================\n",
      "682/10000: train_loss: 4.047137274742127 train_error 47.38% test_error 51.00%\n",
      "================================683===================================\n",
      "683/10000: train_loss: 4.047140344530344 train_error 47.38% test_error 51.00%\n",
      "================================684===================================\n",
      "684/10000: train_loss: 4.047143480926752 train_error 47.38% test_error 51.00%\n",
      "================================685===================================\n",
      "685/10000: train_loss: 4.047146688997746 train_error 47.38% test_error 51.00%\n",
      "================================686===================================\n",
      "686/10000: train_loss: 4.047149958908558 train_error 47.38% test_error 51.00%\n",
      "================================687===================================\n",
      "687/10000: train_loss: 4.047153319120407 train_error 47.38% test_error 51.00%\n",
      "================================688===================================\n",
      "688/10000: train_loss: 4.047156731635332 train_error 47.38% test_error 51.00%\n",
      "================================689===================================\n",
      "689/10000: train_loss: 4.047160213291645 train_error 47.38% test_error 51.00%\n",
      "================================690===================================\n",
      "690/10000: train_loss: 4.0471637669205665 train_error 47.38% test_error 51.00%\n",
      "================================691===================================\n",
      "691/10000: train_loss: 4.047167391628027 train_error 47.38% test_error 51.00%\n",
      "================================692===================================\n",
      "692/10000: train_loss: 4.047171099632979 train_error 47.38% test_error 51.00%\n",
      "================================693===================================\n",
      "693/10000: train_loss: 4.047174847275019 train_error 47.38% test_error 51.00%\n",
      "================================694===================================\n",
      "694/10000: train_loss: 4.0471786826848986 train_error 47.38% test_error 51.00%\n",
      "================================695===================================\n",
      "695/10000: train_loss: 4.04718256905675 train_error 47.38% test_error 51.00%\n",
      "================================696===================================\n",
      "696/10000: train_loss: 4.04718651369214 train_error 47.38% test_error 51.00%\n",
      "================================697===================================\n",
      "697/10000: train_loss: 4.047190531939268 train_error 47.38% test_error 51.00%\n",
      "================================698===================================\n",
      "698/10000: train_loss: 4.047194623500108 train_error 47.38% test_error 51.00%\n",
      "================================699===================================\n",
      "699/10000: train_loss: 4.047198833525181 train_error 47.38% test_error 51.00%\n",
      "================================700===================================\n",
      "700/10000: train_loss: 4.047203133404254 train_error 47.38% test_error 51.00%\n",
      "================================701===================================\n",
      "701/10000: train_loss: 4.047207509577275 train_error 47.38% test_error 51.00%\n",
      "================================702===================================\n",
      "702/10000: train_loss: 4.04721191123128 train_error 47.38% test_error 51.00%\n",
      "================================703===================================\n",
      "703/10000: train_loss: 4.047216390669346 train_error 47.38% test_error 51.00%\n",
      "================================704===================================\n",
      "704/10000: train_loss: 4.04722092434764 train_error 47.38% test_error 51.00%\n",
      "================================705===================================\n",
      "705/10000: train_loss: 4.047225536555052 train_error 47.38% test_error 51.00%\n",
      "================================706===================================\n",
      "706/10000: train_loss: 4.047230219244957 train_error 47.38% test_error 51.00%\n",
      "================================707===================================\n",
      "707/10000: train_loss: 4.047234964966774 train_error 47.38% test_error 51.00%\n",
      "================================708===================================\n",
      "708/10000: train_loss: 4.047239776849747 train_error 47.38% test_error 51.00%\n",
      "================================709===================================\n",
      "709/10000: train_loss: 4.047244620919228 train_error 47.38% test_error 51.00%\n",
      "================================710===================================\n",
      "710/10000: train_loss: 4.047249543964863 train_error 47.38% test_error 51.00%\n",
      "================================711===================================\n",
      "711/10000: train_loss: 4.047254532426596 train_error 47.38% test_error 51.00%\n",
      "================================712===================================\n",
      "712/10000: train_loss: 4.04725956812501 train_error 47.38% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================713===================================\n",
      "713/10000: train_loss: 4.047264680564403 train_error 47.38% test_error 51.00%\n",
      "================================714===================================\n",
      "714/10000: train_loss: 4.047269877046347 train_error 47.38% test_error 51.00%\n",
      "================================715===================================\n",
      "715/10000: train_loss: 4.047275127917528 train_error 47.38% test_error 51.00%\n",
      "================================716===================================\n",
      "716/10000: train_loss: 4.047280435711145 train_error 47.38% test_error 51.00%\n",
      "================================717===================================\n",
      "717/10000: train_loss: 4.047285742163658 train_error 47.38% test_error 51.00%\n",
      "================================718===================================\n",
      "718/10000: train_loss: 4.047291123718024 train_error 47.38% test_error 51.00%\n",
      "================================719===================================\n",
      "719/10000: train_loss: 4.0472965596616275 train_error 47.38% test_error 51.00%\n",
      "================================720===================================\n",
      "720/10000: train_loss: 4.047302053570747 train_error 47.38% test_error 51.00%\n",
      "================================721===================================\n",
      "721/10000: train_loss: 4.047307609021663 train_error 47.38% test_error 51.00%\n",
      "================================722===================================\n",
      "722/10000: train_loss: 4.047313209325075 train_error 47.38% test_error 51.00%\n",
      "================================723===================================\n",
      "723/10000: train_loss: 4.047318891435862 train_error 47.38% test_error 51.00%\n",
      "================================724===================================\n",
      "724/10000: train_loss: 4.047324634194374 train_error 47.38% test_error 51.00%\n",
      "================================725===================================\n",
      "725/10000: train_loss: 4.047330396324396 train_error 47.38% test_error 51.00%\n",
      "================================726===================================\n",
      "726/10000: train_loss: 4.047336170822382 train_error 47.38% test_error 51.00%\n",
      "================================727===================================\n",
      "727/10000: train_loss: 4.047342008501292 train_error 47.38% test_error 51.00%\n",
      "================================728===================================\n",
      "728/10000: train_loss: 4.047347922176122 train_error 47.38% test_error 51.00%\n",
      "================================729===================================\n",
      "729/10000: train_loss: 4.047353943437338 train_error 47.38% test_error 51.00%\n",
      "================================730===================================\n",
      "730/10000: train_loss: 4.04736004114151 train_error 47.38% test_error 51.00%\n",
      "================================731===================================\n",
      "731/10000: train_loss: 4.047366209328175 train_error 47.38% test_error 51.00%\n",
      "================================732===================================\n",
      "732/10000: train_loss: 4.04737242475152 train_error 47.38% test_error 51.00%\n",
      "================================733===================================\n",
      "733/10000: train_loss: 4.04737870901823 train_error 47.38% test_error 51.00%\n",
      "================================734===================================\n",
      "734/10000: train_loss: 4.047385041713715 train_error 47.38% test_error 51.00%\n",
      "================================735===================================\n",
      "735/10000: train_loss: 4.047391413003206 train_error 47.38% test_error 51.00%\n",
      "================================736===================================\n",
      "736/10000: train_loss: 4.047397827208043 train_error 47.38% test_error 51.00%\n",
      "================================737===================================\n",
      "737/10000: train_loss: 4.047404313534498 train_error 47.38% test_error 51.00%\n",
      "================================738===================================\n",
      "738/10000: train_loss: 4.047410830408335 train_error 47.38% test_error 51.00%\n",
      "================================739===================================\n",
      "739/10000: train_loss: 4.047417403608561 train_error 47.38% test_error 51.00%\n",
      "================================740===================================\n",
      "740/10000: train_loss: 4.047424031496048 train_error 47.38% test_error 51.00%\n",
      "================================741===================================\n",
      "741/10000: train_loss: 4.047430712133647 train_error 47.38% test_error 51.00%\n",
      "================================742===================================\n",
      "742/10000: train_loss: 4.0474374419450765 train_error 47.38% test_error 51.00%\n",
      "================================743===================================\n",
      "743/10000: train_loss: 4.047444217354059 train_error 47.38% test_error 51.00%\n",
      "================================744===================================\n",
      "744/10000: train_loss: 4.047451058328152 train_error 47.38% test_error 51.00%\n",
      "================================745===================================\n",
      "745/10000: train_loss: 4.047457930892706 train_error 47.38% test_error 51.00%\n",
      "================================746===================================\n",
      "746/10000: train_loss: 4.047464826852083 train_error 47.38% test_error 51.00%\n",
      "================================747===================================\n",
      "747/10000: train_loss: 4.047471700906754 train_error 47.38% test_error 51.00%\n",
      "================================748===================================\n",
      "748/10000: train_loss: 4.047478647381067 train_error 47.38% test_error 51.00%\n",
      "================================749===================================\n",
      "749/10000: train_loss: 4.047485644072294 train_error 47.38% test_error 51.00%\n",
      "================================750===================================\n",
      "750/10000: train_loss: 4.047492675632238 train_error 47.38% test_error 51.00%\n",
      "================================751===================================\n",
      "751/10000: train_loss: 4.047499758303165 train_error 47.38% test_error 51.00%\n",
      "================================752===================================\n",
      "752/10000: train_loss: 4.047506896108389 train_error 47.38% test_error 51.00%\n",
      "================================753===================================\n",
      "753/10000: train_loss: 4.047514100819827 train_error 47.38% test_error 51.00%\n",
      "================================754===================================\n",
      "754/10000: train_loss: 4.047521343380213 train_error 47.50% test_error 51.00%\n",
      "================================755===================================\n",
      "755/10000: train_loss: 4.0475286507606505 train_error 47.50% test_error 51.00%\n",
      "================================756===================================\n",
      "756/10000: train_loss: 4.047536017745733 train_error 47.50% test_error 51.00%\n",
      "================================757===================================\n",
      "757/10000: train_loss: 4.047543427944183 train_error 47.50% test_error 51.00%\n",
      "================================758===================================\n",
      "758/10000: train_loss: 4.047550909072161 train_error 47.50% test_error 51.00%\n",
      "================================759===================================\n",
      "759/10000: train_loss: 4.047558417469263 train_error 47.50% test_error 51.00%\n",
      "================================760===================================\n",
      "760/10000: train_loss: 4.047565913945436 train_error 47.50% test_error 51.00%\n",
      "================================761===================================\n",
      "761/10000: train_loss: 4.047573439329863 train_error 47.50% test_error 51.00%\n",
      "================================762===================================\n",
      "762/10000: train_loss: 4.047580940872431 train_error 47.50% test_error 51.00%\n",
      "================================763===================================\n",
      "763/10000: train_loss: 4.0475884577631955 train_error 47.50% test_error 51.00%\n",
      "================================764===================================\n",
      "764/10000: train_loss: 4.047596037834882 train_error 47.50% test_error 51.00%\n",
      "================================765===================================\n",
      "765/10000: train_loss: 4.04760366037488 train_error 47.50% test_error 51.00%\n",
      "================================766===================================\n",
      "766/10000: train_loss: 4.047611327022314 train_error 47.50% test_error 51.00%\n",
      "================================767===================================\n",
      "767/10000: train_loss: 4.047619028836489 train_error 47.50% test_error 51.00%\n",
      "================================768===================================\n",
      "768/10000: train_loss: 4.047626787871122 train_error 47.50% test_error 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================769===================================\n",
      "769/10000: train_loss: 4.047634604424238 train_error 47.50% test_error 51.00%\n",
      "================================770===================================\n",
      "770/10000: train_loss: 4.0476424738764765 train_error 47.50% test_error 51.00%\n",
      "================================771===================================\n",
      "771/10000: train_loss: 4.047650378644467 train_error 47.50% test_error 51.00%\n",
      "================================772===================================\n",
      "772/10000: train_loss: 4.047658340632916 train_error 47.50% test_error 51.00%\n",
      "================================773===================================\n",
      "773/10000: train_loss: 4.047666362226009 train_error 47.50% test_error 51.00%\n",
      "================================774===================================\n",
      "774/10000: train_loss: 4.047674412578344 train_error 47.50% test_error 51.00%\n",
      "================================775===================================\n",
      "775/10000: train_loss: 4.047682532519103 train_error 47.50% test_error 51.00%\n",
      "================================776===================================\n",
      "776/10000: train_loss: 4.047690681219101 train_error 47.50% test_error 51.00%\n",
      "================================777===================================\n",
      "777/10000: train_loss: 4.047698949277401 train_error 47.50% test_error 51.00%\n",
      "================================778===================================\n",
      "778/10000: train_loss: 4.047707252204418 train_error 47.50% test_error 51.00%\n",
      "================================779===================================\n",
      "779/10000: train_loss: 4.0477156363427635 train_error 47.50% test_error 51.00%\n",
      "================================780===================================\n",
      "780/10000: train_loss: 4.047724055498838 train_error 47.50% test_error 51.00%\n",
      "================================781===================================\n",
      "781/10000: train_loss: 4.04773252800107 train_error 47.50% test_error 51.00%\n",
      "================================782===================================\n",
      "782/10000: train_loss: 4.047741052657365 train_error 47.50% test_error 51.00%\n",
      "================================783===================================\n",
      "783/10000: train_loss: 4.047749617397785 train_error 47.50% test_error 51.00%\n",
      "================================784===================================\n",
      "784/10000: train_loss: 4.047758211791515 train_error 47.50% test_error 51.00%\n",
      "================================785===================================\n",
      "785/10000: train_loss: 4.0477668786048895 train_error 47.50% test_error 51.00%\n",
      "================================786===================================\n",
      "786/10000: train_loss: 4.047775569558143 train_error 47.50% test_error 51.00%\n",
      "================================787===================================\n",
      "787/10000: train_loss: 4.047784296572209 train_error 47.50% test_error 51.00%\n",
      "================================788===================================\n",
      "788/10000: train_loss: 4.04779305383563 train_error 47.50% test_error 51.00%\n",
      "================================789===================================\n",
      "789/10000: train_loss: 4.0478018766641615 train_error 47.50% test_error 51.00%\n",
      "================================790===================================\n",
      "790/10000: train_loss: 4.047810738533736 train_error 47.50% test_error 51.00%\n",
      "================================791===================================\n",
      "791/10000: train_loss: 4.047819641232491 train_error 47.50% test_error 51.00%\n",
      "================================792===================================\n",
      "792/10000: train_loss: 4.04782853141427 train_error 47.50% test_error 51.00%\n",
      "================================793===================================\n",
      "793/10000: train_loss: 4.0478374586999415 train_error 47.50% test_error 51.00%\n",
      "================================794===================================\n",
      "794/10000: train_loss: 4.047846442908049 train_error 47.50% test_error 51.00%\n",
      "================================795===================================\n",
      "795/10000: train_loss: 4.047855463027954 train_error 47.50% test_error 51.00%\n",
      "================================796===================================\n",
      "796/10000: train_loss: 4.047864515185356 train_error 47.50% test_error 51.00%\n",
      "================================797===================================\n",
      "797/10000: train_loss: 4.047873607128858 train_error 47.50% test_error 51.00%\n",
      "================================798===================================\n",
      "798/10000: train_loss: 4.0478827558457855 train_error 47.50% test_error 51.00%\n",
      "================================799===================================\n",
      "799/10000: train_loss: 4.047891936600208 train_error 47.50% test_error 51.00%\n",
      "================================800===================================\n",
      "800/10000: train_loss: 4.047901155501604 train_error 47.50% test_error 51.00%\n",
      "================================801===================================\n",
      "801/10000: train_loss: 4.047910367846489 train_error 47.50% test_error 51.00%\n",
      "================================802===================================\n",
      "802/10000: train_loss: 4.047919581979513 train_error 47.50% test_error 51.00%\n",
      "================================803===================================\n",
      "803/10000: train_loss: 4.047928810864687 train_error 47.50% test_error 51.00%\n",
      "================================804===================================\n",
      "804/10000: train_loss: 4.047938101440669 train_error 47.50% test_error 51.00%\n",
      "================================805===================================\n",
      "805/10000: train_loss: 4.047947404980659 train_error 47.50% test_error 51.00%\n",
      "================================806===================================\n",
      "806/10000: train_loss: 4.04795677497983 train_error 47.50% test_error 51.00%\n",
      "================================807===================================\n",
      "807/10000: train_loss: 4.0479662024974825 train_error 47.50% test_error 51.00%\n",
      "================================808===================================\n",
      "808/10000: train_loss: 4.047975661605596 train_error 47.50% test_error 51.00%\n",
      "================================809===================================\n",
      "809/10000: train_loss: 4.047985146194696 train_error 47.50% test_error 51.00%\n",
      "================================810===================================\n",
      "810/10000: train_loss: 4.047994686216116 train_error 47.50% test_error 51.00%\n",
      "================================811===================================\n",
      "811/10000: train_loss: 4.048004268556833 train_error 47.50% test_error 51.00%\n",
      "================================812===================================\n",
      "812/10000: train_loss: 4.048013882040977 train_error 47.50% test_error 51.00%\n",
      "================================813===================================\n",
      "813/10000: train_loss: 4.048023504316807 train_error 47.50% test_error 51.00%\n",
      "================================814===================================\n",
      "814/10000: train_loss: 4.048033156841994 train_error 47.50% test_error 51.00%\n",
      "================================815===================================\n",
      "815/10000: train_loss: 4.048042877614498 train_error 47.50% test_error 51.50%\n",
      "================================816===================================\n",
      "816/10000: train_loss: 4.048052636235952 train_error 47.50% test_error 51.50%\n",
      "================================817===================================\n",
      "817/10000: train_loss: 4.0480624184012415 train_error 47.50% test_error 51.50%\n",
      "================================818===================================\n",
      "818/10000: train_loss: 4.0480722376704215 train_error 47.50% test_error 51.50%\n",
      "================================819===================================\n",
      "819/10000: train_loss: 4.04808210849762 train_error 47.50% test_error 51.50%\n",
      "================================820===================================\n",
      "820/10000: train_loss: 4.048092010170221 train_error 47.50% test_error 51.50%\n",
      "================================821===================================\n",
      "821/10000: train_loss: 4.048101934045553 train_error 47.50% test_error 51.50%\n",
      "================================822===================================\n",
      "822/10000: train_loss: 4.048111956417561 train_error 47.50% test_error 51.50%\n",
      "================================823===================================\n",
      "823/10000: train_loss: 4.048121986240149 train_error 47.50% test_error 51.50%\n",
      "================================824===================================\n",
      "824/10000: train_loss: 4.048132063299418 train_error 47.50% test_error 51.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================825===================================\n",
      "825/10000: train_loss: 4.04814218133688 train_error 47.50% test_error 51.50%\n",
      "================================826===================================\n",
      "826/10000: train_loss: 4.0481523881852635 train_error 47.50% test_error 51.50%\n",
      "================================827===================================\n",
      "827/10000: train_loss: 4.048162631541491 train_error 47.50% test_error 51.50%\n",
      "================================828===================================\n",
      "828/10000: train_loss: 4.048172951936722 train_error 47.50% test_error 51.50%\n",
      "================================829===================================\n",
      "829/10000: train_loss: 4.048183352053165 train_error 47.50% test_error 51.50%\n",
      "================================830===================================\n",
      "830/10000: train_loss: 4.048193805813789 train_error 47.50% test_error 51.50%\n",
      "================================831===================================\n",
      "831/10000: train_loss: 4.048204385936261 train_error 47.50% test_error 51.50%\n",
      "================================832===================================\n",
      "832/10000: train_loss: 4.048215002417565 train_error 47.50% test_error 51.50%\n",
      "================================833===================================\n",
      "833/10000: train_loss: 4.048225653767586 train_error 47.50% test_error 51.50%\n",
      "================================834===================================\n",
      "834/10000: train_loss: 4.048236287981272 train_error 47.50% test_error 51.50%\n",
      "================================835===================================\n",
      "835/10000: train_loss: 4.0482469700276855 train_error 47.50% test_error 51.50%\n",
      "================================836===================================\n",
      "836/10000: train_loss: 4.0482576897740365 train_error 47.50% test_error 51.50%\n",
      "================================837===================================\n",
      "837/10000: train_loss: 4.04826845318079 train_error 47.50% test_error 51.50%\n",
      "================================838===================================\n",
      "838/10000: train_loss: 4.048279250115156 train_error 47.50% test_error 51.50%\n",
      "================================839===================================\n",
      "839/10000: train_loss: 4.0482900738716125 train_error 47.50% test_error 51.50%\n",
      "================================840===================================\n",
      "840/10000: train_loss: 4.048300921618939 train_error 47.50% test_error 51.50%\n",
      "================================841===================================\n",
      "841/10000: train_loss: 4.048311823159456 train_error 47.50% test_error 51.50%\n",
      "================================842===================================\n",
      "842/10000: train_loss: 4.048322730511427 train_error 47.50% test_error 51.50%\n",
      "================================843===================================\n",
      "843/10000: train_loss: 4.048333641439676 train_error 47.50% test_error 51.50%\n",
      "================================844===================================\n",
      "844/10000: train_loss: 4.048344592154026 train_error 47.50% test_error 51.50%\n",
      "================================845===================================\n",
      "845/10000: train_loss: 4.048355582654476 train_error 47.50% test_error 51.50%\n",
      "================================846===================================\n",
      "846/10000: train_loss: 4.048366591781378 train_error 47.50% test_error 51.50%\n",
      "================================847===================================\n",
      "847/10000: train_loss: 4.048377657234669 train_error 47.50% test_error 51.50%\n",
      "================================848===================================\n",
      "848/10000: train_loss: 4.0483887343108655 train_error 47.50% test_error 51.50%\n",
      "================================849===================================\n",
      "849/10000: train_loss: 4.048399859815836 train_error 47.50% test_error 51.50%\n",
      "================================850===================================\n",
      "850/10000: train_loss: 4.0484110267460345 train_error 47.50% test_error 52.00%\n",
      "================================851===================================\n",
      "851/10000: train_loss: 4.04842222943902 train_error 47.50% test_error 52.00%\n",
      "================================852===================================\n",
      "852/10000: train_loss: 4.0484334939718245 train_error 47.50% test_error 52.00%\n",
      "================================853===================================\n",
      "853/10000: train_loss: 4.0484448075294495 train_error 47.50% test_error 52.00%\n",
      "================================854===================================\n",
      "854/10000: train_loss: 4.048456183671951 train_error 47.50% test_error 52.00%\n",
      "================================855===================================\n",
      "855/10000: train_loss: 4.048467579632998 train_error 47.50% test_error 52.00%\n",
      "================================856===================================\n",
      "856/10000: train_loss: 4.048478975147009 train_error 47.50% test_error 52.00%\n",
      "================================857===================================\n",
      "857/10000: train_loss: 4.048490409255028 train_error 47.50% test_error 52.00%\n",
      "================================858===================================\n",
      "858/10000: train_loss: 4.048501822054385 train_error 47.50% test_error 52.00%\n",
      "================================859===================================\n",
      "859/10000: train_loss: 4.04851329177618 train_error 47.50% test_error 52.00%\n",
      "================================860===================================\n",
      "860/10000: train_loss: 4.048524746745825 train_error 47.50% test_error 52.00%\n",
      "================================861===================================\n",
      "861/10000: train_loss: 4.0485362283885475 train_error 47.50% test_error 52.00%\n",
      "================================862===================================\n",
      "862/10000: train_loss: 4.048547759354115 train_error 47.50% test_error 52.00%\n",
      "================================863===================================\n",
      "863/10000: train_loss: 4.048559381961822 train_error 47.50% test_error 52.00%\n",
      "================================864===================================\n",
      "864/10000: train_loss: 4.048571064025164 train_error 47.50% test_error 52.00%\n",
      "================================865===================================\n",
      "865/10000: train_loss: 4.048582722395659 train_error 47.50% test_error 52.00%\n",
      "================================866===================================\n",
      "866/10000: train_loss: 4.048594433367253 train_error 47.50% test_error 52.00%\n",
      "================================867===================================\n",
      "867/10000: train_loss: 4.048606187701225 train_error 47.50% test_error 52.00%\n",
      "================================868===================================\n",
      "868/10000: train_loss: 4.048618024587631 train_error 47.50% test_error 52.00%\n",
      "================================869===================================\n",
      "869/10000: train_loss: 4.048629888445139 train_error 47.50% test_error 52.00%\n",
      "================================870===================================\n",
      "870/10000: train_loss: 4.0486417858302595 train_error 47.50% test_error 52.00%\n",
      "================================871===================================\n",
      "871/10000: train_loss: 4.0486537024378775 train_error 47.50% test_error 52.00%\n",
      "================================872===================================\n",
      "872/10000: train_loss: 4.048665645271539 train_error 47.50% test_error 52.00%\n",
      "================================873===================================\n",
      "873/10000: train_loss: 4.048677628785372 train_error 47.50% test_error 52.00%\n",
      "================================874===================================\n",
      "874/10000: train_loss: 4.048689656555652 train_error 47.50% test_error 52.00%\n",
      "================================875===================================\n",
      "875/10000: train_loss: 4.048701712638139 train_error 47.50% test_error 52.00%\n",
      "================================876===================================\n",
      "876/10000: train_loss: 4.0487137794494625 train_error 47.62% test_error 52.00%\n",
      "================================877===================================\n",
      "877/10000: train_loss: 4.0487258777022355 train_error 47.62% test_error 52.00%\n",
      "================================878===================================\n",
      "878/10000: train_loss: 4.048738011270761 train_error 47.62% test_error 52.00%\n",
      "================================879===================================\n",
      "879/10000: train_loss: 4.048750168383122 train_error 47.62% test_error 52.00%\n",
      "================================880===================================\n",
      "880/10000: train_loss: 4.048762369304896 train_error 47.62% test_error 52.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================881===================================\n",
      "881/10000: train_loss: 4.048774582892657 train_error 47.62% test_error 52.00%\n",
      "================================882===================================\n",
      "882/10000: train_loss: 4.048786772489548 train_error 47.62% test_error 52.00%\n",
      "================================883===================================\n",
      "883/10000: train_loss: 4.048798959553242 train_error 47.62% test_error 52.00%\n",
      "================================884===================================\n",
      "884/10000: train_loss: 4.04881115347147 train_error 47.62% test_error 52.00%\n",
      "================================885===================================\n",
      "885/10000: train_loss: 4.048823368400335 train_error 47.62% test_error 52.00%\n",
      "================================886===================================\n",
      "886/10000: train_loss: 4.0488356140255926 train_error 47.62% test_error 52.00%\n",
      "================================887===================================\n",
      "887/10000: train_loss: 4.048847894221544 train_error 47.62% test_error 52.00%\n",
      "================================888===================================\n",
      "888/10000: train_loss: 4.048860202431679 train_error 47.62% test_error 52.00%\n",
      "================================889===================================\n",
      "889/10000: train_loss: 4.0488725402951244 train_error 47.62% test_error 52.00%\n",
      "================================890===================================\n",
      "890/10000: train_loss: 4.048884905129672 train_error 47.62% test_error 52.00%\n",
      "================================891===================================\n",
      "891/10000: train_loss: 4.048897318392992 train_error 47.62% test_error 52.00%\n",
      "================================892===================================\n",
      "892/10000: train_loss: 4.048909761756659 train_error 47.62% test_error 52.00%\n",
      "================================893===================================\n",
      "893/10000: train_loss: 4.048922245502472 train_error 47.62% test_error 52.50%\n",
      "================================894===================================\n",
      "894/10000: train_loss: 4.048934756219387 train_error 47.62% test_error 52.50%\n",
      "================================895===================================\n",
      "895/10000: train_loss: 4.048947291970253 train_error 47.62% test_error 52.50%\n",
      "================================896===================================\n",
      "896/10000: train_loss: 4.04895983427763 train_error 47.62% test_error 52.50%\n",
      "================================897===================================\n",
      "897/10000: train_loss: 4.048972264826298 train_error 47.62% test_error 52.50%\n",
      "================================898===================================\n",
      "898/10000: train_loss: 4.048984755277633 train_error 47.62% test_error 52.50%\n",
      "================================899===================================\n",
      "899/10000: train_loss: 4.048997254669667 train_error 47.62% test_error 52.50%\n",
      "================================900===================================\n",
      "900/10000: train_loss: 4.049009806662798 train_error 47.75% test_error 52.50%\n",
      "================================901===================================\n",
      "901/10000: train_loss: 4.049022360295057 train_error 47.75% test_error 52.50%\n",
      "================================902===================================\n",
      "902/10000: train_loss: 4.049034976959229 train_error 47.75% test_error 52.50%\n",
      "================================903===================================\n",
      "903/10000: train_loss: 4.049047588855029 train_error 47.75% test_error 52.50%\n",
      "================================904===================================\n",
      "904/10000: train_loss: 4.049060249477625 train_error 47.88% test_error 52.50%\n",
      "================================905===================================\n",
      "905/10000: train_loss: 4.049072928279639 train_error 47.88% test_error 52.50%\n",
      "================================906===================================\n",
      "906/10000: train_loss: 4.049085615873337 train_error 47.88% test_error 53.00%\n",
      "================================907===================================\n",
      "907/10000: train_loss: 4.0490983714163304 train_error 47.88% test_error 53.00%\n",
      "================================908===================================\n",
      "908/10000: train_loss: 4.04911109790206 train_error 47.88% test_error 53.00%\n",
      "================================909===================================\n",
      "909/10000: train_loss: 4.049123790860176 train_error 47.88% test_error 53.00%\n",
      "================================910===================================\n",
      "910/10000: train_loss: 4.049136408865452 train_error 48.00% test_error 53.00%\n",
      "================================911===================================\n",
      "911/10000: train_loss: 4.049149094074965 train_error 48.12% test_error 53.00%\n",
      "================================912===================================\n",
      "912/10000: train_loss: 4.049161804914474 train_error 48.12% test_error 53.00%\n",
      "================================913===================================\n",
      "913/10000: train_loss: 4.049174527525902 train_error 48.12% test_error 53.00%\n",
      "================================914===================================\n",
      "914/10000: train_loss: 4.049187317639589 train_error 48.12% test_error 53.00%\n",
      "================================915===================================\n",
      "915/10000: train_loss: 4.049200156480074 train_error 48.12% test_error 53.00%\n",
      "================================916===================================\n",
      "916/10000: train_loss: 4.0492130017280585 train_error 48.12% test_error 53.00%\n",
      "================================917===================================\n",
      "917/10000: train_loss: 4.0492258457839485 train_error 48.12% test_error 53.00%\n",
      "================================918===================================\n",
      "918/10000: train_loss: 4.04923870652914 train_error 48.12% test_error 53.00%\n",
      "================================919===================================\n",
      "919/10000: train_loss: 4.049251571446657 train_error 48.12% test_error 53.00%\n",
      "================================920===================================\n",
      "920/10000: train_loss: 4.049264460653067 train_error 48.12% test_error 53.00%\n",
      "================================921===================================\n",
      "921/10000: train_loss: 4.049277398139239 train_error 48.12% test_error 53.00%\n",
      "================================922===================================\n",
      "922/10000: train_loss: 4.0492903505265705 train_error 48.12% test_error 53.00%\n",
      "================================923===================================\n",
      "923/10000: train_loss: 4.049303317517042 train_error 48.12% test_error 53.00%\n",
      "================================924===================================\n",
      "924/10000: train_loss: 4.049316255003214 train_error 48.12% test_error 53.00%\n",
      "================================925===================================\n",
      "925/10000: train_loss: 4.049329203665256 train_error 48.12% test_error 53.00%\n",
      "================================926===================================\n",
      "926/10000: train_loss: 4.049342201501131 train_error 48.12% test_error 53.00%\n",
      "================================927===================================\n",
      "927/10000: train_loss: 4.049355170279741 train_error 48.12% test_error 53.00%\n",
      "================================928===================================\n",
      "928/10000: train_loss: 4.049368164539337 train_error 48.12% test_error 53.00%\n",
      "================================929===================================\n",
      "929/10000: train_loss: 4.049381166249514 train_error 48.12% test_error 53.00%\n",
      "================================930===================================\n",
      "930/10000: train_loss: 4.049394214451313 train_error 48.12% test_error 53.00%\n",
      "================================931===================================\n",
      "931/10000: train_loss: 4.049407234191895 train_error 48.12% test_error 53.00%\n",
      "================================932===================================\n",
      "932/10000: train_loss: 4.049420317560434 train_error 48.12% test_error 53.00%\n",
      "================================933===================================\n",
      "933/10000: train_loss: 4.049433441311121 train_error 48.12% test_error 53.00%\n",
      "================================934===================================\n",
      "934/10000: train_loss: 4.049446641653776 train_error 48.25% test_error 53.00%\n",
      "================================935===================================\n",
      "935/10000: train_loss: 4.049459874778986 train_error 48.25% test_error 53.00%\n",
      "================================936===================================\n",
      "936/10000: train_loss: 4.0494731150567524 train_error 48.25% test_error 53.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================937===================================\n",
      "937/10000: train_loss: 4.049486383497715 train_error 48.25% test_error 53.00%\n",
      "================================938===================================\n",
      "938/10000: train_loss: 4.049499661326408 train_error 48.25% test_error 53.00%\n",
      "================================939===================================\n",
      "939/10000: train_loss: 4.049512949883939 train_error 48.25% test_error 53.00%\n",
      "================================940===================================\n",
      "940/10000: train_loss: 4.049526258558035 train_error 48.25% test_error 53.00%\n",
      "================================941===================================\n",
      "941/10000: train_loss: 4.049539588242769 train_error 48.25% test_error 53.00%\n",
      "================================942===================================\n",
      "942/10000: train_loss: 4.04955294162035 train_error 48.25% test_error 53.00%\n",
      "================================943===================================\n",
      "943/10000: train_loss: 4.049566339701414 train_error 48.25% test_error 53.00%\n",
      "================================944===================================\n",
      "944/10000: train_loss: 4.049579750001431 train_error 48.25% test_error 53.00%\n",
      "================================945===================================\n",
      "945/10000: train_loss: 4.049593205749989 train_error 48.25% test_error 53.00%\n",
      "================================946===================================\n",
      "946/10000: train_loss: 4.049606705605984 train_error 48.25% test_error 53.00%\n",
      "================================947===================================\n",
      "947/10000: train_loss: 4.049620223790407 train_error 48.25% test_error 53.00%\n",
      "================================948===================================\n",
      "948/10000: train_loss: 4.049633782505989 train_error 48.25% test_error 53.00%\n",
      "================================949===================================\n",
      "949/10000: train_loss: 4.0496473588049415 train_error 48.25% test_error 53.00%\n",
      "================================950===================================\n",
      "950/10000: train_loss: 4.04966095790267 train_error 48.25% test_error 53.00%\n",
      "================================951===================================\n",
      "951/10000: train_loss: 4.0496745736897 train_error 48.25% test_error 53.00%\n",
      "================================952===================================\n",
      "952/10000: train_loss: 4.049688218384981 train_error 48.25% test_error 53.00%\n",
      "================================953===================================\n",
      "953/10000: train_loss: 4.0497018863260745 train_error 48.25% test_error 53.00%\n",
      "================================954===================================\n",
      "954/10000: train_loss: 4.0497155481576925 train_error 48.25% test_error 53.00%\n",
      "================================955===================================\n",
      "955/10000: train_loss: 4.049729249328375 train_error 48.25% test_error 53.00%\n",
      "================================956===================================\n",
      "956/10000: train_loss: 4.0497429686784745 train_error 48.25% test_error 53.00%\n",
      "================================957===================================\n",
      "957/10000: train_loss: 4.04975670337677 train_error 48.25% test_error 53.00%\n",
      "================================958===================================\n",
      "958/10000: train_loss: 4.04977047353983 train_error 48.25% test_error 53.00%\n",
      "================================959===================================\n",
      "959/10000: train_loss: 4.04978432893753 train_error 48.25% test_error 53.00%\n",
      "================================960===================================\n",
      "960/10000: train_loss: 4.04979825630784 train_error 48.25% test_error 53.00%\n",
      "================================961===================================\n",
      "961/10000: train_loss: 4.049812207221985 train_error 48.25% test_error 53.00%\n",
      "================================962===================================\n",
      "962/10000: train_loss: 4.049826152920723 train_error 48.25% test_error 53.00%\n",
      "================================963===================================\n",
      "963/10000: train_loss: 4.049840112775564 train_error 48.25% test_error 53.00%\n",
      "================================964===================================\n",
      "964/10000: train_loss: 4.049854087382555 train_error 48.25% test_error 53.00%\n",
      "================================965===================================\n",
      "965/10000: train_loss: 4.0498680743575095 train_error 48.25% test_error 53.00%\n",
      "================================966===================================\n",
      "966/10000: train_loss: 4.049882096350193 train_error 48.25% test_error 53.00%\n",
      "================================967===================================\n",
      "967/10000: train_loss: 4.049896108061075 train_error 48.25% test_error 53.00%\n",
      "================================968===================================\n",
      "968/10000: train_loss: 4.049910168647766 train_error 48.25% test_error 53.00%\n",
      "================================969===================================\n",
      "969/10000: train_loss: 4.0499242013692855 train_error 48.25% test_error 53.00%\n",
      "================================970===================================\n",
      "970/10000: train_loss: 4.04993814945221 train_error 48.25% test_error 53.00%\n",
      "================================971===================================\n",
      "971/10000: train_loss: 4.049952088296414 train_error 48.25% test_error 53.00%\n",
      "================================972===================================\n",
      "972/10000: train_loss: 4.0499659626185895 train_error 48.25% test_error 53.00%\n",
      "================================973===================================\n",
      "973/10000: train_loss: 4.049979907721281 train_error 48.25% test_error 53.00%\n",
      "================================974===================================\n",
      "974/10000: train_loss: 4.049993839114904 train_error 48.25% test_error 53.00%\n",
      "================================975===================================\n",
      "975/10000: train_loss: 4.0500077907741066 train_error 48.25% test_error 53.00%\n",
      "================================976===================================\n",
      "976/10000: train_loss: 4.050021671950818 train_error 48.38% test_error 53.00%\n",
      "================================977===================================\n",
      "977/10000: train_loss: 4.050035561323165 train_error 48.38% test_error 53.00%\n",
      "================================978===================================\n",
      "978/10000: train_loss: 4.050049437135458 train_error 48.38% test_error 53.00%\n",
      "================================979===================================\n",
      "979/10000: train_loss: 4.050063346922398 train_error 48.38% test_error 53.00%\n",
      "================================980===================================\n",
      "980/10000: train_loss: 4.050077279806137 train_error 48.38% test_error 53.00%\n",
      "================================981===================================\n",
      "981/10000: train_loss: 4.050091187357903 train_error 48.38% test_error 53.00%\n",
      "================================982===================================\n",
      "982/10000: train_loss: 4.050105128437281 train_error 48.38% test_error 53.00%\n",
      "================================983===================================\n",
      "983/10000: train_loss: 4.050119092017412 train_error 48.38% test_error 53.00%\n",
      "================================984===================================\n",
      "984/10000: train_loss: 4.050133057683706 train_error 48.38% test_error 53.00%\n",
      "================================985===================================\n",
      "985/10000: train_loss: 4.0501470439136025 train_error 48.38% test_error 53.00%\n",
      "================================986===================================\n",
      "986/10000: train_loss: 4.050161015987396 train_error 48.38% test_error 53.00%\n",
      "================================987===================================\n",
      "987/10000: train_loss: 4.0501749649643894 train_error 48.38% test_error 53.00%\n",
      "================================988===================================\n",
      "988/10000: train_loss: 4.050188930034637 train_error 48.38% test_error 53.00%\n",
      "================================989===================================\n",
      "989/10000: train_loss: 4.050202875137329 train_error 48.38% test_error 53.00%\n",
      "================================990===================================\n",
      "990/10000: train_loss: 4.050216755270958 train_error 48.38% test_error 53.00%\n",
      "================================991===================================\n",
      "991/10000: train_loss: 4.050230620056391 train_error 48.50% test_error 53.00%\n",
      "================================992===================================\n",
      "992/10000: train_loss: 4.050244474112988 train_error 48.50% test_error 53.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================993===================================\n",
      "993/10000: train_loss: 4.050258317887783 train_error 48.50% test_error 53.00%\n",
      "================================994===================================\n",
      "994/10000: train_loss: 4.050272184461355 train_error 48.50% test_error 53.00%\n",
      "================================995===================================\n",
      "995/10000: train_loss: 4.050286077260971 train_error 48.50% test_error 53.00%\n",
      "================================996===================================\n",
      "996/10000: train_loss: 4.050299960821867 train_error 48.50% test_error 53.00%\n",
      "================================997===================================\n",
      "997/10000: train_loss: 4.050313881784677 train_error 48.62% test_error 53.00%\n",
      "================================998===================================\n",
      "998/10000: train_loss: 4.050327800065279 train_error 48.62% test_error 53.00%\n",
      "================================999===================================\n",
      "999/10000: train_loss: 4.050341745465994 train_error 48.62% test_error 53.00%\n",
      "================================1000===================================\n",
      "1000/10000: train_loss: 4.050355716943741 train_error 48.62% test_error 53.00%\n",
      "================================1001===================================\n",
      "1001/10000: train_loss: 4.050369712412357 train_error 48.62% test_error 53.00%\n",
      "================================1002===================================\n",
      "1002/10000: train_loss: 4.0503837089240555 train_error 48.62% test_error 53.00%\n",
      "================================1003===================================\n",
      "1003/10000: train_loss: 4.050397725254298 train_error 48.62% test_error 53.00%\n",
      "================================1004===================================\n",
      "1004/10000: train_loss: 4.050411771833897 train_error 48.62% test_error 53.00%\n",
      "================================1005===================================\n",
      "1005/10000: train_loss: 4.050425813496113 train_error 48.62% test_error 53.00%\n",
      "================================1006===================================\n",
      "1006/10000: train_loss: 4.050439884960651 train_error 48.62% test_error 53.00%\n",
      "================================1007===================================\n",
      "1007/10000: train_loss: 4.050453961640596 train_error 48.62% test_error 53.00%\n",
      "================================1008===================================\n",
      "1008/10000: train_loss: 4.050468085259199 train_error 48.62% test_error 53.00%\n",
      "================================1009===================================\n",
      "1009/10000: train_loss: 4.050482183247805 train_error 48.62% test_error 53.00%\n",
      "================================1010===================================\n",
      "1010/10000: train_loss: 4.050496283620595 train_error 48.62% test_error 53.00%\n",
      "================================1011===================================\n",
      "1011/10000: train_loss: 4.050510432124138 train_error 48.62% test_error 53.00%\n",
      "================================1012===================================\n",
      "1012/10000: train_loss: 4.050524585396052 train_error 48.62% test_error 53.00%\n",
      "================================1013===================================\n",
      "1013/10000: train_loss: 4.050538753420115 train_error 48.62% test_error 53.00%\n",
      "================================1014===================================\n",
      "1014/10000: train_loss: 4.050552921295166 train_error 48.62% test_error 53.00%\n",
      "================================1015===================================\n",
      "1015/10000: train_loss: 4.0505671232938765 train_error 48.62% test_error 53.00%\n",
      "================================1016===================================\n",
      "1016/10000: train_loss: 4.050581329017877 train_error 48.62% test_error 53.00%\n",
      "================================1017===================================\n",
      "1017/10000: train_loss: 4.050595545172691 train_error 48.62% test_error 53.00%\n",
      "================================1018===================================\n",
      "1018/10000: train_loss: 4.050609759688378 train_error 48.62% test_error 53.00%\n",
      "================================1019===================================\n",
      "1019/10000: train_loss: 4.050623982846737 train_error 48.62% test_error 53.00%\n",
      "================================1020===================================\n",
      "1020/10000: train_loss: 4.050638205111027 train_error 48.62% test_error 53.00%\n",
      "================================1021===================================\n",
      "1021/10000: train_loss: 4.050652420073748 train_error 48.62% test_error 53.00%\n",
      "================================1022===================================\n",
      "1022/10000: train_loss: 4.050666602402925 train_error 48.62% test_error 53.00%\n",
      "================================1023===================================\n",
      "1023/10000: train_loss: 4.0506807512044904 train_error 48.62% test_error 53.00%\n",
      "================================1024===================================\n",
      "1024/10000: train_loss: 4.0506949386000635 train_error 48.62% test_error 53.00%\n",
      "================================1025===================================\n",
      "1025/10000: train_loss: 4.050709160119295 train_error 48.62% test_error 53.00%\n",
      "================================1026===================================\n",
      "1026/10000: train_loss: 4.050723347216844 train_error 48.62% test_error 53.00%\n",
      "================================1027===================================\n",
      "1027/10000: train_loss: 4.050737574696541 train_error 48.62% test_error 53.00%\n",
      "================================1028===================================\n",
      "1028/10000: train_loss: 4.050751881897449 train_error 48.62% test_error 53.00%\n",
      "================================1029===================================\n",
      "1029/10000: train_loss: 4.050766222476959 train_error 48.62% test_error 53.00%\n",
      "================================1030===================================\n",
      "1030/10000: train_loss: 4.050780592113734 train_error 48.62% test_error 53.00%\n",
      "================================1031===================================\n",
      "1031/10000: train_loss: 4.050794984400272 train_error 48.62% test_error 53.50%\n",
      "================================1032===================================\n",
      "1032/10000: train_loss: 4.050809386670589 train_error 48.62% test_error 53.50%\n",
      "================================1033===================================\n",
      "1033/10000: train_loss: 4.050823721885681 train_error 48.62% test_error 53.50%\n",
      "================================1034===================================\n",
      "1034/10000: train_loss: 4.050838035494089 train_error 48.62% test_error 53.50%\n",
      "================================1035===================================\n",
      "1035/10000: train_loss: 4.050852376371622 train_error 48.62% test_error 53.50%\n",
      "================================1036===================================\n",
      "1036/10000: train_loss: 4.050866694301367 train_error 48.62% test_error 53.50%\n",
      "================================1037===================================\n",
      "1037/10000: train_loss: 4.050881001055241 train_error 48.62% test_error 53.50%\n",
      "================================1038===================================\n",
      "1038/10000: train_loss: 4.050895285308361 train_error 48.62% test_error 53.50%\n",
      "================================1039===================================\n",
      "1039/10000: train_loss: 4.050909583121538 train_error 48.62% test_error 53.50%\n",
      "================================1040===================================\n",
      "1040/10000: train_loss: 4.050923852473498 train_error 48.62% test_error 53.50%\n",
      "================================1041===================================\n",
      "1041/10000: train_loss: 4.050938101559877 train_error 48.62% test_error 53.50%\n",
      "================================1042===================================\n",
      "1042/10000: train_loss: 4.050952297300101 train_error 48.62% test_error 53.50%\n",
      "================================1043===================================\n",
      "1043/10000: train_loss: 4.050966500490904 train_error 48.62% test_error 53.50%\n",
      "================================1044===================================\n",
      "1044/10000: train_loss: 4.050980705469847 train_error 48.62% test_error 53.50%\n",
      "================================1045===================================\n",
      "1045/10000: train_loss: 4.0509949335455895 train_error 48.62% test_error 53.50%\n",
      "================================1046===================================\n",
      "1046/10000: train_loss: 4.051009169965982 train_error 48.62% test_error 53.50%\n",
      "================================1047===================================\n",
      "1047/10000: train_loss: 4.05102342262864 train_error 48.62% test_error 53.50%\n",
      "================================1048===================================\n",
      "1048/10000: train_loss: 4.051037688106298 train_error 48.62% test_error 53.50%\n",
      "================================1049===================================\n",
      "1049/10000: train_loss: 4.051051964908838 train_error 48.75% test_error 53.50%\n",
      "================================1050===================================\n",
      "1050/10000: train_loss: 4.051066219955683 train_error 48.75% test_error 53.50%\n",
      "================================1051===================================\n",
      "1051/10000: train_loss: 4.051080466061831 train_error 48.75% test_error 53.50%\n",
      "================================1052===================================\n",
      "1052/10000: train_loss: 4.051094714701176 train_error 48.75% test_error 53.50%\n",
      "================================1053===================================\n",
      "1053/10000: train_loss: 4.05110899195075 train_error 48.75% test_error 53.50%\n",
      "================================1054===================================\n",
      "1054/10000: train_loss: 4.051123268306256 train_error 48.75% test_error 53.50%\n",
      "================================1055===================================\n",
      "1055/10000: train_loss: 4.051137506067753 train_error 48.75% test_error 53.50%\n",
      "================================1056===================================\n",
      "1056/10000: train_loss: 4.051151783466339 train_error 48.75% test_error 53.50%\n",
      "================================1057===================================\n",
      "1057/10000: train_loss: 4.051166049391031 train_error 48.75% test_error 53.50%\n",
      "================================1058===================================\n",
      "1058/10000: train_loss: 4.051180343180896 train_error 48.75% test_error 53.50%\n",
      "================================1059===================================\n",
      "1059/10000: train_loss: 4.051194590330123 train_error 48.75% test_error 53.50%\n",
      "================================1060===================================\n",
      "1060/10000: train_loss: 4.0512087830901145 train_error 48.75% test_error 53.50%\n",
      "================================1061===================================\n",
      "1061/10000: train_loss: 4.051222962141037 train_error 48.75% test_error 53.50%\n",
      "================================1062===================================\n",
      "1062/10000: train_loss: 4.0512371687591076 train_error 48.75% test_error 53.50%\n",
      "================================1063===================================\n",
      "1063/10000: train_loss: 4.051251315176486 train_error 48.75% test_error 53.50%\n",
      "================================1064===================================\n",
      "1064/10000: train_loss: 4.0512654046714305 train_error 48.88% test_error 53.50%\n",
      "================================1065===================================\n",
      "1065/10000: train_loss: 4.051279521584511 train_error 48.88% test_error 53.50%\n",
      "================================1066===================================\n",
      "1066/10000: train_loss: 4.051293644160032 train_error 48.88% test_error 53.50%\n",
      "================================1067===================================\n",
      "1067/10000: train_loss: 4.05130777835846 train_error 48.88% test_error 53.50%\n",
      "================================1068===================================\n",
      "1068/10000: train_loss: 4.051321887224913 train_error 48.88% test_error 53.50%\n",
      "================================1069===================================\n",
      "1069/10000: train_loss: 4.051335943490266 train_error 48.88% test_error 54.00%\n",
      "================================1070===================================\n",
      "1070/10000: train_loss: 4.05135002374649 train_error 48.88% test_error 54.00%\n",
      "================================1071===================================\n",
      "1071/10000: train_loss: 4.05136415719986 train_error 48.88% test_error 54.00%\n",
      "================================1072===================================\n",
      "1072/10000: train_loss: 4.051378320157528 train_error 48.88% test_error 54.00%\n",
      "================================1073===================================\n",
      "1073/10000: train_loss: 4.051392477303743 train_error 48.88% test_error 54.00%\n",
      "================================1074===================================\n",
      "1074/10000: train_loss: 4.051406622380018 train_error 48.88% test_error 54.00%\n",
      "================================1075===================================\n",
      "1075/10000: train_loss: 4.051420747041702 train_error 48.88% test_error 54.00%\n",
      "================================1076===================================\n",
      "1076/10000: train_loss: 4.051434912532567 train_error 48.88% test_error 54.00%\n",
      "================================1077===================================\n",
      "1077/10000: train_loss: 4.051449061036109 train_error 48.88% test_error 54.00%\n",
      "================================1078===================================\n",
      "1078/10000: train_loss: 4.051463231742382 train_error 48.88% test_error 54.00%\n",
      "================================1079===================================\n",
      "1079/10000: train_loss: 4.051477397680283 train_error 49.00% test_error 54.00%\n",
      "================================1080===================================\n",
      "1080/10000: train_loss: 4.051491508036852 train_error 49.00% test_error 54.00%\n",
      "================================1081===================================\n",
      "1081/10000: train_loss: 4.051505600959063 train_error 49.00% test_error 54.00%\n",
      "================================1082===================================\n",
      "1082/10000: train_loss: 4.0515196725726135 train_error 49.00% test_error 54.00%\n",
      "================================1083===================================\n",
      "1083/10000: train_loss: 4.051533781588077 train_error 49.00% test_error 54.00%\n",
      "================================1084===================================\n",
      "1084/10000: train_loss: 4.0515478853881355 train_error 49.00% test_error 54.00%\n",
      "================================1085===================================\n",
      "1085/10000: train_loss: 4.051562000960112 train_error 49.00% test_error 54.00%\n",
      "================================1086===================================\n",
      "1086/10000: train_loss: 4.051576109826565 train_error 49.00% test_error 54.00%\n",
      "================================1087===================================\n",
      "1087/10000: train_loss: 4.051590265333653 train_error 49.00% test_error 54.00%\n",
      "================================1088===================================\n",
      "1088/10000: train_loss: 4.051604404598475 train_error 49.00% test_error 54.00%\n",
      "================================1089===================================\n",
      "1089/10000: train_loss: 4.051618555188179 train_error 49.00% test_error 54.00%\n",
      "================================1090===================================\n",
      "1090/10000: train_loss: 4.051632689088583 train_error 49.12% test_error 54.00%\n",
      "================================1091===================================\n",
      "1091/10000: train_loss: 4.051646839082241 train_error 49.12% test_error 54.00%\n",
      "================================1092===================================\n",
      "1092/10000: train_loss: 4.051660975366831 train_error 49.12% test_error 54.00%\n",
      "================================1093===================================\n",
      "1093/10000: train_loss: 4.051675224751234 train_error 49.12% test_error 54.00%\n",
      "================================1094===================================\n",
      "1094/10000: train_loss: 4.05168949469924 train_error 49.12% test_error 54.00%\n",
      "================================1095===================================\n",
      "1095/10000: train_loss: 4.051703744232654 train_error 49.12% test_error 54.00%\n",
      "================================1096===================================\n",
      "1096/10000: train_loss: 4.051718015819787 train_error 49.12% test_error 54.00%\n",
      "================================1097===================================\n",
      "1097/10000: train_loss: 4.051732306033373 train_error 49.25% test_error 54.00%\n",
      "================================1098===================================\n",
      "1098/10000: train_loss: 4.051746544539928 train_error 49.25% test_error 54.00%\n",
      "================================1099===================================\n",
      "1099/10000: train_loss: 4.051760762929916 train_error 49.25% test_error 54.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1100===================================\n",
      "1100/10000: train_loss: 4.05177499473095 train_error 49.25% test_error 54.00%\n",
      "================================1101===================================\n",
      "1101/10000: train_loss: 4.051789201796055 train_error 49.25% test_error 54.00%\n",
      "================================1102===================================\n",
      "1102/10000: train_loss: 4.051803387701511 train_error 49.25% test_error 54.00%\n",
      "================================1103===================================\n",
      "1103/10000: train_loss: 4.0518174861371525 train_error 49.25% test_error 54.00%\n",
      "================================1104===================================\n",
      "1104/10000: train_loss: 4.051831587702036 train_error 49.25% test_error 54.00%\n",
      "================================1105===================================\n",
      "1105/10000: train_loss: 4.05184567540884 train_error 49.25% test_error 54.00%\n",
      "================================1106===================================\n",
      "1106/10000: train_loss: 4.051859787255526 train_error 49.25% test_error 54.00%\n",
      "================================1107===================================\n",
      "1107/10000: train_loss: 4.05187385827303 train_error 49.25% test_error 54.00%\n",
      "================================1108===================================\n",
      "1108/10000: train_loss: 4.051887995898724 train_error 49.25% test_error 54.00%\n",
      "================================1109===================================\n",
      "1109/10000: train_loss: 4.051902165114879 train_error 49.25% test_error 54.00%\n",
      "================================1110===================================\n",
      "1110/10000: train_loss: 4.051916331201792 train_error 49.25% test_error 54.00%\n",
      "================================1111===================================\n",
      "1111/10000: train_loss: 4.051930514872074 train_error 49.25% test_error 54.00%\n",
      "================================1112===================================\n",
      "1112/10000: train_loss: 4.051944696754217 train_error 49.25% test_error 54.00%\n",
      "================================1113===================================\n",
      "1113/10000: train_loss: 4.051958879679441 train_error 49.25% test_error 54.00%\n",
      "================================1114===================================\n",
      "1114/10000: train_loss: 4.051973081380129 train_error 49.25% test_error 54.00%\n",
      "================================1115===================================\n",
      "1115/10000: train_loss: 4.051987265497447 train_error 49.25% test_error 54.00%\n",
      "================================1116===================================\n",
      "1116/10000: train_loss: 4.0520015001297 train_error 49.25% test_error 54.00%\n",
      "================================1117===================================\n",
      "1117/10000: train_loss: 4.052015691995621 train_error 49.25% test_error 54.00%\n",
      "================================1118===================================\n",
      "1118/10000: train_loss: 4.05202991977334 train_error 49.25% test_error 54.00%\n",
      "================================1119===================================\n",
      "1119/10000: train_loss: 4.052044117897749 train_error 49.25% test_error 54.00%\n",
      "================================1120===================================\n",
      "1120/10000: train_loss: 4.05205834493041 train_error 49.25% test_error 54.00%\n",
      "================================1121===================================\n",
      "1121/10000: train_loss: 4.052072573900222 train_error 49.25% test_error 54.00%\n",
      "================================1122===================================\n",
      "1122/10000: train_loss: 4.052086825966835 train_error 49.25% test_error 54.00%\n",
      "================================1123===================================\n",
      "1123/10000: train_loss: 4.052100964486598 train_error 49.25% test_error 54.00%\n",
      "================================1124===================================\n",
      "1124/10000: train_loss: 4.052115108966827 train_error 49.25% test_error 54.00%\n",
      "================================1125===================================\n",
      "1125/10000: train_loss: 4.052129244208336 train_error 49.25% test_error 54.00%\n",
      "================================1126===================================\n",
      "1126/10000: train_loss: 4.052143395245075 train_error 49.25% test_error 54.00%\n",
      "================================1127===================================\n",
      "1127/10000: train_loss: 4.052157566398382 train_error 49.25% test_error 54.00%\n",
      "================================1128===================================\n",
      "1128/10000: train_loss: 4.052171751409769 train_error 49.25% test_error 54.00%\n",
      "================================1129===================================\n",
      "1129/10000: train_loss: 4.052185981720686 train_error 49.25% test_error 54.00%\n",
      "================================1130===================================\n",
      "1130/10000: train_loss: 4.0522002474963665 train_error 49.25% test_error 54.00%\n",
      "================================1131===================================\n",
      "1131/10000: train_loss: 4.052214533388615 train_error 49.25% test_error 54.00%\n",
      "================================1132===================================\n",
      "1132/10000: train_loss: 4.052228822112083 train_error 49.25% test_error 54.00%\n",
      "================================1133===================================\n",
      "1133/10000: train_loss: 4.052243122011423 train_error 49.25% test_error 54.00%\n",
      "================================1134===================================\n",
      "1134/10000: train_loss: 4.052257439792156 train_error 49.25% test_error 54.00%\n",
      "================================1135===================================\n",
      "1135/10000: train_loss: 4.052271778583527 train_error 49.25% test_error 54.00%\n",
      "================================1136===================================\n",
      "1136/10000: train_loss: 4.05228606581688 train_error 49.25% test_error 54.00%\n",
      "================================1137===================================\n",
      "1137/10000: train_loss: 4.05230039447546 train_error 49.25% test_error 54.00%\n",
      "================================1138===================================\n",
      "1138/10000: train_loss: 4.052314708530902 train_error 49.25% test_error 54.00%\n",
      "================================1139===================================\n",
      "1139/10000: train_loss: 4.052329055070878 train_error 49.25% test_error 54.00%\n",
      "================================1140===================================\n",
      "1140/10000: train_loss: 4.052343402653932 train_error 49.25% test_error 54.00%\n",
      "================================1141===================================\n",
      "1141/10000: train_loss: 4.052357788830996 train_error 49.25% test_error 54.00%\n",
      "================================1142===================================\n",
      "1142/10000: train_loss: 4.0523721854388715 train_error 49.25% test_error 54.00%\n",
      "================================1143===================================\n",
      "1143/10000: train_loss: 4.052386600673199 train_error 49.25% test_error 54.00%\n",
      "================================1144===================================\n",
      "1144/10000: train_loss: 4.052401013821363 train_error 49.25% test_error 54.00%\n",
      "================================1145===================================\n",
      "1145/10000: train_loss: 4.052415420711041 train_error 49.25% test_error 54.00%\n",
      "================================1146===================================\n",
      "1146/10000: train_loss: 4.052429761737585 train_error 49.25% test_error 54.00%\n",
      "================================1147===================================\n",
      "1147/10000: train_loss: 4.052444137185812 train_error 49.25% test_error 54.00%\n",
      "================================1148===================================\n",
      "1148/10000: train_loss: 4.05245854601264 train_error 49.25% test_error 54.00%\n",
      "================================1149===================================\n",
      "1149/10000: train_loss: 4.052472959309816 train_error 49.25% test_error 54.00%\n",
      "================================1150===================================\n",
      "1150/10000: train_loss: 4.0524873693287375 train_error 49.25% test_error 54.00%\n",
      "================================1151===================================\n",
      "1151/10000: train_loss: 4.052501810044051 train_error 49.25% test_error 54.00%\n",
      "================================1152===================================\n",
      "1152/10000: train_loss: 4.0525162468850615 train_error 49.25% test_error 54.00%\n",
      "================================1153===================================\n",
      "1153/10000: train_loss: 4.052530678510666 train_error 49.25% test_error 54.00%\n",
      "================================1154===================================\n",
      "1154/10000: train_loss: 4.052545120418072 train_error 49.25% test_error 54.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1155===================================\n",
      "1155/10000: train_loss: 4.052559558600187 train_error 49.25% test_error 54.00%\n",
      "================================1156===================================\n",
      "1156/10000: train_loss: 4.052573979198933 train_error 49.25% test_error 54.00%\n",
      "================================1157===================================\n",
      "1157/10000: train_loss: 4.0525883954763415 train_error 49.38% test_error 54.00%\n",
      "================================1158===================================\n",
      "1158/10000: train_loss: 4.052602830827237 train_error 49.38% test_error 54.00%\n",
      "================================1159===================================\n",
      "1159/10000: train_loss: 4.052617306113243 train_error 49.38% test_error 54.00%\n",
      "================================1160===================================\n",
      "1160/10000: train_loss: 4.052631827443838 train_error 49.38% test_error 54.00%\n",
      "================================1161===================================\n",
      "1161/10000: train_loss: 4.05264635771513 train_error 49.38% test_error 54.00%\n",
      "================================1162===================================\n",
      "1162/10000: train_loss: 4.052660903483629 train_error 49.38% test_error 54.00%\n",
      "================================1163===================================\n",
      "1163/10000: train_loss: 4.052675464898348 train_error 49.38% test_error 54.00%\n",
      "================================1164===================================\n",
      "1164/10000: train_loss: 4.052690018415451 train_error 49.38% test_error 54.00%\n",
      "================================1165===================================\n",
      "1165/10000: train_loss: 4.05270459011197 train_error 49.38% test_error 54.00%\n",
      "================================1166===================================\n",
      "1166/10000: train_loss: 4.052719165831804 train_error 49.38% test_error 54.00%\n",
      "================================1167===================================\n",
      "1167/10000: train_loss: 4.052733743786812 train_error 49.38% test_error 54.00%\n",
      "================================1168===================================\n",
      "1168/10000: train_loss: 4.052748318016529 train_error 49.50% test_error 54.00%\n",
      "================================1169===================================\n",
      "1169/10000: train_loss: 4.052762901484966 train_error 49.50% test_error 54.00%\n",
      "================================1170===================================\n",
      "1170/10000: train_loss: 4.052777494639158 train_error 49.50% test_error 54.00%\n",
      "================================1171===================================\n",
      "1171/10000: train_loss: 4.0527920821309085 train_error 49.50% test_error 54.00%\n",
      "================================1172===================================\n",
      "1172/10000: train_loss: 4.052806671708822 train_error 49.50% test_error 54.00%\n",
      "================================1173===================================\n",
      "1173/10000: train_loss: 4.052821253985167 train_error 49.62% test_error 54.00%\n",
      "================================1174===================================\n",
      "1174/10000: train_loss: 4.05283577337861 train_error 49.62% test_error 54.00%\n",
      "================================1175===================================\n",
      "1175/10000: train_loss: 4.052850337028503 train_error 49.62% test_error 54.00%\n",
      "================================1176===================================\n",
      "1176/10000: train_loss: 4.052864847034217 train_error 49.62% test_error 54.00%\n",
      "================================1177===================================\n",
      "1177/10000: train_loss: 4.052879392355681 train_error 49.62% test_error 54.00%\n",
      "================================1178===================================\n",
      "1178/10000: train_loss: 4.052893943935633 train_error 49.62% test_error 54.00%\n",
      "================================1179===================================\n",
      "1179/10000: train_loss: 4.052908484637737 train_error 49.62% test_error 54.00%\n",
      "================================1180===================================\n",
      "1180/10000: train_loss: 4.052923063635826 train_error 49.62% test_error 54.00%\n",
      "================================1181===================================\n",
      "1181/10000: train_loss: 4.0529376240074635 train_error 49.62% test_error 54.00%\n",
      "================================1182===================================\n",
      "1182/10000: train_loss: 4.052952188700438 train_error 49.62% test_error 54.00%\n",
      "================================1183===================================\n",
      "1183/10000: train_loss: 4.05296676158905 train_error 49.75% test_error 54.00%\n",
      "================================1184===================================\n",
      "1184/10000: train_loss: 4.052981302589178 train_error 49.75% test_error 54.00%\n",
      "================================1185===================================\n",
      "1185/10000: train_loss: 4.0529958717525005 train_error 49.75% test_error 54.00%\n",
      "================================1186===================================\n",
      "1186/10000: train_loss: 4.053010416924954 train_error 49.75% test_error 54.00%\n",
      "================================1187===================================\n",
      "1187/10000: train_loss: 4.0530249725282195 train_error 49.75% test_error 54.00%\n",
      "================================1188===================================\n",
      "1188/10000: train_loss: 4.0530395354330535 train_error 49.75% test_error 54.00%\n",
      "================================1189===================================\n",
      "1189/10000: train_loss: 4.053054113686085 train_error 49.75% test_error 54.00%\n",
      "================================1190===================================\n",
      "1190/10000: train_loss: 4.053068703860045 train_error 49.75% test_error 54.00%\n",
      "================================1191===================================\n",
      "1191/10000: train_loss: 4.053083280473947 train_error 49.75% test_error 54.00%\n",
      "================================1192===================================\n",
      "1192/10000: train_loss: 4.053097872436047 train_error 49.75% test_error 54.00%\n",
      "================================1193===================================\n",
      "1193/10000: train_loss: 4.05311248511076 train_error 49.75% test_error 54.00%\n",
      "================================1194===================================\n",
      "1194/10000: train_loss: 4.0531271985173225 train_error 49.75% test_error 54.00%\n",
      "================================1195===================================\n",
      "1195/10000: train_loss: 4.053141932487488 train_error 49.75% test_error 54.00%\n",
      "================================1196===================================\n",
      "1196/10000: train_loss: 4.053156553953887 train_error 49.75% test_error 54.00%\n",
      "================================1197===================================\n",
      "1197/10000: train_loss: 4.05317119449377 train_error 49.75% test_error 54.00%\n",
      "================================1198===================================\n",
      "1198/10000: train_loss: 4.05318582072854 train_error 49.75% test_error 54.00%\n",
      "================================1199===================================\n",
      "1199/10000: train_loss: 4.053200438022613 train_error 49.75% test_error 54.00%\n",
      "================================1200===================================\n",
      "1200/10000: train_loss: 4.0532150040566925 train_error 49.75% test_error 54.00%\n",
      "================================1201===================================\n",
      "1201/10000: train_loss: 4.0532295686006545 train_error 49.75% test_error 54.00%\n",
      "================================1202===================================\n",
      "1202/10000: train_loss: 4.0532441589236266 train_error 49.75% test_error 54.00%\n",
      "================================1203===================================\n",
      "1203/10000: train_loss: 4.053258737772703 train_error 49.75% test_error 54.00%\n",
      "================================1204===================================\n",
      "1204/10000: train_loss: 4.053273327797651 train_error 49.75% test_error 54.00%\n",
      "================================1205===================================\n",
      "1205/10000: train_loss: 4.05328788921237 train_error 49.75% test_error 54.00%\n",
      "================================1206===================================\n",
      "1206/10000: train_loss: 4.053302486240863 train_error 49.75% test_error 54.00%\n",
      "================================1207===================================\n",
      "1207/10000: train_loss: 4.053317039608956 train_error 49.75% test_error 54.00%\n",
      "================================1208===================================\n",
      "1208/10000: train_loss: 4.05333164960146 train_error 49.75% test_error 54.00%\n",
      "================================1209===================================\n",
      "1209/10000: train_loss: 4.053346241563558 train_error 49.75% test_error 54.00%\n",
      "================================1210===================================\n",
      "1210/10000: train_loss: 4.0533608610928065 train_error 49.75% test_error 54.00%\n",
      "================================1211===================================\n",
      "1211/10000: train_loss: 4.053375451415777 train_error 49.75% test_error 54.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1212===================================\n",
      "1212/10000: train_loss: 4.0533900314569475 train_error 49.75% test_error 54.00%\n",
      "================================1213===================================\n",
      "1213/10000: train_loss: 4.053404550105333 train_error 49.75% test_error 54.00%\n",
      "================================1214===================================\n",
      "1214/10000: train_loss: 4.053419072628021 train_error 49.75% test_error 54.00%\n",
      "================================1215===================================\n",
      "1215/10000: train_loss: 4.053433608561754 train_error 49.75% test_error 54.00%\n",
      "================================1216===================================\n",
      "1216/10000: train_loss: 4.053448133468628 train_error 49.75% test_error 54.00%\n",
      "================================1217===================================\n",
      "1217/10000: train_loss: 4.053462669700385 train_error 49.75% test_error 54.00%\n",
      "================================1218===================================\n",
      "1218/10000: train_loss: 4.053477216511965 train_error 49.75% test_error 54.00%\n",
      "================================1219===================================\n",
      "1219/10000: train_loss: 4.053491761982441 train_error 49.75% test_error 54.00%\n",
      "================================1220===================================\n",
      "1220/10000: train_loss: 4.0535062885284425 train_error 49.75% test_error 54.00%\n",
      "================================1221===================================\n",
      "1221/10000: train_loss: 4.053520832061768 train_error 49.75% test_error 54.00%\n",
      "================================1222===================================\n",
      "1222/10000: train_loss: 4.053535376340151 train_error 49.75% test_error 54.00%\n",
      "================================1223===================================\n",
      "1223/10000: train_loss: 4.053549958020449 train_error 49.75% test_error 54.00%\n",
      "================================1224===================================\n",
      "1224/10000: train_loss: 4.053564503192901 train_error 49.75% test_error 54.00%\n",
      "================================1225===================================\n",
      "1225/10000: train_loss: 4.053579071313143 train_error 49.75% test_error 54.00%\n",
      "================================1226===================================\n",
      "1226/10000: train_loss: 4.053593625575304 train_error 49.75% test_error 54.00%\n",
      "================================1227===================================\n",
      "1227/10000: train_loss: 4.053608177006244 train_error 49.75% test_error 54.00%\n",
      "================================1228===================================\n",
      "1228/10000: train_loss: 4.053622743189335 train_error 49.75% test_error 54.00%\n",
      "================================1229===================================\n",
      "1229/10000: train_loss: 4.053637342453003 train_error 49.75% test_error 54.00%\n",
      "================================1230===================================\n",
      "1230/10000: train_loss: 4.05365193709731 train_error 49.75% test_error 54.00%\n",
      "================================1231===================================\n",
      "1231/10000: train_loss: 4.053666525632143 train_error 49.75% test_error 54.00%\n",
      "================================1232===================================\n",
      "1232/10000: train_loss: 4.0536811345815655 train_error 49.75% test_error 54.00%\n",
      "================================1233===================================\n",
      "1233/10000: train_loss: 4.053695729374885 train_error 49.75% test_error 54.00%\n",
      "================================1234===================================\n",
      "1234/10000: train_loss: 4.053710322827101 train_error 49.75% test_error 54.00%\n",
      "================================1235===================================\n",
      "1235/10000: train_loss: 4.053724919855595 train_error 49.75% test_error 54.00%\n",
      "================================1236===================================\n",
      "1236/10000: train_loss: 4.053739485293627 train_error 49.75% test_error 54.00%\n",
      "================================1237===================================\n",
      "1237/10000: train_loss: 4.053753943443298 train_error 49.75% test_error 54.00%\n",
      "================================1238===================================\n",
      "1238/10000: train_loss: 4.053768427073956 train_error 49.75% test_error 54.00%\n",
      "================================1239===================================\n",
      "1239/10000: train_loss: 4.053782919198275 train_error 49.75% test_error 54.00%\n",
      "================================1240===================================\n",
      "1240/10000: train_loss: 4.053797310143709 train_error 49.75% test_error 54.00%\n",
      "================================1241===================================\n",
      "1241/10000: train_loss: 4.053811626732349 train_error 49.75% test_error 54.00%\n",
      "================================1242===================================\n",
      "1242/10000: train_loss: 4.053825984299182 train_error 49.75% test_error 54.00%\n",
      "================================1243===================================\n",
      "1243/10000: train_loss: 4.053840311467648 train_error 49.75% test_error 54.00%\n",
      "================================1244===================================\n",
      "1244/10000: train_loss: 4.0538546600937835 train_error 49.75% test_error 54.00%\n",
      "================================1245===================================\n",
      "1245/10000: train_loss: 4.053868971467018 train_error 49.75% test_error 54.00%\n",
      "================================1246===================================\n",
      "1246/10000: train_loss: 4.053883079886437 train_error 49.75% test_error 54.00%\n",
      "================================1247===================================\n",
      "1247/10000: train_loss: 4.053897138386965 train_error 49.75% test_error 54.00%\n",
      "================================1248===================================\n",
      "1248/10000: train_loss: 4.0539112335443495 train_error 49.75% test_error 54.00%\n",
      "================================1249===================================\n",
      "1249/10000: train_loss: 4.0539252884686 train_error 49.75% test_error 54.00%\n",
      "================================1250===================================\n",
      "1250/10000: train_loss: 4.053939347565174 train_error 49.75% test_error 54.00%\n",
      "================================1251===================================\n",
      "1251/10000: train_loss: 4.0539534504711625 train_error 49.75% test_error 54.00%\n",
      "================================1252===================================\n",
      "1252/10000: train_loss: 4.053967599868774 train_error 49.88% test_error 54.00%\n",
      "================================1253===================================\n",
      "1253/10000: train_loss: 4.0539817711710935 train_error 49.88% test_error 54.00%\n",
      "================================1254===================================\n",
      "1254/10000: train_loss: 4.053995956033468 train_error 49.88% test_error 54.00%\n",
      "================================1255===================================\n",
      "1255/10000: train_loss: 4.054010103493929 train_error 49.88% test_error 54.00%\n",
      "================================1256===================================\n",
      "1256/10000: train_loss: 4.054024296849966 train_error 49.88% test_error 54.00%\n",
      "================================1257===================================\n",
      "1257/10000: train_loss: 4.0540384890139105 train_error 49.88% test_error 54.00%\n",
      "================================1258===================================\n",
      "1258/10000: train_loss: 4.054052646905184 train_error 49.88% test_error 54.00%\n",
      "================================1259===================================\n",
      "1259/10000: train_loss: 4.054066821336746 train_error 49.88% test_error 54.00%\n",
      "================================1260===================================\n",
      "1260/10000: train_loss: 4.054080971032381 train_error 49.88% test_error 54.00%\n",
      "================================1261===================================\n",
      "1261/10000: train_loss: 4.054095062911511 train_error 49.88% test_error 54.00%\n",
      "================================1262===================================\n",
      "1262/10000: train_loss: 4.054109177738429 train_error 49.88% test_error 54.00%\n",
      "================================1263===================================\n",
      "1263/10000: train_loss: 4.054123356491328 train_error 49.88% test_error 54.00%\n",
      "================================1264===================================\n",
      "1264/10000: train_loss: 4.054137558192015 train_error 49.88% test_error 54.00%\n",
      "================================1265===================================\n",
      "1265/10000: train_loss: 4.054151721000671 train_error 49.88% test_error 54.00%\n",
      "================================1266===================================\n",
      "1266/10000: train_loss: 4.054165827333927 train_error 49.88% test_error 54.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1267===================================\n",
      "1267/10000: train_loss: 4.054179957807063 train_error 49.88% test_error 54.50%\n",
      "================================1268===================================\n",
      "1268/10000: train_loss: 4.054194088727236 train_error 49.88% test_error 54.50%\n",
      "================================1269===================================\n",
      "1269/10000: train_loss: 4.054208203107119 train_error 49.88% test_error 54.50%\n",
      "================================1270===================================\n",
      "1270/10000: train_loss: 4.054222222864627 train_error 49.88% test_error 54.50%\n",
      "================================1271===================================\n",
      "1271/10000: train_loss: 4.054236204326153 train_error 49.88% test_error 54.50%\n",
      "================================1272===================================\n",
      "1272/10000: train_loss: 4.0542501944303515 train_error 49.88% test_error 54.50%\n",
      "================================1273===================================\n",
      "1273/10000: train_loss: 4.054264164417981 train_error 49.88% test_error 54.50%\n",
      "================================1274===================================\n",
      "1274/10000: train_loss: 4.054278137534856 train_error 49.88% test_error 54.50%\n",
      "================================1275===================================\n",
      "1275/10000: train_loss: 4.054292110204697 train_error 49.88% test_error 55.00%\n",
      "================================1276===================================\n",
      "1276/10000: train_loss: 4.054306083470584 train_error 49.88% test_error 55.00%\n",
      "================================1277===================================\n",
      "1277/10000: train_loss: 4.054320103824138 train_error 49.88% test_error 55.00%\n",
      "================================1278===================================\n",
      "1278/10000: train_loss: 4.054334160685539 train_error 49.88% test_error 55.00%\n",
      "================================1279===================================\n",
      "1279/10000: train_loss: 4.054348199367523 train_error 49.88% test_error 55.00%\n",
      "================================1280===================================\n",
      "1280/10000: train_loss: 4.054362205862999 train_error 49.88% test_error 55.00%\n",
      "================================1281===================================\n",
      "1281/10000: train_loss: 4.054376176446676 train_error 49.88% test_error 55.00%\n",
      "================================1282===================================\n",
      "1282/10000: train_loss: 4.054390126764774 train_error 49.88% test_error 55.00%\n",
      "================================1283===================================\n",
      "1283/10000: train_loss: 4.054404084980487 train_error 49.88% test_error 55.00%\n",
      "================================1284===================================\n",
      "1284/10000: train_loss: 4.054418044090271 train_error 49.88% test_error 55.00%\n",
      "================================1285===================================\n",
      "1285/10000: train_loss: 4.054431989938021 train_error 49.88% test_error 55.00%\n",
      "================================1286===================================\n",
      "1286/10000: train_loss: 4.054445938766003 train_error 49.88% test_error 55.00%\n",
      "================================1287===================================\n",
      "1287/10000: train_loss: 4.054459894746541 train_error 49.88% test_error 55.00%\n",
      "================================1288===================================\n",
      "1288/10000: train_loss: 4.054473828822374 train_error 49.88% test_error 55.00%\n",
      "================================1289===================================\n",
      "1289/10000: train_loss: 4.05448778912425 train_error 49.88% test_error 55.00%\n",
      "================================1290===================================\n",
      "1290/10000: train_loss: 4.054501725435257 train_error 49.88% test_error 55.00%\n",
      "================================1291===================================\n",
      "1291/10000: train_loss: 4.054515686035156 train_error 49.88% test_error 55.00%\n",
      "================================1292===================================\n",
      "1292/10000: train_loss: 4.054529674053192 train_error 49.88% test_error 55.00%\n",
      "================================1293===================================\n",
      "1293/10000: train_loss: 4.054543694108725 train_error 49.88% test_error 55.00%\n",
      "================================1294===================================\n",
      "1294/10000: train_loss: 4.054557723253965 train_error 49.88% test_error 55.00%\n",
      "================================1295===================================\n",
      "1295/10000: train_loss: 4.0545717406272885 train_error 49.88% test_error 55.00%\n",
      "================================1296===================================\n",
      "1296/10000: train_loss: 4.054585843384266 train_error 50.00% test_error 55.00%\n",
      "================================1297===================================\n",
      "1297/10000: train_loss: 4.054599970132113 train_error 50.00% test_error 55.00%\n",
      "================================1298===================================\n",
      "1298/10000: train_loss: 4.054614135026932 train_error 50.12% test_error 55.00%\n",
      "================================1299===================================\n",
      "1299/10000: train_loss: 4.054628326445817 train_error 50.12% test_error 55.00%\n",
      "================================1300===================================\n",
      "1300/10000: train_loss: 4.05464249625802 train_error 50.12% test_error 55.00%\n",
      "================================1301===================================\n",
      "1301/10000: train_loss: 4.054656687378884 train_error 50.12% test_error 55.00%\n",
      "================================1302===================================\n",
      "1302/10000: train_loss: 4.054670846909284 train_error 50.12% test_error 55.00%\n",
      "================================1303===================================\n",
      "1303/10000: train_loss: 4.054685007631779 train_error 50.12% test_error 55.00%\n",
      "================================1304===================================\n",
      "1304/10000: train_loss: 4.05469917356968 train_error 50.12% test_error 55.00%\n",
      "================================1305===================================\n",
      "1305/10000: train_loss: 4.054713306576013 train_error 50.12% test_error 55.00%\n",
      "================================1306===================================\n",
      "1306/10000: train_loss: 4.054727459549904 train_error 50.12% test_error 55.00%\n",
      "================================1307===================================\n",
      "1307/10000: train_loss: 4.054741594195366 train_error 50.12% test_error 55.00%\n",
      "================================1308===================================\n",
      "1308/10000: train_loss: 4.054755691885948 train_error 50.12% test_error 55.00%\n",
      "================================1309===================================\n",
      "1309/10000: train_loss: 4.054769767224789 train_error 50.12% test_error 55.00%\n",
      "================================1310===================================\n",
      "1310/10000: train_loss: 4.054783810377121 train_error 50.12% test_error 55.00%\n",
      "================================1311===================================\n",
      "1311/10000: train_loss: 4.054797893315554 train_error 50.12% test_error 55.00%\n",
      "================================1312===================================\n",
      "1312/10000: train_loss: 4.054812039881945 train_error 50.12% test_error 55.00%\n",
      "================================1313===================================\n",
      "1313/10000: train_loss: 4.054826172590256 train_error 50.12% test_error 55.00%\n",
      "================================1314===================================\n",
      "1314/10000: train_loss: 4.054840261638165 train_error 50.12% test_error 55.00%\n",
      "================================1315===================================\n",
      "1315/10000: train_loss: 4.05485432356596 train_error 50.12% test_error 55.00%\n",
      "================================1316===================================\n",
      "1316/10000: train_loss: 4.054868399202824 train_error 50.12% test_error 55.00%\n",
      "================================1317===================================\n",
      "1317/10000: train_loss: 4.054882470965385 train_error 50.12% test_error 55.00%\n",
      "================================1318===================================\n",
      "1318/10000: train_loss: 4.054896543622017 train_error 50.12% test_error 55.00%\n",
      "================================1319===================================\n",
      "1319/10000: train_loss: 4.0549105949699875 train_error 50.12% test_error 55.00%\n",
      "================================1320===================================\n",
      "1320/10000: train_loss: 4.054924591481686 train_error 50.25% test_error 55.00%\n",
      "================================1321===================================\n",
      "1321/10000: train_loss: 4.054938536286354 train_error 50.25% test_error 55.00%\n",
      "================================1322===================================\n",
      "1322/10000: train_loss: 4.05495242908597 train_error 50.25% test_error 55.00%\n",
      "================================1323===================================\n",
      "1323/10000: train_loss: 4.054966308772564 train_error 50.25% test_error 55.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1324===================================\n",
      "1324/10000: train_loss: 4.054980184584856 train_error 50.25% test_error 55.00%\n",
      "================================1325===================================\n",
      "1325/10000: train_loss: 4.0549940603971475 train_error 50.25% test_error 55.00%\n",
      "================================1326===================================\n",
      "1326/10000: train_loss: 4.0550079329311846 train_error 50.25% test_error 55.00%\n",
      "================================1327===================================\n",
      "1327/10000: train_loss: 4.055021780580283 train_error 50.25% test_error 55.00%\n",
      "================================1328===================================\n",
      "1328/10000: train_loss: 4.055035499483347 train_error 50.25% test_error 55.00%\n",
      "================================1329===================================\n",
      "1329/10000: train_loss: 4.055049219280481 train_error 50.25% test_error 55.00%\n",
      "================================1330===================================\n",
      "1330/10000: train_loss: 4.055062911659479 train_error 50.25% test_error 55.00%\n",
      "================================1331===================================\n",
      "1331/10000: train_loss: 4.0550765113532545 train_error 50.25% test_error 55.00%\n",
      "================================1332===================================\n",
      "1332/10000: train_loss: 4.05509014070034 train_error 50.25% test_error 55.00%\n",
      "================================1333===================================\n",
      "1333/10000: train_loss: 4.055103728175164 train_error 50.25% test_error 55.00%\n",
      "================================1334===================================\n",
      "1334/10000: train_loss: 4.055117327570915 train_error 50.25% test_error 55.00%\n",
      "================================1335===================================\n",
      "1335/10000: train_loss: 4.0551310312747955 train_error 50.25% test_error 55.00%\n",
      "================================1336===================================\n",
      "1336/10000: train_loss: 4.055144772678614 train_error 50.25% test_error 55.00%\n",
      "================================1337===================================\n",
      "1337/10000: train_loss: 4.055158478766679 train_error 50.38% test_error 55.00%\n",
      "================================1338===================================\n",
      "1338/10000: train_loss: 4.055172060281039 train_error 50.38% test_error 55.00%\n",
      "================================1339===================================\n",
      "1339/10000: train_loss: 4.055185636281967 train_error 50.38% test_error 55.00%\n",
      "================================1340===================================\n",
      "1340/10000: train_loss: 4.055199201703071 train_error 50.38% test_error 55.00%\n",
      "================================1341===================================\n",
      "1341/10000: train_loss: 4.055212757885456 train_error 50.38% test_error 55.00%\n",
      "================================1342===================================\n",
      "1342/10000: train_loss: 4.0552263447642325 train_error 50.38% test_error 55.00%\n",
      "================================1343===================================\n",
      "1343/10000: train_loss: 4.055239986628294 train_error 50.38% test_error 55.00%\n",
      "================================1344===================================\n",
      "1344/10000: train_loss: 4.055253593623638 train_error 50.38% test_error 55.00%\n",
      "================================1345===================================\n",
      "1345/10000: train_loss: 4.055267212688923 train_error 50.38% test_error 55.00%\n",
      "================================1346===================================\n",
      "1346/10000: train_loss: 4.05528088003397 train_error 50.38% test_error 55.00%\n",
      "================================1347===================================\n",
      "1347/10000: train_loss: 4.055294585824013 train_error 50.38% test_error 55.00%\n",
      "================================1348===================================\n",
      "1348/10000: train_loss: 4.055308308154345 train_error 50.38% test_error 55.00%\n",
      "================================1349===================================\n",
      "1349/10000: train_loss: 4.055322057753801 train_error 50.38% test_error 55.00%\n",
      "================================1350===================================\n",
      "1350/10000: train_loss: 4.055335803031921 train_error 50.38% test_error 55.00%\n",
      "================================1351===================================\n",
      "1351/10000: train_loss: 4.055349561125039 train_error 50.38% test_error 55.00%\n",
      "================================1352===================================\n",
      "1352/10000: train_loss: 4.055363310724497 train_error 50.50% test_error 55.00%\n",
      "================================1353===================================\n",
      "1353/10000: train_loss: 4.055377013385296 train_error 50.50% test_error 55.00%\n",
      "================================1354===================================\n",
      "1354/10000: train_loss: 4.055390667170286 train_error 50.50% test_error 55.00%\n",
      "================================1355===================================\n",
      "1355/10000: train_loss: 4.055404327213764 train_error 50.50% test_error 55.00%\n",
      "================================1356===================================\n",
      "1356/10000: train_loss: 4.055418005883694 train_error 50.50% test_error 55.00%\n",
      "================================1357===================================\n",
      "1357/10000: train_loss: 4.055431730300188 train_error 50.50% test_error 55.00%\n",
      "================================1358===================================\n",
      "1358/10000: train_loss: 4.0554454585909845 train_error 50.50% test_error 55.00%\n",
      "================================1359===================================\n",
      "1359/10000: train_loss: 4.055459121763706 train_error 50.50% test_error 55.00%\n",
      "================================1360===================================\n",
      "1360/10000: train_loss: 4.05547274082899 train_error 50.50% test_error 55.00%\n",
      "================================1361===================================\n",
      "1361/10000: train_loss: 4.055486342012882 train_error 50.50% test_error 55.00%\n",
      "================================1362===================================\n",
      "1362/10000: train_loss: 4.055499933212996 train_error 50.50% test_error 55.00%\n",
      "================================1363===================================\n",
      "1363/10000: train_loss: 4.055513570010662 train_error 50.50% test_error 55.00%\n",
      "================================1364===================================\n",
      "1364/10000: train_loss: 4.055527154803276 train_error 50.62% test_error 55.00%\n",
      "================================1365===================================\n",
      "1365/10000: train_loss: 4.055540710687637 train_error 50.62% test_error 55.00%\n",
      "================================1366===================================\n",
      "1366/10000: train_loss: 4.055554281622172 train_error 50.62% test_error 55.00%\n",
      "================================1367===================================\n",
      "1367/10000: train_loss: 4.055567819327115 train_error 50.62% test_error 55.00%\n",
      "================================1368===================================\n",
      "1368/10000: train_loss: 4.055581363290548 train_error 50.62% test_error 55.00%\n",
      "================================1369===================================\n",
      "1369/10000: train_loss: 4.055594907402993 train_error 50.62% test_error 55.00%\n",
      "================================1370===================================\n",
      "1370/10000: train_loss: 4.055608441829681 train_error 50.62% test_error 55.00%\n",
      "================================1371===================================\n",
      "1371/10000: train_loss: 4.055621985346079 train_error 50.62% test_error 55.00%\n",
      "================================1372===================================\n",
      "1372/10000: train_loss: 4.055635490864515 train_error 50.62% test_error 55.00%\n",
      "================================1373===================================\n",
      "1373/10000: train_loss: 4.055649012327194 train_error 50.62% test_error 55.00%\n",
      "================================1374===================================\n",
      "1374/10000: train_loss: 4.055662528276444 train_error 50.62% test_error 55.00%\n",
      "================================1375===================================\n",
      "1375/10000: train_loss: 4.0556760346889495 train_error 50.62% test_error 55.00%\n",
      "================================1376===================================\n",
      "1376/10000: train_loss: 4.055689563304186 train_error 50.62% test_error 55.00%\n",
      "================================1377===================================\n",
      "1377/10000: train_loss: 4.055703055560589 train_error 50.75% test_error 55.00%\n",
      "================================1378===================================\n",
      "1378/10000: train_loss: 4.055716567933559 train_error 50.75% test_error 55.00%\n",
      "================================1379===================================\n",
      "1379/10000: train_loss: 4.055730072557926 train_error 50.75% test_error 55.00%\n",
      "================================1380===================================\n",
      "1380/10000: train_loss: 4.055743552595377 train_error 50.75% test_error 55.00%\n",
      "================================1381===================================\n",
      "1381/10000: train_loss: 4.055757058411837 train_error 50.75% test_error 55.00%\n",
      "================================1382===================================\n",
      "1382/10000: train_loss: 4.05577055901289 train_error 50.75% test_error 55.00%\n",
      "================================1383===================================\n",
      "1383/10000: train_loss: 4.055784021168947 train_error 50.75% test_error 55.00%\n",
      "================================1384===================================\n",
      "1384/10000: train_loss: 4.055797507464886 train_error 50.75% test_error 55.00%\n",
      "================================1385===================================\n",
      "1385/10000: train_loss: 4.055810984224081 train_error 50.75% test_error 55.00%\n",
      "================================1386===================================\n",
      "1386/10000: train_loss: 4.055824430137873 train_error 50.75% test_error 55.00%\n",
      "================================1387===================================\n",
      "1387/10000: train_loss: 4.055837829113006 train_error 50.75% test_error 55.00%\n",
      "================================1388===================================\n",
      "1388/10000: train_loss: 4.055851226747036 train_error 50.75% test_error 55.00%\n",
      "================================1389===================================\n",
      "1389/10000: train_loss: 4.055864597707987 train_error 50.75% test_error 55.00%\n",
      "================================1390===================================\n",
      "1390/10000: train_loss: 4.0558779475092885 train_error 50.75% test_error 55.50%\n",
      "================================1391===================================\n",
      "1391/10000: train_loss: 4.055891239196062 train_error 50.75% test_error 55.50%\n",
      "================================1392===================================\n",
      "1392/10000: train_loss: 4.05590445831418 train_error 50.75% test_error 55.50%\n",
      "================================1393===================================\n",
      "1393/10000: train_loss: 4.055917658656836 train_error 50.88% test_error 55.50%\n",
      "================================1394===================================\n",
      "1394/10000: train_loss: 4.055930873155594 train_error 50.88% test_error 55.50%\n",
      "================================1395===================================\n",
      "1395/10000: train_loss: 4.055943960249424 train_error 51.00% test_error 55.50%\n",
      "================================1396===================================\n",
      "1396/10000: train_loss: 4.055956945419311 train_error 51.00% test_error 55.50%\n",
      "================================1397===================================\n",
      "1397/10000: train_loss: 4.055969942808151 train_error 51.00% test_error 55.50%\n",
      "================================1398===================================\n",
      "1398/10000: train_loss: 4.055982887148857 train_error 51.00% test_error 55.50%\n",
      "================================1399===================================\n",
      "1399/10000: train_loss: 4.055995772778988 train_error 51.00% test_error 55.50%\n",
      "================================1400===================================\n",
      "1400/10000: train_loss: 4.056008666008712 train_error 51.00% test_error 55.50%\n",
      "================================1401===================================\n",
      "1401/10000: train_loss: 4.056021553874016 train_error 51.00% test_error 55.50%\n",
      "================================1402===================================\n",
      "1402/10000: train_loss: 4.056034419536591 train_error 51.00% test_error 55.50%\n",
      "================================1403===================================\n",
      "1403/10000: train_loss: 4.05604726806283 train_error 51.00% test_error 55.50%\n",
      "================================1404===================================\n",
      "1404/10000: train_loss: 4.056060132980347 train_error 51.00% test_error 55.50%\n",
      "================================1405===================================\n",
      "1405/10000: train_loss: 4.056072973012924 train_error 51.00% test_error 55.50%\n",
      "================================1406===================================\n",
      "1406/10000: train_loss: 4.056085790246725 train_error 51.00% test_error 55.50%\n",
      "================================1407===================================\n",
      "1407/10000: train_loss: 4.056098640859127 train_error 51.00% test_error 55.50%\n",
      "================================1408===================================\n",
      "1408/10000: train_loss: 4.05611145451665 train_error 51.00% test_error 55.50%\n",
      "================================1409===================================\n",
      "1409/10000: train_loss: 4.056124302893877 train_error 51.00% test_error 55.50%\n",
      "================================1410===================================\n",
      "1410/10000: train_loss: 4.056137171238661 train_error 51.00% test_error 55.50%\n",
      "================================1411===================================\n",
      "1411/10000: train_loss: 4.056150038987398 train_error 51.00% test_error 55.50%\n",
      "================================1412===================================\n",
      "1412/10000: train_loss: 4.056162911057473 train_error 51.00% test_error 55.50%\n",
      "================================1413===================================\n",
      "1413/10000: train_loss: 4.056175793111324 train_error 51.00% test_error 55.50%\n",
      "================================1414===================================\n",
      "1414/10000: train_loss: 4.056188733279706 train_error 51.00% test_error 55.50%\n",
      "================================1415===================================\n",
      "1415/10000: train_loss: 4.056201694756746 train_error 51.00% test_error 55.50%\n",
      "================================1416===================================\n",
      "1416/10000: train_loss: 4.056214643418789 train_error 51.00% test_error 55.50%\n",
      "================================1417===================================\n",
      "1417/10000: train_loss: 4.0562275931239125 train_error 51.00% test_error 55.50%\n",
      "================================1418===================================\n",
      "1418/10000: train_loss: 4.056240567266941 train_error 51.00% test_error 55.50%\n",
      "================================1419===================================\n",
      "1419/10000: train_loss: 4.056253511458635 train_error 51.00% test_error 55.50%\n",
      "================================1420===================================\n",
      "1420/10000: train_loss: 4.056266462504864 train_error 51.00% test_error 55.50%\n",
      "================================1421===================================\n",
      "1421/10000: train_loss: 4.05627939671278 train_error 51.00% test_error 55.50%\n",
      "================================1422===================================\n",
      "1422/10000: train_loss: 4.056292314082384 train_error 51.00% test_error 55.50%\n",
      "================================1423===================================\n",
      "1423/10000: train_loss: 4.056305247396231 train_error 51.00% test_error 55.50%\n",
      "================================1424===================================\n",
      "1424/10000: train_loss: 4.05631816253066 train_error 51.00% test_error 55.50%\n",
      "================================1425===================================\n",
      "1425/10000: train_loss: 4.056331065744161 train_error 51.00% test_error 55.50%\n",
      "================================1426===================================\n",
      "1426/10000: train_loss: 4.05634397700429 train_error 51.00% test_error 55.50%\n",
      "================================1427===================================\n",
      "1427/10000: train_loss: 4.056356880366803 train_error 51.00% test_error 55.50%\n",
      "================================1428===================================\n",
      "1428/10000: train_loss: 4.0563697464764115 train_error 51.00% test_error 55.50%\n",
      "================================1429===================================\n",
      "1429/10000: train_loss: 4.056382535845041 train_error 51.00% test_error 55.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1430===================================\n",
      "1430/10000: train_loss: 4.056395337283612 train_error 51.00% test_error 55.50%\n",
      "================================1431===================================\n",
      "1431/10000: train_loss: 4.056408152282238 train_error 51.00% test_error 55.50%\n",
      "================================1432===================================\n",
      "1432/10000: train_loss: 4.056420929282904 train_error 51.00% test_error 55.50%\n",
      "================================1433===================================\n",
      "1433/10000: train_loss: 4.056433717161417 train_error 51.00% test_error 55.50%\n",
      "================================1434===================================\n",
      "1434/10000: train_loss: 4.056446532011032 train_error 51.00% test_error 55.50%\n",
      "================================1435===================================\n",
      "1435/10000: train_loss: 4.056459347754717 train_error 51.00% test_error 55.50%\n",
      "================================1436===================================\n",
      "1436/10000: train_loss: 4.056472144275904 train_error 51.00% test_error 55.50%\n",
      "================================1437===================================\n",
      "1437/10000: train_loss: 4.0564849679172035 train_error 51.12% test_error 55.50%\n",
      "================================1438===================================\n",
      "1438/10000: train_loss: 4.056497770696879 train_error 51.12% test_error 55.50%\n",
      "================================1439===================================\n",
      "1439/10000: train_loss: 4.05651055753231 train_error 51.25% test_error 55.50%\n",
      "================================1440===================================\n",
      "1440/10000: train_loss: 4.056523338109255 train_error 51.25% test_error 55.50%\n",
      "================================1441===================================\n",
      "1441/10000: train_loss: 4.056536118090153 train_error 51.25% test_error 55.50%\n",
      "================================1442===================================\n",
      "1442/10000: train_loss: 4.056548888683319 train_error 51.25% test_error 55.50%\n",
      "================================1443===================================\n",
      "1443/10000: train_loss: 4.05656163752079 train_error 51.25% test_error 55.50%\n",
      "================================1444===================================\n",
      "1444/10000: train_loss: 4.056574358791113 train_error 51.25% test_error 55.50%\n",
      "================================1445===================================\n",
      "1445/10000: train_loss: 4.056587014645338 train_error 51.25% test_error 55.50%\n",
      "================================1446===================================\n",
      "1446/10000: train_loss: 4.0565996216237545 train_error 51.25% test_error 55.50%\n",
      "================================1447===================================\n",
      "1447/10000: train_loss: 4.0566121755540365 train_error 51.38% test_error 55.50%\n",
      "================================1448===================================\n",
      "1448/10000: train_loss: 4.056624815016985 train_error 51.38% test_error 55.50%\n",
      "================================1449===================================\n",
      "1449/10000: train_loss: 4.056637448370457 train_error 51.38% test_error 55.50%\n",
      "================================1450===================================\n",
      "1450/10000: train_loss: 4.056650090366602 train_error 51.38% test_error 55.50%\n",
      "================================1451===================================\n",
      "1451/10000: train_loss: 4.056662720739841 train_error 51.38% test_error 55.50%\n",
      "================================1452===================================\n",
      "1452/10000: train_loss: 4.056675335615873 train_error 51.38% test_error 55.50%\n",
      "================================1453===================================\n",
      "1453/10000: train_loss: 4.056687897890806 train_error 51.38% test_error 55.50%\n",
      "================================1454===================================\n",
      "1454/10000: train_loss: 4.056700394749642 train_error 51.38% test_error 55.50%\n",
      "================================1455===================================\n",
      "1455/10000: train_loss: 4.0567128653824325 train_error 51.38% test_error 55.50%\n",
      "================================1456===================================\n",
      "1456/10000: train_loss: 4.056725316047668 train_error 51.38% test_error 55.50%\n",
      "================================1457===================================\n",
      "1457/10000: train_loss: 4.0567377181351185 train_error 51.38% test_error 55.50%\n",
      "================================1458===================================\n",
      "1458/10000: train_loss: 4.0567500904202465 train_error 51.38% test_error 55.50%\n",
      "================================1459===================================\n",
      "1459/10000: train_loss: 4.056762299388647 train_error 51.38% test_error 55.50%\n",
      "================================1460===================================\n",
      "1460/10000: train_loss: 4.056774344444275 train_error 51.38% test_error 55.50%\n",
      "================================1461===================================\n",
      "1461/10000: train_loss: 4.0567863470315935 train_error 51.50% test_error 55.50%\n",
      "================================1462===================================\n",
      "1462/10000: train_loss: 4.056798244714737 train_error 51.50% test_error 55.50%\n",
      "================================1463===================================\n",
      "1463/10000: train_loss: 4.056810077428818 train_error 51.50% test_error 55.50%\n",
      "================================1464===================================\n",
      "1464/10000: train_loss: 4.056821890771388 train_error 51.50% test_error 55.50%\n",
      "================================1465===================================\n",
      "1465/10000: train_loss: 4.056833686828614 train_error 51.50% test_error 55.50%\n",
      "================================1466===================================\n",
      "1466/10000: train_loss: 4.056845444589853 train_error 51.50% test_error 55.50%\n",
      "================================1467===================================\n",
      "1467/10000: train_loss: 4.0568571951985355 train_error 51.50% test_error 55.50%\n",
      "================================1468===================================\n",
      "1468/10000: train_loss: 4.056868783831597 train_error 51.50% test_error 55.50%\n",
      "================================1469===================================\n",
      "1469/10000: train_loss: 4.056880331337451 train_error 51.62% test_error 55.50%\n",
      "================================1470===================================\n",
      "1470/10000: train_loss: 4.056891874521971 train_error 51.62% test_error 55.50%\n",
      "================================1471===================================\n",
      "1471/10000: train_loss: 4.056903424412013 train_error 51.62% test_error 55.50%\n",
      "================================1472===================================\n",
      "1472/10000: train_loss: 4.056914957463741 train_error 51.62% test_error 55.50%\n",
      "================================1473===================================\n",
      "1473/10000: train_loss: 4.0569264571368695 train_error 51.62% test_error 55.50%\n",
      "================================1474===================================\n",
      "1474/10000: train_loss: 4.056937923133374 train_error 51.62% test_error 55.50%\n",
      "================================1475===================================\n",
      "1475/10000: train_loss: 4.056949294507504 train_error 51.62% test_error 55.50%\n",
      "================================1476===================================\n",
      "1476/10000: train_loss: 4.056960669606924 train_error 51.62% test_error 55.50%\n",
      "================================1477===================================\n",
      "1477/10000: train_loss: 4.056972010880708 train_error 51.62% test_error 55.50%\n",
      "================================1478===================================\n",
      "1478/10000: train_loss: 4.056983354538679 train_error 51.62% test_error 55.50%\n",
      "================================1479===================================\n",
      "1479/10000: train_loss: 4.056994695514441 train_error 51.75% test_error 55.50%\n",
      "================================1480===================================\n",
      "1480/10000: train_loss: 4.057006026357413 train_error 51.75% test_error 55.50%\n",
      "================================1481===================================\n",
      "1481/10000: train_loss: 4.057017343938351 train_error 51.75% test_error 55.50%\n",
      "================================1482===================================\n",
      "1482/10000: train_loss: 4.057028655856848 train_error 51.75% test_error 55.50%\n",
      "================================1483===================================\n",
      "1483/10000: train_loss: 4.057040015757083 train_error 51.75% test_error 55.50%\n",
      "================================1484===================================\n",
      "1484/10000: train_loss: 4.057051351964474 train_error 51.75% test_error 55.50%\n",
      "================================1485===================================\n",
      "1485/10000: train_loss: 4.057062658518553 train_error 51.75% test_error 55.50%\n",
      "================================1486===================================\n",
      "1486/10000: train_loss: 4.057073856890202 train_error 51.75% test_error 55.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1487===================================\n",
      "1487/10000: train_loss: 4.057085050344467 train_error 51.75% test_error 55.50%\n",
      "================================1488===================================\n",
      "1488/10000: train_loss: 4.057096216082573 train_error 51.75% test_error 55.50%\n",
      "================================1489===================================\n",
      "1489/10000: train_loss: 4.057107406109571 train_error 51.75% test_error 55.50%\n",
      "================================1490===================================\n",
      "1490/10000: train_loss: 4.057118627578021 train_error 51.75% test_error 55.50%\n",
      "================================1491===================================\n",
      "1491/10000: train_loss: 4.057129607200623 train_error 51.75% test_error 55.50%\n",
      "================================1492===================================\n",
      "1492/10000: train_loss: 4.057140559852123 train_error 51.75% test_error 55.50%\n",
      "================================1493===================================\n",
      "1493/10000: train_loss: 4.0571513967216015 train_error 51.75% test_error 55.50%\n",
      "================================1494===================================\n",
      "1494/10000: train_loss: 4.057162272483111 train_error 51.75% test_error 55.50%\n",
      "================================1495===================================\n",
      "1495/10000: train_loss: 4.057173095494509 train_error 51.75% test_error 55.50%\n",
      "================================1496===================================\n",
      "1496/10000: train_loss: 4.057183851003646 train_error 51.75% test_error 55.50%\n",
      "================================1497===================================\n",
      "1497/10000: train_loss: 4.057194583863019 train_error 51.75% test_error 55.50%\n",
      "================================1498===================================\n",
      "1498/10000: train_loss: 4.057205313295126 train_error 51.75% test_error 55.50%\n",
      "================================1499===================================\n",
      "1499/10000: train_loss: 4.057216012179851 train_error 51.75% test_error 55.50%\n",
      "================================1500===================================\n",
      "1500/10000: train_loss: 4.057226668447256 train_error 51.75% test_error 55.50%\n",
      "================================1501===================================\n",
      "1501/10000: train_loss: 4.057237233668566 train_error 51.75% test_error 55.50%\n",
      "================================1502===================================\n",
      "1502/10000: train_loss: 4.057247793078423 train_error 51.75% test_error 55.50%\n",
      "================================1503===================================\n",
      "1503/10000: train_loss: 4.057258327901364 train_error 51.75% test_error 55.50%\n",
      "================================1504===================================\n",
      "1504/10000: train_loss: 4.057268854826688 train_error 51.75% test_error 55.50%\n",
      "================================1505===================================\n",
      "1505/10000: train_loss: 4.0572793903946875 train_error 51.75% test_error 55.50%\n",
      "================================1506===================================\n",
      "1506/10000: train_loss: 4.0572898852825166 train_error 51.75% test_error 55.50%\n",
      "================================1507===================================\n",
      "1507/10000: train_loss: 4.057300255000591 train_error 51.75% test_error 55.50%\n",
      "================================1508===================================\n",
      "1508/10000: train_loss: 4.057310622930527 train_error 51.75% test_error 55.50%\n",
      "================================1509===================================\n",
      "1509/10000: train_loss: 4.057320959717035 train_error 51.75% test_error 55.50%\n",
      "================================1510===================================\n",
      "1510/10000: train_loss: 4.05733123794198 train_error 51.75% test_error 55.50%\n",
      "================================1511===================================\n",
      "1511/10000: train_loss: 4.057341489493847 train_error 51.75% test_error 55.50%\n",
      "================================1512===================================\n",
      "1512/10000: train_loss: 4.057351773530245 train_error 51.75% test_error 55.50%\n",
      "================================1513===================================\n",
      "1513/10000: train_loss: 4.057362097650766 train_error 51.75% test_error 55.50%\n",
      "================================1514===================================\n",
      "1514/10000: train_loss: 4.057372333258391 train_error 51.75% test_error 55.50%\n",
      "================================1515===================================\n",
      "1515/10000: train_loss: 4.0573825155198575 train_error 51.75% test_error 55.50%\n",
      "================================1516===================================\n",
      "1516/10000: train_loss: 4.057392595261335 train_error 51.75% test_error 55.50%\n",
      "================================1517===================================\n",
      "1517/10000: train_loss: 4.057402669787407 train_error 51.75% test_error 55.50%\n",
      "================================1518===================================\n",
      "1518/10000: train_loss: 4.057412747442722 train_error 51.88% test_error 55.50%\n",
      "================================1519===================================\n",
      "1519/10000: train_loss: 4.057422705590725 train_error 51.88% test_error 55.50%\n",
      "================================1520===================================\n",
      "1520/10000: train_loss: 4.057432587891817 train_error 51.88% test_error 55.50%\n",
      "================================1521===================================\n",
      "1521/10000: train_loss: 4.057442467808723 train_error 51.88% test_error 55.50%\n",
      "================================1522===================================\n",
      "1522/10000: train_loss: 4.0574523448944095 train_error 51.88% test_error 55.50%\n",
      "================================1523===================================\n",
      "1523/10000: train_loss: 4.057462136298418 train_error 51.88% test_error 55.50%\n",
      "================================1524===================================\n",
      "1524/10000: train_loss: 4.057471841424704 train_error 51.88% test_error 55.50%\n",
      "================================1525===================================\n",
      "1525/10000: train_loss: 4.0574815370142465 train_error 51.88% test_error 55.50%\n",
      "================================1526===================================\n",
      "1526/10000: train_loss: 4.057491208910942 train_error 51.88% test_error 55.50%\n",
      "================================1527===================================\n",
      "1527/10000: train_loss: 4.057500817328691 train_error 51.88% test_error 55.50%\n",
      "================================1528===================================\n",
      "1528/10000: train_loss: 4.0575103387236595 train_error 51.88% test_error 55.50%\n",
      "================================1529===================================\n",
      "1529/10000: train_loss: 4.05751974672079 train_error 52.00% test_error 55.50%\n",
      "================================1530===================================\n",
      "1530/10000: train_loss: 4.057529111504555 train_error 52.00% test_error 55.50%\n",
      "================================1531===================================\n",
      "1531/10000: train_loss: 4.05753848940134 train_error 52.00% test_error 55.50%\n",
      "================================1532===================================\n",
      "1532/10000: train_loss: 4.057547831535339 train_error 52.00% test_error 55.50%\n",
      "================================1533===================================\n",
      "1533/10000: train_loss: 4.057557104676961 train_error 52.00% test_error 55.50%\n",
      "================================1534===================================\n",
      "1534/10000: train_loss: 4.057566314190627 train_error 52.00% test_error 55.50%\n",
      "================================1535===================================\n",
      "1535/10000: train_loss: 4.0575755411386485 train_error 52.00% test_error 55.50%\n",
      "================================1536===================================\n",
      "1536/10000: train_loss: 4.05758475959301 train_error 52.00% test_error 55.50%\n",
      "================================1537===================================\n",
      "1537/10000: train_loss: 4.057593975365162 train_error 52.00% test_error 55.50%\n",
      "================================1538===================================\n",
      "1538/10000: train_loss: 4.057603161931038 train_error 52.00% test_error 55.50%\n",
      "================================1539===================================\n",
      "1539/10000: train_loss: 4.057612334638834 train_error 52.00% test_error 56.00%\n",
      "================================1540===================================\n",
      "1540/10000: train_loss: 4.05762138992548 train_error 52.00% test_error 56.00%\n",
      "================================1541===================================\n",
      "1541/10000: train_loss: 4.057630430907011 train_error 52.00% test_error 56.00%\n",
      "================================1542===================================\n",
      "1542/10000: train_loss: 4.05763945132494 train_error 52.00% test_error 56.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1543===================================\n",
      "1543/10000: train_loss: 4.0576484276354305 train_error 52.00% test_error 56.00%\n",
      "================================1544===================================\n",
      "1544/10000: train_loss: 4.057657391726971 train_error 52.00% test_error 56.00%\n",
      "================================1545===================================\n",
      "1545/10000: train_loss: 4.057666278332472 train_error 52.00% test_error 56.00%\n",
      "================================1546===================================\n",
      "1546/10000: train_loss: 4.057675142586231 train_error 52.00% test_error 56.00%\n",
      "================================1547===================================\n",
      "1547/10000: train_loss: 4.0576839615404605 train_error 52.00% test_error 56.00%\n",
      "================================1548===================================\n",
      "1548/10000: train_loss: 4.0576926258206365 train_error 52.00% test_error 56.00%\n",
      "================================1549===================================\n",
      "1549/10000: train_loss: 4.057701302617788 train_error 52.00% test_error 56.00%\n",
      "================================1550===================================\n",
      "1550/10000: train_loss: 4.057709944397211 train_error 52.00% test_error 56.00%\n",
      "================================1551===================================\n",
      "1551/10000: train_loss: 4.057718478292227 train_error 52.00% test_error 56.00%\n",
      "================================1552===================================\n",
      "1552/10000: train_loss: 4.057726952582598 train_error 52.00% test_error 56.00%\n",
      "================================1553===================================\n",
      "1553/10000: train_loss: 4.057735415399074 train_error 52.00% test_error 56.50%\n",
      "================================1554===================================\n",
      "1554/10000: train_loss: 4.057743715494871 train_error 52.00% test_error 56.50%\n",
      "================================1555===================================\n",
      "1555/10000: train_loss: 4.057752022445202 train_error 52.00% test_error 56.50%\n",
      "================================1556===================================\n",
      "1556/10000: train_loss: 4.057760371565818 train_error 52.00% test_error 56.50%\n",
      "================================1557===================================\n",
      "1557/10000: train_loss: 4.057768668234348 train_error 52.00% test_error 56.50%\n",
      "================================1558===================================\n",
      "1558/10000: train_loss: 4.057776981443167 train_error 52.00% test_error 56.50%\n",
      "================================1559===================================\n",
      "1559/10000: train_loss: 4.057785247564317 train_error 52.00% test_error 56.50%\n",
      "================================1560===================================\n",
      "1560/10000: train_loss: 4.057793489992618 train_error 52.00% test_error 56.50%\n",
      "================================1561===================================\n",
      "1561/10000: train_loss: 4.05780172586441 train_error 52.00% test_error 56.50%\n",
      "================================1562===================================\n",
      "1562/10000: train_loss: 4.057809922099113 train_error 52.00% test_error 56.50%\n",
      "================================1563===================================\n",
      "1563/10000: train_loss: 4.057818154990673 train_error 52.00% test_error 56.50%\n",
      "================================1564===================================\n",
      "1564/10000: train_loss: 4.057826309502125 train_error 52.00% test_error 56.50%\n",
      "================================1565===================================\n",
      "1565/10000: train_loss: 4.05783444300294 train_error 52.00% test_error 56.50%\n",
      "================================1566===================================\n",
      "1566/10000: train_loss: 4.057842477411032 train_error 52.00% test_error 56.50%\n",
      "================================1567===================================\n",
      "1567/10000: train_loss: 4.057850290834904 train_error 52.00% test_error 56.50%\n",
      "================================1568===================================\n",
      "1568/10000: train_loss: 4.057857869267464 train_error 52.00% test_error 57.00%\n",
      "================================1569===================================\n",
      "1569/10000: train_loss: 4.0578654302656645 train_error 52.00% test_error 57.00%\n",
      "================================1570===================================\n",
      "1570/10000: train_loss: 4.057872982174159 train_error 52.00% test_error 57.00%\n",
      "================================1571===================================\n",
      "1571/10000: train_loss: 4.0578805553913115 train_error 52.00% test_error 57.00%\n",
      "================================1572===================================\n",
      "1572/10000: train_loss: 4.05788822710514 train_error 52.00% test_error 57.00%\n",
      "================================1573===================================\n",
      "1573/10000: train_loss: 4.057895895987749 train_error 52.00% test_error 57.00%\n",
      "================================1574===================================\n",
      "1574/10000: train_loss: 4.057903547435998 train_error 52.00% test_error 57.00%\n",
      "================================1575===================================\n",
      "1575/10000: train_loss: 4.0579111719131475 train_error 52.00% test_error 57.00%\n",
      "================================1576===================================\n",
      "1576/10000: train_loss: 4.057918792217969 train_error 52.00% test_error 57.00%\n",
      "================================1577===================================\n",
      "1577/10000: train_loss: 4.05792639374733 train_error 52.00% test_error 57.00%\n",
      "================================1578===================================\n",
      "1578/10000: train_loss: 4.057933977693319 train_error 52.12% test_error 57.00%\n",
      "================================1579===================================\n",
      "1579/10000: train_loss: 4.057941519469023 train_error 52.25% test_error 57.00%\n",
      "================================1580===================================\n",
      "1580/10000: train_loss: 4.057949088960886 train_error 52.25% test_error 57.00%\n",
      "================================1581===================================\n",
      "1581/10000: train_loss: 4.057956814318895 train_error 52.25% test_error 57.00%\n",
      "================================1582===================================\n",
      "1582/10000: train_loss: 4.057964549064636 train_error 52.25% test_error 57.00%\n",
      "================================1583===================================\n",
      "1583/10000: train_loss: 4.057972268313169 train_error 52.25% test_error 57.00%\n",
      "================================1584===================================\n",
      "1584/10000: train_loss: 4.057979977577925 train_error 52.25% test_error 57.00%\n",
      "================================1585===================================\n",
      "1585/10000: train_loss: 4.057987674325704 train_error 52.25% test_error 57.00%\n",
      "================================1586===================================\n",
      "1586/10000: train_loss: 4.057995347678661 train_error 52.25% test_error 57.00%\n",
      "================================1587===================================\n",
      "1587/10000: train_loss: 4.058002989292145 train_error 52.25% test_error 57.00%\n",
      "================================1588===================================\n",
      "1588/10000: train_loss: 4.05801065042615 train_error 52.25% test_error 57.00%\n",
      "================================1589===================================\n",
      "1589/10000: train_loss: 4.058018269240856 train_error 52.25% test_error 57.00%\n",
      "================================1590===================================\n",
      "1590/10000: train_loss: 4.0580257780849935 train_error 52.25% test_error 57.00%\n",
      "================================1591===================================\n",
      "1591/10000: train_loss: 4.058033196777105 train_error 52.25% test_error 57.00%\n",
      "================================1592===================================\n",
      "1592/10000: train_loss: 4.058040553778411 train_error 52.25% test_error 57.00%\n",
      "================================1593===================================\n",
      "1593/10000: train_loss: 4.058047915846109 train_error 52.25% test_error 57.00%\n",
      "================================1594===================================\n",
      "1594/10000: train_loss: 4.058055244088173 train_error 52.25% test_error 57.00%\n",
      "================================1595===================================\n",
      "1595/10000: train_loss: 4.058062483519316 train_error 52.25% test_error 57.00%\n",
      "================================1596===================================\n",
      "1596/10000: train_loss: 4.058069654852151 train_error 52.25% test_error 57.00%\n",
      "================================1597===================================\n",
      "1597/10000: train_loss: 4.058076894581318 train_error 52.25% test_error 57.00%\n",
      "================================1598===================================\n",
      "1598/10000: train_loss: 4.058084024488926 train_error 52.25% test_error 57.00%\n",
      "================================1599===================================\n",
      "1599/10000: train_loss: 4.058090963959694 train_error 52.25% test_error 57.00%\n",
      "================================1600===================================\n",
      "1600/10000: train_loss: 4.0580978353321555 train_error 52.25% test_error 57.00%\n",
      "================================1601===================================\n",
      "1601/10000: train_loss: 4.058104649186134 train_error 52.25% test_error 57.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1602===================================\n",
      "1602/10000: train_loss: 4.058111416399479 train_error 52.25% test_error 57.00%\n",
      "================================1603===================================\n",
      "1603/10000: train_loss: 4.058118162602186 train_error 52.25% test_error 57.00%\n",
      "================================1604===================================\n",
      "1604/10000: train_loss: 4.058124991208315 train_error 52.25% test_error 57.00%\n",
      "================================1605===================================\n",
      "1605/10000: train_loss: 4.058131907582283 train_error 52.25% test_error 57.00%\n",
      "================================1606===================================\n",
      "1606/10000: train_loss: 4.058138802945614 train_error 52.25% test_error 57.00%\n",
      "================================1607===================================\n",
      "1607/10000: train_loss: 4.05814569413662 train_error 52.25% test_error 57.00%\n",
      "================================1608===================================\n",
      "1608/10000: train_loss: 4.058152547031641 train_error 52.25% test_error 57.00%\n",
      "================================1609===================================\n",
      "1609/10000: train_loss: 4.058159364163876 train_error 52.25% test_error 57.00%\n",
      "================================1610===================================\n",
      "1610/10000: train_loss: 4.058166025876999 train_error 52.25% test_error 57.00%\n",
      "================================1611===================================\n",
      "1611/10000: train_loss: 4.058172329515219 train_error 52.25% test_error 57.00%\n",
      "================================1612===================================\n",
      "1612/10000: train_loss: 4.058178480416537 train_error 52.25% test_error 57.00%\n",
      "================================1613===================================\n",
      "1613/10000: train_loss: 4.058184462487698 train_error 52.25% test_error 57.00%\n",
      "================================1614===================================\n",
      "1614/10000: train_loss: 4.058190421313048 train_error 52.25% test_error 57.00%\n",
      "================================1615===================================\n",
      "1615/10000: train_loss: 4.058196359276772 train_error 52.25% test_error 57.00%\n",
      "================================1616===================================\n",
      "1616/10000: train_loss: 4.0582021138072015 train_error 52.25% test_error 57.00%\n",
      "================================1617===================================\n",
      "1617/10000: train_loss: 4.058207674026489 train_error 52.25% test_error 57.00%\n",
      "================================1618===================================\n",
      "1618/10000: train_loss: 4.058213162720203 train_error 52.25% test_error 57.00%\n",
      "================================1619===================================\n",
      "1619/10000: train_loss: 4.058218667507171 train_error 52.25% test_error 57.00%\n",
      "================================1620===================================\n",
      "1620/10000: train_loss: 4.058224068880081 train_error 52.25% test_error 57.00%\n",
      "================================1621===================================\n",
      "1621/10000: train_loss: 4.058229396045208 train_error 52.25% test_error 57.00%\n",
      "================================1622===================================\n",
      "1622/10000: train_loss: 4.058234750926495 train_error 52.25% test_error 57.00%\n",
      "================================1623===================================\n",
      "1623/10000: train_loss: 4.058240118771792 train_error 52.25% test_error 57.00%\n",
      "================================1624===================================\n",
      "1624/10000: train_loss: 4.058245484232903 train_error 52.25% test_error 57.00%\n",
      "================================1625===================================\n",
      "1625/10000: train_loss: 4.058250795304775 train_error 52.25% test_error 57.00%\n",
      "================================1626===================================\n",
      "1626/10000: train_loss: 4.058256084918976 train_error 52.25% test_error 57.00%\n",
      "================================1627===================================\n",
      "1627/10000: train_loss: 4.058261370807886 train_error 52.25% test_error 57.00%\n",
      "================================1628===================================\n",
      "1628/10000: train_loss: 4.058266622275114 train_error 52.25% test_error 57.00%\n",
      "================================1629===================================\n",
      "1629/10000: train_loss: 4.058271890431643 train_error 52.25% test_error 57.00%\n",
      "================================1630===================================\n",
      "1630/10000: train_loss: 4.058276903778315 train_error 52.25% test_error 57.00%\n",
      "================================1631===================================\n",
      "1631/10000: train_loss: 4.05828186661005 train_error 52.25% test_error 57.00%\n",
      "================================1632===================================\n",
      "1632/10000: train_loss: 4.058286845982075 train_error 52.25% test_error 57.00%\n",
      "================================1633===================================\n",
      "1633/10000: train_loss: 4.058291783332825 train_error 52.25% test_error 57.00%\n",
      "================================1634===================================\n",
      "1634/10000: train_loss: 4.058296693116426 train_error 52.25% test_error 57.00%\n",
      "================================1635===================================\n",
      "1635/10000: train_loss: 4.058301587998867 train_error 52.25% test_error 57.00%\n",
      "================================1636===================================\n",
      "1636/10000: train_loss: 4.058306437581778 train_error 52.25% test_error 57.00%\n",
      "================================1637===================================\n",
      "1637/10000: train_loss: 4.058311442136764 train_error 52.25% test_error 57.00%\n",
      "================================1638===================================\n",
      "1638/10000: train_loss: 4.058316468447447 train_error 52.25% test_error 57.00%\n",
      "================================1639===================================\n",
      "1639/10000: train_loss: 4.0583215087652205 train_error 52.25% test_error 57.00%\n",
      "================================1640===================================\n",
      "1640/10000: train_loss: 4.0583264707028865 train_error 52.25% test_error 57.00%\n",
      "================================1641===================================\n",
      "1641/10000: train_loss: 4.058331106007099 train_error 52.25% test_error 57.00%\n",
      "================================1642===================================\n",
      "1642/10000: train_loss: 4.058335607349873 train_error 52.25% test_error 57.00%\n",
      "================================1643===================================\n",
      "1643/10000: train_loss: 4.058340083509683 train_error 52.25% test_error 57.00%\n",
      "================================1644===================================\n",
      "1644/10000: train_loss: 4.058344683498143 train_error 52.38% test_error 57.00%\n",
      "================================1645===================================\n",
      "1645/10000: train_loss: 4.058349271118641 train_error 52.38% test_error 57.00%\n",
      "================================1646===================================\n",
      "1646/10000: train_loss: 4.058353650271893 train_error 52.38% test_error 57.00%\n",
      "================================1647===================================\n",
      "1647/10000: train_loss: 4.058357907980681 train_error 52.38% test_error 57.00%\n",
      "================================1648===================================\n",
      "1648/10000: train_loss: 4.058362164646388 train_error 52.38% test_error 57.00%\n",
      "================================1649===================================\n",
      "1649/10000: train_loss: 4.05836639791727 train_error 52.38% test_error 57.00%\n",
      "================================1650===================================\n",
      "1650/10000: train_loss: 4.058370606452227 train_error 52.38% test_error 57.00%\n",
      "================================1651===================================\n",
      "1651/10000: train_loss: 4.058374787271023 train_error 52.38% test_error 57.00%\n",
      "================================1652===================================\n",
      "1652/10000: train_loss: 4.058378952294588 train_error 52.38% test_error 57.00%\n",
      "================================1653===================================\n",
      "1653/10000: train_loss: 4.058383122980595 train_error 52.38% test_error 57.00%\n",
      "================================1654===================================\n",
      "1654/10000: train_loss: 4.0583871510624885 train_error 52.38% test_error 57.00%\n",
      "================================1655===================================\n",
      "1655/10000: train_loss: 4.05839096531272 train_error 52.38% test_error 57.00%\n",
      "================================1656===================================\n",
      "1656/10000: train_loss: 4.0583946478366855 train_error 52.38% test_error 57.00%\n",
      "================================1657===================================\n",
      "1657/10000: train_loss: 4.058398285359145 train_error 52.38% test_error 57.00%\n",
      "================================1658===================================\n",
      "1658/10000: train_loss: 4.058401903957129 train_error 52.38% test_error 57.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1659===================================\n",
      "1659/10000: train_loss: 4.058405462950468 train_error 52.38% test_error 57.00%\n",
      "================================1660===================================\n",
      "1660/10000: train_loss: 4.05840903967619 train_error 52.38% test_error 57.00%\n",
      "================================1661===================================\n",
      "1661/10000: train_loss: 4.058412617146969 train_error 52.38% test_error 57.00%\n",
      "================================1662===================================\n",
      "1662/10000: train_loss: 4.058416154384613 train_error 52.38% test_error 57.00%\n",
      "================================1663===================================\n",
      "1663/10000: train_loss: 4.058419820815325 train_error 52.38% test_error 57.00%\n",
      "================================1664===================================\n",
      "1664/10000: train_loss: 4.058423587828875 train_error 52.38% test_error 57.00%\n",
      "================================1665===================================\n",
      "1665/10000: train_loss: 4.05842733219266 train_error 52.38% test_error 57.00%\n",
      "================================1666===================================\n",
      "1666/10000: train_loss: 4.058431302905082 train_error 52.38% test_error 57.00%\n",
      "================================1667===================================\n",
      "1667/10000: train_loss: 4.058435168713331 train_error 52.38% test_error 57.00%\n",
      "================================1668===================================\n",
      "1668/10000: train_loss: 4.058438818752766 train_error 52.38% test_error 57.00%\n",
      "================================1669===================================\n",
      "1669/10000: train_loss: 4.058442378640175 train_error 52.38% test_error 57.00%\n",
      "================================1670===================================\n",
      "1670/10000: train_loss: 4.0584455211460595 train_error 52.38% test_error 57.00%\n",
      "================================1671===================================\n",
      "1671/10000: train_loss: 4.05844863831997 train_error 52.38% test_error 57.00%\n",
      "================================1672===================================\n",
      "1672/10000: train_loss: 4.058451718091964 train_error 52.38% test_error 57.00%\n",
      "================================1673===================================\n",
      "1673/10000: train_loss: 4.058454815596342 train_error 52.38% test_error 57.00%\n",
      "================================1674===================================\n",
      "1674/10000: train_loss: 4.058457851707935 train_error 52.38% test_error 57.00%\n",
      "================================1675===================================\n",
      "1675/10000: train_loss: 4.058460880815983 train_error 52.38% test_error 57.00%\n",
      "================================1676===================================\n",
      "1676/10000: train_loss: 4.0584638790786265 train_error 52.38% test_error 57.00%\n",
      "================================1677===================================\n",
      "1677/10000: train_loss: 4.058466858267784 train_error 52.38% test_error 57.00%\n",
      "================================1678===================================\n",
      "1678/10000: train_loss: 4.058469815850258 train_error 52.38% test_error 57.00%\n",
      "================================1679===================================\n",
      "1679/10000: train_loss: 4.058472641259431 train_error 52.38% test_error 57.00%\n",
      "================================1680===================================\n",
      "1680/10000: train_loss: 4.058475198149681 train_error 52.38% test_error 57.50%\n",
      "================================1681===================================\n",
      "1681/10000: train_loss: 4.058477909862995 train_error 52.38% test_error 57.50%\n",
      "================================1682===================================\n",
      "1682/10000: train_loss: 4.058480595946312 train_error 52.38% test_error 57.50%\n",
      "================================1683===================================\n",
      "1683/10000: train_loss: 4.058482912778855 train_error 52.38% test_error 57.50%\n",
      "================================1684===================================\n",
      "1684/10000: train_loss: 4.058485202342272 train_error 52.38% test_error 57.50%\n",
      "================================1685===================================\n",
      "1685/10000: train_loss: 4.058487476855516 train_error 52.38% test_error 57.50%\n",
      "================================1686===================================\n",
      "1686/10000: train_loss: 4.058489712029696 train_error 52.38% test_error 57.50%\n",
      "================================1687===================================\n",
      "1687/10000: train_loss: 4.058491931855679 train_error 52.38% test_error 57.50%\n",
      "================================1688===================================\n",
      "1688/10000: train_loss: 4.058494141995907 train_error 52.38% test_error 57.50%\n",
      "================================1689===================================\n",
      "1689/10000: train_loss: 4.058496311455965 train_error 52.38% test_error 57.50%\n",
      "================================1690===================================\n",
      "1690/10000: train_loss: 4.058498434871435 train_error 52.38% test_error 57.50%\n",
      "================================1691===================================\n",
      "1691/10000: train_loss: 4.058500621467829 train_error 52.38% test_error 57.50%\n",
      "================================1692===================================\n",
      "1692/10000: train_loss: 4.058502809405327 train_error 52.38% test_error 57.50%\n",
      "================================1693===================================\n",
      "1693/10000: train_loss: 4.058504599183798 train_error 52.38% test_error 57.50%\n",
      "================================1694===================================\n",
      "1694/10000: train_loss: 4.058506040722132 train_error 52.38% test_error 57.50%\n",
      "================================1695===================================\n",
      "1695/10000: train_loss: 4.0585073097050195 train_error 52.38% test_error 57.50%\n",
      "================================1696===================================\n",
      "1696/10000: train_loss: 4.058508578687906 train_error 52.50% test_error 57.50%\n",
      "================================1697===================================\n",
      "1697/10000: train_loss: 4.058509901612997 train_error 52.50% test_error 57.50%\n",
      "================================1698===================================\n",
      "1698/10000: train_loss: 4.058511200547218 train_error 52.50% test_error 57.50%\n",
      "================================1699===================================\n",
      "1699/10000: train_loss: 4.058512318581343 train_error 52.62% test_error 57.50%\n",
      "================================1700===================================\n",
      "1700/10000: train_loss: 4.058513369262219 train_error 52.62% test_error 57.50%\n",
      "================================1701===================================\n",
      "1701/10000: train_loss: 4.058514376878738 train_error 52.62% test_error 57.50%\n",
      "================================1702===================================\n",
      "1702/10000: train_loss: 4.058515548110009 train_error 52.62% test_error 57.50%\n",
      "================================1703===================================\n",
      "1703/10000: train_loss: 4.0585167428851125 train_error 52.62% test_error 57.50%\n",
      "================================1704===================================\n",
      "1704/10000: train_loss: 4.0585179786384105 train_error 52.62% test_error 57.50%\n",
      "================================1705===================================\n",
      "1705/10000: train_loss: 4.0585192187130446 train_error 52.62% test_error 57.50%\n",
      "================================1706===================================\n",
      "1706/10000: train_loss: 4.058520316630602 train_error 52.62% test_error 57.50%\n",
      "================================1707===================================\n",
      "1707/10000: train_loss: 4.058521419465542 train_error 52.62% test_error 57.50%\n",
      "================================1708===================================\n",
      "1708/10000: train_loss: 4.058522535562515 train_error 52.62% test_error 57.50%\n",
      "================================1709===================================\n",
      "1709/10000: train_loss: 4.058523549288512 train_error 52.62% test_error 57.50%\n",
      "================================1710===================================\n",
      "1710/10000: train_loss: 4.058524459004403 train_error 52.62% test_error 57.50%\n",
      "================================1711===================================\n",
      "1711/10000: train_loss: 4.058525354415178 train_error 52.62% test_error 57.50%\n",
      "================================1712===================================\n",
      "1712/10000: train_loss: 4.0585261140763755 train_error 52.62% test_error 57.50%\n",
      "================================1713===================================\n",
      "1713/10000: train_loss: 4.0585267804563046 train_error 52.62% test_error 57.50%\n",
      "================================1714===================================\n",
      "1714/10000: train_loss: 4.058527348190546 train_error 52.62% test_error 57.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1715===================================\n",
      "1715/10000: train_loss: 4.058527907133102 train_error 52.62% test_error 57.50%\n",
      "================================1716===================================\n",
      "1716/10000: train_loss: 4.0585284362733365 train_error 52.75% test_error 57.50%\n",
      "================================1717===================================\n",
      "1717/10000: train_loss: 4.058528962135314 train_error 52.75% test_error 57.50%\n",
      "================================1718===================================\n",
      "1718/10000: train_loss: 4.058529336601496 train_error 52.75% test_error 57.50%\n",
      "================================1719===================================\n",
      "1719/10000: train_loss: 4.058529544174672 train_error 52.75% test_error 57.50%\n",
      "================================1720===================================\n",
      "1720/10000: train_loss: 4.058529728949069 train_error 52.75% test_error 57.50%\n",
      "================================1721===================================\n",
      "1721/10000: train_loss: 4.058529820740223 train_error 52.75% test_error 57.50%\n",
      "================================1722===================================\n",
      "1722/10000: train_loss: 4.058529815524817 train_error 52.75% test_error 57.50%\n",
      "================================1723===================================\n",
      "1723/10000: train_loss: 4.058529779613019 train_error 52.75% test_error 57.50%\n",
      "================================1724===================================\n",
      "1724/10000: train_loss: 4.058529758006335 train_error 52.75% test_error 57.50%\n",
      "================================1725===================================\n",
      "1725/10000: train_loss: 4.058529672920704 train_error 52.75% test_error 57.50%\n",
      "================================1726===================================\n",
      "1726/10000: train_loss: 4.058529583215714 train_error 52.75% test_error 57.50%\n",
      "================================1727===================================\n",
      "1727/10000: train_loss: 4.058529543429613 train_error 52.75% test_error 57.50%\n",
      "================================1728===================================\n",
      "1728/10000: train_loss: 4.05852949142456 train_error 52.75% test_error 57.50%\n",
      "================================1729===================================\n",
      "1729/10000: train_loss: 4.058529401272535 train_error 52.75% test_error 57.50%\n",
      "================================1730===================================\n",
      "1730/10000: train_loss: 4.058529200851917 train_error 52.75% test_error 57.50%\n",
      "================================1731===================================\n",
      "1731/10000: train_loss: 4.058529002219439 train_error 52.75% test_error 57.50%\n",
      "================================1732===================================\n",
      "1732/10000: train_loss: 4.058528774529695 train_error 52.75% test_error 57.50%\n",
      "================================1733===================================\n",
      "1733/10000: train_loss: 4.058528342545033 train_error 52.75% test_error 57.50%\n",
      "================================1734===================================\n",
      "1734/10000: train_loss: 4.058527905195952 train_error 52.75% test_error 57.50%\n",
      "================================1735===================================\n",
      "1735/10000: train_loss: 4.0585273079574105 train_error 52.75% test_error 57.50%\n",
      "================================1736===================================\n",
      "1736/10000: train_loss: 4.05852646484971 train_error 52.75% test_error 57.50%\n",
      "================================1737===================================\n",
      "1737/10000: train_loss: 4.058525208383799 train_error 52.75% test_error 57.50%\n",
      "================================1738===================================\n",
      "1738/10000: train_loss: 4.058523882180452 train_error 52.75% test_error 57.50%\n",
      "================================1739===================================\n",
      "1739/10000: train_loss: 4.058522490561009 train_error 52.75% test_error 57.50%\n",
      "================================1740===================================\n",
      "1740/10000: train_loss: 4.058521098643541 train_error 52.75% test_error 57.50%\n",
      "================================1741===================================\n",
      "1741/10000: train_loss: 4.0585196803510195 train_error 52.75% test_error 57.50%\n",
      "================================1742===================================\n",
      "1742/10000: train_loss: 4.058518448770046 train_error 52.75% test_error 57.50%\n",
      "================================1743===================================\n",
      "1743/10000: train_loss: 4.058517262339592 train_error 52.75% test_error 57.50%\n",
      "================================1744===================================\n",
      "1744/10000: train_loss: 4.058516092896461 train_error 52.75% test_error 57.50%\n",
      "================================1745===================================\n",
      "1745/10000: train_loss: 4.058514466434717 train_error 52.75% test_error 57.50%\n",
      "================================1746===================================\n",
      "1746/10000: train_loss: 4.058512669503688 train_error 52.75% test_error 57.50%\n",
      "================================1747===================================\n",
      "1747/10000: train_loss: 4.05851085036993 train_error 52.75% test_error 57.50%\n",
      "================================1748===================================\n",
      "1748/10000: train_loss: 4.058509063571691 train_error 52.75% test_error 57.50%\n",
      "================================1749===================================\n",
      "1749/10000: train_loss: 4.058507194966078 train_error 52.75% test_error 57.50%\n",
      "================================1750===================================\n",
      "1750/10000: train_loss: 4.058505226075649 train_error 52.75% test_error 57.50%\n",
      "================================1751===================================\n",
      "1751/10000: train_loss: 4.0585032050311565 train_error 52.75% test_error 57.50%\n",
      "================================1752===================================\n",
      "1752/10000: train_loss: 4.058501145541668 train_error 52.75% test_error 57.50%\n",
      "================================1753===================================\n",
      "1753/10000: train_loss: 4.05849907681346 train_error 52.75% test_error 57.50%\n",
      "================================1754===================================\n",
      "1754/10000: train_loss: 4.058496986925602 train_error 52.75% test_error 57.50%\n",
      "================================1755===================================\n",
      "1755/10000: train_loss: 4.058494858294726 train_error 52.75% test_error 57.50%\n",
      "================================1756===================================\n",
      "1756/10000: train_loss: 4.058492514789105 train_error 52.75% test_error 57.50%\n",
      "================================1757===================================\n",
      "1757/10000: train_loss: 4.058490067571402 train_error 52.75% test_error 57.50%\n",
      "================================1758===================================\n",
      "1758/10000: train_loss: 4.058487571775913 train_error 52.75% test_error 57.50%\n",
      "================================1759===================================\n",
      "1759/10000: train_loss: 4.0584850673377515 train_error 52.75% test_error 57.50%\n",
      "================================1760===================================\n",
      "1760/10000: train_loss: 4.058482736200094 train_error 52.75% test_error 57.50%\n",
      "================================1761===================================\n",
      "1761/10000: train_loss: 4.058480322360992 train_error 52.75% test_error 57.50%\n",
      "================================1762===================================\n",
      "1762/10000: train_loss: 4.058477856814861 train_error 52.75% test_error 57.50%\n",
      "================================1763===================================\n",
      "1763/10000: train_loss: 4.05847538113594 train_error 52.75% test_error 57.50%\n",
      "================================1764===================================\n",
      "1764/10000: train_loss: 4.05847290545702 train_error 52.75% test_error 57.50%\n",
      "================================1765===================================\n",
      "1765/10000: train_loss: 4.0584702393412595 train_error 52.75% test_error 57.50%\n",
      "================================1766===================================\n",
      "1766/10000: train_loss: 4.05846742272377 train_error 52.75% test_error 57.50%\n",
      "================================1767===================================\n",
      "1767/10000: train_loss: 4.0584646321833135 train_error 52.75% test_error 57.50%\n",
      "================================1768===================================\n",
      "1768/10000: train_loss: 4.0584617105126375 train_error 52.75% test_error 57.50%\n",
      "================================1769===================================\n",
      "1769/10000: train_loss: 4.0584587833285335 train_error 52.75% test_error 57.50%\n",
      "================================1770===================================\n",
      "1770/10000: train_loss: 4.058455447852611 train_error 52.75% test_error 57.50%\n",
      "================================1771===================================\n",
      "1771/10000: train_loss: 4.0584520402550694 train_error 52.75% test_error 57.50%\n",
      "================================1772===================================\n",
      "1772/10000: train_loss: 4.058448578864336 train_error 52.88% test_error 57.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1773===================================\n",
      "1773/10000: train_loss: 4.058445116430521 train_error 52.88% test_error 57.50%\n",
      "================================1774===================================\n",
      "1774/10000: train_loss: 4.058441653102636 train_error 52.88% test_error 57.50%\n",
      "================================1775===================================\n",
      "1775/10000: train_loss: 4.058438113480807 train_error 52.88% test_error 57.50%\n",
      "================================1776===================================\n",
      "1776/10000: train_loss: 4.05843456864357 train_error 52.88% test_error 57.50%\n",
      "================================1777===================================\n",
      "1777/10000: train_loss: 4.058430804163217 train_error 52.88% test_error 57.50%\n",
      "================================1778===================================\n",
      "1778/10000: train_loss: 4.058426896035671 train_error 52.88% test_error 57.50%\n",
      "================================1779===================================\n",
      "1779/10000: train_loss: 4.0584229655563835 train_error 52.75% test_error 57.50%\n",
      "================================1780===================================\n",
      "1780/10000: train_loss: 4.05841897904873 train_error 52.75% test_error 57.50%\n",
      "================================1781===================================\n",
      "1781/10000: train_loss: 4.058414931744337 train_error 52.75% test_error 57.50%\n",
      "================================1782===================================\n",
      "1782/10000: train_loss: 4.0584107920527455 train_error 52.75% test_error 57.50%\n",
      "================================1783===================================\n",
      "1783/10000: train_loss: 4.058406799733639 train_error 52.75% test_error 57.50%\n",
      "================================1784===================================\n",
      "1784/10000: train_loss: 4.058402609080076 train_error 52.75% test_error 57.50%\n",
      "================================1785===================================\n",
      "1785/10000: train_loss: 4.05839804187417 train_error 52.75% test_error 57.50%\n",
      "================================1786===================================\n",
      "1786/10000: train_loss: 4.058393402546644 train_error 52.75% test_error 57.50%\n",
      "================================1787===================================\n",
      "1787/10000: train_loss: 4.0583887508511545 train_error 52.75% test_error 57.50%\n",
      "================================1788===================================\n",
      "1788/10000: train_loss: 4.058384065181016 train_error 52.75% test_error 57.50%\n",
      "================================1789===================================\n",
      "1789/10000: train_loss: 4.05837937131524 train_error 52.75% test_error 57.50%\n",
      "================================1790===================================\n",
      "1790/10000: train_loss: 4.058374664187431 train_error 52.75% test_error 57.50%\n",
      "================================1791===================================\n",
      "1791/10000: train_loss: 4.058369913250208 train_error 52.75% test_error 57.50%\n",
      "================================1792===================================\n",
      "1792/10000: train_loss: 4.058365150243045 train_error 52.75% test_error 57.50%\n",
      "================================1793===================================\n",
      "1793/10000: train_loss: 4.058360345065594 train_error 52.75% test_error 57.50%\n",
      "================================1794===================================\n",
      "1794/10000: train_loss: 4.058355430066586 train_error 52.75% test_error 57.50%\n",
      "================================1795===================================\n",
      "1795/10000: train_loss: 4.058350308388472 train_error 52.88% test_error 57.50%\n",
      "================================1796===================================\n",
      "1796/10000: train_loss: 4.058344982862472 train_error 52.88% test_error 57.50%\n",
      "================================1797===================================\n",
      "1797/10000: train_loss: 4.058339497894049 train_error 52.88% test_error 57.50%\n",
      "================================1798===================================\n",
      "1798/10000: train_loss: 4.058333971947431 train_error 52.88% test_error 57.50%\n",
      "================================1799===================================\n",
      "1799/10000: train_loss: 4.058328474164009 train_error 53.00% test_error 57.50%\n",
      "================================1800===================================\n",
      "1800/10000: train_loss: 4.058322898745537 train_error 53.00% test_error 57.50%\n",
      "================================1801===================================\n",
      "1801/10000: train_loss: 4.0583172979950906 train_error 53.00% test_error 57.50%\n",
      "================================1802===================================\n",
      "1802/10000: train_loss: 4.05831138908863 train_error 53.00% test_error 57.50%\n",
      "================================1803===================================\n",
      "1803/10000: train_loss: 4.058305363357068 train_error 53.00% test_error 58.00%\n",
      "================================1804===================================\n",
      "1804/10000: train_loss: 4.058299364447594 train_error 53.12% test_error 58.00%\n",
      "================================1805===================================\n",
      "1805/10000: train_loss: 4.058293359279633 train_error 53.12% test_error 58.00%\n",
      "================================1806===================================\n",
      "1806/10000: train_loss: 4.0582873386144644 train_error 53.12% test_error 58.00%\n",
      "================================1807===================================\n",
      "1807/10000: train_loss: 4.058281251937151 train_error 53.12% test_error 58.00%\n",
      "================================1808===================================\n",
      "1808/10000: train_loss: 4.058274918645621 train_error 53.12% test_error 58.00%\n",
      "================================1809===================================\n",
      "1809/10000: train_loss: 4.058268045186997 train_error 53.12% test_error 58.00%\n",
      "================================1810===================================\n",
      "1810/10000: train_loss: 4.0582606905698775 train_error 53.12% test_error 58.00%\n",
      "================================1811===================================\n",
      "1811/10000: train_loss: 4.058253149390221 train_error 53.12% test_error 58.00%\n",
      "================================1812===================================\n",
      "1812/10000: train_loss: 4.058245573192835 train_error 53.12% test_error 58.00%\n",
      "================================1813===================================\n",
      "1813/10000: train_loss: 4.058237947523594 train_error 53.12% test_error 58.00%\n",
      "================================1814===================================\n",
      "1814/10000: train_loss: 4.058230289965868 train_error 53.25% test_error 58.00%\n",
      "================================1815===================================\n",
      "1815/10000: train_loss: 4.05822254166007 train_error 53.25% test_error 58.50%\n",
      "================================1816===================================\n",
      "1816/10000: train_loss: 4.058214672058821 train_error 53.25% test_error 58.50%\n",
      "================================1817===================================\n",
      "1817/10000: train_loss: 4.05820669978857 train_error 53.25% test_error 58.50%\n",
      "================================1818===================================\n",
      "1818/10000: train_loss: 4.05819853886962 train_error 53.25% test_error 58.50%\n",
      "================================1819===================================\n",
      "1819/10000: train_loss: 4.0581902472674845 train_error 53.25% test_error 58.50%\n",
      "================================1820===================================\n",
      "1820/10000: train_loss: 4.058181806951762 train_error 53.25% test_error 58.50%\n",
      "================================1821===================================\n",
      "1821/10000: train_loss: 4.058173079639673 train_error 53.25% test_error 58.50%\n",
      "================================1822===================================\n",
      "1822/10000: train_loss: 4.058164095431566 train_error 53.25% test_error 58.50%\n",
      "================================1823===================================\n",
      "1823/10000: train_loss: 4.0581550325453275 train_error 53.25% test_error 58.50%\n",
      "================================1824===================================\n",
      "1824/10000: train_loss: 4.058145905286074 train_error 53.25% test_error 58.50%\n",
      "================================1825===================================\n",
      "1825/10000: train_loss: 4.058136767745018 train_error 53.25% test_error 58.50%\n",
      "================================1826===================================\n",
      "1826/10000: train_loss: 4.058127595037222 train_error 53.37% test_error 58.50%\n",
      "================================1827===================================\n",
      "1827/10000: train_loss: 4.0581184801459305 train_error 53.37% test_error 58.50%\n",
      "================================1828===================================\n",
      "1828/10000: train_loss: 4.058109374642372 train_error 53.37% test_error 58.50%\n",
      "================================1829===================================\n",
      "1829/10000: train_loss: 4.058100255280733 train_error 53.37% test_error 58.50%\n",
      "================================1830===================================\n",
      "1830/10000: train_loss: 4.05809101998806 train_error 53.37% test_error 58.50%\n",
      "================================1831===================================\n",
      "1831/10000: train_loss: 4.058081764280796 train_error 53.37% test_error 58.50%\n",
      "================================1832===================================\n",
      "1832/10000: train_loss: 4.058072344660759 train_error 53.37% test_error 58.50%\n",
      "================================1833===================================\n",
      "1833/10000: train_loss: 4.058062959462404 train_error 53.37% test_error 58.50%\n",
      "================================1834===================================\n",
      "1834/10000: train_loss: 4.0580535659193995 train_error 53.37% test_error 58.50%\n",
      "================================1835===================================\n",
      "1835/10000: train_loss: 4.058044206798076 train_error 53.37% test_error 58.50%\n",
      "================================1836===================================\n",
      "1836/10000: train_loss: 4.058034659922123 train_error 53.37% test_error 58.50%\n",
      "================================1837===================================\n",
      "1837/10000: train_loss: 4.058025064468383 train_error 53.37% test_error 58.50%\n",
      "================================1838===================================\n",
      "1838/10000: train_loss: 4.0580154490470886 train_error 53.50% test_error 58.50%\n",
      "================================1839===================================\n",
      "1839/10000: train_loss: 4.058005812466146 train_error 53.50% test_error 58.50%\n",
      "================================1840===================================\n",
      "1840/10000: train_loss: 4.057996147572995 train_error 53.50% test_error 58.50%\n",
      "================================1841===================================\n",
      "1841/10000: train_loss: 4.057986444979906 train_error 53.50% test_error 58.50%\n",
      "================================1842===================================\n",
      "1842/10000: train_loss: 4.057976697534323 train_error 53.50% test_error 58.50%\n",
      "================================1843===================================\n",
      "1843/10000: train_loss: 4.0579669272899626 train_error 53.50% test_error 58.50%\n",
      "================================1844===================================\n",
      "1844/10000: train_loss: 4.057957021147013 train_error 53.50% test_error 58.50%\n",
      "================================1845===================================\n",
      "1845/10000: train_loss: 4.057946954369545 train_error 53.50% test_error 58.50%\n",
      "================================1846===================================\n",
      "1846/10000: train_loss: 4.057936856895685 train_error 53.50% test_error 58.50%\n",
      "================================1847===================================\n",
      "1847/10000: train_loss: 4.057926473915577 train_error 53.50% test_error 58.50%\n",
      "================================1848===================================\n",
      "1848/10000: train_loss: 4.057915880978108 train_error 53.50% test_error 58.50%\n",
      "================================1849===================================\n",
      "1849/10000: train_loss: 4.0579051063954825 train_error 53.50% test_error 58.50%\n",
      "================================1850===================================\n",
      "1850/10000: train_loss: 4.05789407029748 train_error 53.50% test_error 58.50%\n",
      "================================1851===================================\n",
      "1851/10000: train_loss: 4.057883008122444 train_error 53.50% test_error 58.50%\n",
      "================================1852===================================\n",
      "1852/10000: train_loss: 4.057871920764446 train_error 53.50% test_error 58.50%\n",
      "================================1853===================================\n",
      "1853/10000: train_loss: 4.057860842049122 train_error 53.50% test_error 58.50%\n",
      "================================1854===================================\n",
      "1854/10000: train_loss: 4.0578497631847865 train_error 53.50% test_error 58.50%\n",
      "================================1855===================================\n",
      "1855/10000: train_loss: 4.057838788479566 train_error 53.50% test_error 58.50%\n",
      "================================1856===================================\n",
      "1856/10000: train_loss: 4.057827756851911 train_error 53.50% test_error 58.50%\n",
      "================================1857===================================\n",
      "1857/10000: train_loss: 4.057816650569439 train_error 53.50% test_error 58.50%\n",
      "================================1858===================================\n",
      "1858/10000: train_loss: 4.057805461287499 train_error 53.50% test_error 58.50%\n",
      "================================1859===================================\n",
      "1859/10000: train_loss: 4.057794238477945 train_error 53.50% test_error 58.50%\n",
      "================================1860===================================\n",
      "1860/10000: train_loss: 4.0577829708158974 train_error 53.50% test_error 58.50%\n",
      "================================1861===================================\n",
      "1861/10000: train_loss: 4.0577716542780395 train_error 53.50% test_error 58.50%\n",
      "================================1862===================================\n",
      "1862/10000: train_loss: 4.0577603285014625 train_error 53.50% test_error 58.50%\n",
      "================================1863===================================\n",
      "1863/10000: train_loss: 4.0577489513158795 train_error 53.50% test_error 58.50%\n",
      "================================1864===================================\n",
      "1864/10000: train_loss: 4.057737555205822 train_error 53.50% test_error 58.50%\n",
      "================================1865===================================\n",
      "1865/10000: train_loss: 4.05772598579526 train_error 53.50% test_error 58.50%\n",
      "================================1866===================================\n",
      "1866/10000: train_loss: 4.057714293897152 train_error 53.50% test_error 58.50%\n",
      "================================1867===================================\n",
      "1867/10000: train_loss: 4.057702573388815 train_error 53.50% test_error 58.50%\n",
      "================================1868===================================\n",
      "1868/10000: train_loss: 4.057690801918507 train_error 53.50% test_error 58.50%\n",
      "================================1869===================================\n",
      "1869/10000: train_loss: 4.057678750753403 train_error 53.50% test_error 58.50%\n",
      "================================1870===================================\n",
      "1870/10000: train_loss: 4.057666609436274 train_error 53.50% test_error 58.50%\n",
      "================================1871===================================\n",
      "1871/10000: train_loss: 4.057654429674148 train_error 53.50% test_error 58.50%\n",
      "================================1872===================================\n",
      "1872/10000: train_loss: 4.057642212808132 train_error 53.62% test_error 58.50%\n",
      "================================1873===================================\n",
      "1873/10000: train_loss: 4.057629999369382 train_error 53.75% test_error 58.50%\n",
      "================================1874===================================\n",
      "1874/10000: train_loss: 4.057617683112621 train_error 53.75% test_error 58.50%\n",
      "================================1875===================================\n",
      "1875/10000: train_loss: 4.057605237662791 train_error 53.75% test_error 58.50%\n",
      "================================1876===================================\n",
      "1876/10000: train_loss: 4.0575926521420485 train_error 53.75% test_error 58.50%\n",
      "================================1877===================================\n",
      "1877/10000: train_loss: 4.057579887211324 train_error 53.75% test_error 58.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1878===================================\n",
      "1878/10000: train_loss: 4.057566983401776 train_error 53.75% test_error 58.50%\n",
      "================================1879===================================\n",
      "1879/10000: train_loss: 4.0575539898872375 train_error 53.75% test_error 58.50%\n",
      "================================1880===================================\n",
      "1880/10000: train_loss: 4.057541274875402 train_error 53.75% test_error 58.50%\n",
      "================================1881===================================\n",
      "1881/10000: train_loss: 4.057528578788043 train_error 53.75% test_error 58.50%\n",
      "================================1882===================================\n",
      "1882/10000: train_loss: 4.057515864372253 train_error 53.75% test_error 58.50%\n",
      "================================1883===================================\n",
      "1883/10000: train_loss: 4.0575032204389565 train_error 53.75% test_error 58.50%\n",
      "================================1884===================================\n",
      "1884/10000: train_loss: 4.057490485906601 train_error 53.75% test_error 58.50%\n",
      "================================1885===================================\n",
      "1885/10000: train_loss: 4.057477694302797 train_error 53.75% test_error 58.50%\n",
      "================================1886===================================\n",
      "1886/10000: train_loss: 4.057465051859617 train_error 53.75% test_error 58.50%\n",
      "================================1887===================================\n",
      "1887/10000: train_loss: 4.057452358454466 train_error 53.75% test_error 58.50%\n",
      "================================1888===================================\n",
      "1888/10000: train_loss: 4.057439645975828 train_error 53.75% test_error 58.50%\n",
      "================================1889===================================\n",
      "1889/10000: train_loss: 4.0574269276857375 train_error 53.75% test_error 58.50%\n",
      "================================1890===================================\n",
      "1890/10000: train_loss: 4.057414227575064 train_error 53.75% test_error 58.50%\n",
      "================================1891===================================\n",
      "1891/10000: train_loss: 4.057401334792376 train_error 53.75% test_error 58.50%\n",
      "================================1892===================================\n",
      "1892/10000: train_loss: 4.057388210892677 train_error 53.75% test_error 58.50%\n",
      "================================1893===================================\n",
      "1893/10000: train_loss: 4.057375001311302 train_error 53.75% test_error 58.50%\n",
      "================================1894===================================\n",
      "1894/10000: train_loss: 4.057361834049225 train_error 53.75% test_error 58.50%\n",
      "================================1895===================================\n",
      "1895/10000: train_loss: 4.0573485952615735 train_error 53.75% test_error 58.50%\n",
      "================================1896===================================\n",
      "1896/10000: train_loss: 4.0573353472352025 train_error 53.75% test_error 58.50%\n",
      "================================1897===================================\n",
      "1897/10000: train_loss: 4.057322040498256 train_error 53.75% test_error 58.50%\n",
      "================================1898===================================\n",
      "1898/10000: train_loss: 4.057308711111546 train_error 53.75% test_error 58.50%\n",
      "================================1899===================================\n",
      "1899/10000: train_loss: 4.057295332998038 train_error 53.75% test_error 58.50%\n",
      "================================1900===================================\n",
      "1900/10000: train_loss: 4.057281864136457 train_error 53.75% test_error 58.50%\n",
      "================================1901===================================\n",
      "1901/10000: train_loss: 4.057268171012401 train_error 53.75% test_error 58.00%\n",
      "================================1902===================================\n",
      "1902/10000: train_loss: 4.05725426375866 train_error 53.75% test_error 58.00%\n",
      "================================1903===================================\n",
      "1903/10000: train_loss: 4.057239980250597 train_error 53.75% test_error 58.00%\n",
      "================================1904===================================\n",
      "1904/10000: train_loss: 4.057225650697946 train_error 53.75% test_error 58.00%\n",
      "================================1905===================================\n",
      "1905/10000: train_loss: 4.057211234867573 train_error 53.75% test_error 58.00%\n",
      "================================1906===================================\n",
      "1906/10000: train_loss: 4.057196689844131 train_error 53.75% test_error 58.00%\n",
      "================================1907===================================\n",
      "1907/10000: train_loss: 4.057182177156211 train_error 53.75% test_error 58.00%\n",
      "================================1908===================================\n",
      "1908/10000: train_loss: 4.057167777419091 train_error 53.75% test_error 58.00%\n",
      "================================1909===================================\n",
      "1909/10000: train_loss: 4.057153115570545 train_error 53.75% test_error 58.00%\n",
      "================================1910===================================\n",
      "1910/10000: train_loss: 4.057138374000788 train_error 53.75% test_error 58.50%\n",
      "================================1911===================================\n",
      "1911/10000: train_loss: 4.057123596221208 train_error 53.75% test_error 58.50%\n",
      "================================1912===================================\n",
      "1912/10000: train_loss: 4.057108504325152 train_error 53.75% test_error 58.50%\n",
      "================================1913===================================\n",
      "1913/10000: train_loss: 4.057093395441771 train_error 53.75% test_error 58.50%\n",
      "================================1914===================================\n",
      "1914/10000: train_loss: 4.057078214734792 train_error 53.75% test_error 58.50%\n",
      "================================1915===================================\n",
      "1915/10000: train_loss: 4.057062910348177 train_error 53.75% test_error 58.50%\n",
      "================================1916===================================\n",
      "1916/10000: train_loss: 4.057047555297613 train_error 53.75% test_error 58.50%\n",
      "================================1917===================================\n",
      "1917/10000: train_loss: 4.057032195180654 train_error 53.75% test_error 58.50%\n",
      "================================1918===================================\n",
      "1918/10000: train_loss: 4.05701688170433 train_error 53.75% test_error 58.50%\n",
      "================================1919===================================\n",
      "1919/10000: train_loss: 4.057001501470804 train_error 53.75% test_error 58.50%\n",
      "================================1920===================================\n",
      "1920/10000: train_loss: 4.056986154764891 train_error 53.75% test_error 58.50%\n",
      "================================1921===================================\n",
      "1921/10000: train_loss: 4.056970775872469 train_error 53.75% test_error 58.50%\n",
      "================================1922===================================\n",
      "1922/10000: train_loss: 4.0569551348686215 train_error 53.75% test_error 58.50%\n",
      "================================1923===================================\n",
      "1923/10000: train_loss: 4.056939266324044 train_error 53.75% test_error 58.50%\n",
      "================================1924===================================\n",
      "1924/10000: train_loss: 4.056923372298479 train_error 53.62% test_error 58.50%\n",
      "================================1925===================================\n",
      "1925/10000: train_loss: 4.056907387524843 train_error 53.62% test_error 58.50%\n",
      "================================1926===================================\n",
      "1926/10000: train_loss: 4.056891480982303 train_error 53.62% test_error 58.50%\n",
      "================================1927===================================\n",
      "1927/10000: train_loss: 4.056875637769699 train_error 53.62% test_error 58.50%\n",
      "================================1928===================================\n",
      "1928/10000: train_loss: 4.056859736889601 train_error 53.62% test_error 58.50%\n",
      "================================1929===================================\n",
      "1929/10000: train_loss: 4.056843880414963 train_error 53.62% test_error 58.50%\n",
      "================================1930===================================\n",
      "1930/10000: train_loss: 4.0568282230198385 train_error 53.62% test_error 58.50%\n",
      "================================1931===================================\n",
      "1931/10000: train_loss: 4.056812637299299 train_error 53.62% test_error 58.50%\n",
      "================================1932===================================\n",
      "1932/10000: train_loss: 4.056796917915345 train_error 53.75% test_error 58.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================1933===================================\n",
      "1933/10000: train_loss: 4.056780732870102 train_error 53.75% test_error 58.50%\n",
      "================================1934===================================\n",
      "1934/10000: train_loss: 4.056764483302832 train_error 53.75% test_error 58.50%\n",
      "================================1935===================================\n",
      "1935/10000: train_loss: 4.05674815967679 train_error 53.75% test_error 58.50%\n",
      "================================1936===================================\n",
      "1936/10000: train_loss: 4.056731479614973 train_error 53.62% test_error 58.50%\n",
      "================================1937===================================\n",
      "1937/10000: train_loss: 4.056714764982463 train_error 53.62% test_error 58.50%\n",
      "================================1938===================================\n",
      "1938/10000: train_loss: 4.056698016822338 train_error 53.62% test_error 58.50%\n",
      "================================1939===================================\n",
      "1939/10000: train_loss: 4.056681193709373 train_error 53.62% test_error 58.50%\n",
      "================================1940===================================\n",
      "1940/10000: train_loss: 4.056664274185897 train_error 53.62% test_error 58.50%\n",
      "================================1941===================================\n",
      "1941/10000: train_loss: 4.056647337079048 train_error 53.62% test_error 58.50%\n",
      "================================1942===================================\n",
      "1942/10000: train_loss: 4.056630342751741 train_error 53.62% test_error 58.50%\n",
      "================================1943===================================\n",
      "1943/10000: train_loss: 4.056613314002752 train_error 53.62% test_error 58.50%\n",
      "================================1944===================================\n",
      "1944/10000: train_loss: 4.056596291959286 train_error 53.62% test_error 58.50%\n",
      "================================1945===================================\n",
      "1945/10000: train_loss: 4.056579149067401 train_error 53.62% test_error 58.50%\n",
      "================================1946===================================\n",
      "1946/10000: train_loss: 4.056561983376742 train_error 53.62% test_error 58.50%\n",
      "================================1947===================================\n",
      "1947/10000: train_loss: 4.056544688493013 train_error 53.62% test_error 58.50%\n",
      "================================1948===================================\n",
      "1948/10000: train_loss: 4.056527069956064 train_error 53.62% test_error 58.50%\n",
      "================================1949===================================\n",
      "1949/10000: train_loss: 4.0565092021226885 train_error 53.62% test_error 58.50%\n",
      "================================1950===================================\n",
      "1950/10000: train_loss: 4.056491318792105 train_error 53.62% test_error 58.50%\n",
      "================================1951===================================\n",
      "1951/10000: train_loss: 4.056473708301782 train_error 53.62% test_error 58.50%\n",
      "================================1952===================================\n",
      "1952/10000: train_loss: 4.056456251442432 train_error 53.62% test_error 58.50%\n",
      "================================1953===================================\n",
      "1953/10000: train_loss: 4.056438735872508 train_error 53.62% test_error 58.50%\n",
      "================================1954===================================\n",
      "1954/10000: train_loss: 4.056421058028937 train_error 53.62% test_error 58.50%\n",
      "================================1955===================================\n",
      "1955/10000: train_loss: 4.056402838528156 train_error 53.62% test_error 58.50%\n",
      "================================1956===================================\n",
      "1956/10000: train_loss: 4.056384395211935 train_error 53.62% test_error 58.50%\n",
      "================================1957===================================\n",
      "1957/10000: train_loss: 4.056365919560194 train_error 53.62% test_error 58.50%\n",
      "================================1958===================================\n",
      "1958/10000: train_loss: 4.056347332000732 train_error 53.62% test_error 58.50%\n",
      "================================1959===================================\n",
      "1959/10000: train_loss: 4.056328714936971 train_error 53.62% test_error 58.50%\n",
      "================================1960===================================\n",
      "1960/10000: train_loss: 4.056310094892979 train_error 53.62% test_error 59.00%\n",
      "================================1961===================================\n",
      "1961/10000: train_loss: 4.05629139482975 train_error 53.62% test_error 59.00%\n",
      "================================1962===================================\n",
      "1962/10000: train_loss: 4.056272495388985 train_error 53.62% test_error 59.00%\n",
      "================================1963===================================\n",
      "1963/10000: train_loss: 4.056253532618284 train_error 53.62% test_error 59.50%\n",
      "================================1964===================================\n",
      "1964/10000: train_loss: 4.056234527230263 train_error 53.62% test_error 59.50%\n",
      "================================1965===================================\n",
      "1965/10000: train_loss: 4.0562153570353985 train_error 53.62% test_error 59.50%\n",
      "================================1966===================================\n",
      "1966/10000: train_loss: 4.05619609490037 train_error 53.62% test_error 59.50%\n",
      "================================1967===================================\n",
      "1967/10000: train_loss: 4.056176779270173 train_error 53.62% test_error 59.50%\n",
      "================================1968===================================\n",
      "1968/10000: train_loss: 4.056157375574112 train_error 53.62% test_error 59.50%\n",
      "================================1969===================================\n",
      "1969/10000: train_loss: 4.056137867569923 train_error 53.62% test_error 59.50%\n",
      "================================1970===================================\n",
      "1970/10000: train_loss: 4.0561183877289295 train_error 53.62% test_error 59.50%\n",
      "================================1971===================================\n",
      "1971/10000: train_loss: 4.056098875701427 train_error 53.62% test_error 59.50%\n",
      "================================1972===================================\n",
      "1972/10000: train_loss: 4.056079316139221 train_error 53.62% test_error 59.50%\n",
      "================================1973===================================\n",
      "1973/10000: train_loss: 4.05605970621109 train_error 53.62% test_error 59.50%\n",
      "================================1974===================================\n",
      "1974/10000: train_loss: 4.0560399125516415 train_error 53.62% test_error 59.50%\n",
      "================================1975===================================\n",
      "1975/10000: train_loss: 4.056019764393568 train_error 53.62% test_error 59.50%\n",
      "================================1976===================================\n",
      "1976/10000: train_loss: 4.0559993992745875 train_error 53.62% test_error 59.50%\n",
      "================================1977===================================\n",
      "1977/10000: train_loss: 4.055978586524725 train_error 53.62% test_error 59.50%\n",
      "================================1978===================================\n",
      "1978/10000: train_loss: 4.055957660079002 train_error 53.62% test_error 59.50%\n",
      "================================1979===================================\n",
      "1979/10000: train_loss: 4.055936770737171 train_error 53.62% test_error 59.50%\n",
      "================================1980===================================\n",
      "1980/10000: train_loss: 4.055915812551975 train_error 53.62% test_error 59.50%\n",
      "================================1981===================================\n",
      "1981/10000: train_loss: 4.055894620120525 train_error 53.62% test_error 59.50%\n",
      "================================1982===================================\n",
      "1982/10000: train_loss: 4.05587326541543 train_error 53.62% test_error 59.50%\n",
      "================================1983===================================\n",
      "1983/10000: train_loss: 4.055851822644472 train_error 53.62% test_error 59.50%\n",
      "================================1984===================================\n",
      "1984/10000: train_loss: 4.055830290317536 train_error 53.62% test_error 59.50%\n",
      "================================1985===================================\n",
      "1985/10000: train_loss: 4.0558084544539454 train_error 53.62% test_error 59.50%\n",
      "================================1986===================================\n",
      "1986/10000: train_loss: 4.055786465257406 train_error 53.62% test_error 59.50%\n",
      "================================1987===================================\n",
      "1987/10000: train_loss: 4.055764660388231 train_error 53.62% test_error 59.50%\n",
      "================================1988===================================\n",
      "1988/10000: train_loss: 4.055742817521095 train_error 53.62% test_error 59.50%\n",
      "================================1989===================================\n",
      "1989/10000: train_loss: 4.055720753073692 train_error 53.62% test_error 59.50%\n",
      "================================1990===================================\n",
      "1990/10000: train_loss: 4.055698647350073 train_error 53.62% test_error 59.50%\n",
      "================================1991===================================\n",
      "1991/10000: train_loss: 4.055676337331533 train_error 53.75% test_error 59.50%\n",
      "================================1992===================================\n",
      "1992/10000: train_loss: 4.055654152780771 train_error 53.62% test_error 59.50%\n",
      "================================1993===================================\n",
      "1993/10000: train_loss: 4.055631997287273 train_error 53.62% test_error 59.50%\n",
      "================================1994===================================\n",
      "1994/10000: train_loss: 4.055609792023897 train_error 53.62% test_error 59.50%\n",
      "================================1995===================================\n",
      "1995/10000: train_loss: 4.055587424337864 train_error 53.62% test_error 59.50%\n",
      "================================1996===================================\n",
      "1996/10000: train_loss: 4.055564811974763 train_error 53.62% test_error 59.50%\n",
      "================================1997===================================\n",
      "1997/10000: train_loss: 4.05554214373231 train_error 53.62% test_error 59.50%\n",
      "================================1998===================================\n",
      "1998/10000: train_loss: 4.055519329756498 train_error 53.62% test_error 59.50%\n",
      "================================1999===================================\n",
      "1999/10000: train_loss: 4.055496393293143 train_error 53.62% test_error 59.50%\n",
      "================================2000===================================\n",
      "2000/10000: train_loss: 4.055473399460316 train_error 53.62% test_error 60.00%\n",
      "================================2001===================================\n",
      "2001/10000: train_loss: 4.055450358241797 train_error 53.75% test_error 60.00%\n",
      "================================2002===================================\n",
      "2002/10000: train_loss: 4.055427267849446 train_error 53.75% test_error 60.00%\n",
      "================================2003===================================\n",
      "2003/10000: train_loss: 4.055404113531113 train_error 53.75% test_error 60.00%\n",
      "================================2004===================================\n",
      "2004/10000: train_loss: 4.055380734205246 train_error 53.75% test_error 60.00%\n",
      "================================2005===================================\n",
      "2005/10000: train_loss: 4.055357337146997 train_error 53.75% test_error 60.00%\n",
      "================================2006===================================\n",
      "2006/10000: train_loss: 4.055333855301141 train_error 53.75% test_error 60.00%\n",
      "================================2007===================================\n",
      "2007/10000: train_loss: 4.055310035794974 train_error 53.75% test_error 60.00%\n",
      "================================2008===================================\n",
      "2008/10000: train_loss: 4.055286080390215 train_error 53.75% test_error 60.00%\n",
      "================================2009===================================\n",
      "2009/10000: train_loss: 4.055262025892734 train_error 53.75% test_error 60.00%\n",
      "================================2010===================================\n",
      "2010/10000: train_loss: 4.055237956643104 train_error 53.75% test_error 60.00%\n",
      "================================2011===================================\n",
      "2011/10000: train_loss: 4.055213925540447 train_error 53.75% test_error 60.00%\n",
      "================================2012===================================\n",
      "2012/10000: train_loss: 4.055189815312623 train_error 53.75% test_error 60.00%\n",
      "================================2013===================================\n",
      "2013/10000: train_loss: 4.055165595263242 train_error 53.75% test_error 60.00%\n",
      "================================2014===================================\n",
      "2014/10000: train_loss: 4.05514126509428 train_error 53.75% test_error 60.00%\n",
      "================================2015===================================\n",
      "2015/10000: train_loss: 4.05511702671647 train_error 53.75% test_error 60.00%\n",
      "================================2016===================================\n",
      "2016/10000: train_loss: 4.055093003809452 train_error 53.75% test_error 60.00%\n",
      "================================2017===================================\n",
      "2017/10000: train_loss: 4.055068945139647 train_error 53.75% test_error 60.00%\n",
      "================================2018===================================\n",
      "2018/10000: train_loss: 4.055044831484556 train_error 53.75% test_error 60.00%\n",
      "================================2019===================================\n",
      "2019/10000: train_loss: 4.055020646899939 train_error 53.75% test_error 60.00%\n",
      "================================2020===================================\n",
      "2020/10000: train_loss: 4.054996369034052 train_error 53.75% test_error 60.00%\n",
      "================================2021===================================\n",
      "2021/10000: train_loss: 4.054971860349179 train_error 53.75% test_error 60.00%\n",
      "================================2022===================================\n",
      "2022/10000: train_loss: 4.05494697496295 train_error 53.75% test_error 60.00%\n",
      "================================2023===================================\n",
      "2023/10000: train_loss: 4.054921867549419 train_error 53.75% test_error 60.00%\n",
      "================================2024===================================\n",
      "2024/10000: train_loss: 4.054896588027477 train_error 53.75% test_error 60.00%\n",
      "================================2025===================================\n",
      "2025/10000: train_loss: 4.054871219694615 train_error 53.75% test_error 60.00%\n",
      "================================2026===================================\n",
      "2026/10000: train_loss: 4.054845712482929 train_error 53.75% test_error 60.00%\n",
      "================================2027===================================\n",
      "2027/10000: train_loss: 4.054820131361485 train_error 53.75% test_error 60.00%\n",
      "================================2028===================================\n",
      "2028/10000: train_loss: 4.054794484972954 train_error 53.75% test_error 60.00%\n",
      "================================2029===================================\n",
      "2029/10000: train_loss: 4.054768794924021 train_error 53.75% test_error 60.00%\n",
      "================================2030===================================\n",
      "2030/10000: train_loss: 4.054743116497994 train_error 53.75% test_error 60.00%\n",
      "================================2031===================================\n",
      "2031/10000: train_loss: 4.054717415124178 train_error 53.75% test_error 60.00%\n",
      "================================2032===================================\n",
      "2032/10000: train_loss: 4.054691629111767 train_error 53.75% test_error 60.00%\n",
      "================================2033===================================\n",
      "2033/10000: train_loss: 4.054665966629981 train_error 53.75% test_error 60.00%\n",
      "================================2034===================================\n",
      "2034/10000: train_loss: 4.054640404433012 train_error 53.75% test_error 60.00%\n",
      "================================2035===================================\n",
      "2035/10000: train_loss: 4.054614440798759 train_error 53.75% test_error 60.00%\n",
      "================================2036===================================\n",
      "2036/10000: train_loss: 4.054588406682014 train_error 53.75% test_error 60.00%\n",
      "================================2037===================================\n",
      "2037/10000: train_loss: 4.054562349319458 train_error 53.75% test_error 60.00%\n",
      "================================2038===================================\n",
      "2038/10000: train_loss: 4.0545362344384195 train_error 53.75% test_error 60.00%\n",
      "================================2039===================================\n",
      "2039/10000: train_loss: 4.054510045945644 train_error 53.87% test_error 60.00%\n",
      "================================2040===================================\n",
      "2040/10000: train_loss: 4.054483849555254 train_error 53.87% test_error 60.00%\n",
      "================================2041===================================\n",
      "2041/10000: train_loss: 4.054457637220621 train_error 53.87% test_error 60.00%\n",
      "================================2042===================================\n",
      "2042/10000: train_loss: 4.054431046694518 train_error 53.87% test_error 60.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2043===================================\n",
      "2043/10000: train_loss: 4.0544043250381945 train_error 53.87% test_error 60.00%\n",
      "================================2044===================================\n",
      "2044/10000: train_loss: 4.054377529621124 train_error 53.87% test_error 60.00%\n",
      "================================2045===================================\n",
      "2045/10000: train_loss: 4.054350678920747 train_error 53.87% test_error 60.00%\n",
      "================================2046===================================\n",
      "2046/10000: train_loss: 4.054323791265488 train_error 53.87% test_error 60.00%\n",
      "================================2047===================================\n",
      "2047/10000: train_loss: 4.054296756833792 train_error 53.87% test_error 60.00%\n",
      "================================2048===================================\n",
      "2048/10000: train_loss: 4.0542696146667 train_error 53.87% test_error 60.00%\n",
      "================================2049===================================\n",
      "2049/10000: train_loss: 4.054242821484804 train_error 53.87% test_error 60.00%\n",
      "================================2050===================================\n",
      "2050/10000: train_loss: 4.054216026812792 train_error 53.87% test_error 60.00%\n",
      "================================2051===================================\n",
      "2051/10000: train_loss: 4.0541891688108445 train_error 53.87% test_error 60.00%\n",
      "================================2052===================================\n",
      "2052/10000: train_loss: 4.054162266552448 train_error 53.87% test_error 60.00%\n",
      "================================2053===================================\n",
      "2053/10000: train_loss: 4.054135297685861 train_error 53.87% test_error 60.00%\n",
      "================================2054===================================\n",
      "2054/10000: train_loss: 4.054108342528343 train_error 53.87% test_error 60.00%\n",
      "================================2055===================================\n",
      "2055/10000: train_loss: 4.054081345051527 train_error 53.87% test_error 60.00%\n",
      "================================2056===================================\n",
      "2056/10000: train_loss: 4.054054339826107 train_error 54.00% test_error 60.00%\n",
      "================================2057===================================\n",
      "2057/10000: train_loss: 4.054027304053307 train_error 54.00% test_error 60.00%\n",
      "================================2058===================================\n",
      "2058/10000: train_loss: 4.054000233411789 train_error 54.00% test_error 60.00%\n",
      "================================2059===================================\n",
      "2059/10000: train_loss: 4.053973036259412 train_error 54.00% test_error 60.00%\n",
      "================================2060===================================\n",
      "2060/10000: train_loss: 4.053945769965648 train_error 54.00% test_error 60.00%\n",
      "================================2061===================================\n",
      "2061/10000: train_loss: 4.05391845986247 train_error 54.00% test_error 60.00%\n",
      "================================2062===================================\n",
      "2062/10000: train_loss: 4.053891068398953 train_error 54.00% test_error 60.00%\n",
      "================================2063===================================\n",
      "2063/10000: train_loss: 4.053863636255264 train_error 54.00% test_error 60.00%\n",
      "================================2064===================================\n",
      "2064/10000: train_loss: 4.053835958391428 train_error 54.00% test_error 60.00%\n",
      "================================2065===================================\n",
      "2065/10000: train_loss: 4.053807987719774 train_error 54.00% test_error 60.00%\n",
      "================================2066===================================\n",
      "2066/10000: train_loss: 4.0537799578905105 train_error 54.00% test_error 60.00%\n",
      "================================2067===================================\n",
      "2067/10000: train_loss: 4.053751883357763 train_error 54.00% test_error 60.00%\n",
      "================================2068===================================\n",
      "2068/10000: train_loss: 4.053723507374524 train_error 54.00% test_error 60.00%\n",
      "================================2069===================================\n",
      "2069/10000: train_loss: 4.053694845288992 train_error 54.00% test_error 60.00%\n",
      "================================2070===================================\n",
      "2070/10000: train_loss: 4.0536660991609095 train_error 54.00% test_error 60.00%\n",
      "================================2071===================================\n",
      "2071/10000: train_loss: 4.053637337833643 train_error 54.00% test_error 60.00%\n",
      "================================2072===================================\n",
      "2072/10000: train_loss: 4.0536085098981856 train_error 54.00% test_error 60.00%\n",
      "================================2073===================================\n",
      "2073/10000: train_loss: 4.053579730242491 train_error 54.00% test_error 60.00%\n",
      "================================2074===================================\n",
      "2074/10000: train_loss: 4.053550927788019 train_error 54.00% test_error 60.00%\n",
      "================================2075===================================\n",
      "2075/10000: train_loss: 4.053522270023823 train_error 54.00% test_error 60.00%\n",
      "================================2076===================================\n",
      "2076/10000: train_loss: 4.0534935337305065 train_error 54.00% test_error 60.00%\n",
      "================================2077===================================\n",
      "2077/10000: train_loss: 4.053464499861002 train_error 54.00% test_error 60.50%\n",
      "================================2078===================================\n",
      "2078/10000: train_loss: 4.053435205221176 train_error 54.00% test_error 60.50%\n",
      "================================2079===================================\n",
      "2079/10000: train_loss: 4.053405940532684 train_error 54.00% test_error 60.50%\n",
      "================================2080===================================\n",
      "2080/10000: train_loss: 4.053376624882222 train_error 54.00% test_error 60.50%\n",
      "================================2081===================================\n",
      "2081/10000: train_loss: 4.05334712356329 train_error 54.00% test_error 60.50%\n",
      "================================2082===================================\n",
      "2082/10000: train_loss: 4.053317503184081 train_error 54.00% test_error 61.00%\n",
      "================================2083===================================\n",
      "2083/10000: train_loss: 4.0532877470552915 train_error 54.12% test_error 61.00%\n",
      "================================2084===================================\n",
      "2084/10000: train_loss: 4.053257715851069 train_error 54.12% test_error 61.00%\n",
      "================================2085===================================\n",
      "2085/10000: train_loss: 4.053227756023407 train_error 54.12% test_error 61.00%\n",
      "================================2086===================================\n",
      "2086/10000: train_loss: 4.053197751045227 train_error 54.12% test_error 61.00%\n",
      "================================2087===================================\n",
      "2087/10000: train_loss: 4.053167695999146 train_error 54.12% test_error 61.00%\n",
      "================================2088===================================\n",
      "2088/10000: train_loss: 4.053137767463923 train_error 54.12% test_error 61.00%\n",
      "================================2089===================================\n",
      "2089/10000: train_loss: 4.053107898980379 train_error 54.12% test_error 61.00%\n",
      "================================2090===================================\n",
      "2090/10000: train_loss: 4.053077998757363 train_error 54.12% test_error 61.00%\n",
      "================================2091===================================\n",
      "2091/10000: train_loss: 4.053048003017903 train_error 54.12% test_error 61.00%\n",
      "================================2092===================================\n",
      "2092/10000: train_loss: 4.053017938137054 train_error 54.12% test_error 61.00%\n",
      "================================2093===================================\n",
      "2093/10000: train_loss: 4.052987811863423 train_error 54.12% test_error 61.00%\n",
      "================================2094===================================\n",
      "2094/10000: train_loss: 4.052957611382007 train_error 54.12% test_error 61.00%\n",
      "================================2095===================================\n",
      "2095/10000: train_loss: 4.052927346974611 train_error 54.12% test_error 61.00%\n",
      "================================2096===================================\n",
      "2096/10000: train_loss: 4.052897057384253 train_error 54.12% test_error 61.00%\n",
      "================================2097===================================\n",
      "2097/10000: train_loss: 4.052866658270359 train_error 54.12% test_error 61.00%\n",
      "================================2098===================================\n",
      "2098/10000: train_loss: 4.052835936397314 train_error 54.00% test_error 61.00%\n",
      "================================2099===================================\n",
      "2099/10000: train_loss: 4.052804907560349 train_error 54.00% test_error 61.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2100===================================\n",
      "2100/10000: train_loss: 4.052773839086294 train_error 54.00% test_error 61.00%\n",
      "================================2101===================================\n",
      "2101/10000: train_loss: 4.052742693871259 train_error 54.00% test_error 61.00%\n",
      "================================2102===================================\n",
      "2102/10000: train_loss: 4.052711504250764 train_error 54.00% test_error 61.00%\n",
      "================================2103===================================\n",
      "2103/10000: train_loss: 4.052680280804634 train_error 54.00% test_error 61.00%\n",
      "================================2104===================================\n",
      "2104/10000: train_loss: 4.052649082541466 train_error 54.00% test_error 61.00%\n",
      "================================2105===================================\n",
      "2105/10000: train_loss: 4.052617888748646 train_error 54.00% test_error 61.00%\n",
      "================================2106===================================\n",
      "2106/10000: train_loss: 4.052586706876755 train_error 54.00% test_error 61.00%\n",
      "================================2107===================================\n",
      "2107/10000: train_loss: 4.0525554749369626 train_error 54.00% test_error 61.00%\n",
      "================================2108===================================\n",
      "2108/10000: train_loss: 4.0525242365896705 train_error 54.00% test_error 61.00%\n",
      "================================2109===================================\n",
      "2109/10000: train_loss: 4.052492968589068 train_error 54.00% test_error 61.00%\n",
      "================================2110===================================\n",
      "2110/10000: train_loss: 4.052461714297533 train_error 53.87% test_error 61.00%\n",
      "================================2111===================================\n",
      "2111/10000: train_loss: 4.0524304410815235 train_error 53.87% test_error 61.00%\n",
      "================================2112===================================\n",
      "2112/10000: train_loss: 4.052399017065763 train_error 53.87% test_error 60.50%\n",
      "================================2113===================================\n",
      "2113/10000: train_loss: 4.052367232590914 train_error 53.87% test_error 60.50%\n",
      "================================2114===================================\n",
      "2114/10000: train_loss: 4.052335300594568 train_error 53.87% test_error 60.50%\n",
      "================================2115===================================\n",
      "2115/10000: train_loss: 4.052303361147642 train_error 53.87% test_error 60.50%\n",
      "================================2116===================================\n",
      "2116/10000: train_loss: 4.0522714273631575 train_error 53.87% test_error 60.50%\n",
      "================================2117===================================\n",
      "2117/10000: train_loss: 4.052239240556956 train_error 53.87% test_error 60.50%\n",
      "================================2118===================================\n",
      "2118/10000: train_loss: 4.052206796258688 train_error 53.87% test_error 60.50%\n",
      "================================2119===================================\n",
      "2119/10000: train_loss: 4.052174687236548 train_error 53.87% test_error 60.50%\n",
      "================================2120===================================\n",
      "2120/10000: train_loss: 4.052142447382212 train_error 53.87% test_error 60.50%\n",
      "================================2121===================================\n",
      "2121/10000: train_loss: 4.052110340744257 train_error 53.87% test_error 60.50%\n",
      "================================2122===================================\n",
      "2122/10000: train_loss: 4.052078214883805 train_error 53.87% test_error 60.00%\n",
      "================================2123===================================\n",
      "2123/10000: train_loss: 4.052046045660973 train_error 53.75% test_error 60.00%\n",
      "================================2124===================================\n",
      "2124/10000: train_loss: 4.052013753056526 train_error 53.75% test_error 60.00%\n",
      "================================2125===================================\n",
      "2125/10000: train_loss: 4.051981412172317 train_error 53.75% test_error 60.00%\n",
      "================================2126===================================\n",
      "2126/10000: train_loss: 4.051949062198401 train_error 53.75% test_error 60.00%\n",
      "================================2127===================================\n",
      "2127/10000: train_loss: 4.051916646808386 train_error 53.75% test_error 60.00%\n",
      "================================2128===================================\n",
      "2128/10000: train_loss: 4.051884229034186 train_error 53.75% test_error 60.00%\n",
      "================================2129===================================\n",
      "2129/10000: train_loss: 4.051851662397385 train_error 53.62% test_error 60.50%\n",
      "================================2130===================================\n",
      "2130/10000: train_loss: 4.05181903153658 train_error 53.62% test_error 60.50%\n",
      "================================2131===================================\n",
      "2131/10000: train_loss: 4.0517863021790985 train_error 53.62% test_error 60.50%\n",
      "================================2132===================================\n",
      "2132/10000: train_loss: 4.051753519922495 train_error 53.62% test_error 60.50%\n",
      "================================2133===================================\n",
      "2133/10000: train_loss: 4.051720635294915 train_error 53.75% test_error 60.50%\n",
      "================================2134===================================\n",
      "2134/10000: train_loss: 4.05168764308095 train_error 53.75% test_error 60.50%\n",
      "================================2135===================================\n",
      "2135/10000: train_loss: 4.051654572933913 train_error 53.75% test_error 60.50%\n",
      "================================2136===================================\n",
      "2136/10000: train_loss: 4.051621462106704 train_error 53.75% test_error 60.50%\n",
      "================================2137===================================\n",
      "2137/10000: train_loss: 4.051588283777237 train_error 53.75% test_error 60.50%\n",
      "================================2138===================================\n",
      "2138/10000: train_loss: 4.051554826050997 train_error 53.75% test_error 60.50%\n",
      "================================2139===================================\n",
      "2139/10000: train_loss: 4.051521037966013 train_error 53.75% test_error 60.50%\n",
      "================================2140===================================\n",
      "2140/10000: train_loss: 4.051487176567316 train_error 53.75% test_error 60.50%\n",
      "================================2141===================================\n",
      "2141/10000: train_loss: 4.051453285813331 train_error 53.75% test_error 60.50%\n",
      "================================2142===================================\n",
      "2142/10000: train_loss: 4.05141927599907 train_error 53.75% test_error 60.50%\n",
      "================================2143===================================\n",
      "2143/10000: train_loss: 4.051385159641505 train_error 53.75% test_error 60.50%\n",
      "================================2144===================================\n",
      "2144/10000: train_loss: 4.051350916475057 train_error 53.75% test_error 60.50%\n",
      "================================2145===================================\n",
      "2145/10000: train_loss: 4.051316429823636 train_error 53.75% test_error 60.50%\n",
      "================================2146===================================\n",
      "2146/10000: train_loss: 4.051281887739897 train_error 53.75% test_error 60.50%\n",
      "================================2147===================================\n",
      "2147/10000: train_loss: 4.051247390806675 train_error 53.75% test_error 60.50%\n",
      "================================2148===================================\n",
      "2148/10000: train_loss: 4.051212954819202 train_error 53.75% test_error 60.50%\n",
      "================================2149===================================\n",
      "2149/10000: train_loss: 4.051178763508797 train_error 53.75% test_error 60.50%\n",
      "================================2150===================================\n",
      "2150/10000: train_loss: 4.051144557148218 train_error 53.75% test_error 60.50%\n",
      "================================2151===================================\n",
      "2151/10000: train_loss: 4.051110094785691 train_error 53.75% test_error 60.50%\n",
      "================================2152===================================\n",
      "2152/10000: train_loss: 4.051075208038092 train_error 53.75% test_error 60.50%\n",
      "================================2153===================================\n",
      "2153/10000: train_loss: 4.0510401825606825 train_error 53.75% test_error 60.00%\n",
      "================================2154===================================\n",
      "2154/10000: train_loss: 4.051004836112261 train_error 53.75% test_error 60.00%\n",
      "================================2155===================================\n",
      "2155/10000: train_loss: 4.050969195961952 train_error 53.75% test_error 60.00%\n",
      "================================2156===================================\n",
      "2156/10000: train_loss: 4.050933513194322 train_error 53.75% test_error 60.00%\n",
      "================================2157===================================\n",
      "2157/10000: train_loss: 4.0508976589143275 train_error 53.87% test_error 60.00%\n",
      "================================2158===================================\n",
      "2158/10000: train_loss: 4.0508616848289964 train_error 53.75% test_error 60.00%\n",
      "================================2159===================================\n",
      "2159/10000: train_loss: 4.050825668126344 train_error 53.75% test_error 60.00%\n",
      "================================2160===================================\n",
      "2160/10000: train_loss: 4.050789381116629 train_error 53.75% test_error 60.00%\n",
      "================================2161===================================\n",
      "2161/10000: train_loss: 4.050752702206373 train_error 53.75% test_error 60.00%\n",
      "================================2162===================================\n",
      "2162/10000: train_loss: 4.050715892910958 train_error 53.75% test_error 60.00%\n",
      "================================2163===================================\n",
      "2163/10000: train_loss: 4.050679053366184 train_error 53.75% test_error 60.00%\n",
      "================================2164===================================\n",
      "2164/10000: train_loss: 4.050642429739236 train_error 53.62% test_error 60.00%\n",
      "================================2165===================================\n",
      "2165/10000: train_loss: 4.050605721175671 train_error 53.75% test_error 60.00%\n",
      "================================2166===================================\n",
      "2166/10000: train_loss: 4.050569001436234 train_error 53.75% test_error 60.00%\n",
      "================================2167===================================\n",
      "2167/10000: train_loss: 4.0505322119593625 train_error 53.75% test_error 60.00%\n",
      "================================2168===================================\n",
      "2168/10000: train_loss: 4.050495315790177 train_error 53.75% test_error 60.00%\n",
      "================================2169===================================\n",
      "2169/10000: train_loss: 4.050457918047905 train_error 53.75% test_error 60.00%\n",
      "================================2170===================================\n",
      "2170/10000: train_loss: 4.050420545339584 train_error 53.75% test_error 60.00%\n",
      "================================2171===================================\n",
      "2171/10000: train_loss: 4.05038292258978 train_error 53.75% test_error 60.00%\n",
      "================================2172===================================\n",
      "2172/10000: train_loss: 4.0503450205922125 train_error 53.75% test_error 60.00%\n",
      "================================2173===================================\n",
      "2173/10000: train_loss: 4.050306954234838 train_error 53.75% test_error 60.00%\n",
      "================================2174===================================\n",
      "2174/10000: train_loss: 4.050268842577934 train_error 53.87% test_error 60.00%\n",
      "================================2175===================================\n",
      "2175/10000: train_loss: 4.050230647623539 train_error 53.87% test_error 60.00%\n",
      "================================2176===================================\n",
      "2176/10000: train_loss: 4.050192642509937 train_error 53.87% test_error 60.00%\n",
      "================================2177===================================\n",
      "2177/10000: train_loss: 4.050154528617859 train_error 53.87% test_error 60.00%\n",
      "================================2178===================================\n",
      "2178/10000: train_loss: 4.0501162810623645 train_error 53.87% test_error 60.00%\n",
      "================================2179===================================\n",
      "2179/10000: train_loss: 4.05007807508111 train_error 53.87% test_error 60.00%\n",
      "================================2180===================================\n",
      "2180/10000: train_loss: 4.050039877444506 train_error 54.00% test_error 60.00%\n",
      "================================2181===================================\n",
      "2181/10000: train_loss: 4.0500016283988955 train_error 54.00% test_error 60.00%\n",
      "================================2182===================================\n",
      "2182/10000: train_loss: 4.049963321685792 train_error 54.00% test_error 60.00%\n",
      "================================2183===================================\n",
      "2183/10000: train_loss: 4.049924925118685 train_error 54.00% test_error 60.00%\n",
      "================================2184===================================\n",
      "2184/10000: train_loss: 4.049886423647404 train_error 54.00% test_error 60.00%\n",
      "================================2185===================================\n",
      "2185/10000: train_loss: 4.049847854226828 train_error 54.00% test_error 60.00%\n",
      "================================2186===================================\n",
      "2186/10000: train_loss: 4.049809200316668 train_error 54.00% test_error 60.00%\n",
      "================================2187===================================\n",
      "2187/10000: train_loss: 4.049769968241453 train_error 54.00% test_error 60.00%\n",
      "================================2188===================================\n",
      "2188/10000: train_loss: 4.049730352610349 train_error 54.00% test_error 60.00%\n",
      "================================2189===================================\n",
      "2189/10000: train_loss: 4.0496901312470435 train_error 54.00% test_error 60.00%\n",
      "================================2190===================================\n",
      "2190/10000: train_loss: 4.049649673253297 train_error 54.00% test_error 60.00%\n",
      "================================2191===================================\n",
      "2191/10000: train_loss: 4.049609291851521 train_error 54.00% test_error 60.00%\n",
      "================================2192===================================\n",
      "2192/10000: train_loss: 4.0495691411197186 train_error 54.00% test_error 60.00%\n",
      "================================2193===================================\n",
      "2193/10000: train_loss: 4.049528947621584 train_error 54.00% test_error 60.00%\n",
      "================================2194===================================\n",
      "2194/10000: train_loss: 4.049488778561353 train_error 54.00% test_error 60.00%\n",
      "================================2195===================================\n",
      "2195/10000: train_loss: 4.049448497444391 train_error 54.00% test_error 60.00%\n",
      "================================2196===================================\n",
      "2196/10000: train_loss: 4.049408141970634 train_error 54.00% test_error 60.00%\n",
      "================================2197===================================\n",
      "2197/10000: train_loss: 4.049367749840021 train_error 54.12% test_error 60.00%\n",
      "================================2198===================================\n",
      "2198/10000: train_loss: 4.049326909184456 train_error 54.12% test_error 60.00%\n",
      "================================2199===================================\n",
      "2199/10000: train_loss: 4.049285699129105 train_error 54.12% test_error 60.00%\n",
      "================================2200===================================\n",
      "2200/10000: train_loss: 4.0492445664107795 train_error 54.12% test_error 60.00%\n",
      "================================2201===================================\n",
      "2201/10000: train_loss: 4.049203713834286 train_error 54.12% test_error 60.00%\n",
      "================================2202===================================\n",
      "2202/10000: train_loss: 4.049163359552622 train_error 54.12% test_error 60.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2203===================================\n",
      "2203/10000: train_loss: 4.049123232960701 train_error 54.12% test_error 60.00%\n",
      "================================2204===================================\n",
      "2204/10000: train_loss: 4.049083035290241 train_error 54.12% test_error 60.00%\n",
      "================================2205===================================\n",
      "2205/10000: train_loss: 4.0490427400171765 train_error 54.25% test_error 60.00%\n",
      "================================2206===================================\n",
      "2206/10000: train_loss: 4.049002312272787 train_error 54.25% test_error 60.00%\n",
      "================================2207===================================\n",
      "2207/10000: train_loss: 4.048961904495955 train_error 54.25% test_error 60.00%\n",
      "================================2208===================================\n",
      "2208/10000: train_loss: 4.048921375423669 train_error 54.25% test_error 60.00%\n",
      "================================2209===================================\n",
      "2209/10000: train_loss: 4.04888073772192 train_error 54.25% test_error 60.00%\n",
      "================================2210===================================\n",
      "2210/10000: train_loss: 4.04883990868926 train_error 54.25% test_error 60.00%\n",
      "================================2211===================================\n",
      "2211/10000: train_loss: 4.048798960000276 train_error 54.25% test_error 60.00%\n",
      "================================2212===================================\n",
      "2212/10000: train_loss: 4.048757938891649 train_error 54.25% test_error 60.00%\n",
      "================================2213===================================\n",
      "2213/10000: train_loss: 4.04871667817235 train_error 54.25% test_error 60.00%\n",
      "================================2214===================================\n",
      "2214/10000: train_loss: 4.048675308227539 train_error 54.25% test_error 60.00%\n",
      "================================2215===================================\n",
      "2215/10000: train_loss: 4.048633776158094 train_error 54.25% test_error 60.00%\n",
      "================================2216===================================\n",
      "2216/10000: train_loss: 4.048592267930507 train_error 54.25% test_error 60.00%\n",
      "================================2217===================================\n",
      "2217/10000: train_loss: 4.048550656735897 train_error 54.25% test_error 60.00%\n",
      "================================2218===================================\n",
      "2218/10000: train_loss: 4.048509018421173 train_error 54.25% test_error 60.00%\n",
      "================================2219===================================\n",
      "2219/10000: train_loss: 4.048467410057783 train_error 54.25% test_error 60.00%\n",
      "================================2220===================================\n",
      "2220/10000: train_loss: 4.048425701707602 train_error 54.37% test_error 60.00%\n",
      "================================2221===================================\n",
      "2221/10000: train_loss: 4.048383942991496 train_error 54.37% test_error 60.00%\n",
      "================================2222===================================\n",
      "2222/10000: train_loss: 4.04834218531847 train_error 54.50% test_error 60.00%\n",
      "================================2223===================================\n",
      "2223/10000: train_loss: 4.048300413638353 train_error 54.50% test_error 60.00%\n",
      "================================2224===================================\n",
      "2224/10000: train_loss: 4.048258524388075 train_error 54.50% test_error 60.00%\n",
      "================================2225===================================\n",
      "2225/10000: train_loss: 4.048216607570648 train_error 54.50% test_error 60.00%\n",
      "================================2226===================================\n",
      "2226/10000: train_loss: 4.048174625486135 train_error 54.50% test_error 60.00%\n",
      "================================2227===================================\n",
      "2227/10000: train_loss: 4.048132603913546 train_error 54.50% test_error 60.00%\n",
      "================================2228===================================\n",
      "2228/10000: train_loss: 4.048090664297343 train_error 54.50% test_error 60.00%\n",
      "================================2229===================================\n",
      "2229/10000: train_loss: 4.048048612773418 train_error 54.50% test_error 60.00%\n",
      "================================2230===================================\n",
      "2230/10000: train_loss: 4.048006377220154 train_error 54.50% test_error 60.00%\n",
      "================================2231===================================\n",
      "2231/10000: train_loss: 4.047964072376489 train_error 54.50% test_error 60.00%\n",
      "================================2232===================================\n",
      "2232/10000: train_loss: 4.047921672016383 train_error 54.50% test_error 60.00%\n",
      "================================2233===================================\n",
      "2233/10000: train_loss: 4.04787922218442 train_error 54.50% test_error 60.00%\n",
      "================================2234===================================\n",
      "2234/10000: train_loss: 4.047836791872978 train_error 54.50% test_error 60.00%\n",
      "================================2235===================================\n",
      "2235/10000: train_loss: 4.0477942945063115 train_error 54.62% test_error 60.00%\n",
      "================================2236===================================\n",
      "2236/10000: train_loss: 4.047751679569483 train_error 54.62% test_error 60.00%\n",
      "================================2237===================================\n",
      "2237/10000: train_loss: 4.047708977013826 train_error 54.62% test_error 60.00%\n",
      "================================2238===================================\n",
      "2238/10000: train_loss: 4.047666531950235 train_error 54.62% test_error 60.00%\n",
      "================================2239===================================\n",
      "2239/10000: train_loss: 4.047624474167824 train_error 54.50% test_error 60.00%\n",
      "================================2240===================================\n",
      "2240/10000: train_loss: 4.04758236438036 train_error 54.50% test_error 60.00%\n",
      "================================2241===================================\n",
      "2241/10000: train_loss: 4.047540179342032 train_error 54.50% test_error 60.00%\n",
      "================================2242===================================\n",
      "2242/10000: train_loss: 4.047497951090336 train_error 54.50% test_error 60.00%\n",
      "================================2243===================================\n",
      "2243/10000: train_loss: 4.047455653399229 train_error 54.50% test_error 60.00%\n",
      "================================2244===================================\n",
      "2244/10000: train_loss: 4.047413345128298 train_error 54.50% test_error 60.00%\n",
      "================================2245===================================\n",
      "2245/10000: train_loss: 4.047371123582124 train_error 54.50% test_error 60.00%\n",
      "================================2246===================================\n",
      "2246/10000: train_loss: 4.047328836321831 train_error 54.50% test_error 60.00%\n",
      "================================2247===================================\n",
      "2247/10000: train_loss: 4.047286411076784 train_error 54.50% test_error 60.00%\n",
      "================================2248===================================\n",
      "2248/10000: train_loss: 4.047243894189597 train_error 54.50% test_error 60.00%\n",
      "================================2249===================================\n",
      "2249/10000: train_loss: 4.0472013410925864 train_error 54.50% test_error 60.00%\n",
      "================================2250===================================\n",
      "2250/10000: train_loss: 4.047158737331629 train_error 54.50% test_error 60.00%\n",
      "================================2251===================================\n",
      "2251/10000: train_loss: 4.0471161685884 train_error 54.50% test_error 60.00%\n",
      "================================2252===================================\n",
      "2252/10000: train_loss: 4.047073670774698 train_error 54.62% test_error 60.00%\n",
      "================================2253===================================\n",
      "2253/10000: train_loss: 4.047031158357859 train_error 54.62% test_error 60.00%\n",
      "================================2254===================================\n",
      "2254/10000: train_loss: 4.046988580226898 train_error 54.62% test_error 60.00%\n",
      "================================2255===================================\n",
      "2255/10000: train_loss: 4.046946022212506 train_error 54.62% test_error 60.00%\n",
      "================================2256===================================\n",
      "2256/10000: train_loss: 4.04690351486206 train_error 54.62% test_error 60.00%\n",
      "================================2257===================================\n",
      "2257/10000: train_loss: 4.04686101898551 train_error 54.62% test_error 60.00%\n",
      "================================2258===================================\n",
      "2258/10000: train_loss: 4.046818662434816 train_error 54.62% test_error 60.00%\n",
      "================================2259===================================\n",
      "2259/10000: train_loss: 4.046776530891656 train_error 54.62% test_error 60.00%\n",
      "================================2260===================================\n",
      "2260/10000: train_loss: 4.046734631210565 train_error 54.62% test_error 60.00%\n",
      "================================2261===================================\n",
      "2261/10000: train_loss: 4.046692824363709 train_error 54.62% test_error 60.00%\n",
      "================================2262===================================\n",
      "2262/10000: train_loss: 4.046651163697243 train_error 54.62% test_error 60.00%\n",
      "================================2263===================================\n",
      "2263/10000: train_loss: 4.046609009355307 train_error 54.62% test_error 60.00%\n",
      "================================2264===================================\n",
      "2264/10000: train_loss: 4.046567218601703 train_error 54.62% test_error 60.00%\n",
      "================================2265===================================\n",
      "2265/10000: train_loss: 4.046525383591652 train_error 54.62% test_error 60.00%\n",
      "================================2266===================================\n",
      "2266/10000: train_loss: 4.046483396291733 train_error 54.62% test_error 60.00%\n",
      "================================2267===================================\n",
      "2267/10000: train_loss: 4.046441176384688 train_error 54.62% test_error 60.00%\n",
      "================================2268===================================\n",
      "2268/10000: train_loss: 4.046398752480745 train_error 54.62% test_error 60.00%\n",
      "================================2269===================================\n",
      "2269/10000: train_loss: 4.046356301158666 train_error 54.62% test_error 60.00%\n",
      "================================2270===================================\n",
      "2270/10000: train_loss: 4.046313735693692 train_error 54.62% test_error 60.00%\n",
      "================================2271===================================\n",
      "2271/10000: train_loss: 4.046271110773087 train_error 54.50% test_error 60.00%\n",
      "================================2272===================================\n",
      "2272/10000: train_loss: 4.046228544861078 train_error 54.50% test_error 60.00%\n",
      "================================2273===================================\n",
      "2273/10000: train_loss: 4.046185931116343 train_error 54.50% test_error 60.00%\n",
      "================================2274===================================\n",
      "2274/10000: train_loss: 4.046143146902322 train_error 54.50% test_error 60.00%\n",
      "================================2275===================================\n",
      "2275/10000: train_loss: 4.046100466102361 train_error 54.50% test_error 60.00%\n",
      "================================2276===================================\n",
      "2276/10000: train_loss: 4.046057800352574 train_error 54.50% test_error 60.00%\n",
      "================================2277===================================\n",
      "2277/10000: train_loss: 4.046015069037676 train_error 54.50% test_error 60.00%\n",
      "================================2278===================================\n",
      "2278/10000: train_loss: 4.045972235947847 train_error 54.50% test_error 60.00%\n",
      "================================2279===================================\n",
      "2279/10000: train_loss: 4.045929367840291 train_error 54.50% test_error 60.00%\n",
      "================================2280===================================\n",
      "2280/10000: train_loss: 4.0458864603936675 train_error 54.62% test_error 60.00%\n",
      "================================2281===================================\n",
      "2281/10000: train_loss: 4.045843508094549 train_error 54.62% test_error 60.00%\n",
      "================================2282===================================\n",
      "2282/10000: train_loss: 4.04580050110817 train_error 54.62% test_error 60.00%\n",
      "================================2283===================================\n",
      "2283/10000: train_loss: 4.045757371634245 train_error 54.62% test_error 60.00%\n",
      "================================2284===================================\n",
      "2284/10000: train_loss: 4.045714106857776 train_error 54.62% test_error 60.00%\n",
      "================================2285===================================\n",
      "2285/10000: train_loss: 4.045670798569918 train_error 54.62% test_error 60.00%\n",
      "================================2286===================================\n",
      "2286/10000: train_loss: 4.045627446621657 train_error 54.75% test_error 60.00%\n",
      "================================2287===================================\n",
      "2287/10000: train_loss: 4.0455841204524035 train_error 54.62% test_error 60.00%\n",
      "================================2288===================================\n",
      "2288/10000: train_loss: 4.045540892928838 train_error 54.62% test_error 60.00%\n",
      "================================2289===================================\n",
      "2289/10000: train_loss: 4.045497746765613 train_error 54.62% test_error 60.00%\n",
      "================================2290===================================\n",
      "2290/10000: train_loss: 4.045454551726579 train_error 54.62% test_error 60.00%\n",
      "================================2291===================================\n",
      "2291/10000: train_loss: 4.045411307215691 train_error 54.75% test_error 60.00%\n",
      "================================2292===================================\n",
      "2292/10000: train_loss: 4.045368007868529 train_error 54.75% test_error 60.00%\n",
      "================================2293===================================\n",
      "2293/10000: train_loss: 4.045324736237526 train_error 54.75% test_error 60.00%\n",
      "================================2294===================================\n",
      "2294/10000: train_loss: 4.045281380563974 train_error 54.75% test_error 60.00%\n",
      "================================2295===================================\n",
      "2295/10000: train_loss: 4.045237953662873 train_error 54.87% test_error 60.00%\n",
      "================================2296===================================\n",
      "2296/10000: train_loss: 4.045194647908211 train_error 54.87% test_error 60.00%\n",
      "================================2297===================================\n",
      "2297/10000: train_loss: 4.0451514977216725 train_error 54.87% test_error 60.00%\n",
      "================================2298===================================\n",
      "2298/10000: train_loss: 4.04510837495327 train_error 54.87% test_error 60.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2299===================================\n",
      "2299/10000: train_loss: 4.0450651970505715 train_error 54.87% test_error 60.00%\n",
      "================================2300===================================\n",
      "2300/10000: train_loss: 4.04502183496952 train_error 54.87% test_error 60.00%\n",
      "================================2301===================================\n",
      "2301/10000: train_loss: 4.044978396594525 train_error 54.87% test_error 60.00%\n",
      "================================2302===================================\n",
      "2302/10000: train_loss: 4.044935034960508 train_error 54.87% test_error 60.00%\n",
      "================================2303===================================\n",
      "2303/10000: train_loss: 4.044891605079174 train_error 54.87% test_error 60.00%\n",
      "================================2304===================================\n",
      "2304/10000: train_loss: 4.044848049283027 train_error 55.00% test_error 60.00%\n",
      "================================2305===================================\n",
      "2305/10000: train_loss: 4.044804394692182 train_error 55.00% test_error 60.00%\n",
      "================================2306===================================\n",
      "2306/10000: train_loss: 4.04476075693965 train_error 55.00% test_error 60.00%\n",
      "================================2307===================================\n",
      "2307/10000: train_loss: 4.044717495143414 train_error 55.00% test_error 60.00%\n",
      "================================2308===================================\n",
      "2308/10000: train_loss: 4.044673989117145 train_error 54.87% test_error 60.00%\n",
      "================================2309===================================\n",
      "2309/10000: train_loss: 4.044630478024482 train_error 54.87% test_error 60.00%\n",
      "================================2310===================================\n",
      "2310/10000: train_loss: 4.044586879312992 train_error 54.87% test_error 60.00%\n",
      "================================2311===================================\n",
      "2311/10000: train_loss: 4.044543198049069 train_error 54.87% test_error 60.00%\n",
      "================================2312===================================\n",
      "2312/10000: train_loss: 4.044499475210905 train_error 54.87% test_error 60.00%\n",
      "================================2313===================================\n",
      "2313/10000: train_loss: 4.044455840736627 train_error 54.87% test_error 60.00%\n",
      "================================2314===================================\n",
      "2314/10000: train_loss: 4.044412234425545 train_error 55.00% test_error 60.00%\n",
      "================================2315===================================\n",
      "2315/10000: train_loss: 4.044368513673544 train_error 55.00% test_error 60.00%\n",
      "================================2316===================================\n",
      "2316/10000: train_loss: 4.044324530661106 train_error 55.00% test_error 60.00%\n",
      "================================2317===================================\n",
      "2317/10000: train_loss: 4.044280491173267 train_error 55.00% test_error 60.00%\n",
      "================================2318===================================\n",
      "2318/10000: train_loss: 4.044236727952957 train_error 55.00% test_error 60.00%\n",
      "================================2319===================================\n",
      "2319/10000: train_loss: 4.0441929829120635 train_error 55.00% test_error 60.00%\n",
      "================================2320===================================\n",
      "2320/10000: train_loss: 4.044149168431759 train_error 55.00% test_error 60.00%\n",
      "================================2321===================================\n",
      "2321/10000: train_loss: 4.044105102866888 train_error 55.00% test_error 60.00%\n",
      "================================2322===================================\n",
      "2322/10000: train_loss: 4.044060893654823 train_error 55.00% test_error 60.00%\n",
      "================================2323===================================\n",
      "2323/10000: train_loss: 4.044016654491424 train_error 55.00% test_error 60.00%\n",
      "================================2324===================================\n",
      "2324/10000: train_loss: 4.043972450345755 train_error 55.00% test_error 60.00%\n",
      "================================2325===================================\n",
      "2325/10000: train_loss: 4.043928493410348 train_error 55.00% test_error 60.00%\n",
      "================================2326===================================\n",
      "2326/10000: train_loss: 4.043884591311217 train_error 55.00% test_error 60.00%\n",
      "================================2327===================================\n",
      "2327/10000: train_loss: 4.043840670585633 train_error 55.00% test_error 60.00%\n",
      "================================2328===================================\n",
      "2328/10000: train_loss: 4.04379665568471 train_error 55.00% test_error 60.00%\n",
      "================================2329===================================\n",
      "2329/10000: train_loss: 4.043752673715352 train_error 55.00% test_error 60.00%\n",
      "================================2330===================================\n",
      "2330/10000: train_loss: 4.0437086533010005 train_error 55.00% test_error 60.00%\n",
      "================================2331===================================\n",
      "2331/10000: train_loss: 4.043664576560259 train_error 55.00% test_error 60.00%\n",
      "================================2332===================================\n",
      "2332/10000: train_loss: 4.043620367646218 train_error 55.00% test_error 60.00%\n",
      "================================2333===================================\n",
      "2333/10000: train_loss: 4.04357613325119 train_error 55.00% test_error 60.00%\n",
      "================================2334===================================\n",
      "2334/10000: train_loss: 4.04353201970458 train_error 55.00% test_error 60.00%\n",
      "================================2335===================================\n",
      "2335/10000: train_loss: 4.043487972021103 train_error 55.00% test_error 60.00%\n",
      "================================2336===================================\n",
      "2336/10000: train_loss: 4.043444059044123 train_error 55.00% test_error 60.00%\n",
      "================================2337===================================\n",
      "2337/10000: train_loss: 4.0434003119170665 train_error 55.00% test_error 60.00%\n",
      "================================2338===================================\n",
      "2338/10000: train_loss: 4.043356597870588 train_error 55.00% test_error 60.00%\n",
      "================================2339===================================\n",
      "2339/10000: train_loss: 4.043312860578299 train_error 55.12% test_error 60.00%\n",
      "================================2340===================================\n",
      "2340/10000: train_loss: 4.0432688690721985 train_error 55.12% test_error 60.00%\n",
      "================================2341===================================\n",
      "2341/10000: train_loss: 4.043224638700485 train_error 55.12% test_error 60.00%\n",
      "================================2342===================================\n",
      "2342/10000: train_loss: 4.0431804212927815 train_error 55.12% test_error 60.00%\n",
      "================================2343===================================\n",
      "2343/10000: train_loss: 4.04313610881567 train_error 55.12% test_error 60.00%\n",
      "================================2344===================================\n",
      "2344/10000: train_loss: 4.043091669231654 train_error 55.12% test_error 60.00%\n",
      "================================2345===================================\n",
      "2345/10000: train_loss: 4.043047168254852 train_error 55.12% test_error 60.00%\n",
      "================================2346===================================\n",
      "2346/10000: train_loss: 4.043002555817366 train_error 55.12% test_error 60.00%\n",
      "================================2347===================================\n",
      "2347/10000: train_loss: 4.042957827746868 train_error 55.12% test_error 60.00%\n",
      "================================2348===================================\n",
      "2348/10000: train_loss: 4.04291305243969 train_error 55.12% test_error 60.00%\n",
      "================================2349===================================\n",
      "2349/10000: train_loss: 4.04286818653345 train_error 55.12% test_error 60.00%\n",
      "================================2350===================================\n",
      "2350/10000: train_loss: 4.042823269814253 train_error 55.12% test_error 60.00%\n",
      "================================2351===================================\n",
      "2351/10000: train_loss: 4.0427782019972796 train_error 55.12% test_error 60.00%\n",
      "================================2352===================================\n",
      "2352/10000: train_loss: 4.042733075618744 train_error 55.12% test_error 60.00%\n",
      "================================2353===================================\n",
      "2353/10000: train_loss: 4.042688082754612 train_error 55.12% test_error 60.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2354===================================\n",
      "2354/10000: train_loss: 4.042643165141344 train_error 55.12% test_error 60.00%\n",
      "================================2355===================================\n",
      "2355/10000: train_loss: 4.042598205059766 train_error 55.12% test_error 60.00%\n",
      "================================2356===================================\n",
      "2356/10000: train_loss: 4.042553234100342 train_error 55.12% test_error 60.00%\n",
      "================================2357===================================\n",
      "2357/10000: train_loss: 4.042508211880922 train_error 55.12% test_error 60.00%\n",
      "================================2358===================================\n",
      "2358/10000: train_loss: 4.042463043779135 train_error 55.12% test_error 60.00%\n",
      "================================2359===================================\n",
      "2359/10000: train_loss: 4.0424177564680575 train_error 55.12% test_error 60.00%\n",
      "================================2360===================================\n",
      "2360/10000: train_loss: 4.042372447103261 train_error 55.12% test_error 60.00%\n",
      "================================2361===================================\n",
      "2361/10000: train_loss: 4.042326828539371 train_error 55.12% test_error 60.00%\n",
      "================================2362===================================\n",
      "2362/10000: train_loss: 4.042281100898981 train_error 55.12% test_error 60.00%\n",
      "================================2363===================================\n",
      "2363/10000: train_loss: 4.042235291153193 train_error 55.12% test_error 60.00%\n",
      "================================2364===================================\n",
      "2364/10000: train_loss: 4.042189433425666 train_error 55.12% test_error 60.50%\n",
      "================================2365===================================\n",
      "2365/10000: train_loss: 4.04214373216033 train_error 55.12% test_error 60.50%\n",
      "================================2366===================================\n",
      "2366/10000: train_loss: 4.042098326086998 train_error 55.12% test_error 60.50%\n",
      "================================2367===================================\n",
      "2367/10000: train_loss: 4.042052743732929 train_error 55.12% test_error 60.50%\n",
      "================================2368===================================\n",
      "2368/10000: train_loss: 4.042006948441267 train_error 55.12% test_error 60.50%\n",
      "================================2369===================================\n",
      "2369/10000: train_loss: 4.041961213797331 train_error 55.12% test_error 60.50%\n",
      "================================2370===================================\n",
      "2370/10000: train_loss: 4.041915808767081 train_error 55.12% test_error 60.50%\n",
      "================================2371===================================\n",
      "2371/10000: train_loss: 4.041870337575674 train_error 55.12% test_error 60.50%\n",
      "================================2372===================================\n",
      "2372/10000: train_loss: 4.04182493403554 train_error 55.12% test_error 60.50%\n",
      "================================2373===================================\n",
      "2373/10000: train_loss: 4.041779436618089 train_error 55.12% test_error 60.50%\n",
      "================================2374===================================\n",
      "2374/10000: train_loss: 4.041733869165182 train_error 55.12% test_error 60.50%\n",
      "================================2375===================================\n",
      "2375/10000: train_loss: 4.0416881744563575 train_error 55.12% test_error 60.50%\n",
      "================================2376===================================\n",
      "2376/10000: train_loss: 4.041642349213362 train_error 55.12% test_error 60.50%\n",
      "================================2377===================================\n",
      "2377/10000: train_loss: 4.041596440374851 train_error 55.12% test_error 60.50%\n",
      "================================2378===================================\n",
      "2378/10000: train_loss: 4.041550454199314 train_error 55.12% test_error 60.50%\n",
      "================================2379===================================\n",
      "2379/10000: train_loss: 4.041504634171725 train_error 55.25% test_error 60.50%\n",
      "================================2380===================================\n",
      "2380/10000: train_loss: 4.041458847820759 train_error 55.25% test_error 60.50%\n",
      "================================2381===================================\n",
      "2381/10000: train_loss: 4.0414130137860775 train_error 55.25% test_error 60.50%\n",
      "================================2382===================================\n",
      "2382/10000: train_loss: 4.041366906911135 train_error 55.38% test_error 60.50%\n",
      "================================2383===================================\n",
      "2383/10000: train_loss: 4.041320441961289 train_error 55.38% test_error 60.50%\n",
      "================================2384===================================\n",
      "2384/10000: train_loss: 4.0412737394869325 train_error 55.50% test_error 60.50%\n",
      "================================2385===================================\n",
      "2385/10000: train_loss: 4.041226333975793 train_error 55.50% test_error 60.50%\n",
      "================================2386===================================\n",
      "2386/10000: train_loss: 4.041179033666849 train_error 55.50% test_error 60.50%\n",
      "================================2387===================================\n",
      "2387/10000: train_loss: 4.041132008284331 train_error 55.50% test_error 60.50%\n",
      "================================2388===================================\n",
      "2388/10000: train_loss: 4.041085141897201 train_error 55.50% test_error 60.50%\n",
      "================================2389===================================\n",
      "2389/10000: train_loss: 4.041038266122341 train_error 55.50% test_error 60.50%\n",
      "================================2390===================================\n",
      "2390/10000: train_loss: 4.040991369187831 train_error 55.50% test_error 60.50%\n",
      "================================2391===================================\n",
      "2391/10000: train_loss: 4.04094432964921 train_error 55.50% test_error 60.50%\n",
      "================================2392===================================\n",
      "2392/10000: train_loss: 4.0408975203335284 train_error 55.50% test_error 60.50%\n",
      "================================2393===================================\n",
      "2393/10000: train_loss: 4.040850981771946 train_error 55.50% test_error 60.50%\n",
      "================================2394===================================\n",
      "2394/10000: train_loss: 4.04080444380641 train_error 55.50% test_error 60.50%\n",
      "================================2395===================================\n",
      "2395/10000: train_loss: 4.0407578112185 train_error 55.50% test_error 60.50%\n",
      "================================2396===================================\n",
      "2396/10000: train_loss: 4.040711135119199 train_error 55.50% test_error 61.00%\n",
      "================================2397===================================\n",
      "2397/10000: train_loss: 4.040664397329092 train_error 55.50% test_error 61.00%\n",
      "================================2398===================================\n",
      "2398/10000: train_loss: 4.040617535561323 train_error 55.50% test_error 61.00%\n",
      "================================2399===================================\n",
      "2399/10000: train_loss: 4.040570569038391 train_error 55.62% test_error 61.00%\n",
      "================================2400===================================\n",
      "2400/10000: train_loss: 4.040523805320263 train_error 55.62% test_error 61.00%\n",
      "================================2401===================================\n",
      "2401/10000: train_loss: 4.040477080643177 train_error 55.62% test_error 61.00%\n",
      "================================2402===================================\n",
      "2402/10000: train_loss: 4.040430169850588 train_error 55.62% test_error 61.00%\n",
      "================================2403===================================\n",
      "2403/10000: train_loss: 4.040383058041335 train_error 55.62% test_error 61.00%\n",
      "================================2404===================================\n",
      "2404/10000: train_loss: 4.040335899591446 train_error 55.62% test_error 61.00%\n",
      "================================2405===================================\n",
      "2405/10000: train_loss: 4.040288654118776 train_error 55.62% test_error 61.00%\n",
      "================================2406===================================\n",
      "2406/10000: train_loss: 4.040241021811962 train_error 55.62% test_error 61.00%\n",
      "================================2407===================================\n",
      "2407/10000: train_loss: 4.040193066447973 train_error 55.62% test_error 61.00%\n",
      "================================2408===================================\n",
      "2408/10000: train_loss: 4.0401448990404605 train_error 55.50% test_error 61.00%\n",
      "================================2409===================================\n",
      "2409/10000: train_loss: 4.040096704214811 train_error 55.50% test_error 61.00%\n",
      "================================2410===================================\n",
      "2410/10000: train_loss: 4.040048472583294 train_error 55.50% test_error 61.00%\n",
      "================================2411===================================\n",
      "2411/10000: train_loss: 4.040000086128712 train_error 55.50% test_error 61.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2412===================================\n",
      "2412/10000: train_loss: 4.039951688200235 train_error 55.50% test_error 61.00%\n",
      "================================2413===================================\n",
      "2413/10000: train_loss: 4.039903453886509 train_error 55.50% test_error 61.00%\n",
      "================================2414===================================\n",
      "2414/10000: train_loss: 4.03985531270504 train_error 55.50% test_error 61.00%\n",
      "================================2415===================================\n",
      "2415/10000: train_loss: 4.039807137399912 train_error 55.50% test_error 61.00%\n",
      "================================2416===================================\n",
      "2416/10000: train_loss: 4.039758925139904 train_error 55.50% test_error 60.50%\n",
      "================================2417===================================\n",
      "2417/10000: train_loss: 4.0397106164693835 train_error 55.62% test_error 60.50%\n",
      "================================2418===================================\n",
      "2418/10000: train_loss: 4.039662137627602 train_error 55.62% test_error 60.00%\n",
      "================================2419===================================\n",
      "2419/10000: train_loss: 4.0396135663986215 train_error 55.62% test_error 60.00%\n",
      "================================2420===================================\n",
      "2420/10000: train_loss: 4.039564961045981 train_error 55.62% test_error 60.00%\n",
      "================================2421===================================\n",
      "2421/10000: train_loss: 4.0395161914825435 train_error 55.62% test_error 60.00%\n",
      "================================2422===================================\n",
      "2422/10000: train_loss: 4.039467317312956 train_error 55.62% test_error 60.00%\n",
      "================================2423===================================\n",
      "2423/10000: train_loss: 4.039418249577285 train_error 55.62% test_error 60.00%\n",
      "================================2424===================================\n",
      "2424/10000: train_loss: 4.0393686987459665 train_error 55.62% test_error 60.00%\n",
      "================================2425===================================\n",
      "2425/10000: train_loss: 4.039319094717503 train_error 55.50% test_error 60.00%\n",
      "================================2426===================================\n",
      "2426/10000: train_loss: 4.039269409626723 train_error 55.50% test_error 60.00%\n",
      "================================2427===================================\n",
      "2427/10000: train_loss: 4.039219668060541 train_error 55.50% test_error 60.00%\n",
      "================================2428===================================\n",
      "2428/10000: train_loss: 4.039169869571924 train_error 55.50% test_error 60.00%\n",
      "================================2429===================================\n",
      "2429/10000: train_loss: 4.039120053499937 train_error 55.50% test_error 60.00%\n",
      "================================2430===================================\n",
      "2430/10000: train_loss: 4.039070318341255 train_error 55.50% test_error 60.00%\n",
      "================================2431===================================\n",
      "2431/10000: train_loss: 4.039020461589098 train_error 55.50% test_error 60.00%\n",
      "================================2432===================================\n",
      "2432/10000: train_loss: 4.038970515578985 train_error 55.50% test_error 60.00%\n",
      "================================2433===================================\n",
      "2433/10000: train_loss: 4.038920768350362 train_error 55.50% test_error 60.00%\n",
      "================================2434===================================\n",
      "2434/10000: train_loss: 4.038871354460716 train_error 55.50% test_error 60.00%\n",
      "================================2435===================================\n",
      "2435/10000: train_loss: 4.038821842223406 train_error 55.50% test_error 60.00%\n",
      "================================2436===================================\n",
      "2436/10000: train_loss: 4.038772333264351 train_error 55.50% test_error 60.00%\n",
      "================================2437===================================\n",
      "2437/10000: train_loss: 4.0387228956818575 train_error 55.50% test_error 60.00%\n",
      "================================2438===================================\n",
      "2438/10000: train_loss: 4.038673461973667 train_error 55.50% test_error 60.00%\n",
      "================================2439===================================\n",
      "2439/10000: train_loss: 4.038623973578215 train_error 55.50% test_error 60.00%\n",
      "================================2440===================================\n",
      "2440/10000: train_loss: 4.038574439734221 train_error 55.62% test_error 60.00%\n",
      "================================2441===================================\n",
      "2441/10000: train_loss: 4.038524916321039 train_error 55.62% test_error 60.00%\n",
      "================================2442===================================\n",
      "2442/10000: train_loss: 4.038475489318371 train_error 55.62% test_error 60.00%\n",
      "================================2443===================================\n",
      "2443/10000: train_loss: 4.038426043689251 train_error 55.62% test_error 60.00%\n",
      "================================2444===================================\n",
      "2444/10000: train_loss: 4.038376407623291 train_error 55.62% test_error 60.00%\n",
      "================================2445===================================\n",
      "2445/10000: train_loss: 4.0383265081048005 train_error 55.62% test_error 60.00%\n",
      "================================2446===================================\n",
      "2446/10000: train_loss: 4.038276694118977 train_error 55.62% test_error 60.00%\n",
      "================================2447===================================\n",
      "2447/10000: train_loss: 4.0382270336151125 train_error 55.62% test_error 59.50%\n",
      "================================2448===================================\n",
      "2448/10000: train_loss: 4.038177274018526 train_error 55.62% test_error 59.50%\n",
      "================================2449===================================\n",
      "2449/10000: train_loss: 4.03812743961811 train_error 55.75% test_error 59.50%\n",
      "================================2450===================================\n",
      "2450/10000: train_loss: 4.038077467828989 train_error 55.75% test_error 59.50%\n",
      "================================2451===================================\n",
      "2451/10000: train_loss: 4.0380273486673826 train_error 55.75% test_error 59.50%\n",
      "================================2452===================================\n",
      "2452/10000: train_loss: 4.037977221310139 train_error 55.75% test_error 59.50%\n",
      "================================2453===================================\n",
      "2453/10000: train_loss: 4.037927065640688 train_error 55.75% test_error 59.50%\n",
      "================================2454===================================\n",
      "2454/10000: train_loss: 4.0378770190477375 train_error 55.75% test_error 59.50%\n",
      "================================2455===================================\n",
      "2455/10000: train_loss: 4.037826997786761 train_error 55.75% test_error 59.50%\n",
      "================================2456===================================\n",
      "2456/10000: train_loss: 4.037776835858821 train_error 55.75% test_error 59.50%\n",
      "================================2457===================================\n",
      "2457/10000: train_loss: 4.0377265211939815 train_error 55.75% test_error 59.50%\n",
      "================================2458===================================\n",
      "2458/10000: train_loss: 4.037676106989384 train_error 55.75% test_error 59.50%\n",
      "================================2459===================================\n",
      "2459/10000: train_loss: 4.037625488936901 train_error 55.75% test_error 59.50%\n",
      "================================2460===================================\n",
      "2460/10000: train_loss: 4.037574991285801 train_error 55.75% test_error 59.50%\n",
      "================================2461===================================\n",
      "2461/10000: train_loss: 4.037524535208941 train_error 55.75% test_error 59.50%\n",
      "================================2462===================================\n",
      "2462/10000: train_loss: 4.037474028021097 train_error 55.75% test_error 59.50%\n",
      "================================2463===================================\n",
      "2463/10000: train_loss: 4.03742344751954 train_error 55.62% test_error 59.50%\n",
      "================================2464===================================\n",
      "2464/10000: train_loss: 4.037372824251651 train_error 55.62% test_error 59.50%\n",
      "================================2465===================================\n",
      "2465/10000: train_loss: 4.037322254627943 train_error 55.62% test_error 59.50%\n",
      "================================2466===================================\n",
      "2466/10000: train_loss: 4.037271645218134 train_error 55.62% test_error 59.50%\n",
      "================================2467===================================\n",
      "2467/10000: train_loss: 4.037221229076385 train_error 55.62% test_error 59.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2468===================================\n",
      "2468/10000: train_loss: 4.037170994281769 train_error 55.75% test_error 59.50%\n",
      "================================2469===================================\n",
      "2469/10000: train_loss: 4.037120702415704 train_error 55.75% test_error 59.50%\n",
      "================================2470===================================\n",
      "2470/10000: train_loss: 4.037070781737566 train_error 55.62% test_error 59.50%\n",
      "================================2471===================================\n",
      "2471/10000: train_loss: 4.037021131813526 train_error 55.62% test_error 59.50%\n",
      "================================2472===================================\n",
      "2472/10000: train_loss: 4.036971709430218 train_error 55.62% test_error 59.50%\n",
      "================================2473===================================\n",
      "2473/10000: train_loss: 4.036922266483307 train_error 55.62% test_error 59.50%\n",
      "================================2474===================================\n",
      "2474/10000: train_loss: 4.036872807741165 train_error 55.62% test_error 59.50%\n",
      "================================2475===================================\n",
      "2475/10000: train_loss: 4.036823459267616 train_error 55.75% test_error 59.50%\n",
      "================================2476===================================\n",
      "2476/10000: train_loss: 4.0367741252481935 train_error 55.75% test_error 59.50%\n",
      "================================2477===================================\n",
      "2477/10000: train_loss: 4.036724681407213 train_error 55.75% test_error 59.50%\n",
      "================================2478===================================\n",
      "2478/10000: train_loss: 4.036675695627928 train_error 55.62% test_error 59.50%\n",
      "================================2479===================================\n",
      "2479/10000: train_loss: 4.036627120524645 train_error 55.62% test_error 59.50%\n",
      "================================2480===================================\n",
      "2480/10000: train_loss: 4.036578466743231 train_error 55.62% test_error 59.50%\n",
      "================================2481===================================\n",
      "2481/10000: train_loss: 4.036529734432698 train_error 55.62% test_error 59.50%\n",
      "================================2482===================================\n",
      "2482/10000: train_loss: 4.0364809525012975 train_error 55.62% test_error 59.50%\n",
      "================================2483===================================\n",
      "2483/10000: train_loss: 4.036432138681412 train_error 55.75% test_error 59.50%\n",
      "================================2484===================================\n",
      "2484/10000: train_loss: 4.036383423507214 train_error 55.75% test_error 59.50%\n",
      "================================2485===================================\n",
      "2485/10000: train_loss: 4.036334709823132 train_error 55.75% test_error 59.50%\n",
      "================================2486===================================\n",
      "2486/10000: train_loss: 4.036285923570395 train_error 55.75% test_error 59.50%\n",
      "================================2487===================================\n",
      "2487/10000: train_loss: 4.036237079650164 train_error 55.75% test_error 59.50%\n",
      "================================2488===================================\n",
      "2488/10000: train_loss: 4.036188307106495 train_error 55.75% test_error 59.50%\n",
      "================================2489===================================\n",
      "2489/10000: train_loss: 4.036139422953129 train_error 55.75% test_error 59.50%\n",
      "================================2490===================================\n",
      "2490/10000: train_loss: 4.03609045818448 train_error 55.75% test_error 59.50%\n",
      "================================2491===================================\n",
      "2491/10000: train_loss: 4.03604115024209 train_error 55.62% test_error 59.50%\n",
      "================================2492===================================\n",
      "2492/10000: train_loss: 4.03599151879549 train_error 55.62% test_error 59.50%\n",
      "================================2493===================================\n",
      "2493/10000: train_loss: 4.035941770225763 train_error 55.50% test_error 59.50%\n",
      "================================2494===================================\n",
      "2494/10000: train_loss: 4.035891959667206 train_error 55.50% test_error 59.50%\n",
      "================================2495===================================\n",
      "2495/10000: train_loss: 4.035842110216617 train_error 55.38% test_error 59.50%\n",
      "================================2496===================================\n",
      "2496/10000: train_loss: 4.035792204588652 train_error 55.38% test_error 59.50%\n",
      "================================2497===================================\n",
      "2497/10000: train_loss: 4.035742277503013 train_error 55.38% test_error 59.00%\n",
      "================================2498===================================\n",
      "2498/10000: train_loss: 4.0356925727427 train_error 55.38% test_error 59.00%\n",
      "================================2499===================================\n",
      "2499/10000: train_loss: 4.035642458498478 train_error 55.38% test_error 59.00%\n",
      "================================2500===================================\n",
      "2500/10000: train_loss: 4.035592023134232 train_error 55.38% test_error 59.50%\n",
      "================================2501===================================\n",
      "2501/10000: train_loss: 4.035541397929192 train_error 55.25% test_error 59.50%\n",
      "================================2502===================================\n",
      "2502/10000: train_loss: 4.035490785837173 train_error 55.25% test_error 59.50%\n",
      "================================2503===================================\n",
      "2503/10000: train_loss: 4.035439678579569 train_error 55.25% test_error 59.50%\n",
      "================================2504===================================\n",
      "2504/10000: train_loss: 4.035388383269311 train_error 55.38% test_error 59.50%\n",
      "================================2505===================================\n",
      "2505/10000: train_loss: 4.0353370004892355 train_error 55.38% test_error 59.50%\n",
      "================================2506===================================\n",
      "2506/10000: train_loss: 4.035285637080669 train_error 55.38% test_error 59.50%\n",
      "================================2507===================================\n",
      "2507/10000: train_loss: 4.035234398394823 train_error 55.38% test_error 59.50%\n",
      "================================2508===================================\n",
      "2508/10000: train_loss: 4.035183120667934 train_error 55.38% test_error 59.50%\n",
      "================================2509===================================\n",
      "2509/10000: train_loss: 4.035131701231002 train_error 55.38% test_error 59.50%\n",
      "================================2510===================================\n",
      "2510/10000: train_loss: 4.035080144405365 train_error 55.38% test_error 59.50%\n",
      "================================2511===================================\n",
      "2511/10000: train_loss: 4.035028584450483 train_error 55.38% test_error 59.50%\n",
      "================================2512===================================\n",
      "2512/10000: train_loss: 4.034977466464042 train_error 55.38% test_error 59.50%\n",
      "================================2513===================================\n",
      "2513/10000: train_loss: 4.034926286190748 train_error 55.38% test_error 59.50%\n",
      "================================2514===================================\n",
      "2514/10000: train_loss: 4.034874980598688 train_error 55.38% test_error 59.50%\n",
      "================================2515===================================\n",
      "2515/10000: train_loss: 4.034823722839356 train_error 55.38% test_error 59.50%\n",
      "================================2516===================================\n",
      "2516/10000: train_loss: 4.034772807210683 train_error 55.38% test_error 59.50%\n",
      "================================2517===================================\n",
      "2517/10000: train_loss: 4.034721926301717 train_error 55.38% test_error 59.50%\n",
      "================================2518===================================\n",
      "2518/10000: train_loss: 4.03467099994421 train_error 55.38% test_error 59.50%\n",
      "================================2519===================================\n",
      "2519/10000: train_loss: 4.034620336294174 train_error 55.38% test_error 59.50%\n",
      "================================2520===================================\n",
      "2520/10000: train_loss: 4.034569715559482 train_error 55.38% test_error 59.50%\n",
      "================================2521===================================\n",
      "2521/10000: train_loss: 4.034519066810608 train_error 55.38% test_error 59.50%\n",
      "================================2522===================================\n",
      "2522/10000: train_loss: 4.034468393623829 train_error 55.38% test_error 59.50%\n",
      "================================2523===================================\n",
      "2523/10000: train_loss: 4.034417717605829 train_error 55.38% test_error 59.50%\n",
      "================================2524===================================\n",
      "2524/10000: train_loss: 4.034367129355669 train_error 55.38% test_error 59.50%\n",
      "================================2525===================================\n",
      "2525/10000: train_loss: 4.034316494613886 train_error 55.38% test_error 59.50%\n",
      "================================2526===================================\n",
      "2526/10000: train_loss: 4.034265778213739 train_error 55.38% test_error 59.50%\n",
      "================================2527===================================\n",
      "2527/10000: train_loss: 4.034214951694011 train_error 55.38% test_error 59.50%\n",
      "================================2528===================================\n",
      "2528/10000: train_loss: 4.034163744449615 train_error 55.38% test_error 59.50%\n",
      "================================2529===================================\n",
      "2529/10000: train_loss: 4.03411227747798 train_error 55.25% test_error 59.50%\n",
      "================================2530===================================\n",
      "2530/10000: train_loss: 4.034060776531697 train_error 55.25% test_error 59.50%\n",
      "================================2531===================================\n",
      "2531/10000: train_loss: 4.034009269624949 train_error 55.25% test_error 59.50%\n",
      "================================2532===================================\n",
      "2532/10000: train_loss: 4.033957644551992 train_error 55.25% test_error 59.50%\n",
      "================================2533===================================\n",
      "2533/10000: train_loss: 4.033905966430902 train_error 55.25% test_error 59.50%\n",
      "================================2534===================================\n",
      "2534/10000: train_loss: 4.03385423913598 train_error 55.25% test_error 59.50%\n",
      "================================2535===================================\n",
      "2535/10000: train_loss: 4.033802452087403 train_error 55.25% test_error 59.50%\n",
      "================================2536===================================\n",
      "2536/10000: train_loss: 4.03375073030591 train_error 55.25% test_error 59.50%\n",
      "================================2537===================================\n",
      "2537/10000: train_loss: 4.033699105679989 train_error 55.12% test_error 59.50%\n",
      "================================2538===================================\n",
      "2538/10000: train_loss: 4.0336474314332005 train_error 55.12% test_error 59.50%\n",
      "================================2539===================================\n",
      "2539/10000: train_loss: 4.033595725744963 train_error 55.12% test_error 59.50%\n",
      "================================2540===================================\n",
      "2540/10000: train_loss: 4.033543926626445 train_error 55.25% test_error 59.50%\n",
      "================================2541===================================\n",
      "2541/10000: train_loss: 4.033492175191641 train_error 55.25% test_error 59.50%\n",
      "================================2542===================================\n",
      "2542/10000: train_loss: 4.033440380543471 train_error 55.25% test_error 59.50%\n",
      "================================2543===================================\n",
      "2543/10000: train_loss: 4.03338854238391 train_error 55.38% test_error 59.50%\n",
      "================================2544===================================\n",
      "2544/10000: train_loss: 4.03333690136671 train_error 55.38% test_error 59.50%\n",
      "================================2545===================================\n",
      "2545/10000: train_loss: 4.033285422027111 train_error 55.38% test_error 59.50%\n",
      "================================2546===================================\n",
      "2546/10000: train_loss: 4.033233658075332 train_error 55.38% test_error 59.50%\n",
      "================================2547===================================\n",
      "2547/10000: train_loss: 4.0331816899776465 train_error 55.38% test_error 59.50%\n",
      "================================2548===================================\n",
      "2548/10000: train_loss: 4.033129712045193 train_error 55.38% test_error 59.50%\n",
      "================================2549===================================\n",
      "2549/10000: train_loss: 4.0330779169499875 train_error 55.38% test_error 59.50%\n",
      "================================2550===================================\n",
      "2550/10000: train_loss: 4.033026280254125 train_error 55.12% test_error 59.50%\n",
      "================================2551===================================\n",
      "2551/10000: train_loss: 4.032974882125854 train_error 55.12% test_error 59.50%\n",
      "================================2552===================================\n",
      "2552/10000: train_loss: 4.032923502624035 train_error 55.12% test_error 59.50%\n",
      "================================2553===================================\n",
      "2553/10000: train_loss: 4.032872186154128 train_error 55.12% test_error 59.00%\n",
      "================================2554===================================\n",
      "2554/10000: train_loss: 4.032820758223534 train_error 55.12% test_error 59.00%\n",
      "================================2555===================================\n",
      "2555/10000: train_loss: 4.032769283801317 train_error 55.12% test_error 59.00%\n",
      "================================2556===================================\n",
      "2556/10000: train_loss: 4.032717760056258 train_error 55.12% test_error 59.00%\n",
      "================================2557===================================\n",
      "2557/10000: train_loss: 4.032666211277247 train_error 55.12% test_error 59.00%\n",
      "================================2558===================================\n",
      "2558/10000: train_loss: 4.032614576965571 train_error 55.12% test_error 59.00%\n",
      "================================2559===================================\n",
      "2559/10000: train_loss: 4.0325629705190655 train_error 55.12% test_error 59.00%\n",
      "================================2560===================================\n",
      "2560/10000: train_loss: 4.032511517703533 train_error 55.12% test_error 59.00%\n",
      "================================2561===================================\n",
      "2561/10000: train_loss: 4.032460502386093 train_error 55.12% test_error 59.50%\n",
      "================================2562===================================\n",
      "2562/10000: train_loss: 4.032409428954124 train_error 55.12% test_error 59.50%\n",
      "================================2563===================================\n",
      "2563/10000: train_loss: 4.032358263134957 train_error 55.12% test_error 59.50%\n",
      "================================2564===================================\n",
      "2564/10000: train_loss: 4.0323068684339525 train_error 55.12% test_error 59.50%\n",
      "================================2565===================================\n",
      "2565/10000: train_loss: 4.032254964858293 train_error 55.12% test_error 59.50%\n",
      "================================2566===================================\n",
      "2566/10000: train_loss: 4.032203292548656 train_error 55.12% test_error 59.50%\n",
      "================================2567===================================\n",
      "2567/10000: train_loss: 4.032151670604944 train_error 55.12% test_error 59.50%\n",
      "================================2568===================================\n",
      "2568/10000: train_loss: 4.032100059837103 train_error 55.12% test_error 59.50%\n",
      "================================2569===================================\n",
      "2569/10000: train_loss: 4.032048608958721 train_error 55.12% test_error 59.50%\n",
      "================================2570===================================\n",
      "2570/10000: train_loss: 4.0319970221817485 train_error 55.12% test_error 60.00%\n",
      "================================2571===================================\n",
      "2571/10000: train_loss: 4.031945556551218 train_error 55.12% test_error 60.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2572===================================\n",
      "2572/10000: train_loss: 4.031894038468599 train_error 55.00% test_error 60.00%\n",
      "================================2573===================================\n",
      "2573/10000: train_loss: 4.031842506229877 train_error 55.00% test_error 60.00%\n",
      "================================2574===================================\n",
      "2574/10000: train_loss: 4.031790754497051 train_error 55.00% test_error 60.00%\n",
      "================================2575===================================\n",
      "2575/10000: train_loss: 4.031739058196544 train_error 55.00% test_error 60.00%\n",
      "================================2576===================================\n",
      "2576/10000: train_loss: 4.031687328368426 train_error 54.87% test_error 60.00%\n",
      "================================2577===================================\n",
      "2577/10000: train_loss: 4.031635663360357 train_error 54.87% test_error 60.00%\n",
      "================================2578===================================\n",
      "2578/10000: train_loss: 4.031583915650844 train_error 54.87% test_error 60.00%\n",
      "================================2579===================================\n",
      "2579/10000: train_loss: 4.031532136946916 train_error 54.75% test_error 59.50%\n",
      "================================2580===================================\n",
      "2580/10000: train_loss: 4.031480268836022 train_error 54.75% test_error 60.00%\n",
      "================================2581===================================\n",
      "2581/10000: train_loss: 4.031427918076515 train_error 54.75% test_error 60.00%\n",
      "================================2582===================================\n",
      "2582/10000: train_loss: 4.031374902278184 train_error 54.75% test_error 60.00%\n",
      "================================2583===================================\n",
      "2583/10000: train_loss: 4.031321786493063 train_error 54.75% test_error 60.00%\n",
      "================================2584===================================\n",
      "2584/10000: train_loss: 4.031268974244595 train_error 54.87% test_error 60.00%\n",
      "================================2585===================================\n",
      "2585/10000: train_loss: 4.031216306388378 train_error 54.87% test_error 60.00%\n",
      "================================2586===================================\n",
      "2586/10000: train_loss: 4.031163669377565 train_error 54.87% test_error 60.00%\n",
      "================================2587===================================\n",
      "2587/10000: train_loss: 4.031110946238041 train_error 54.87% test_error 60.00%\n",
      "================================2588===================================\n",
      "2588/10000: train_loss: 4.031058355122804 train_error 55.00% test_error 60.00%\n",
      "================================2589===================================\n",
      "2589/10000: train_loss: 4.031005781292915 train_error 55.00% test_error 60.00%\n",
      "================================2590===================================\n",
      "2590/10000: train_loss: 4.030953041762114 train_error 55.00% test_error 60.00%\n",
      "================================2591===================================\n",
      "2591/10000: train_loss: 4.030900225043297 train_error 55.00% test_error 60.00%\n",
      "================================2592===================================\n",
      "2592/10000: train_loss: 4.030847485214472 train_error 55.00% test_error 60.00%\n",
      "================================2593===================================\n",
      "2593/10000: train_loss: 4.030794905275106 train_error 55.00% test_error 60.00%\n",
      "================================2594===================================\n",
      "2594/10000: train_loss: 4.030742418915033 train_error 55.00% test_error 60.00%\n",
      "================================2595===================================\n",
      "2595/10000: train_loss: 4.030689797848463 train_error 55.00% test_error 60.00%\n",
      "================================2596===================================\n",
      "2596/10000: train_loss: 4.030636981427669 train_error 55.00% test_error 60.00%\n",
      "================================2597===================================\n",
      "2597/10000: train_loss: 4.0305841191113 train_error 55.00% test_error 60.00%\n",
      "================================2598===================================\n",
      "2598/10000: train_loss: 4.030531157702208 train_error 55.00% test_error 60.00%\n",
      "================================2599===================================\n",
      "2599/10000: train_loss: 4.030478519648314 train_error 55.00% test_error 60.00%\n",
      "================================2600===================================\n",
      "2600/10000: train_loss: 4.030425872951746 train_error 54.87% test_error 60.00%\n",
      "================================2601===================================\n",
      "2601/10000: train_loss: 4.030373224616051 train_error 54.87% test_error 60.00%\n",
      "================================2602===================================\n",
      "2602/10000: train_loss: 4.0303204664587975 train_error 54.87% test_error 60.00%\n",
      "================================2603===================================\n",
      "2603/10000: train_loss: 4.03026766359806 train_error 54.87% test_error 60.00%\n",
      "================================2604===================================\n",
      "2604/10000: train_loss: 4.030214866250753 train_error 54.87% test_error 60.00%\n",
      "================================2605===================================\n",
      "2605/10000: train_loss: 4.030162021964788 train_error 54.87% test_error 60.00%\n",
      "================================2606===================================\n",
      "2606/10000: train_loss: 4.030109167397023 train_error 54.87% test_error 60.00%\n",
      "================================2607===================================\n",
      "2607/10000: train_loss: 4.030056313872338 train_error 54.87% test_error 60.00%\n",
      "================================2608===================================\n",
      "2608/10000: train_loss: 4.030003728419542 train_error 54.87% test_error 60.00%\n",
      "================================2609===================================\n",
      "2609/10000: train_loss: 4.029951213598252 train_error 54.87% test_error 60.00%\n",
      "================================2610===================================\n",
      "2610/10000: train_loss: 4.029898519068956 train_error 54.87% test_error 60.00%\n",
      "================================2611===================================\n",
      "2611/10000: train_loss: 4.029845908284187 train_error 54.87% test_error 60.00%\n",
      "================================2612===================================\n",
      "2612/10000: train_loss: 4.029793187379837 train_error 54.87% test_error 60.00%\n",
      "================================2613===================================\n",
      "2613/10000: train_loss: 4.029740412831307 train_error 54.87% test_error 60.00%\n",
      "================================2614===================================\n",
      "2614/10000: train_loss: 4.02968750372529 train_error 54.87% test_error 60.00%\n",
      "================================2615===================================\n",
      "2615/10000: train_loss: 4.0296344904601575 train_error 54.87% test_error 60.00%\n",
      "================================2616===================================\n",
      "2616/10000: train_loss: 4.029581364244223 train_error 54.87% test_error 60.50%\n",
      "================================2617===================================\n",
      "2617/10000: train_loss: 4.02952824011445 train_error 54.87% test_error 60.50%\n",
      "================================2618===================================\n",
      "2618/10000: train_loss: 4.0294751948118215 train_error 54.75% test_error 60.50%\n",
      "================================2619===================================\n",
      "2619/10000: train_loss: 4.029422161728144 train_error 54.75% test_error 60.50%\n",
      "================================2620===================================\n",
      "2620/10000: train_loss: 4.029369111061096 train_error 54.75% test_error 60.50%\n",
      "================================2621===================================\n",
      "2621/10000: train_loss: 4.029316000640392 train_error 54.75% test_error 60.50%\n",
      "================================2622===================================\n",
      "2622/10000: train_loss: 4.029262541234494 train_error 54.75% test_error 60.50%\n",
      "================================2623===================================\n",
      "2623/10000: train_loss: 4.0292087808251384 train_error 54.75% test_error 60.50%\n",
      "================================2624===================================\n",
      "2624/10000: train_loss: 4.029154961109161 train_error 54.75% test_error 60.50%\n",
      "================================2625===================================\n",
      "2625/10000: train_loss: 4.0291010670363905 train_error 54.87% test_error 60.50%\n",
      "================================2626===================================\n",
      "2626/10000: train_loss: 4.02904717952013 train_error 54.87% test_error 60.50%\n",
      "================================2627===================================\n",
      "2627/10000: train_loss: 4.028992762118579 train_error 54.87% test_error 60.50%\n",
      "================================2628===================================\n",
      "2628/10000: train_loss: 4.028938070684672 train_error 54.87% test_error 60.50%\n",
      "================================2629===================================\n",
      "2629/10000: train_loss: 4.0288832522928715 train_error 54.87% test_error 60.50%\n",
      "================================2630===================================\n",
      "2630/10000: train_loss: 4.028828406333924 train_error 54.87% test_error 60.50%\n",
      "================================2631===================================\n",
      "2631/10000: train_loss: 4.028773516863584 train_error 54.87% test_error 60.50%\n",
      "================================2632===================================\n",
      "2632/10000: train_loss: 4.028718585819006 train_error 54.87% test_error 60.50%\n",
      "================================2633===================================\n",
      "2633/10000: train_loss: 4.028663533329963 train_error 54.87% test_error 60.50%\n",
      "================================2634===================================\n",
      "2634/10000: train_loss: 4.028608295172453 train_error 54.87% test_error 60.50%\n",
      "================================2635===================================\n",
      "2635/10000: train_loss: 4.0285528126358985 train_error 54.87% test_error 60.50%\n",
      "================================2636===================================\n",
      "2636/10000: train_loss: 4.028497844040395 train_error 54.87% test_error 60.50%\n",
      "================================2637===================================\n",
      "2637/10000: train_loss: 4.028442843109369 train_error 54.87% test_error 60.50%\n",
      "================================2638===================================\n",
      "2638/10000: train_loss: 4.028387598842382 train_error 54.87% test_error 60.50%\n",
      "================================2639===================================\n",
      "2639/10000: train_loss: 4.0283322273194795 train_error 54.75% test_error 60.50%\n",
      "================================2640===================================\n",
      "2640/10000: train_loss: 4.0282771296799185 train_error 54.75% test_error 60.50%\n",
      "================================2641===================================\n",
      "2641/10000: train_loss: 4.028221834152937 train_error 54.75% test_error 60.50%\n",
      "================================2642===================================\n",
      "2642/10000: train_loss: 4.028166234195233 train_error 54.75% test_error 60.50%\n",
      "================================2643===================================\n",
      "2643/10000: train_loss: 4.028110411614179 train_error 54.75% test_error 60.50%\n",
      "================================2644===================================\n",
      "2644/10000: train_loss: 4.028054634183645 train_error 54.75% test_error 60.50%\n",
      "================================2645===================================\n",
      "2645/10000: train_loss: 4.027999213337898 train_error 54.75% test_error 60.50%\n",
      "================================2646===================================\n",
      "2646/10000: train_loss: 4.027944105565548 train_error 54.75% test_error 60.50%\n",
      "================================2647===================================\n",
      "2647/10000: train_loss: 4.027888989895582 train_error 54.75% test_error 60.50%\n",
      "================================2648===================================\n",
      "2648/10000: train_loss: 4.02783386901021 train_error 54.75% test_error 60.50%\n",
      "================================2649===================================\n",
      "2649/10000: train_loss: 4.027777977883816 train_error 54.75% test_error 60.50%\n",
      "================================2650===================================\n",
      "2650/10000: train_loss: 4.027721710056067 train_error 54.75% test_error 60.50%\n",
      "================================2651===================================\n",
      "2651/10000: train_loss: 4.027665388286113 train_error 54.75% test_error 60.50%\n",
      "================================2652===================================\n",
      "2652/10000: train_loss: 4.027609057426452 train_error 54.75% test_error 60.50%\n",
      "================================2653===================================\n",
      "2653/10000: train_loss: 4.0275528062880035 train_error 54.75% test_error 60.50%\n",
      "================================2654===================================\n",
      "2654/10000: train_loss: 4.027496798783541 train_error 54.75% test_error 60.50%\n",
      "================================2655===================================\n",
      "2655/10000: train_loss: 4.027440772652626 train_error 54.75% test_error 60.50%\n",
      "================================2656===================================\n",
      "2656/10000: train_loss: 4.027384278774262 train_error 54.62% test_error 60.50%\n",
      "================================2657===================================\n",
      "2657/10000: train_loss: 4.02732774540782 train_error 54.62% test_error 60.50%\n",
      "================================2658===================================\n",
      "2658/10000: train_loss: 4.027271166145802 train_error 54.50% test_error 60.50%\n",
      "================================2659===================================\n",
      "2659/10000: train_loss: 4.027214383631945 train_error 54.50% test_error 60.50%\n",
      "================================2660===================================\n",
      "2660/10000: train_loss: 4.027157227396964 train_error 54.50% test_error 60.50%\n",
      "================================2661===================================\n",
      "2661/10000: train_loss: 4.0271000078320505 train_error 54.50% test_error 60.50%\n",
      "================================2662===================================\n",
      "2662/10000: train_loss: 4.027042838484049 train_error 54.50% test_error 60.50%\n",
      "================================2663===================================\n",
      "2663/10000: train_loss: 4.02698551595211 train_error 54.37% test_error 60.50%\n",
      "================================2664===================================\n",
      "2664/10000: train_loss: 4.026927913874387 train_error 54.37% test_error 60.00%\n",
      "================================2665===================================\n",
      "2665/10000: train_loss: 4.026870148181915 train_error 54.37% test_error 60.00%\n",
      "================================2666===================================\n",
      "2666/10000: train_loss: 4.026811881512404 train_error 54.37% test_error 60.00%\n",
      "================================2667===================================\n",
      "2667/10000: train_loss: 4.026753534674645 train_error 54.37% test_error 60.00%\n",
      "================================2668===================================\n",
      "2668/10000: train_loss: 4.026695277690887 train_error 54.37% test_error 60.00%\n",
      "================================2669===================================\n",
      "2669/10000: train_loss: 4.026637207567692 train_error 54.37% test_error 60.00%\n",
      "================================2670===================================\n",
      "2670/10000: train_loss: 4.0265791021287445 train_error 54.37% test_error 60.00%\n",
      "================================2671===================================\n",
      "2671/10000: train_loss: 4.026520726382732 train_error 54.37% test_error 60.00%\n",
      "================================2672===================================\n",
      "2672/10000: train_loss: 4.0264619334042075 train_error 54.37% test_error 60.00%\n",
      "================================2673===================================\n",
      "2673/10000: train_loss: 4.02640277415514 train_error 54.37% test_error 60.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2674===================================\n",
      "2674/10000: train_loss: 4.026343606114388 train_error 54.37% test_error 60.00%\n",
      "================================2675===================================\n",
      "2675/10000: train_loss: 4.026284490972757 train_error 54.37% test_error 60.00%\n",
      "================================2676===================================\n",
      "2676/10000: train_loss: 4.026225063949823 train_error 54.37% test_error 60.00%\n",
      "================================2677===================================\n",
      "2677/10000: train_loss: 4.0261654825508595 train_error 54.37% test_error 60.00%\n",
      "================================2678===================================\n",
      "2678/10000: train_loss: 4.026105773448944 train_error 54.37% test_error 60.00%\n",
      "================================2679===================================\n",
      "2679/10000: train_loss: 4.026046027690172 train_error 54.37% test_error 60.00%\n",
      "================================2680===================================\n",
      "2680/10000: train_loss: 4.025986194163561 train_error 54.37% test_error 60.00%\n",
      "================================2681===================================\n",
      "2681/10000: train_loss: 4.025926351696253 train_error 54.37% test_error 60.00%\n",
      "================================2682===================================\n",
      "2682/10000: train_loss: 4.025866654962301 train_error 54.37% test_error 60.00%\n",
      "================================2683===================================\n",
      "2683/10000: train_loss: 4.025806758403778 train_error 54.37% test_error 60.00%\n",
      "================================2684===================================\n",
      "2684/10000: train_loss: 4.025746789872646 train_error 54.37% test_error 60.00%\n",
      "================================2685===================================\n",
      "2685/10000: train_loss: 4.02568689107895 train_error 54.37% test_error 60.00%\n",
      "================================2686===================================\n",
      "2686/10000: train_loss: 4.025626973807812 train_error 54.37% test_error 60.00%\n",
      "================================2687===================================\n",
      "2687/10000: train_loss: 4.025566635727882 train_error 54.37% test_error 60.00%\n",
      "================================2688===================================\n",
      "2688/10000: train_loss: 4.025506193041801 train_error 54.37% test_error 60.00%\n",
      "================================2689===================================\n",
      "2689/10000: train_loss: 4.02544568374753 train_error 54.37% test_error 60.00%\n",
      "================================2690===================================\n",
      "2690/10000: train_loss: 4.025385164320469 train_error 54.37% test_error 60.00%\n",
      "================================2691===================================\n",
      "2691/10000: train_loss: 4.025324752479792 train_error 54.37% test_error 60.00%\n",
      "================================2692===================================\n",
      "2692/10000: train_loss: 4.025264623165131 train_error 54.37% test_error 60.00%\n",
      "================================2693===================================\n",
      "2693/10000: train_loss: 4.025204503834248 train_error 54.37% test_error 60.00%\n",
      "================================2694===================================\n",
      "2694/10000: train_loss: 4.025144321769476 train_error 54.37% test_error 60.00%\n",
      "================================2695===================================\n",
      "2695/10000: train_loss: 4.025084105283022 train_error 54.37% test_error 60.00%\n",
      "================================2696===================================\n",
      "2696/10000: train_loss: 4.025023973286152 train_error 54.37% test_error 60.00%\n",
      "================================2697===================================\n",
      "2697/10000: train_loss: 4.02496373295784 train_error 54.25% test_error 60.00%\n",
      "================================2698===================================\n",
      "2698/10000: train_loss: 4.0249034290015695 train_error 54.25% test_error 60.00%\n",
      "================================2699===================================\n",
      "2699/10000: train_loss: 4.024843395650387 train_error 54.25% test_error 60.00%\n",
      "================================2700===================================\n",
      "2700/10000: train_loss: 4.024783232659102 train_error 54.25% test_error 60.00%\n",
      "================================2701===================================\n",
      "2701/10000: train_loss: 4.024722789078951 train_error 54.25% test_error 60.00%\n",
      "================================2702===================================\n",
      "2702/10000: train_loss: 4.024662320911884 train_error 54.25% test_error 60.00%\n",
      "================================2703===================================\n",
      "2703/10000: train_loss: 4.02460184186697 train_error 54.25% test_error 60.00%\n",
      "================================2704===================================\n",
      "2704/10000: train_loss: 4.024541354626417 train_error 54.25% test_error 60.00%\n",
      "================================2705===================================\n",
      "2705/10000: train_loss: 4.024480966627598 train_error 54.25% test_error 60.00%\n",
      "================================2706===================================\n",
      "2706/10000: train_loss: 4.0244206352531915 train_error 54.25% test_error 60.00%\n",
      "================================2707===================================\n",
      "2707/10000: train_loss: 4.024359862059355 train_error 54.25% test_error 60.00%\n",
      "================================2708===================================\n",
      "2708/10000: train_loss: 4.024298615306616 train_error 54.25% test_error 60.00%\n",
      "================================2709===================================\n",
      "2709/10000: train_loss: 4.02423706099391 train_error 54.25% test_error 60.00%\n",
      "================================2710===================================\n",
      "2710/10000: train_loss: 4.02417525678873 train_error 54.25% test_error 60.00%\n",
      "================================2711===================================\n",
      "2711/10000: train_loss: 4.0241131916642185 train_error 54.25% test_error 60.00%\n",
      "================================2712===================================\n",
      "2712/10000: train_loss: 4.024051078408957 train_error 54.25% test_error 60.00%\n",
      "================================2713===================================\n",
      "2713/10000: train_loss: 4.023988964855671 train_error 54.25% test_error 60.00%\n",
      "================================2714===================================\n",
      "2714/10000: train_loss: 4.023926628828049 train_error 54.25% test_error 60.00%\n",
      "================================2715===================================\n",
      "2715/10000: train_loss: 4.02386435046792 train_error 54.25% test_error 60.00%\n",
      "================================2716===================================\n",
      "2716/10000: train_loss: 4.023802593797445 train_error 54.25% test_error 60.00%\n",
      "================================2717===================================\n",
      "2717/10000: train_loss: 4.023740947693587 train_error 54.12% test_error 60.00%\n",
      "================================2718===================================\n",
      "2718/10000: train_loss: 4.023679469525814 train_error 54.12% test_error 60.00%\n",
      "================================2719===================================\n",
      "2719/10000: train_loss: 4.023617895841598 train_error 54.12% test_error 60.00%\n",
      "================================2720===================================\n",
      "2720/10000: train_loss: 4.023555785864591 train_error 54.12% test_error 60.00%\n",
      "================================2721===================================\n",
      "2721/10000: train_loss: 4.023493564575911 train_error 54.12% test_error 60.00%\n",
      "================================2722===================================\n",
      "2722/10000: train_loss: 4.02343132480979 train_error 54.12% test_error 60.00%\n",
      "================================2723===================================\n",
      "2723/10000: train_loss: 4.0233690190315246 train_error 54.12% test_error 60.00%\n",
      "================================2724===================================\n",
      "2724/10000: train_loss: 4.023306405395269 train_error 54.12% test_error 59.50%\n",
      "================================2725===================================\n",
      "2725/10000: train_loss: 4.02324339479208 train_error 54.12% test_error 59.50%\n",
      "================================2726===================================\n",
      "2726/10000: train_loss: 4.023180133700371 train_error 54.12% test_error 59.50%\n",
      "================================2727===================================\n",
      "2727/10000: train_loss: 4.023116555809975 train_error 54.00% test_error 59.50%\n",
      "================================2728===================================\n",
      "2728/10000: train_loss: 4.023052844405174 train_error 54.00% test_error 59.50%\n",
      "================================2729===================================\n",
      "2729/10000: train_loss: 4.022989232838153 train_error 54.00% test_error 59.50%\n",
      "================================2730===================================\n",
      "2730/10000: train_loss: 4.022925566583872 train_error 54.00% test_error 59.50%\n",
      "================================2731===================================\n",
      "2731/10000: train_loss: 4.0228618486225605 train_error 54.00% test_error 59.50%\n",
      "================================2732===================================\n",
      "2732/10000: train_loss: 4.022798113524914 train_error 54.00% test_error 59.50%\n",
      "================================2733===================================\n",
      "2733/10000: train_loss: 4.022734440565109 train_error 54.00% test_error 59.50%\n",
      "================================2734===================================\n",
      "2734/10000: train_loss: 4.0226708988845346 train_error 54.00% test_error 59.50%\n",
      "================================2735===================================\n",
      "2735/10000: train_loss: 4.022607394009828 train_error 54.00% test_error 59.50%\n",
      "================================2736===================================\n",
      "2736/10000: train_loss: 4.022543668597937 train_error 54.00% test_error 59.50%\n",
      "================================2737===================================\n",
      "2737/10000: train_loss: 4.022479647994041 train_error 54.00% test_error 59.50%\n",
      "================================2738===================================\n",
      "2738/10000: train_loss: 4.0224153470993045 train_error 54.00% test_error 59.50%\n",
      "================================2739===================================\n",
      "2739/10000: train_loss: 4.022350634634495 train_error 54.00% test_error 59.50%\n",
      "================================2740===================================\n",
      "2740/10000: train_loss: 4.0222861334681514 train_error 54.00% test_error 59.50%\n",
      "================================2741===================================\n",
      "2741/10000: train_loss: 4.022221589684486 train_error 54.00% test_error 59.50%\n",
      "================================2742===================================\n",
      "2742/10000: train_loss: 4.022157153189182 train_error 54.00% test_error 59.50%\n",
      "================================2743===================================\n",
      "2743/10000: train_loss: 4.022092388123275 train_error 54.00% test_error 59.50%\n",
      "================================2744===================================\n",
      "2744/10000: train_loss: 4.022027509659528 train_error 54.00% test_error 59.00%\n",
      "================================2745===================================\n",
      "2745/10000: train_loss: 4.021962613463402 train_error 54.00% test_error 59.00%\n",
      "================================2746===================================\n",
      "2746/10000: train_loss: 4.021897505223751 train_error 54.00% test_error 58.50%\n",
      "================================2747===================================\n",
      "2747/10000: train_loss: 4.02183239877224 train_error 54.00% test_error 58.50%\n",
      "================================2748===================================\n",
      "2748/10000: train_loss: 4.021767142415047 train_error 54.12% test_error 58.50%\n",
      "================================2749===================================\n",
      "2749/10000: train_loss: 4.02170185253024 train_error 54.12% test_error 58.50%\n",
      "================================2750===================================\n",
      "2750/10000: train_loss: 4.021636859923601 train_error 54.12% test_error 58.50%\n",
      "================================2751===================================\n",
      "2751/10000: train_loss: 4.021572373509407 train_error 54.12% test_error 58.50%\n",
      "================================2752===================================\n",
      "2752/10000: train_loss: 4.021507814973592 train_error 54.12% test_error 58.50%\n",
      "================================2753===================================\n",
      "2753/10000: train_loss: 4.021442890316248 train_error 54.12% test_error 58.50%\n",
      "================================2754===================================\n",
      "2754/10000: train_loss: 4.021377313733101 train_error 54.12% test_error 58.50%\n",
      "================================2755===================================\n",
      "2755/10000: train_loss: 4.021311704665423 train_error 54.12% test_error 58.50%\n",
      "================================2756===================================\n",
      "2756/10000: train_loss: 4.021246053427458 train_error 54.12% test_error 58.50%\n",
      "================================2757===================================\n",
      "2757/10000: train_loss: 4.021180442869663 train_error 54.12% test_error 58.50%\n",
      "================================2758===================================\n",
      "2758/10000: train_loss: 4.021114710122347 train_error 54.12% test_error 58.50%\n",
      "================================2759===================================\n",
      "2759/10000: train_loss: 4.021048953384161 train_error 54.12% test_error 58.50%\n",
      "================================2760===================================\n",
      "2760/10000: train_loss: 4.020983134359121 train_error 54.12% test_error 58.50%\n",
      "================================2761===================================\n",
      "2761/10000: train_loss: 4.0209173147380355 train_error 54.12% test_error 58.50%\n",
      "================================2762===================================\n",
      "2762/10000: train_loss: 4.020851478874683 train_error 54.12% test_error 58.50%\n",
      "================================2763===================================\n",
      "2763/10000: train_loss: 4.020785808861256 train_error 54.12% test_error 58.50%\n",
      "================================2764===================================\n",
      "2764/10000: train_loss: 4.020720280259848 train_error 54.12% test_error 58.50%\n",
      "================================2765===================================\n",
      "2765/10000: train_loss: 4.020654658079147 train_error 54.12% test_error 58.50%\n",
      "================================2766===================================\n",
      "2766/10000: train_loss: 4.020589135140181 train_error 54.12% test_error 58.50%\n",
      "================================2767===================================\n",
      "2767/10000: train_loss: 4.020523597598076 train_error 54.25% test_error 58.50%\n",
      "================================2768===================================\n",
      "2768/10000: train_loss: 4.020458040684462 train_error 54.37% test_error 58.50%\n",
      "================================2769===================================\n",
      "2769/10000: train_loss: 4.020392502099275 train_error 54.37% test_error 58.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2770===================================\n",
      "2770/10000: train_loss: 4.020326878428459 train_error 54.37% test_error 58.50%\n",
      "================================2771===================================\n",
      "2771/10000: train_loss: 4.020261155217886 train_error 54.37% test_error 58.50%\n",
      "================================2772===================================\n",
      "2772/10000: train_loss: 4.020195373147726 train_error 54.50% test_error 58.50%\n",
      "================================2773===================================\n",
      "2773/10000: train_loss: 4.020129548311234 train_error 54.50% test_error 58.50%\n",
      "================================2774===================================\n",
      "2774/10000: train_loss: 4.020063620656729 train_error 54.50% test_error 58.50%\n",
      "================================2775===================================\n",
      "2775/10000: train_loss: 4.019997443854809 train_error 54.50% test_error 58.50%\n",
      "================================2776===================================\n",
      "2776/10000: train_loss: 4.019931132942438 train_error 54.50% test_error 58.50%\n",
      "================================2777===================================\n",
      "2777/10000: train_loss: 4.019864838719368 train_error 54.62% test_error 58.50%\n",
      "================================2778===================================\n",
      "2778/10000: train_loss: 4.019798542708158 train_error 54.62% test_error 58.50%\n",
      "================================2779===================================\n",
      "2779/10000: train_loss: 4.019732210338115 train_error 54.62% test_error 58.50%\n",
      "================================2780===================================\n",
      "2780/10000: train_loss: 4.019665711522102 train_error 54.62% test_error 58.50%\n",
      "================================2781===================================\n",
      "2781/10000: train_loss: 4.019598880112171 train_error 54.62% test_error 58.50%\n",
      "================================2782===================================\n",
      "2782/10000: train_loss: 4.01953203484416 train_error 54.62% test_error 58.50%\n",
      "================================2783===================================\n",
      "2783/10000: train_loss: 4.019464409798384 train_error 54.62% test_error 58.50%\n",
      "================================2784===================================\n",
      "2784/10000: train_loss: 4.019396511912346 train_error 54.62% test_error 58.50%\n",
      "================================2785===================================\n",
      "2785/10000: train_loss: 4.019328544288874 train_error 54.62% test_error 58.00%\n",
      "================================2786===================================\n",
      "2786/10000: train_loss: 4.019260621964931 train_error 54.62% test_error 58.00%\n",
      "================================2787===================================\n",
      "2787/10000: train_loss: 4.019192716181278 train_error 54.62% test_error 58.00%\n",
      "================================2788===================================\n",
      "2788/10000: train_loss: 4.019124716669321 train_error 54.62% test_error 58.00%\n",
      "================================2789===================================\n",
      "2789/10000: train_loss: 4.019056708216667 train_error 54.62% test_error 58.00%\n",
      "================================2790===================================\n",
      "2790/10000: train_loss: 4.018988519310951 train_error 54.62% test_error 58.00%\n",
      "================================2791===================================\n",
      "2791/10000: train_loss: 4.018920033872128 train_error 54.62% test_error 58.00%\n",
      "================================2792===================================\n",
      "2792/10000: train_loss: 4.018851533383131 train_error 54.62% test_error 58.00%\n",
      "================================2793===================================\n",
      "2793/10000: train_loss: 4.018782936036587 train_error 54.62% test_error 58.00%\n",
      "================================2794===================================\n",
      "2794/10000: train_loss: 4.018714299947024 train_error 54.62% test_error 58.00%\n",
      "================================2795===================================\n",
      "2795/10000: train_loss: 4.018645277023316 train_error 54.62% test_error 58.00%\n",
      "================================2796===================================\n",
      "2796/10000: train_loss: 4.018576256334781 train_error 54.62% test_error 58.00%\n",
      "================================2797===================================\n",
      "2797/10000: train_loss: 4.018507285416126 train_error 54.62% test_error 58.00%\n",
      "================================2798===================================\n",
      "2798/10000: train_loss: 4.018438380658626 train_error 54.62% test_error 58.00%\n",
      "================================2799===================================\n",
      "2799/10000: train_loss: 4.018370001465082 train_error 54.62% test_error 58.00%\n",
      "================================2800===================================\n",
      "2800/10000: train_loss: 4.018301606178284 train_error 54.62% test_error 58.00%\n",
      "================================2801===================================\n",
      "2801/10000: train_loss: 4.018233230412006 train_error 54.62% test_error 58.00%\n",
      "================================2802===================================\n",
      "2802/10000: train_loss: 4.018164788782597 train_error 54.62% test_error 58.00%\n",
      "================================2803===================================\n",
      "2803/10000: train_loss: 4.018096060305834 train_error 54.62% test_error 58.00%\n",
      "================================2804===================================\n",
      "2804/10000: train_loss: 4.018027157634497 train_error 54.62% test_error 58.00%\n",
      "================================2805===================================\n",
      "2805/10000: train_loss: 4.017957889288664 train_error 54.62% test_error 58.00%\n",
      "================================2806===================================\n",
      "2806/10000: train_loss: 4.017888175398111 train_error 54.62% test_error 58.00%\n",
      "================================2807===================================\n",
      "2807/10000: train_loss: 4.017818705886603 train_error 54.62% test_error 58.00%\n",
      "================================2808===================================\n",
      "2808/10000: train_loss: 4.017749646306038 train_error 54.50% test_error 58.00%\n",
      "================================2809===================================\n",
      "2809/10000: train_loss: 4.017680320590735 train_error 54.50% test_error 58.50%\n",
      "================================2810===================================\n",
      "2810/10000: train_loss: 4.0176106980443 train_error 54.50% test_error 58.50%\n",
      "================================2811===================================\n",
      "2811/10000: train_loss: 4.017540987730026 train_error 54.50% test_error 58.50%\n",
      "================================2812===================================\n",
      "2812/10000: train_loss: 4.017471245825291 train_error 54.50% test_error 58.50%\n",
      "================================2813===================================\n",
      "2813/10000: train_loss: 4.01740132406354 train_error 54.50% test_error 58.50%\n",
      "================================2814===================================\n",
      "2814/10000: train_loss: 4.017331160902977 train_error 54.50% test_error 58.50%\n",
      "================================2815===================================\n",
      "2815/10000: train_loss: 4.017261004596949 train_error 54.50% test_error 58.50%\n",
      "================================2816===================================\n",
      "2816/10000: train_loss: 4.017190775573254 train_error 54.50% test_error 58.50%\n",
      "================================2817===================================\n",
      "2817/10000: train_loss: 4.017120284289122 train_error 54.50% test_error 58.50%\n",
      "================================2818===================================\n",
      "2818/10000: train_loss: 4.0170495054125785 train_error 54.50% test_error 58.50%\n",
      "================================2819===================================\n",
      "2819/10000: train_loss: 4.016978708505631 train_error 54.50% test_error 58.50%\n",
      "================================2820===================================\n",
      "2820/10000: train_loss: 4.016907899826765 train_error 54.50% test_error 58.50%\n",
      "================================2821===================================\n",
      "2821/10000: train_loss: 4.016836962401867 train_error 54.50% test_error 58.50%\n",
      "================================2822===================================\n",
      "2822/10000: train_loss: 4.0167659227550025 train_error 54.50% test_error 58.50%\n",
      "================================2823===================================\n",
      "2823/10000: train_loss: 4.016694284379483 train_error 54.50% test_error 58.50%\n",
      "================================2824===================================\n",
      "2824/10000: train_loss: 4.016622580885887 train_error 54.50% test_error 58.50%\n",
      "================================2825===================================\n",
      "2825/10000: train_loss: 4.016550706028939 train_error 54.50% test_error 58.50%\n",
      "================================2826===================================\n",
      "2826/10000: train_loss: 4.016478608697653 train_error 54.50% test_error 58.50%\n",
      "================================2827===================================\n",
      "2827/10000: train_loss: 4.016406485140324 train_error 54.50% test_error 58.50%\n",
      "================================2828===================================\n",
      "2828/10000: train_loss: 4.016334366798401 train_error 54.50% test_error 58.50%\n",
      "================================2829===================================\n",
      "2829/10000: train_loss: 4.016262225061655 train_error 54.50% test_error 58.50%\n",
      "================================2830===================================\n",
      "2830/10000: train_loss: 4.0161898607015605 train_error 54.50% test_error 58.50%\n",
      "================================2831===================================\n",
      "2831/10000: train_loss: 4.01611717402935 train_error 54.50% test_error 58.50%\n",
      "================================2832===================================\n",
      "2832/10000: train_loss: 4.016044504344463 train_error 54.50% test_error 58.50%\n",
      "================================2833===================================\n",
      "2833/10000: train_loss: 4.015971910357475 train_error 54.50% test_error 58.50%\n",
      "================================2834===================================\n",
      "2834/10000: train_loss: 4.015899256318807 train_error 54.50% test_error 58.50%\n",
      "================================2835===================================\n",
      "2835/10000: train_loss: 4.0158265885710716 train_error 54.50% test_error 58.50%\n",
      "================================2836===================================\n",
      "2836/10000: train_loss: 4.015753922909498 train_error 54.50% test_error 58.50%\n",
      "================================2837===================================\n",
      "2837/10000: train_loss: 4.015681213140487 train_error 54.50% test_error 58.50%\n",
      "================================2838===================================\n",
      "2838/10000: train_loss: 4.015608522742987 train_error 54.37% test_error 58.50%\n",
      "================================2839===================================\n",
      "2839/10000: train_loss: 4.015535781681538 train_error 54.37% test_error 58.50%\n",
      "================================2840===================================\n",
      "2840/10000: train_loss: 4.015462925881147 train_error 54.37% test_error 58.50%\n",
      "================================2841===================================\n",
      "2841/10000: train_loss: 4.015390096902847 train_error 54.37% test_error 58.50%\n",
      "================================2842===================================\n",
      "2842/10000: train_loss: 4.015317220687866 train_error 54.37% test_error 58.50%\n",
      "================================2843===================================\n",
      "2843/10000: train_loss: 4.015244569629431 train_error 54.37% test_error 58.50%\n",
      "================================2844===================================\n",
      "2844/10000: train_loss: 4.015171980559826 train_error 54.37% test_error 58.50%\n",
      "================================2845===================================\n",
      "2845/10000: train_loss: 4.015099315792322 train_error 54.37% test_error 58.50%\n",
      "================================2846===================================\n",
      "2846/10000: train_loss: 4.015026546567678 train_error 54.37% test_error 58.50%\n",
      "================================2847===================================\n",
      "2847/10000: train_loss: 4.014953693300486 train_error 54.37% test_error 58.50%\n",
      "================================2848===================================\n",
      "2848/10000: train_loss: 4.014880787879228 train_error 54.50% test_error 58.50%\n",
      "================================2849===================================\n",
      "2849/10000: train_loss: 4.014807699471712 train_error 54.62% test_error 58.00%\n",
      "================================2850===================================\n",
      "2850/10000: train_loss: 4.014734486192465 train_error 54.50% test_error 58.00%\n",
      "================================2851===================================\n",
      "2851/10000: train_loss: 4.014661275744438 train_error 54.50% test_error 58.00%\n",
      "================================2852===================================\n",
      "2852/10000: train_loss: 4.014587967693806 train_error 54.50% test_error 58.00%\n",
      "================================2853===================================\n",
      "2853/10000: train_loss: 4.014514637589455 train_error 54.50% test_error 58.00%\n",
      "================================2854===================================\n",
      "2854/10000: train_loss: 4.014441174566746 train_error 54.50% test_error 58.00%\n",
      "================================2855===================================\n",
      "2855/10000: train_loss: 4.014367523491383 train_error 54.50% test_error 58.00%\n",
      "================================2856===================================\n",
      "2856/10000: train_loss: 4.014293660372496 train_error 54.50% test_error 58.00%\n",
      "================================2857===================================\n",
      "2857/10000: train_loss: 4.014219734072685 train_error 54.50% test_error 58.00%\n",
      "================================2858===================================\n",
      "2858/10000: train_loss: 4.014145898967982 train_error 54.50% test_error 58.00%\n",
      "================================2859===================================\n",
      "2859/10000: train_loss: 4.014072220474482 train_error 54.62% test_error 58.00%\n",
      "================================2860===================================\n",
      "2860/10000: train_loss: 4.0139986206591125 train_error 54.62% test_error 58.00%\n",
      "================================2861===================================\n",
      "2861/10000: train_loss: 4.01392472833395 train_error 54.62% test_error 58.00%\n",
      "================================2862===================================\n",
      "2862/10000: train_loss: 4.013850456476211 train_error 54.62% test_error 58.00%\n",
      "================================2863===================================\n",
      "2863/10000: train_loss: 4.013775925338268 train_error 54.62% test_error 58.00%\n",
      "================================2864===================================\n",
      "2864/10000: train_loss: 4.013701494634152 train_error 54.62% test_error 58.00%\n",
      "================================2865===================================\n",
      "2865/10000: train_loss: 4.013627174049615 train_error 54.62% test_error 58.00%\n",
      "================================2866===================================\n",
      "2866/10000: train_loss: 4.013552436232567 train_error 54.62% test_error 58.00%\n",
      "================================2867===================================\n",
      "2867/10000: train_loss: 4.0134768237173555 train_error 54.50% test_error 58.00%\n",
      "================================2868===================================\n",
      "2868/10000: train_loss: 4.0134010054171085 train_error 54.50% test_error 58.00%\n",
      "================================2869===================================\n",
      "2869/10000: train_loss: 4.01332486703992 train_error 54.50% test_error 58.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2870===================================\n",
      "2870/10000: train_loss: 4.013248735070229 train_error 54.50% test_error 58.00%\n",
      "================================2871===================================\n",
      "2871/10000: train_loss: 4.013172663003206 train_error 54.50% test_error 58.00%\n",
      "================================2872===================================\n",
      "2872/10000: train_loss: 4.013096551895142 train_error 54.50% test_error 58.00%\n",
      "================================2873===================================\n",
      "2873/10000: train_loss: 4.013020399063826 train_error 54.50% test_error 58.00%\n",
      "================================2874===================================\n",
      "2874/10000: train_loss: 4.012944474071264 train_error 54.50% test_error 58.00%\n",
      "================================2875===================================\n",
      "2875/10000: train_loss: 4.012868721336126 train_error 54.50% test_error 58.00%\n",
      "================================2876===================================\n",
      "2876/10000: train_loss: 4.01279329136014 train_error 54.50% test_error 58.00%\n",
      "================================2877===================================\n",
      "2877/10000: train_loss: 4.0127178062498565 train_error 54.50% test_error 58.00%\n",
      "================================2878===================================\n",
      "2878/10000: train_loss: 4.012641782909632 train_error 54.62% test_error 58.00%\n",
      "================================2879===================================\n",
      "2879/10000: train_loss: 4.012565345019103 train_error 54.62% test_error 58.00%\n",
      "================================2880===================================\n",
      "2880/10000: train_loss: 4.012488892525434 train_error 54.62% test_error 58.00%\n",
      "================================2881===================================\n",
      "2881/10000: train_loss: 4.012412408292294 train_error 54.62% test_error 58.00%\n",
      "================================2882===================================\n",
      "2882/10000: train_loss: 4.01233592659235 train_error 54.62% test_error 58.00%\n",
      "================================2883===================================\n",
      "2883/10000: train_loss: 4.012259360700845 train_error 54.62% test_error 58.00%\n",
      "================================2884===================================\n",
      "2884/10000: train_loss: 4.0121827748417855 train_error 54.62% test_error 58.00%\n",
      "================================2885===================================\n",
      "2885/10000: train_loss: 4.012106221020222 train_error 54.62% test_error 58.00%\n",
      "================================2886===================================\n",
      "2886/10000: train_loss: 4.012029713392257 train_error 54.62% test_error 58.00%\n",
      "================================2887===================================\n",
      "2887/10000: train_loss: 4.011953129917384 train_error 54.62% test_error 58.00%\n",
      "================================2888===================================\n",
      "2888/10000: train_loss: 4.011876285076141 train_error 54.62% test_error 58.00%\n",
      "================================2889===================================\n",
      "2889/10000: train_loss: 4.01179921939969 train_error 54.62% test_error 58.00%\n",
      "================================2890===================================\n",
      "2890/10000: train_loss: 4.011722085624934 train_error 54.62% test_error 58.00%\n",
      "================================2891===================================\n",
      "2891/10000: train_loss: 4.011645008325576 train_error 54.62% test_error 58.00%\n",
      "================================2892===================================\n",
      "2892/10000: train_loss: 4.011568109095096 train_error 54.62% test_error 58.00%\n",
      "================================2893===================================\n",
      "2893/10000: train_loss: 4.0114906822144984 train_error 54.62% test_error 58.00%\n",
      "================================2894===================================\n",
      "2894/10000: train_loss: 4.01141319334507 train_error 54.62% test_error 58.00%\n",
      "================================2895===================================\n",
      "2895/10000: train_loss: 4.011335603594779 train_error 54.62% test_error 58.00%\n",
      "================================2896===================================\n",
      "2896/10000: train_loss: 4.01125793710351 train_error 54.62% test_error 58.00%\n",
      "================================2897===================================\n",
      "2897/10000: train_loss: 4.0111801689863205 train_error 54.62% test_error 58.00%\n",
      "================================2898===================================\n",
      "2898/10000: train_loss: 4.01110236093402 train_error 54.75% test_error 58.00%\n",
      "================================2899===================================\n",
      "2899/10000: train_loss: 4.011024139672518 train_error 54.87% test_error 58.00%\n",
      "================================2900===================================\n",
      "2900/10000: train_loss: 4.010945669114589 train_error 54.87% test_error 58.00%\n",
      "================================2901===================================\n",
      "2901/10000: train_loss: 4.01086724370718 train_error 54.87% test_error 58.00%\n",
      "================================2902===================================\n",
      "2902/10000: train_loss: 4.010788810253143 train_error 54.87% test_error 58.00%\n",
      "================================2903===================================\n",
      "2903/10000: train_loss: 4.010710308104754 train_error 54.87% test_error 58.00%\n",
      "================================2904===================================\n",
      "2904/10000: train_loss: 4.010631755292415 train_error 54.87% test_error 58.00%\n",
      "================================2905===================================\n",
      "2905/10000: train_loss: 4.010552901923656 train_error 54.87% test_error 58.00%\n",
      "================================2906===================================\n",
      "2906/10000: train_loss: 4.010473682880402 train_error 54.87% test_error 58.00%\n",
      "================================2907===================================\n",
      "2907/10000: train_loss: 4.010394442677498 train_error 54.87% test_error 58.00%\n",
      "================================2908===================================\n",
      "2908/10000: train_loss: 4.010315216034651 train_error 54.87% test_error 58.00%\n",
      "================================2909===================================\n",
      "2909/10000: train_loss: 4.010235997885466 train_error 54.87% test_error 58.00%\n",
      "================================2910===================================\n",
      "2910/10000: train_loss: 4.0101567573845385 train_error 54.87% test_error 58.00%\n",
      "================================2911===================================\n",
      "2911/10000: train_loss: 4.010077427774668 train_error 54.87% test_error 58.00%\n",
      "================================2912===================================\n",
      "2912/10000: train_loss: 4.009997987300157 train_error 54.87% test_error 58.00%\n",
      "================================2913===================================\n",
      "2913/10000: train_loss: 4.009918471127749 train_error 54.87% test_error 58.00%\n",
      "================================2914===================================\n",
      "2914/10000: train_loss: 4.009838856607676 train_error 54.87% test_error 58.00%\n",
      "================================2915===================================\n",
      "2915/10000: train_loss: 4.009759054034948 train_error 54.87% test_error 58.00%\n",
      "================================2916===================================\n",
      "2916/10000: train_loss: 4.009679046273231 train_error 54.87% test_error 58.00%\n",
      "================================2917===================================\n",
      "2917/10000: train_loss: 4.009598516821861 train_error 54.87% test_error 58.00%\n",
      "================================2918===================================\n",
      "2918/10000: train_loss: 4.009517683982849 train_error 54.87% test_error 58.00%\n",
      "================================2919===================================\n",
      "2919/10000: train_loss: 4.009436848759651 train_error 54.87% test_error 58.00%\n",
      "================================2920===================================\n",
      "2920/10000: train_loss: 4.009356020092964 train_error 55.00% test_error 58.00%\n",
      "================================2921===================================\n",
      "2921/10000: train_loss: 4.009275354146958 train_error 55.00% test_error 58.00%\n",
      "================================2922===================================\n",
      "2922/10000: train_loss: 4.009194338470698 train_error 55.00% test_error 58.00%\n",
      "================================2923===================================\n",
      "2923/10000: train_loss: 4.009113307744264 train_error 55.00% test_error 58.00%\n",
      "================================2924===================================\n",
      "2924/10000: train_loss: 4.009032194912434 train_error 55.00% test_error 58.00%\n",
      "================================2925===================================\n",
      "2925/10000: train_loss: 4.008950920701027 train_error 55.00% test_error 58.00%\n",
      "================================2926===================================\n",
      "2926/10000: train_loss: 4.008869461119175 train_error 55.00% test_error 58.00%\n",
      "================================2927===================================\n",
      "2927/10000: train_loss: 4.008787728995085 train_error 55.00% test_error 58.00%\n",
      "================================2928===================================\n",
      "2928/10000: train_loss: 4.0087060235440735 train_error 55.00% test_error 58.00%\n",
      "================================2929===================================\n",
      "2929/10000: train_loss: 4.008624220490455 train_error 55.00% test_error 58.00%\n",
      "================================2930===================================\n",
      "2930/10000: train_loss: 4.00854240834713 train_error 55.00% test_error 58.00%\n",
      "================================2931===================================\n",
      "2931/10000: train_loss: 4.008460839241743 train_error 55.00% test_error 58.00%\n",
      "================================2932===================================\n",
      "2932/10000: train_loss: 4.008379407525062 train_error 55.00% test_error 58.00%\n",
      "================================2933===================================\n",
      "2933/10000: train_loss: 4.00829781755805 train_error 55.00% test_error 58.00%\n",
      "================================2934===================================\n",
      "2934/10000: train_loss: 4.008216121494771 train_error 55.00% test_error 58.00%\n",
      "================================2935===================================\n",
      "2935/10000: train_loss: 4.008134253025055 train_error 55.00% test_error 58.00%\n",
      "================================2936===================================\n",
      "2936/10000: train_loss: 4.008052166253329 train_error 55.00% test_error 58.00%\n",
      "================================2937===================================\n",
      "2937/10000: train_loss: 4.007970234304667 train_error 55.00% test_error 58.00%\n",
      "================================2938===================================\n",
      "2938/10000: train_loss: 4.007888582348824 train_error 55.00% test_error 58.00%\n",
      "================================2939===================================\n",
      "2939/10000: train_loss: 4.007806679904461 train_error 55.00% test_error 58.00%\n",
      "================================2940===================================\n",
      "2940/10000: train_loss: 4.007724452465773 train_error 55.00% test_error 58.00%\n",
      "================================2941===================================\n",
      "2941/10000: train_loss: 4.007642021328211 train_error 55.00% test_error 58.00%\n",
      "================================2942===================================\n",
      "2942/10000: train_loss: 4.007559347897768 train_error 55.00% test_error 58.00%\n",
      "================================2943===================================\n",
      "2943/10000: train_loss: 4.007476482093335 train_error 55.00% test_error 58.00%\n",
      "================================2944===================================\n",
      "2944/10000: train_loss: 4.007393007874489 train_error 55.00% test_error 58.00%\n",
      "================================2945===================================\n",
      "2945/10000: train_loss: 4.007309534698725 train_error 55.00% test_error 58.00%\n",
      "================================2946===================================\n",
      "2946/10000: train_loss: 4.007225989848376 train_error 54.87% test_error 58.00%\n",
      "================================2947===================================\n",
      "2947/10000: train_loss: 4.007142394334078 train_error 54.87% test_error 58.00%\n",
      "================================2948===================================\n",
      "2948/10000: train_loss: 4.0070586265623565 train_error 55.00% test_error 58.00%\n",
      "================================2949===================================\n",
      "2949/10000: train_loss: 4.006974342614412 train_error 55.00% test_error 58.00%\n",
      "================================2950===================================\n",
      "2950/10000: train_loss: 4.006889976859092 train_error 55.00% test_error 58.00%\n",
      "================================2951===================================\n",
      "2951/10000: train_loss: 4.0068056195974355 train_error 55.00% test_error 58.00%\n",
      "================================2952===================================\n",
      "2952/10000: train_loss: 4.0067212355136865 train_error 55.00% test_error 58.00%\n",
      "================================2953===================================\n",
      "2953/10000: train_loss: 4.006637299954891 train_error 55.00% test_error 58.00%\n",
      "================================2954===================================\n",
      "2954/10000: train_loss: 4.006553307324648 train_error 55.00% test_error 58.00%\n",
      "================================2955===================================\n",
      "2955/10000: train_loss: 4.006469292044639 train_error 55.00% test_error 58.00%\n",
      "================================2956===================================\n",
      "2956/10000: train_loss: 4.006385263502597 train_error 55.00% test_error 58.00%\n",
      "================================2957===================================\n",
      "2957/10000: train_loss: 4.006301193982363 train_error 54.87% test_error 58.00%\n",
      "================================2958===================================\n",
      "2958/10000: train_loss: 4.006216799020767 train_error 54.75% test_error 58.00%\n",
      "================================2959===================================\n",
      "2959/10000: train_loss: 4.006132419556379 train_error 54.75% test_error 58.00%\n",
      "================================2960===================================\n",
      "2960/10000: train_loss: 4.006048040539026 train_error 54.75% test_error 58.00%\n",
      "================================2961===================================\n",
      "2961/10000: train_loss: 4.00596350312233 train_error 54.75% test_error 58.00%\n",
      "================================2962===================================\n",
      "2962/10000: train_loss: 4.005878793895245 train_error 54.75% test_error 58.00%\n",
      "================================2963===================================\n",
      "2963/10000: train_loss: 4.005794030129909 train_error 54.75% test_error 58.00%\n",
      "================================2964===================================\n",
      "2964/10000: train_loss: 4.005709223151207 train_error 54.75% test_error 58.00%\n",
      "================================2965===================================\n",
      "2965/10000: train_loss: 4.005624509900809 train_error 54.75% test_error 58.00%\n",
      "================================2966===================================\n",
      "2966/10000: train_loss: 4.005539900660515 train_error 54.75% test_error 58.00%\n",
      "================================2967===================================\n",
      "2967/10000: train_loss: 4.00545538291335 train_error 54.75% test_error 58.00%\n",
      "================================2968===================================\n",
      "2968/10000: train_loss: 4.0053707510232925 train_error 54.75% test_error 58.00%\n",
      "================================2969===================================\n",
      "2969/10000: train_loss: 4.005285948514938 train_error 54.75% test_error 58.00%\n",
      "================================2970===================================\n",
      "2970/10000: train_loss: 4.005201254338026 train_error 54.75% test_error 58.00%\n",
      "================================2971===================================\n",
      "2971/10000: train_loss: 4.005116479098797 train_error 54.75% test_error 58.00%\n",
      "================================2972===================================\n",
      "2972/10000: train_loss: 4.005031621605158 train_error 54.75% test_error 58.00%\n",
      "================================2973===================================\n",
      "2973/10000: train_loss: 4.004946690797806 train_error 54.75% test_error 58.00%\n",
      "================================2974===================================\n",
      "2974/10000: train_loss: 4.004861567914486 train_error 54.75% test_error 58.00%\n",
      "================================2975===================================\n",
      "2975/10000: train_loss: 4.004776374399662 train_error 54.75% test_error 58.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================2976===================================\n",
      "2976/10000: train_loss: 4.004691156446934 train_error 54.75% test_error 58.00%\n",
      "================================2977===================================\n",
      "2977/10000: train_loss: 4.0046055978536605 train_error 54.75% test_error 58.00%\n",
      "================================2978===================================\n",
      "2978/10000: train_loss: 4.004519877433777 train_error 54.75% test_error 58.00%\n",
      "================================2979===================================\n",
      "2979/10000: train_loss: 4.004433763176203 train_error 54.75% test_error 58.00%\n",
      "================================2980===================================\n",
      "2980/10000: train_loss: 4.0043476934731 train_error 54.75% test_error 58.00%\n",
      "================================2981===================================\n",
      "2981/10000: train_loss: 4.004261500388385 train_error 54.75% test_error 58.00%\n",
      "================================2982===================================\n",
      "2982/10000: train_loss: 4.004175205677748 train_error 54.75% test_error 58.00%\n",
      "================================2983===================================\n",
      "2983/10000: train_loss: 4.004088058173656 train_error 54.87% test_error 58.00%\n",
      "================================2984===================================\n",
      "2984/10000: train_loss: 4.00400009304285 train_error 54.87% test_error 58.00%\n",
      "================================2985===================================\n",
      "2985/10000: train_loss: 4.003911835849285 train_error 54.87% test_error 58.00%\n",
      "================================2986===================================\n",
      "2986/10000: train_loss: 4.003823165595532 train_error 54.87% test_error 58.00%\n",
      "================================2987===================================\n",
      "2987/10000: train_loss: 4.003734005391598 train_error 54.87% test_error 58.00%\n",
      "================================2988===================================\n",
      "2988/10000: train_loss: 4.003644642233849 train_error 54.75% test_error 58.00%\n",
      "================================2989===================================\n",
      "2989/10000: train_loss: 4.003555257469415 train_error 54.75% test_error 58.00%\n",
      "================================2990===================================\n",
      "2990/10000: train_loss: 4.003465733230114 train_error 54.75% test_error 58.00%\n",
      "================================2991===================================\n",
      "2991/10000: train_loss: 4.003376155048609 train_error 54.62% test_error 58.00%\n",
      "================================2992===================================\n",
      "2992/10000: train_loss: 4.003285998702049 train_error 54.62% test_error 58.00%\n",
      "================================2993===================================\n",
      "2993/10000: train_loss: 4.003195796906948 train_error 54.62% test_error 58.00%\n",
      "================================2994===================================\n",
      "2994/10000: train_loss: 4.003105737417936 train_error 54.62% test_error 58.00%\n",
      "================================2995===================================\n",
      "2995/10000: train_loss: 4.003015528172255 train_error 54.62% test_error 58.00%\n",
      "================================2996===================================\n",
      "2996/10000: train_loss: 4.002925749272108 train_error 54.62% test_error 58.00%\n",
      "================================2997===================================\n",
      "2997/10000: train_loss: 4.002835911214351 train_error 54.62% test_error 58.00%\n",
      "================================2998===================================\n",
      "2998/10000: train_loss: 4.002746098935604 train_error 54.62% test_error 58.00%\n",
      "================================2999===================================\n",
      "2999/10000: train_loss: 4.002655952423811 train_error 54.62% test_error 58.00%\n",
      "================================3000===================================\n",
      "3000/10000: train_loss: 4.0025651063025 train_error 54.62% test_error 58.00%\n",
      "================================3001===================================\n",
      "3001/10000: train_loss: 4.002474258691072 train_error 54.62% test_error 58.00%\n",
      "================================3002===================================\n",
      "3002/10000: train_loss: 4.002383444160223 train_error 54.50% test_error 58.00%\n",
      "================================3003===================================\n",
      "3003/10000: train_loss: 4.002292605042458 train_error 54.50% test_error 58.00%\n",
      "================================3004===================================\n",
      "3004/10000: train_loss: 4.002201779037715 train_error 54.50% test_error 58.00%\n",
      "================================3005===================================\n",
      "3005/10000: train_loss: 4.002110925614834 train_error 54.50% test_error 58.00%\n",
      "================================3006===================================\n",
      "3006/10000: train_loss: 4.00202005520463 train_error 54.50% test_error 58.00%\n",
      "================================3007===================================\n",
      "3007/10000: train_loss: 4.001929048150778 train_error 54.50% test_error 58.00%\n",
      "================================3008===================================\n",
      "3008/10000: train_loss: 4.001837501376867 train_error 54.50% test_error 58.00%\n",
      "================================3009===================================\n",
      "3009/10000: train_loss: 4.001745860129595 train_error 54.50% test_error 58.00%\n",
      "================================3010===================================\n",
      "3010/10000: train_loss: 4.00165414005518 train_error 54.50% test_error 58.00%\n",
      "================================3011===================================\n",
      "3011/10000: train_loss: 4.0015623770654205 train_error 54.50% test_error 58.00%\n",
      "================================3012===================================\n",
      "3012/10000: train_loss: 4.001470409333706 train_error 54.50% test_error 58.00%\n",
      "================================3013===================================\n",
      "3013/10000: train_loss: 4.001378272771835 train_error 54.50% test_error 58.00%\n",
      "================================3014===================================\n",
      "3014/10000: train_loss: 4.001285636723042 train_error 54.50% test_error 58.00%\n",
      "================================3015===================================\n",
      "3015/10000: train_loss: 4.001192564070225 train_error 54.50% test_error 58.00%\n",
      "================================3016===================================\n",
      "3016/10000: train_loss: 4.001099307388067 train_error 54.50% test_error 58.00%\n",
      "================================3017===================================\n",
      "3017/10000: train_loss: 4.001005883216858 train_error 54.50% test_error 58.00%\n",
      "================================3018===================================\n",
      "3018/10000: train_loss: 4.000912309736013 train_error 54.50% test_error 58.00%\n",
      "================================3019===================================\n",
      "3019/10000: train_loss: 4.000818733721971 train_error 54.50% test_error 58.00%\n",
      "================================3020===================================\n",
      "3020/10000: train_loss: 4.00072531670332 train_error 54.50% test_error 58.00%\n",
      "================================3021===================================\n",
      "3021/10000: train_loss: 4.00063206538558 train_error 54.62% test_error 58.00%\n",
      "================================3022===================================\n",
      "3022/10000: train_loss: 4.000538637787104 train_error 54.62% test_error 58.00%\n",
      "================================3023===================================\n",
      "3023/10000: train_loss: 4.0004448659718035 train_error 54.62% test_error 58.00%\n",
      "================================3024===================================\n",
      "3024/10000: train_loss: 4.00035105317831 train_error 54.62% test_error 58.00%\n",
      "================================3025===================================\n",
      "3025/10000: train_loss: 4.00025723695755 train_error 54.62% test_error 58.00%\n",
      "================================3026===================================\n",
      "3026/10000: train_loss: 4.000163082778453 train_error 54.62% test_error 58.00%\n",
      "================================3027===================================\n",
      "3027/10000: train_loss: 4.000068346410989 train_error 54.62% test_error 58.00%\n",
      "================================3028===================================\n",
      "3028/10000: train_loss: 3.999973488152027 train_error 54.62% test_error 58.00%\n",
      "================================3029===================================\n",
      "3029/10000: train_loss: 3.99987856015563 train_error 54.62% test_error 58.00%\n",
      "================================3030===================================\n",
      "3030/10000: train_loss: 3.999783445745707 train_error 54.62% test_error 58.00%\n",
      "================================3031===================================\n",
      "3031/10000: train_loss: 3.999688238054514 train_error 54.62% test_error 58.00%\n",
      "================================3032===================================\n",
      "3032/10000: train_loss: 3.9995928911864755 train_error 54.62% test_error 58.00%\n",
      "================================3033===================================\n",
      "3033/10000: train_loss: 3.999497518837452 train_error 54.62% test_error 58.00%\n",
      "================================3034===================================\n",
      "3034/10000: train_loss: 3.999402095079422 train_error 54.62% test_error 58.00%\n",
      "================================3035===================================\n",
      "3035/10000: train_loss: 3.999306411594153 train_error 54.62% test_error 58.00%\n",
      "================================3036===================================\n",
      "3036/10000: train_loss: 3.9992106299102304 train_error 54.62% test_error 58.00%\n",
      "================================3037===================================\n",
      "3037/10000: train_loss: 3.999114669710398 train_error 54.62% test_error 58.00%\n",
      "================================3038===================================\n",
      "3038/10000: train_loss: 3.999017666578293 train_error 54.50% test_error 58.00%\n",
      "================================3039===================================\n",
      "3039/10000: train_loss: 3.9989203968644143 train_error 54.50% test_error 58.00%\n",
      "================================3040===================================\n",
      "3040/10000: train_loss: 3.998823067843914 train_error 54.50% test_error 58.00%\n",
      "================================3041===================================\n",
      "3041/10000: train_loss: 3.9987255826592447 train_error 54.50% test_error 58.00%\n",
      "================================3042===================================\n",
      "3042/10000: train_loss: 3.9986280858516694 train_error 54.50% test_error 58.00%\n",
      "================================3043===================================\n",
      "3043/10000: train_loss: 3.9985305462777614 train_error 54.50% test_error 58.00%\n",
      "================================3044===================================\n",
      "3044/10000: train_loss: 3.998432952016592 train_error 54.50% test_error 58.00%\n",
      "================================3045===================================\n",
      "3045/10000: train_loss: 3.9983352443575857 train_error 54.50% test_error 58.00%\n",
      "================================3046===================================\n",
      "3046/10000: train_loss: 3.998237584680319 train_error 54.50% test_error 58.00%\n",
      "================================3047===================================\n",
      "3047/10000: train_loss: 3.99814001634717 train_error 54.50% test_error 58.00%\n",
      "================================3048===================================\n",
      "3048/10000: train_loss: 3.9980424128472802 train_error 54.50% test_error 58.00%\n",
      "================================3049===================================\n",
      "3049/10000: train_loss: 3.9979447460174558 train_error 54.50% test_error 58.00%\n",
      "================================3050===================================\n",
      "3050/10000: train_loss: 3.9978468020260336 train_error 54.50% test_error 58.00%\n",
      "================================3051===================================\n",
      "3051/10000: train_loss: 3.9977484560012817 train_error 54.50% test_error 58.00%\n",
      "================================3052===================================\n",
      "3052/10000: train_loss: 3.9976501037180423 train_error 54.50% test_error 58.00%\n",
      "================================3053===================================\n",
      "3053/10000: train_loss: 3.997551524788141 train_error 54.50% test_error 58.00%\n",
      "================================3054===================================\n",
      "3054/10000: train_loss: 3.997452542930841 train_error 54.50% test_error 58.00%\n",
      "================================3055===================================\n",
      "3055/10000: train_loss: 3.9973534297943116 train_error 54.37% test_error 58.00%\n",
      "================================3056===================================\n",
      "3056/10000: train_loss: 3.997254420369864 train_error 54.37% test_error 58.00%\n",
      "================================3057===================================\n",
      "3057/10000: train_loss: 3.9971556001901627 train_error 54.37% test_error 58.00%\n",
      "================================3058===================================\n",
      "3058/10000: train_loss: 3.9970564506947994 train_error 54.37% test_error 58.00%\n",
      "================================3059===================================\n",
      "3059/10000: train_loss: 3.9969567503035073 train_error 54.37% test_error 58.00%\n",
      "================================3060===================================\n",
      "3060/10000: train_loss: 3.99685665845871 train_error 54.37% test_error 58.00%\n",
      "================================3061===================================\n",
      "3061/10000: train_loss: 3.99675658300519 train_error 54.37% test_error 58.00%\n",
      "================================3062===================================\n",
      "3062/10000: train_loss: 3.9966564854979514 train_error 54.37% test_error 58.00%\n",
      "================================3063===================================\n",
      "3063/10000: train_loss: 3.996556106954813 train_error 54.37% test_error 58.00%\n",
      "================================3064===================================\n",
      "3064/10000: train_loss: 3.996455719321966 train_error 54.37% test_error 58.00%\n",
      "================================3065===================================\n",
      "3065/10000: train_loss: 3.9963552767038344 train_error 54.37% test_error 58.00%\n",
      "================================3066===================================\n",
      "3066/10000: train_loss: 3.9962544012069703 train_error 54.37% test_error 58.00%\n",
      "================================3067===================================\n",
      "3067/10000: train_loss: 3.9961534057557584 train_error 54.37% test_error 58.00%\n",
      "================================3068===================================\n",
      "3068/10000: train_loss: 3.9960523387789726 train_error 54.37% test_error 58.00%\n",
      "================================3069===================================\n",
      "3069/10000: train_loss: 3.995951178222895 train_error 54.25% test_error 58.00%\n",
      "================================3070===================================\n",
      "3070/10000: train_loss: 3.9958495841920376 train_error 54.25% test_error 58.00%\n",
      "================================3071===================================\n",
      "3071/10000: train_loss: 3.9957474820315837 train_error 54.25% test_error 58.00%\n",
      "================================3072===================================\n",
      "3072/10000: train_loss: 3.995645179003477 train_error 54.25% test_error 58.00%\n",
      "================================3073===================================\n",
      "3073/10000: train_loss: 3.995542080998421 train_error 54.37% test_error 58.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3074===================================\n",
      "3074/10000: train_loss: 3.995438433736563 train_error 54.37% test_error 58.00%\n",
      "================================3075===================================\n",
      "3075/10000: train_loss: 3.9953347887098793 train_error 54.37% test_error 58.00%\n",
      "================================3076===================================\n",
      "3076/10000: train_loss: 3.9952311284840105 train_error 54.37% test_error 58.00%\n",
      "================================3077===================================\n",
      "3077/10000: train_loss: 3.9951273854076863 train_error 54.37% test_error 58.00%\n",
      "================================3078===================================\n",
      "3078/10000: train_loss: 3.995023457556963 train_error 54.37% test_error 58.00%\n",
      "================================3079===================================\n",
      "3079/10000: train_loss: 3.9949196116626258 train_error 54.50% test_error 58.00%\n",
      "================================3080===================================\n",
      "3080/10000: train_loss: 3.9948155276477335 train_error 54.50% test_error 58.00%\n",
      "================================3081===================================\n",
      "3081/10000: train_loss: 3.994711261689663 train_error 54.50% test_error 58.00%\n",
      "================================3082===================================\n",
      "3082/10000: train_loss: 3.994606886059046 train_error 54.50% test_error 58.00%\n",
      "================================3083===================================\n",
      "3083/10000: train_loss: 3.994502217620611 train_error 54.50% test_error 58.00%\n",
      "================================3084===================================\n",
      "3084/10000: train_loss: 3.9943975861370564 train_error 54.50% test_error 58.00%\n",
      "================================3085===================================\n",
      "3085/10000: train_loss: 3.9942930170893667 train_error 54.37% test_error 58.00%\n",
      "================================3086===================================\n",
      "3086/10000: train_loss: 3.9941884049773217 train_error 54.37% test_error 58.00%\n",
      "================================3087===================================\n",
      "3087/10000: train_loss: 3.994083650559187 train_error 54.50% test_error 58.00%\n",
      "================================3088===================================\n",
      "3088/10000: train_loss: 3.9939786866307263 train_error 54.50% test_error 58.00%\n",
      "================================3089===================================\n",
      "3089/10000: train_loss: 3.993873501121998 train_error 54.50% test_error 58.00%\n",
      "================================3090===================================\n",
      "3090/10000: train_loss: 3.9937680944800373 train_error 54.50% test_error 58.00%\n",
      "================================3091===================================\n",
      "3091/10000: train_loss: 3.993662405759096 train_error 54.50% test_error 58.00%\n",
      "================================3092===================================\n",
      "3092/10000: train_loss: 3.9935566414892674 train_error 54.50% test_error 58.00%\n",
      "================================3093===================================\n",
      "3093/10000: train_loss: 3.993451091647148 train_error 54.50% test_error 58.00%\n",
      "================================3094===================================\n",
      "3094/10000: train_loss: 3.993345587849617 train_error 54.50% test_error 58.00%\n",
      "================================3095===================================\n",
      "3095/10000: train_loss: 3.9932396383583546 train_error 54.50% test_error 58.00%\n",
      "================================3096===================================\n",
      "3096/10000: train_loss: 3.993132966607809 train_error 54.50% test_error 58.00%\n",
      "================================3097===================================\n",
      "3097/10000: train_loss: 3.9930253835022445 train_error 54.50% test_error 58.00%\n",
      "================================3098===================================\n",
      "3098/10000: train_loss: 3.9929175166785713 train_error 54.50% test_error 58.00%\n",
      "================================3099===================================\n",
      "3099/10000: train_loss: 3.9928094218671317 train_error 54.50% test_error 58.00%\n",
      "================================3100===================================\n",
      "3100/10000: train_loss: 3.9927009963989253 train_error 54.50% test_error 58.00%\n",
      "================================3101===================================\n",
      "3101/10000: train_loss: 3.9925924509763715 train_error 54.50% test_error 58.00%\n",
      "================================3102===================================\n",
      "3102/10000: train_loss: 3.9924837566912172 train_error 54.50% test_error 58.00%\n",
      "================================3103===================================\n",
      "3103/10000: train_loss: 3.992375039160251 train_error 54.50% test_error 58.00%\n",
      "================================3104===================================\n",
      "3104/10000: train_loss: 3.9922661869227882 train_error 54.50% test_error 58.00%\n",
      "================================3105===================================\n",
      "3105/10000: train_loss: 3.9921573424339294 train_error 54.62% test_error 58.00%\n",
      "================================3106===================================\n",
      "3106/10000: train_loss: 3.99204837307334 train_error 54.62% test_error 58.00%\n",
      "================================3107===================================\n",
      "3107/10000: train_loss: 3.9919391536712645 train_error 54.62% test_error 58.00%\n",
      "================================3108===================================\n",
      "3108/10000: train_loss: 3.991829878538847 train_error 54.62% test_error 58.00%\n",
      "================================3109===================================\n",
      "3109/10000: train_loss: 3.9917205260694026 train_error 54.62% test_error 58.00%\n",
      "================================3110===================================\n",
      "3110/10000: train_loss: 3.991611108928919 train_error 54.62% test_error 58.00%\n",
      "================================3111===================================\n",
      "3111/10000: train_loss: 3.991501472890377 train_error 54.62% test_error 58.00%\n",
      "================================3112===================================\n",
      "3112/10000: train_loss: 3.991391737759113 train_error 54.62% test_error 58.00%\n",
      "================================3113===================================\n",
      "3113/10000: train_loss: 3.991282093077898 train_error 54.62% test_error 58.00%\n",
      "================================3114===================================\n",
      "3114/10000: train_loss: 3.9911725233495234 train_error 54.62% test_error 58.00%\n",
      "================================3115===================================\n",
      "3115/10000: train_loss: 3.9910628348588943 train_error 54.62% test_error 58.00%\n",
      "================================3116===================================\n",
      "3116/10000: train_loss: 3.99095310613513 train_error 54.62% test_error 58.00%\n",
      "================================3117===================================\n",
      "3117/10000: train_loss: 3.9908433592319486 train_error 54.62% test_error 58.00%\n",
      "================================3118===================================\n",
      "3118/10000: train_loss: 3.990733687132597 train_error 54.62% test_error 58.00%\n",
      "================================3119===================================\n",
      "3119/10000: train_loss: 3.99062359392643 train_error 54.62% test_error 58.00%\n",
      "================================3120===================================\n",
      "3120/10000: train_loss: 3.9905133005976676 train_error 54.62% test_error 58.00%\n",
      "================================3121===================================\n",
      "3121/10000: train_loss: 3.990403266400099 train_error 54.62% test_error 58.00%\n",
      "================================3122===================================\n",
      "3122/10000: train_loss: 3.990293634235859 train_error 54.62% test_error 58.00%\n",
      "================================3123===================================\n",
      "3123/10000: train_loss: 3.9901838602125643 train_error 54.62% test_error 58.00%\n",
      "================================3124===================================\n",
      "3124/10000: train_loss: 3.9900739905238147 train_error 54.50% test_error 58.00%\n",
      "================================3125===================================\n",
      "3125/10000: train_loss: 3.9899636955559252 train_error 54.50% test_error 58.00%\n",
      "================================3126===================================\n",
      "3126/10000: train_loss: 3.989852530360222 train_error 54.50% test_error 58.00%\n",
      "================================3127===================================\n",
      "3127/10000: train_loss: 3.989741308242082 train_error 54.50% test_error 58.00%\n",
      "================================3128===================================\n",
      "3128/10000: train_loss: 3.9896297214925287 train_error 54.50% test_error 58.00%\n",
      "================================3129===================================\n",
      "3129/10000: train_loss: 3.989517717808485 train_error 54.50% test_error 58.00%\n",
      "================================3130===================================\n",
      "3130/10000: train_loss: 3.9894055701792235 train_error 54.50% test_error 58.00%\n",
      "================================3131===================================\n",
      "3131/10000: train_loss: 3.9892930632829673 train_error 54.50% test_error 58.00%\n",
      "================================3132===================================\n",
      "3132/10000: train_loss: 3.989180472791195 train_error 54.50% test_error 58.00%\n",
      "================================3133===================================\n",
      "3133/10000: train_loss: 3.9890677495300775 train_error 54.50% test_error 58.00%\n",
      "================================3134===================================\n",
      "3134/10000: train_loss: 3.988954934924841 train_error 54.50% test_error 58.00%\n",
      "================================3135===================================\n",
      "3135/10000: train_loss: 3.9888419935107233 train_error 54.25% test_error 58.00%\n",
      "================================3136===================================\n",
      "3136/10000: train_loss: 3.988728738427162 train_error 54.25% test_error 58.00%\n",
      "================================3137===================================\n",
      "3137/10000: train_loss: 3.9886153213679787 train_error 54.25% test_error 58.00%\n",
      "================================3138===================================\n",
      "3138/10000: train_loss: 3.988501735329628 train_error 54.25% test_error 58.00%\n",
      "================================3139===================================\n",
      "3139/10000: train_loss: 3.988388156592846 train_error 54.25% test_error 58.00%\n",
      "================================3140===================================\n",
      "3140/10000: train_loss: 3.988274720311165 train_error 54.25% test_error 58.00%\n",
      "================================3141===================================\n",
      "3141/10000: train_loss: 3.9881611706316473 train_error 54.25% test_error 58.00%\n",
      "================================3142===================================\n",
      "3142/10000: train_loss: 3.9880474105477335 train_error 54.25% test_error 58.00%\n",
      "================================3143===================================\n",
      "3143/10000: train_loss: 3.9879333792626857 train_error 54.25% test_error 58.00%\n",
      "================================3144===================================\n",
      "3144/10000: train_loss: 3.987819267064333 train_error 54.25% test_error 58.00%\n",
      "================================3145===================================\n",
      "3145/10000: train_loss: 3.9877047364413736 train_error 54.25% test_error 58.00%\n",
      "================================3146===================================\n",
      "3146/10000: train_loss: 3.987589791417122 train_error 54.25% test_error 58.00%\n",
      "================================3147===================================\n",
      "3147/10000: train_loss: 3.987474534362555 train_error 54.37% test_error 58.00%\n",
      "================================3148===================================\n",
      "3148/10000: train_loss: 3.9873586775362493 train_error 54.37% test_error 58.00%\n",
      "================================3149===================================\n",
      "3149/10000: train_loss: 3.987241610735655 train_error 54.37% test_error 58.00%\n",
      "================================3150===================================\n",
      "3150/10000: train_loss: 3.987124283015728 train_error 54.37% test_error 58.00%\n",
      "================================3151===================================\n",
      "3151/10000: train_loss: 3.987006863802671 train_error 54.37% test_error 58.00%\n",
      "================================3152===================================\n",
      "3152/10000: train_loss: 3.9868897107243537 train_error 54.37% test_error 58.00%\n",
      "================================3153===================================\n",
      "3153/10000: train_loss: 3.986772698611021 train_error 54.37% test_error 58.00%\n",
      "================================3154===================================\n",
      "3154/10000: train_loss: 3.9866555431485176 train_error 54.25% test_error 58.00%\n",
      "================================3155===================================\n",
      "3155/10000: train_loss: 3.9865381151437758 train_error 54.25% test_error 58.00%\n",
      "================================3156===================================\n",
      "3156/10000: train_loss: 3.986420423388481 train_error 54.25% test_error 58.00%\n",
      "================================3157===================================\n",
      "3157/10000: train_loss: 3.986302311122418 train_error 54.25% test_error 58.00%\n",
      "================================3158===================================\n",
      "3158/10000: train_loss: 3.9861840310692784 train_error 54.25% test_error 58.00%\n",
      "================================3159===================================\n",
      "3159/10000: train_loss: 3.986065618097782 train_error 54.25% test_error 58.00%\n",
      "================================3160===================================\n",
      "3160/10000: train_loss: 3.9859470704197886 train_error 54.25% test_error 58.00%\n",
      "================================3161===================================\n",
      "3161/10000: train_loss: 3.9858277155458928 train_error 54.12% test_error 58.00%\n",
      "================================3162===================================\n",
      "3162/10000: train_loss: 3.9857080587744713 train_error 54.12% test_error 58.00%\n",
      "================================3163===================================\n",
      "3163/10000: train_loss: 3.985587767958641 train_error 54.12% test_error 58.00%\n",
      "================================3164===================================\n",
      "3164/10000: train_loss: 3.9854671938717363 train_error 54.12% test_error 57.50%\n",
      "================================3165===================================\n",
      "3165/10000: train_loss: 3.9853463964164257 train_error 54.12% test_error 57.50%\n",
      "================================3166===================================\n",
      "3166/10000: train_loss: 3.9852252262830734 train_error 54.12% test_error 57.50%\n",
      "================================3167===================================\n",
      "3167/10000: train_loss: 3.9851039706170566 train_error 54.12% test_error 57.50%\n",
      "================================3168===================================\n",
      "3168/10000: train_loss: 3.9849825455248356 train_error 54.12% test_error 57.50%\n",
      "================================3169===================================\n",
      "3169/10000: train_loss: 3.9848610666394233 train_error 54.12% test_error 57.50%\n",
      "================================3170===================================\n",
      "3170/10000: train_loss: 3.9847387391328812 train_error 54.12% test_error 57.50%\n",
      "================================3171===================================\n",
      "3171/10000: train_loss: 3.9846159178018565 train_error 54.12% test_error 57.50%\n",
      "================================3172===================================\n",
      "3172/10000: train_loss: 3.9844928073883055 train_error 54.12% test_error 57.50%\n",
      "================================3173===================================\n",
      "3173/10000: train_loss: 3.984369185715914 train_error 54.00% test_error 57.50%\n",
      "================================3174===================================\n",
      "3174/10000: train_loss: 3.9842448739707472 train_error 54.00% test_error 57.50%\n",
      "================================3175===================================\n",
      "3175/10000: train_loss: 3.9841204364597798 train_error 54.12% test_error 57.50%\n",
      "================================3176===================================\n",
      "3176/10000: train_loss: 3.983995841741562 train_error 54.12% test_error 57.50%\n",
      "================================3177===================================\n",
      "3177/10000: train_loss: 3.983870790451765 train_error 54.12% test_error 57.50%\n",
      "================================3178===================================\n",
      "3178/10000: train_loss: 3.9837448248267178 train_error 54.12% test_error 57.50%\n",
      "================================3179===================================\n",
      "3179/10000: train_loss: 3.9836182793974872 train_error 54.12% test_error 57.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3180===================================\n",
      "3180/10000: train_loss: 3.983492469340563 train_error 54.12% test_error 57.50%\n",
      "================================3181===================================\n",
      "3181/10000: train_loss: 3.9833665309846404 train_error 54.12% test_error 57.50%\n",
      "================================3182===================================\n",
      "3182/10000: train_loss: 3.9832403998076917 train_error 54.12% test_error 57.50%\n",
      "================================3183===================================\n",
      "3183/10000: train_loss: 3.9831140215694907 train_error 54.12% test_error 57.00%\n",
      "================================3184===================================\n",
      "3184/10000: train_loss: 3.982987725585699 train_error 54.12% test_error 57.00%\n",
      "================================3185===================================\n",
      "3185/10000: train_loss: 3.982861271202564 train_error 54.00% test_error 57.00%\n",
      "================================3186===================================\n",
      "3186/10000: train_loss: 3.9827344846725463 train_error 54.00% test_error 57.00%\n",
      "================================3187===================================\n",
      "3187/10000: train_loss: 3.982607159912586 train_error 54.00% test_error 57.00%\n",
      "================================3188===================================\n",
      "3188/10000: train_loss: 3.9824792985618114 train_error 54.00% test_error 57.00%\n",
      "================================3189===================================\n",
      "3189/10000: train_loss: 3.982351321429014 train_error 54.00% test_error 57.00%\n",
      "================================3190===================================\n",
      "3190/10000: train_loss: 3.9822231487929822 train_error 54.00% test_error 57.00%\n",
      "================================3191===================================\n",
      "3191/10000: train_loss: 3.9820947550237182 train_error 54.00% test_error 57.00%\n",
      "================================3192===================================\n",
      "3192/10000: train_loss: 3.981966237723827 train_error 54.00% test_error 57.00%\n",
      "================================3193===================================\n",
      "3193/10000: train_loss: 3.9818376424908637 train_error 54.00% test_error 57.00%\n",
      "================================3194===================================\n",
      "3194/10000: train_loss: 3.9817090371251105 train_error 54.00% test_error 57.00%\n",
      "================================3195===================================\n",
      "3195/10000: train_loss: 3.9815801195800304 train_error 54.00% test_error 57.00%\n",
      "================================3196===================================\n",
      "3196/10000: train_loss: 3.981450937986374 train_error 54.00% test_error 57.00%\n",
      "================================3197===================================\n",
      "3197/10000: train_loss: 3.981321879476309 train_error 54.00% test_error 57.00%\n",
      "================================3198===================================\n",
      "3198/10000: train_loss: 3.981192249804735 train_error 54.00% test_error 57.00%\n",
      "================================3199===================================\n",
      "3199/10000: train_loss: 3.981062064766884 train_error 54.00% test_error 57.00%\n",
      "================================3200===================================\n",
      "3200/10000: train_loss: 3.9809318120777606 train_error 54.00% test_error 57.00%\n",
      "================================3201===================================\n",
      "3201/10000: train_loss: 3.9808015641570087 train_error 54.00% test_error 57.00%\n",
      "================================3202===================================\n",
      "3202/10000: train_loss: 3.9806712760031226 train_error 54.00% test_error 57.00%\n",
      "================================3203===================================\n",
      "3203/10000: train_loss: 3.980540721565485 train_error 54.00% test_error 57.50%\n",
      "================================3204===================================\n",
      "3204/10000: train_loss: 3.9804097187519076 train_error 54.00% test_error 57.50%\n",
      "================================3205===================================\n",
      "3205/10000: train_loss: 3.9802784849703308 train_error 54.00% test_error 57.50%\n",
      "================================3206===================================\n",
      "3206/10000: train_loss: 3.980147044211626 train_error 54.00% test_error 57.50%\n",
      "================================3207===================================\n",
      "3207/10000: train_loss: 3.980015545934439 train_error 54.00% test_error 57.50%\n",
      "================================3208===================================\n",
      "3208/10000: train_loss: 3.979884004294872 train_error 54.00% test_error 57.50%\n",
      "================================3209===================================\n",
      "3209/10000: train_loss: 3.9797523425519463 train_error 53.87% test_error 57.50%\n",
      "================================3210===================================\n",
      "3210/10000: train_loss: 3.9796206742525095 train_error 53.87% test_error 57.50%\n",
      "================================3211===================================\n",
      "3211/10000: train_loss: 3.979488669037819 train_error 53.87% test_error 57.50%\n",
      "================================3212===================================\n",
      "3212/10000: train_loss: 3.979356488734483 train_error 53.87% test_error 57.50%\n",
      "================================3213===================================\n",
      "3213/10000: train_loss: 3.97922421887517 train_error 53.87% test_error 57.50%\n",
      "================================3214===================================\n",
      "3214/10000: train_loss: 3.979092747718096 train_error 53.87% test_error 57.50%\n",
      "================================3215===================================\n",
      "3215/10000: train_loss: 3.9789611658453943 train_error 53.87% test_error 57.50%\n",
      "================================3216===================================\n",
      "3216/10000: train_loss: 3.9788291388750077 train_error 53.87% test_error 57.50%\n",
      "================================3217===================================\n",
      "3217/10000: train_loss: 3.9786972519755364 train_error 53.87% test_error 57.50%\n",
      "================================3218===================================\n",
      "3218/10000: train_loss: 3.9785653962194916 train_error 53.87% test_error 57.00%\n",
      "================================3219===================================\n",
      "3219/10000: train_loss: 3.978433704674244 train_error 53.87% test_error 57.00%\n",
      "================================3220===================================\n",
      "3220/10000: train_loss: 3.978302446454763 train_error 53.87% test_error 57.00%\n",
      "================================3221===================================\n",
      "3221/10000: train_loss: 3.9781713168323036 train_error 53.87% test_error 57.00%\n",
      "================================3222===================================\n",
      "3222/10000: train_loss: 3.9780400942265985 train_error 53.87% test_error 57.00%\n",
      "================================3223===================================\n",
      "3223/10000: train_loss: 3.977908986061811 train_error 53.87% test_error 57.00%\n",
      "================================3224===================================\n",
      "3224/10000: train_loss: 3.977778035849333 train_error 53.87% test_error 57.00%\n",
      "================================3225===================================\n",
      "3225/10000: train_loss: 3.9776470679044724 train_error 53.75% test_error 57.00%\n",
      "================================3226===================================\n",
      "3226/10000: train_loss: 3.977516114860773 train_error 53.75% test_error 57.00%\n",
      "================================3227===================================\n",
      "3227/10000: train_loss: 3.977384277433157 train_error 53.75% test_error 57.00%\n",
      "================================3228===================================\n",
      "3228/10000: train_loss: 3.977251237034798 train_error 53.75% test_error 57.00%\n",
      "================================3229===================================\n",
      "3229/10000: train_loss: 3.977117334902286 train_error 53.75% test_error 57.00%\n",
      "================================3230===================================\n",
      "3230/10000: train_loss: 3.9769824485480783 train_error 53.62% test_error 57.00%\n",
      "================================3231===================================\n",
      "3231/10000: train_loss: 3.9768476410210134 train_error 53.50% test_error 57.00%\n",
      "================================3232===================================\n",
      "3232/10000: train_loss: 3.9767115926742553 train_error 53.50% test_error 57.00%\n",
      "================================3233===================================\n",
      "3233/10000: train_loss: 3.976575451046229 train_error 53.50% test_error 57.00%\n",
      "================================3234===================================\n",
      "3234/10000: train_loss: 3.976439894586801 train_error 53.50% test_error 57.00%\n",
      "================================3235===================================\n",
      "3235/10000: train_loss: 3.976305186003447 train_error 53.50% test_error 57.00%\n",
      "================================3236===================================\n",
      "3236/10000: train_loss: 3.9761701595783236 train_error 53.50% test_error 57.00%\n",
      "================================3237===================================\n",
      "3237/10000: train_loss: 3.9760350383818146 train_error 53.50% test_error 57.00%\n",
      "================================3238===================================\n",
      "3238/10000: train_loss: 3.975900186896324 train_error 53.50% test_error 57.00%\n",
      "================================3239===================================\n",
      "3239/10000: train_loss: 3.975765629410744 train_error 53.50% test_error 57.00%\n",
      "================================3240===================================\n",
      "3240/10000: train_loss: 3.9756309907138343 train_error 53.50% test_error 57.00%\n",
      "================================3241===================================\n",
      "3241/10000: train_loss: 3.9754962843656543 train_error 53.50% test_error 57.00%\n",
      "================================3242===================================\n",
      "3242/10000: train_loss: 3.9753618201613423 train_error 53.50% test_error 57.00%\n",
      "================================3243===================================\n",
      "3243/10000: train_loss: 3.975227981954813 train_error 53.62% test_error 57.00%\n",
      "================================3244===================================\n",
      "3244/10000: train_loss: 3.975094119459391 train_error 53.62% test_error 57.00%\n",
      "================================3245===================================\n",
      "3245/10000: train_loss: 3.9749599647521974 train_error 53.50% test_error 57.00%\n",
      "================================3246===================================\n",
      "3246/10000: train_loss: 3.9748253263533115 train_error 53.37% test_error 57.00%\n",
      "================================3247===================================\n",
      "3247/10000: train_loss: 3.9746897822618483 train_error 53.37% test_error 57.00%\n",
      "================================3248===================================\n",
      "3248/10000: train_loss: 3.9745528207719323 train_error 53.37% test_error 57.00%\n",
      "================================3249===================================\n",
      "3249/10000: train_loss: 3.974415237605572 train_error 53.37% test_error 57.00%\n",
      "================================3250===================================\n",
      "3250/10000: train_loss: 3.9742772416770458 train_error 53.37% test_error 57.00%\n",
      "================================3251===================================\n",
      "3251/10000: train_loss: 3.974139111787081 train_error 53.37% test_error 57.00%\n",
      "================================3252===================================\n",
      "3252/10000: train_loss: 3.9740010236203673 train_error 53.37% test_error 57.00%\n",
      "================================3253===================================\n",
      "3253/10000: train_loss: 3.973863192051649 train_error 53.37% test_error 57.00%\n",
      "================================3254===================================\n",
      "3254/10000: train_loss: 3.9737248688936235 train_error 53.37% test_error 57.00%\n",
      "================================3255===================================\n",
      "3255/10000: train_loss: 3.9735862155258657 train_error 53.37% test_error 57.00%\n",
      "================================3256===================================\n",
      "3256/10000: train_loss: 3.97344749853015 train_error 53.37% test_error 57.00%\n",
      "================================3257===================================\n",
      "3257/10000: train_loss: 3.973308481425047 train_error 53.37% test_error 57.00%\n",
      "================================3258===================================\n",
      "3258/10000: train_loss: 3.9731690005958082 train_error 53.37% test_error 57.00%\n",
      "================================3259===================================\n",
      "3259/10000: train_loss: 3.9730292528867723 train_error 53.37% test_error 57.00%\n",
      "================================3260===================================\n",
      "3260/10000: train_loss: 3.972889537215233 train_error 53.25% test_error 57.00%\n",
      "================================3261===================================\n",
      "3261/10000: train_loss: 3.972750597447157 train_error 53.25% test_error 57.00%\n",
      "================================3262===================================\n",
      "3262/10000: train_loss: 3.972611625343561 train_error 53.25% test_error 57.00%\n",
      "================================3263===================================\n",
      "3263/10000: train_loss: 3.972472522705793 train_error 53.25% test_error 57.00%\n",
      "================================3264===================================\n",
      "3264/10000: train_loss: 3.972333457022905 train_error 53.25% test_error 57.00%\n",
      "================================3265===================================\n",
      "3265/10000: train_loss: 3.9721939216554167 train_error 53.25% test_error 57.00%\n",
      "================================3266===================================\n",
      "3266/10000: train_loss: 3.972054150849581 train_error 53.12% test_error 57.00%\n",
      "================================3267===================================\n",
      "3267/10000: train_loss: 3.9719141764938835 train_error 53.12% test_error 57.00%\n",
      "================================3268===================================\n",
      "3268/10000: train_loss: 3.971773888915777 train_error 53.12% test_error 57.00%\n",
      "================================3269===================================\n",
      "3269/10000: train_loss: 3.9716334146261216 train_error 53.12% test_error 57.00%\n",
      "================================3270===================================\n",
      "3270/10000: train_loss: 3.971492723673582 train_error 53.12% test_error 57.00%\n",
      "================================3271===================================\n",
      "3271/10000: train_loss: 3.9713516952097416 train_error 53.12% test_error 57.00%\n",
      "================================3272===================================\n",
      "3272/10000: train_loss: 3.97121018692851 train_error 53.12% test_error 57.00%\n",
      "================================3273===================================\n",
      "3273/10000: train_loss: 3.9710686056315896 train_error 53.12% test_error 57.00%\n",
      "================================3274===================================\n",
      "3274/10000: train_loss: 3.9709264473617076 train_error 53.12% test_error 57.00%\n",
      "================================3275===================================\n",
      "3275/10000: train_loss: 3.9707850979268553 train_error 53.12% test_error 57.00%\n",
      "================================3276===================================\n",
      "3276/10000: train_loss: 3.970643968582153 train_error 53.12% test_error 57.00%\n",
      "================================3277===================================\n",
      "3277/10000: train_loss: 3.970502781867981 train_error 53.00% test_error 57.00%\n",
      "================================3278===================================\n",
      "3278/10000: train_loss: 3.9703615824878216 train_error 53.00% test_error 57.00%\n",
      "================================3279===================================\n",
      "3279/10000: train_loss: 3.970220566689968 train_error 53.00% test_error 57.00%\n",
      "================================3280===================================\n",
      "3280/10000: train_loss: 3.970079805850983 train_error 53.12% test_error 57.00%\n",
      "================================3281===================================\n",
      "3281/10000: train_loss: 3.969938230365515 train_error 53.12% test_error 57.00%\n",
      "================================3282===================================\n",
      "3282/10000: train_loss: 3.969795756340027 train_error 53.12% test_error 57.00%\n",
      "================================3283===================================\n",
      "3283/10000: train_loss: 3.9696526111662385 train_error 53.12% test_error 57.00%\n",
      "================================3284===================================\n",
      "3284/10000: train_loss: 3.9695094254612924 train_error 53.12% test_error 57.00%\n",
      "================================3285===================================\n",
      "3285/10000: train_loss: 3.969366123527289 train_error 53.12% test_error 57.00%\n",
      "================================3286===================================\n",
      "3286/10000: train_loss: 3.9692227628827093 train_error 53.12% test_error 57.00%\n",
      "================================3287===================================\n",
      "3287/10000: train_loss: 3.9690791974961757 train_error 53.12% test_error 57.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3288===================================\n",
      "3288/10000: train_loss: 3.968935418725014 train_error 53.12% test_error 57.00%\n",
      "================================3289===================================\n",
      "3289/10000: train_loss: 3.96879034742713 train_error 53.12% test_error 57.00%\n",
      "================================3290===================================\n",
      "3290/10000: train_loss: 3.9686446774005892 train_error 53.12% test_error 56.50%\n",
      "================================3291===================================\n",
      "3291/10000: train_loss: 3.968498955070973 train_error 53.12% test_error 56.50%\n",
      "================================3292===================================\n",
      "3292/10000: train_loss: 3.968353093415499 train_error 53.12% test_error 56.50%\n",
      "================================3293===================================\n",
      "3293/10000: train_loss: 3.968206778615713 train_error 53.12% test_error 56.50%\n",
      "================================3294===================================\n",
      "3294/10000: train_loss: 3.9680603960156438 train_error 53.12% test_error 56.50%\n",
      "================================3295===================================\n",
      "3295/10000: train_loss: 3.9679139593243598 train_error 53.12% test_error 56.50%\n",
      "================================3296===================================\n",
      "3296/10000: train_loss: 3.967767132669687 train_error 53.00% test_error 56.50%\n",
      "================================3297===================================\n",
      "3297/10000: train_loss: 3.9676201826334 train_error 53.00% test_error 56.50%\n",
      "================================3298===================================\n",
      "3298/10000: train_loss: 3.9674738730490207 train_error 53.00% test_error 56.50%\n",
      "================================3299===================================\n",
      "3299/10000: train_loss: 3.9673279501497745 train_error 53.00% test_error 56.50%\n",
      "================================3300===================================\n",
      "3300/10000: train_loss: 3.967182632535696 train_error 53.00% test_error 56.50%\n",
      "================================3301===================================\n",
      "3301/10000: train_loss: 3.967037635147572 train_error 53.00% test_error 56.50%\n",
      "================================3302===================================\n",
      "3302/10000: train_loss: 3.9668928346037866 train_error 53.00% test_error 56.50%\n",
      "================================3303===================================\n",
      "3303/10000: train_loss: 3.9667483910918233 train_error 53.00% test_error 56.50%\n",
      "================================3304===================================\n",
      "3304/10000: train_loss: 3.9666042745113375 train_error 53.00% test_error 56.50%\n",
      "================================3305===================================\n",
      "3305/10000: train_loss: 3.9664598482847215 train_error 53.00% test_error 56.50%\n",
      "================================3306===================================\n",
      "3306/10000: train_loss: 3.9663151371479035 train_error 53.00% test_error 56.50%\n",
      "================================3307===================================\n",
      "3307/10000: train_loss: 3.966170371323824 train_error 53.00% test_error 56.50%\n",
      "================================3308===================================\n",
      "3308/10000: train_loss: 3.9660255263745783 train_error 53.00% test_error 56.50%\n",
      "================================3309===================================\n",
      "3309/10000: train_loss: 3.9658806219697 train_error 53.00% test_error 56.50%\n",
      "================================3310===================================\n",
      "3310/10000: train_loss: 3.9657356622815136 train_error 52.88% test_error 56.50%\n",
      "================================3311===================================\n",
      "3311/10000: train_loss: 3.9655908547341823 train_error 52.88% test_error 56.50%\n",
      "================================3312===================================\n",
      "3312/10000: train_loss: 3.9654459246993063 train_error 52.88% test_error 56.50%\n",
      "================================3313===================================\n",
      "3313/10000: train_loss: 3.9653008985519405 train_error 52.88% test_error 56.50%\n",
      "================================3314===================================\n",
      "3314/10000: train_loss: 3.965155768096447 train_error 52.88% test_error 56.50%\n",
      "================================3315===================================\n",
      "3315/10000: train_loss: 3.9650105790793893 train_error 52.88% test_error 56.00%\n",
      "================================3316===================================\n",
      "3316/10000: train_loss: 3.964865341931582 train_error 52.88% test_error 56.00%\n",
      "================================3317===================================\n",
      "3317/10000: train_loss: 3.9647198386490348 train_error 52.88% test_error 56.00%\n",
      "================================3318===================================\n",
      "3318/10000: train_loss: 3.964573653191328 train_error 52.88% test_error 56.00%\n",
      "================================3319===================================\n",
      "3319/10000: train_loss: 3.9644271680712695 train_error 52.88% test_error 56.00%\n",
      "================================3320===================================\n",
      "3320/10000: train_loss: 3.9642806124687198 train_error 52.88% test_error 56.00%\n",
      "================================3321===================================\n",
      "3321/10000: train_loss: 3.9641340297460554 train_error 53.00% test_error 56.00%\n",
      "================================3322===================================\n",
      "3322/10000: train_loss: 3.9639870616793633 train_error 53.00% test_error 56.00%\n",
      "================================3323===================================\n",
      "3323/10000: train_loss: 3.9638393582403655 train_error 53.00% test_error 56.00%\n",
      "================================3324===================================\n",
      "3324/10000: train_loss: 3.9636915704607967 train_error 52.88% test_error 56.00%\n",
      "================================3325===================================\n",
      "3325/10000: train_loss: 3.963543790280819 train_error 52.88% test_error 56.00%\n",
      "================================3326===================================\n",
      "3326/10000: train_loss: 3.96339588329196 train_error 52.88% test_error 56.00%\n",
      "================================3327===================================\n",
      "3327/10000: train_loss: 3.9632472006976602 train_error 52.88% test_error 56.00%\n",
      "================================3328===================================\n",
      "3328/10000: train_loss: 3.963098190277815 train_error 52.88% test_error 56.00%\n",
      "================================3329===================================\n",
      "3329/10000: train_loss: 3.9629484748840333 train_error 52.88% test_error 56.00%\n",
      "================================3330===================================\n",
      "3330/10000: train_loss: 3.9627989791333675 train_error 52.88% test_error 56.00%\n",
      "================================3331===================================\n",
      "3331/10000: train_loss: 3.9626495641469957 train_error 52.88% test_error 56.00%\n",
      "================================3332===================================\n",
      "3332/10000: train_loss: 3.9625006622076033 train_error 52.88% test_error 56.00%\n",
      "================================3333===================================\n",
      "3333/10000: train_loss: 3.962351446002722 train_error 53.00% test_error 56.00%\n",
      "================================3334===================================\n",
      "3334/10000: train_loss: 3.962201705276966 train_error 53.00% test_error 56.00%\n",
      "================================3335===================================\n",
      "3335/10000: train_loss: 3.962051796019077 train_error 53.00% test_error 56.00%\n",
      "================================3336===================================\n",
      "3336/10000: train_loss: 3.9619014151394367 train_error 53.00% test_error 56.00%\n",
      "================================3337===================================\n",
      "3337/10000: train_loss: 3.96175094306469 train_error 53.00% test_error 56.00%\n",
      "================================3338===================================\n",
      "3338/10000: train_loss: 3.9616003054380418 train_error 53.00% test_error 56.00%\n",
      "================================3339===================================\n",
      "3339/10000: train_loss: 3.961449386626482 train_error 53.00% test_error 56.00%\n",
      "================================3340===================================\n",
      "3340/10000: train_loss: 3.9612983687222005 train_error 52.88% test_error 56.00%\n",
      "================================3341===================================\n",
      "3341/10000: train_loss: 3.9611472846567626 train_error 52.88% test_error 56.00%\n",
      "================================3342===================================\n",
      "3342/10000: train_loss: 3.9609961318969726 train_error 52.88% test_error 56.00%\n",
      "================================3343===================================\n",
      "3343/10000: train_loss: 3.960845081657171 train_error 52.88% test_error 56.00%\n",
      "================================3344===================================\n",
      "3344/10000: train_loss: 3.960694041848183 train_error 52.88% test_error 56.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3345===================================\n",
      "3345/10000: train_loss: 3.9605424432456493 train_error 52.88% test_error 56.00%\n",
      "================================3346===================================\n",
      "3346/10000: train_loss: 3.9603907534480096 train_error 52.88% test_error 56.00%\n",
      "================================3347===================================\n",
      "3347/10000: train_loss: 3.9602389247715477 train_error 52.75% test_error 56.00%\n",
      "================================3348===================================\n",
      "3348/10000: train_loss: 3.9600872491300105 train_error 52.75% test_error 56.00%\n",
      "================================3349===================================\n",
      "3349/10000: train_loss: 3.9599353991448876 train_error 52.75% test_error 56.00%\n",
      "================================3350===================================\n",
      "3350/10000: train_loss: 3.9597836515307425 train_error 52.75% test_error 56.00%\n",
      "================================3351===================================\n",
      "3351/10000: train_loss: 3.959632578790188 train_error 52.62% test_error 56.00%\n",
      "================================3352===================================\n",
      "3352/10000: train_loss: 3.9594813999533653 train_error 52.62% test_error 56.00%\n",
      "================================3353===================================\n",
      "3353/10000: train_loss: 3.9593301460146906 train_error 52.62% test_error 56.00%\n",
      "================================3354===================================\n",
      "3354/10000: train_loss: 3.9591784453392034 train_error 52.62% test_error 56.00%\n",
      "================================3355===================================\n",
      "3355/10000: train_loss: 3.9590263910591608 train_error 52.62% test_error 56.00%\n",
      "================================3356===================================\n",
      "3356/10000: train_loss: 3.958874100446701 train_error 52.50% test_error 56.00%\n",
      "================================3357===================================\n",
      "3357/10000: train_loss: 3.958721795231104 train_error 52.50% test_error 56.00%\n",
      "================================3358===================================\n",
      "3358/10000: train_loss: 3.9585693134367466 train_error 52.50% test_error 56.00%\n",
      "================================3359===================================\n",
      "3359/10000: train_loss: 3.9584168441593652 train_error 52.50% test_error 56.00%\n",
      "================================3360===================================\n",
      "3360/10000: train_loss: 3.958264338970184 train_error 52.50% test_error 56.00%\n",
      "================================3361===================================\n",
      "3361/10000: train_loss: 3.9581110410392286 train_error 52.50% test_error 56.00%\n",
      "================================3362===================================\n",
      "3362/10000: train_loss: 3.95795702368021 train_error 52.38% test_error 56.00%\n",
      "================================3363===================================\n",
      "3363/10000: train_loss: 3.9578034181892874 train_error 52.38% test_error 56.00%\n",
      "================================3364===================================\n",
      "3364/10000: train_loss: 3.9576497414708136 train_error 52.38% test_error 56.00%\n",
      "================================3365===================================\n",
      "3365/10000: train_loss: 3.957497759461403 train_error 52.38% test_error 56.00%\n",
      "================================3366===================================\n",
      "3366/10000: train_loss: 3.9573474849760535 train_error 52.38% test_error 56.00%\n",
      "================================3367===================================\n",
      "3367/10000: train_loss: 3.957197234779596 train_error 52.38% test_error 56.00%\n",
      "================================3368===================================\n",
      "3368/10000: train_loss: 3.957047098129988 train_error 52.38% test_error 56.50%\n",
      "================================3369===================================\n",
      "3369/10000: train_loss: 3.9568966808915143 train_error 52.38% test_error 56.50%\n",
      "================================3370===================================\n",
      "3370/10000: train_loss: 3.9567461165785787 train_error 52.38% test_error 56.50%\n",
      "================================3371===================================\n",
      "3371/10000: train_loss: 3.956594237089157 train_error 52.38% test_error 56.50%\n",
      "================================3372===================================\n",
      "3372/10000: train_loss: 3.9564422933757304 train_error 52.50% test_error 56.50%\n",
      "================================3373===================================\n",
      "3373/10000: train_loss: 3.956290329247713 train_error 52.50% test_error 56.50%\n",
      "================================3374===================================\n",
      "3374/10000: train_loss: 3.956138306111097 train_error 52.50% test_error 56.50%\n",
      "================================3375===================================\n",
      "3375/10000: train_loss: 3.955986693352461 train_error 52.38% test_error 56.50%\n",
      "================================3376===================================\n",
      "3376/10000: train_loss: 3.955835543125868 train_error 52.38% test_error 56.50%\n",
      "================================3377===================================\n",
      "3377/10000: train_loss: 3.9556846532225607 train_error 52.38% test_error 56.50%\n",
      "================================3378===================================\n",
      "3378/10000: train_loss: 3.9555341802537445 train_error 52.38% test_error 56.00%\n",
      "================================3379===================================\n",
      "3379/10000: train_loss: 3.955383681952953 train_error 52.38% test_error 56.00%\n",
      "================================3380===================================\n",
      "3380/10000: train_loss: 3.9552332623302933 train_error 52.38% test_error 56.00%\n",
      "================================3381===================================\n",
      "3381/10000: train_loss: 3.9550825318694116 train_error 52.38% test_error 56.00%\n",
      "================================3382===================================\n",
      "3382/10000: train_loss: 3.95493193924427 train_error 52.25% test_error 56.00%\n",
      "================================3383===================================\n",
      "3383/10000: train_loss: 3.95478176087141 train_error 52.25% test_error 56.00%\n",
      "================================3384===================================\n",
      "3384/10000: train_loss: 3.954630772322416 train_error 52.12% test_error 56.00%\n",
      "================================3385===================================\n",
      "3385/10000: train_loss: 3.9544793155789377 train_error 52.12% test_error 56.00%\n",
      "================================3386===================================\n",
      "3386/10000: train_loss: 3.9543278919160363 train_error 52.12% test_error 56.00%\n",
      "================================3387===================================\n",
      "3387/10000: train_loss: 3.9541763038933277 train_error 52.12% test_error 56.00%\n",
      "================================3388===================================\n",
      "3388/10000: train_loss: 3.9540246167778967 train_error 52.12% test_error 56.00%\n",
      "================================3389===================================\n",
      "3389/10000: train_loss: 3.953872846364975 train_error 52.12% test_error 56.00%\n",
      "================================3390===================================\n",
      "3390/10000: train_loss: 3.9537209013104437 train_error 52.12% test_error 56.00%\n",
      "================================3391===================================\n",
      "3391/10000: train_loss: 3.953568201959133 train_error 52.12% test_error 56.00%\n",
      "================================3392===================================\n",
      "3392/10000: train_loss: 3.9534148441255095 train_error 52.12% test_error 56.00%\n",
      "================================3393===================================\n",
      "3393/10000: train_loss: 3.9532623858749867 train_error 52.00% test_error 56.00%\n",
      "================================3394===================================\n",
      "3394/10000: train_loss: 3.9531108109652995 train_error 52.00% test_error 56.00%\n",
      "================================3395===================================\n",
      "3395/10000: train_loss: 3.9529586841166013 train_error 52.00% test_error 56.00%\n",
      "================================3396===================================\n",
      "3396/10000: train_loss: 3.952806553095579 train_error 52.00% test_error 56.00%\n",
      "================================3397===================================\n",
      "3397/10000: train_loss: 3.9526544603705407 train_error 52.00% test_error 56.00%\n",
      "================================3398===================================\n",
      "3398/10000: train_loss: 3.952501989603042 train_error 52.00% test_error 56.00%\n",
      "================================3399===================================\n",
      "3399/10000: train_loss: 3.9523492719233033 train_error 52.00% test_error 56.00%\n",
      "================================3400===================================\n",
      "3400/10000: train_loss: 3.9521963775157927 train_error 52.00% test_error 56.00%\n",
      "================================3401===================================\n",
      "3401/10000: train_loss: 3.9520440658926965 train_error 52.00% test_error 56.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3402===================================\n",
      "3402/10000: train_loss: 3.951892033070326 train_error 52.00% test_error 56.00%\n",
      "================================3403===================================\n",
      "3403/10000: train_loss: 3.951739526540041 train_error 52.00% test_error 56.00%\n",
      "================================3404===================================\n",
      "3404/10000: train_loss: 3.9515868920087813 train_error 52.00% test_error 56.00%\n",
      "================================3405===================================\n",
      "3405/10000: train_loss: 3.951434487998485 train_error 52.00% test_error 56.00%\n",
      "================================3406===================================\n",
      "3406/10000: train_loss: 3.95128197863698 train_error 52.00% test_error 56.00%\n",
      "================================3407===================================\n",
      "3407/10000: train_loss: 3.951129055917263 train_error 52.00% test_error 56.00%\n",
      "================================3408===================================\n",
      "3408/10000: train_loss: 3.950975643247366 train_error 52.00% test_error 56.00%\n",
      "================================3409===================================\n",
      "3409/10000: train_loss: 3.9508220280706885 train_error 52.00% test_error 56.00%\n",
      "================================3410===================================\n",
      "3410/10000: train_loss: 3.9506684909760947 train_error 51.88% test_error 56.00%\n",
      "================================3411===================================\n",
      "3411/10000: train_loss: 3.9505139295756813 train_error 51.88% test_error 56.00%\n",
      "================================3412===================================\n",
      "3412/10000: train_loss: 3.9503578723967077 train_error 51.75% test_error 56.00%\n",
      "================================3413===================================\n",
      "3413/10000: train_loss: 3.950202232450247 train_error 51.75% test_error 56.00%\n",
      "================================3414===================================\n",
      "3414/10000: train_loss: 3.9500474178791047 train_error 51.75% test_error 56.00%\n",
      "================================3415===================================\n",
      "3415/10000: train_loss: 3.949892552047968 train_error 51.75% test_error 56.00%\n",
      "================================3416===================================\n",
      "3416/10000: train_loss: 3.9497384451329705 train_error 51.75% test_error 56.00%\n",
      "================================3417===================================\n",
      "3417/10000: train_loss: 3.9495846304297446 train_error 51.75% test_error 56.00%\n",
      "================================3418===================================\n",
      "3418/10000: train_loss: 3.949430558979511 train_error 51.75% test_error 56.00%\n",
      "================================3419===================================\n",
      "3419/10000: train_loss: 3.9492761914432046 train_error 51.75% test_error 56.00%\n",
      "================================3420===================================\n",
      "3420/10000: train_loss: 3.9491217090189457 train_error 51.75% test_error 56.00%\n",
      "================================3421===================================\n",
      "3421/10000: train_loss: 3.948966585099697 train_error 51.75% test_error 56.00%\n",
      "================================3422===================================\n",
      "3422/10000: train_loss: 3.9488119511306286 train_error 51.75% test_error 56.00%\n",
      "================================3423===================================\n",
      "3423/10000: train_loss: 3.9486573955416677 train_error 51.75% test_error 56.00%\n",
      "================================3424===================================\n",
      "3424/10000: train_loss: 3.9485024511814117 train_error 51.75% test_error 56.00%\n",
      "================================3425===================================\n",
      "3425/10000: train_loss: 3.948347372412681 train_error 51.75% test_error 56.00%\n",
      "================================3426===================================\n",
      "3426/10000: train_loss: 3.9481919364631173 train_error 51.75% test_error 56.00%\n",
      "================================3427===================================\n",
      "3427/10000: train_loss: 3.9480363258719446 train_error 51.75% test_error 56.00%\n",
      "================================3428===================================\n",
      "3428/10000: train_loss: 3.9478809402883055 train_error 51.75% test_error 56.00%\n",
      "================================3429===================================\n",
      "3429/10000: train_loss: 3.9477256311476228 train_error 51.62% test_error 56.00%\n",
      "================================3430===================================\n",
      "3430/10000: train_loss: 3.947570723891258 train_error 51.62% test_error 56.00%\n",
      "================================3431===================================\n",
      "3431/10000: train_loss: 3.947416179925203 train_error 51.62% test_error 56.00%\n",
      "================================3432===================================\n",
      "3432/10000: train_loss: 3.9472615820169445 train_error 51.62% test_error 56.00%\n",
      "================================3433===================================\n",
      "3433/10000: train_loss: 3.9471069594472645 train_error 51.62% test_error 56.00%\n",
      "================================3434===================================\n",
      "3434/10000: train_loss: 3.9469522364437575 train_error 51.62% test_error 56.00%\n",
      "================================3435===================================\n",
      "3435/10000: train_loss: 3.9467971672117708 train_error 51.62% test_error 56.50%\n",
      "================================3436===================================\n",
      "3436/10000: train_loss: 3.9466412059962748 train_error 51.62% test_error 56.50%\n",
      "================================3437===================================\n",
      "3437/10000: train_loss: 3.9464851938188072 train_error 51.62% test_error 56.50%\n",
      "================================3438===================================\n",
      "3438/10000: train_loss: 3.9463284309953455 train_error 51.62% test_error 56.50%\n",
      "================================3439===================================\n",
      "3439/10000: train_loss: 3.94617146551609 train_error 51.62% test_error 56.50%\n",
      "================================3440===================================\n",
      "3440/10000: train_loss: 3.946014456525445 train_error 51.62% test_error 56.50%\n",
      "================================3441===================================\n",
      "3441/10000: train_loss: 3.9458595047146083 train_error 51.62% test_error 56.50%\n",
      "================================3442===================================\n",
      "3442/10000: train_loss: 3.9457055347412826 train_error 51.62% test_error 56.50%\n",
      "================================3443===================================\n",
      "3443/10000: train_loss: 3.945551574230194 train_error 51.62% test_error 56.50%\n",
      "================================3444===================================\n",
      "3444/10000: train_loss: 3.9453975468873974 train_error 51.62% test_error 56.50%\n",
      "================================3445===================================\n",
      "3445/10000: train_loss: 3.945243626534939 train_error 51.62% test_error 56.00%\n",
      "================================3446===================================\n",
      "3446/10000: train_loss: 3.9450899969786404 train_error 51.62% test_error 56.00%\n",
      "================================3447===================================\n",
      "3447/10000: train_loss: 3.944936905428767 train_error 51.62% test_error 56.00%\n",
      "================================3448===================================\n",
      "3448/10000: train_loss: 3.9447837886214256 train_error 51.62% test_error 56.00%\n",
      "================================3449===================================\n",
      "3449/10000: train_loss: 3.944630546271801 train_error 51.62% test_error 56.00%\n",
      "================================3450===================================\n",
      "3450/10000: train_loss: 3.944477149173617 train_error 51.62% test_error 56.00%\n",
      "================================3451===================================\n",
      "3451/10000: train_loss: 3.944323094934225 train_error 51.62% test_error 56.00%\n",
      "================================3452===================================\n",
      "3452/10000: train_loss: 3.94416996397078 train_error 51.62% test_error 56.00%\n",
      "================================3453===================================\n",
      "3453/10000: train_loss: 3.9440176007896657 train_error 51.62% test_error 56.00%\n",
      "================================3454===================================\n",
      "3454/10000: train_loss: 3.943865486904979 train_error 51.62% test_error 56.00%\n",
      "================================3455===================================\n",
      "3455/10000: train_loss: 3.9437133472412826 train_error 51.62% test_error 56.00%\n",
      "================================3456===================================\n",
      "3456/10000: train_loss: 3.9435616721212865 train_error 51.62% test_error 56.00%\n",
      "================================3457===================================\n",
      "3457/10000: train_loss: 3.9434099553525446 train_error 51.62% test_error 56.00%\n",
      "================================3458===================================\n",
      "3458/10000: train_loss: 3.943257620558142 train_error 51.62% test_error 56.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3459===================================\n",
      "3459/10000: train_loss: 3.9431043576449163 train_error 51.62% test_error 56.00%\n",
      "================================3460===================================\n",
      "3460/10000: train_loss: 3.9429510322958228 train_error 51.62% test_error 56.00%\n",
      "================================3461===================================\n",
      "3461/10000: train_loss: 3.9427976434677836 train_error 51.62% test_error 56.00%\n",
      "================================3462===================================\n",
      "3462/10000: train_loss: 3.9426440985500815 train_error 51.50% test_error 56.00%\n",
      "================================3463===================================\n",
      "3463/10000: train_loss: 3.942490365058184 train_error 51.50% test_error 56.00%\n",
      "================================3464===================================\n",
      "3464/10000: train_loss: 3.9423371109366414 train_error 51.50% test_error 56.00%\n",
      "================================3465===================================\n",
      "3465/10000: train_loss: 3.9421836757659916 train_error 51.50% test_error 56.00%\n",
      "================================3466===================================\n",
      "3466/10000: train_loss: 3.9420301849395036 train_error 51.50% test_error 56.00%\n",
      "================================3467===================================\n",
      "3467/10000: train_loss: 3.9418766671419143 train_error 51.50% test_error 56.00%\n",
      "================================3468===================================\n",
      "3468/10000: train_loss: 3.9417232245206835 train_error 51.50% test_error 56.00%\n",
      "================================3469===================================\n",
      "3469/10000: train_loss: 3.941569478660822 train_error 51.50% test_error 56.00%\n",
      "================================3470===================================\n",
      "3470/10000: train_loss: 3.9414156473428013 train_error 51.50% test_error 56.00%\n",
      "================================3471===================================\n",
      "3471/10000: train_loss: 3.9412617401033643 train_error 51.50% test_error 56.00%\n",
      "================================3472===================================\n",
      "3472/10000: train_loss: 3.941107729822397 train_error 51.50% test_error 56.00%\n",
      "================================3473===================================\n",
      "3473/10000: train_loss: 3.9409540864825248 train_error 51.50% test_error 56.00%\n",
      "================================3474===================================\n",
      "3474/10000: train_loss: 3.940800411850214 train_error 51.50% test_error 56.00%\n",
      "================================3475===================================\n",
      "3475/10000: train_loss: 3.9406467101722957 train_error 51.50% test_error 56.00%\n",
      "================================3476===================================\n",
      "3476/10000: train_loss: 3.9404929449409245 train_error 51.50% test_error 56.00%\n",
      "================================3477===================================\n",
      "3477/10000: train_loss: 3.9403390976786614 train_error 51.62% test_error 56.00%\n",
      "================================3478===================================\n",
      "3478/10000: train_loss: 3.9401844311505556 train_error 51.62% test_error 56.00%\n",
      "================================3479===================================\n",
      "3479/10000: train_loss: 3.9400302716344595 train_error 51.62% test_error 56.00%\n",
      "================================3480===================================\n",
      "3480/10000: train_loss: 3.939876594543457 train_error 51.62% test_error 56.00%\n",
      "================================3481===================================\n",
      "3481/10000: train_loss: 3.9397228740155694 train_error 51.62% test_error 56.00%\n",
      "================================3482===================================\n",
      "3482/10000: train_loss: 3.939569513648748 train_error 51.75% test_error 56.00%\n",
      "================================3483===================================\n",
      "3483/10000: train_loss: 3.9394165091216564 train_error 51.75% test_error 56.00%\n",
      "================================3484===================================\n",
      "3484/10000: train_loss: 3.939263956323266 train_error 51.75% test_error 56.00%\n",
      "================================3485===================================\n",
      "3485/10000: train_loss: 3.9391113021224733 train_error 51.75% test_error 56.00%\n",
      "================================3486===================================\n",
      "3486/10000: train_loss: 3.93895807184279 train_error 51.75% test_error 56.00%\n",
      "================================3487===================================\n",
      "3487/10000: train_loss: 3.9388047797977923 train_error 51.75% test_error 56.50%\n",
      "================================3488===================================\n",
      "3488/10000: train_loss: 3.9386514589190487 train_error 51.75% test_error 56.50%\n",
      "================================3489===================================\n",
      "3489/10000: train_loss: 3.93849824346602 train_error 51.75% test_error 56.50%\n",
      "================================3490===================================\n",
      "3490/10000: train_loss: 3.9383447067439556 train_error 51.75% test_error 56.00%\n",
      "================================3491===================================\n",
      "3491/10000: train_loss: 3.938190931975842 train_error 51.75% test_error 56.00%\n",
      "================================3492===================================\n",
      "3492/10000: train_loss: 3.9380370916426184 train_error 51.75% test_error 56.00%\n",
      "================================3493===================================\n",
      "3493/10000: train_loss: 3.937883164137602 train_error 51.75% test_error 56.00%\n",
      "================================3494===================================\n",
      "3494/10000: train_loss: 3.9377283897995947 train_error 51.75% test_error 56.00%\n",
      "================================3495===================================\n",
      "3495/10000: train_loss: 3.937573238313198 train_error 51.75% test_error 56.00%\n",
      "================================3496===================================\n",
      "3496/10000: train_loss: 3.9374182099103923 train_error 51.75% test_error 56.00%\n",
      "================================3497===================================\n",
      "3497/10000: train_loss: 3.937262448966503 train_error 51.75% test_error 56.00%\n",
      "================================3498===================================\n",
      "3498/10000: train_loss: 3.9371065951883795 train_error 51.75% test_error 56.00%\n",
      "================================3499===================================\n",
      "3499/10000: train_loss: 3.936950658559799 train_error 51.75% test_error 56.00%\n",
      "================================3500===================================\n",
      "3500/10000: train_loss: 3.9367948891967535 train_error 51.75% test_error 56.00%\n",
      "================================3501===================================\n",
      "3501/10000: train_loss: 3.9366396999359132 train_error 51.75% test_error 56.00%\n",
      "================================3502===================================\n",
      "3502/10000: train_loss: 3.9364848776161674 train_error 51.75% test_error 56.00%\n",
      "================================3503===================================\n",
      "3503/10000: train_loss: 3.9363318248838186 train_error 51.75% test_error 56.00%\n",
      "================================3504===================================\n",
      "3504/10000: train_loss: 3.9361787279695273 train_error 51.75% test_error 56.00%\n",
      "================================3505===================================\n",
      "3505/10000: train_loss: 3.936025571227074 train_error 51.75% test_error 56.00%\n",
      "================================3506===================================\n",
      "3506/10000: train_loss: 3.9358723528683184 train_error 51.75% test_error 56.00%\n",
      "================================3507===================================\n",
      "3507/10000: train_loss: 3.9357190369814634 train_error 51.75% test_error 56.00%\n",
      "================================3508===================================\n",
      "3508/10000: train_loss: 3.935566241890192 train_error 51.75% test_error 56.00%\n",
      "================================3509===================================\n",
      "3509/10000: train_loss: 3.935413936674595 train_error 51.75% test_error 56.00%\n",
      "================================3510===================================\n",
      "3510/10000: train_loss: 3.935261498913169 train_error 51.75% test_error 56.00%\n",
      "================================3511===================================\n",
      "3511/10000: train_loss: 3.935109015405178 train_error 51.75% test_error 56.00%\n",
      "================================3512===================================\n",
      "3512/10000: train_loss: 3.9349565599113703 train_error 51.75% test_error 56.00%\n",
      "================================3513===================================\n",
      "3513/10000: train_loss: 3.934804620444775 train_error 51.75% test_error 56.00%\n",
      "================================3514===================================\n",
      "3514/10000: train_loss: 3.934652877673507 train_error 51.75% test_error 56.00%\n",
      "================================3515===================================\n",
      "3515/10000: train_loss: 3.934500743076205 train_error 51.75% test_error 56.00%\n",
      "================================3516===================================\n",
      "3516/10000: train_loss: 3.9343468069285152 train_error 51.75% test_error 56.00%\n",
      "================================3517===================================\n",
      "3517/10000: train_loss: 3.934192020744085 train_error 51.75% test_error 56.00%\n",
      "================================3518===================================\n",
      "3518/10000: train_loss: 3.934037283733487 train_error 51.75% test_error 56.00%\n",
      "================================3519===================================\n",
      "3519/10000: train_loss: 3.9338822502642867 train_error 51.88% test_error 56.00%\n",
      "================================3520===================================\n",
      "3520/10000: train_loss: 3.9337265759706495 train_error 51.88% test_error 56.00%\n",
      "================================3521===================================\n",
      "3521/10000: train_loss: 3.9335698810964823 train_error 51.88% test_error 56.00%\n",
      "================================3522===================================\n",
      "3522/10000: train_loss: 3.9334127551317213 train_error 51.88% test_error 56.00%\n",
      "================================3523===================================\n",
      "3523/10000: train_loss: 3.9332555007189516 train_error 51.88% test_error 56.00%\n",
      "================================3524===================================\n",
      "3524/10000: train_loss: 3.933098211735487 train_error 51.88% test_error 56.00%\n",
      "================================3525===================================\n",
      "3525/10000: train_loss: 3.932940955534577 train_error 51.88% test_error 56.00%\n",
      "================================3526===================================\n",
      "3526/10000: train_loss: 3.932783743441105 train_error 51.88% test_error 56.00%\n",
      "================================3527===================================\n",
      "3527/10000: train_loss: 3.9326264163851743 train_error 51.88% test_error 56.00%\n",
      "================================3528===================================\n",
      "3528/10000: train_loss: 3.9324690567702056 train_error 51.88% test_error 56.00%\n",
      "================================3529===================================\n",
      "3529/10000: train_loss: 3.9323109655827286 train_error 51.88% test_error 56.00%\n",
      "================================3530===================================\n",
      "3530/10000: train_loss: 3.9321524035185575 train_error 51.88% test_error 56.00%\n",
      "================================3531===================================\n",
      "3531/10000: train_loss: 3.9319935926049947 train_error 51.88% test_error 56.00%\n",
      "================================3532===================================\n",
      "3532/10000: train_loss: 3.9318350230157373 train_error 51.88% test_error 56.00%\n",
      "================================3533===================================\n",
      "3533/10000: train_loss: 3.931676331833005 train_error 51.88% test_error 56.00%\n",
      "================================3534===================================\n",
      "3534/10000: train_loss: 3.931517520099878 train_error 51.88% test_error 56.00%\n",
      "================================3535===================================\n",
      "3535/10000: train_loss: 3.9313583774119616 train_error 51.88% test_error 56.00%\n",
      "================================3536===================================\n",
      "3536/10000: train_loss: 3.931199033260345 train_error 51.88% test_error 56.00%\n",
      "================================3537===================================\n",
      "3537/10000: train_loss: 3.9310395098477597 train_error 51.88% test_error 56.00%\n",
      "================================3538===================================\n",
      "3538/10000: train_loss: 3.9308799123764038 train_error 51.88% test_error 56.00%\n",
      "================================3539===================================\n",
      "3539/10000: train_loss: 3.930721035003662 train_error 51.88% test_error 56.00%\n",
      "================================3540===================================\n",
      "3540/10000: train_loss: 3.93056261844933 train_error 51.88% test_error 56.00%\n",
      "================================3541===================================\n",
      "3541/10000: train_loss: 3.9304040970653293 train_error 51.88% test_error 56.00%\n",
      "================================3542===================================\n",
      "3542/10000: train_loss: 3.9302455011755226 train_error 51.88% test_error 56.00%\n",
      "================================3543===================================\n",
      "3543/10000: train_loss: 3.930086802020669 train_error 51.88% test_error 56.00%\n",
      "================================3544===================================\n",
      "3544/10000: train_loss: 3.9299279816448687 train_error 51.88% test_error 56.00%\n",
      "================================3545===================================\n",
      "3545/10000: train_loss: 3.929769871607423 train_error 51.88% test_error 56.00%\n",
      "================================3546===================================\n",
      "3546/10000: train_loss: 3.929612438380718 train_error 51.88% test_error 56.00%\n",
      "================================3547===================================\n",
      "3547/10000: train_loss: 3.9294548807293177 train_error 51.88% test_error 56.00%\n",
      "================================3548===================================\n",
      "3548/10000: train_loss: 3.9292973059415814 train_error 51.88% test_error 56.00%\n",
      "================================3549===================================\n",
      "3549/10000: train_loss: 3.929139691591263 train_error 51.88% test_error 56.00%\n",
      "================================3550===================================\n",
      "3550/10000: train_loss: 3.928982060104609 train_error 51.75% test_error 56.00%\n",
      "================================3551===================================\n",
      "3551/10000: train_loss: 3.928823747932911 train_error 51.75% test_error 56.00%\n",
      "================================3552===================================\n",
      "3552/10000: train_loss: 3.9286650907993317 train_error 51.75% test_error 56.50%\n",
      "================================3553===================================\n",
      "3553/10000: train_loss: 3.928506828248501 train_error 51.75% test_error 56.50%\n",
      "================================3554===================================\n",
      "3554/10000: train_loss: 3.92834815710783 train_error 51.75% test_error 56.50%\n",
      "================================3555===================================\n",
      "3555/10000: train_loss: 3.928188995048404 train_error 51.75% test_error 56.50%\n",
      "================================3556===================================\n",
      "3556/10000: train_loss: 3.9280297463387255 train_error 51.62% test_error 56.50%\n",
      "================================3557===================================\n",
      "3557/10000: train_loss: 3.9278704495728016 train_error 51.62% test_error 56.50%\n",
      "================================3558===================================\n",
      "3558/10000: train_loss: 3.9277098824083807 train_error 51.62% test_error 56.50%\n",
      "================================3559===================================\n",
      "3559/10000: train_loss: 3.9275487984716895 train_error 51.62% test_error 56.50%\n",
      "================================3560===================================\n",
      "3560/10000: train_loss: 3.9273876460641626 train_error 51.62% test_error 56.50%\n",
      "================================3561===================================\n",
      "3561/10000: train_loss: 3.9272263484448193 train_error 51.62% test_error 56.50%\n",
      "================================3562===================================\n",
      "3562/10000: train_loss: 3.927064972221851 train_error 51.62% test_error 56.50%\n",
      "================================3563===================================\n",
      "3563/10000: train_loss: 3.926902671456337 train_error 51.62% test_error 56.50%\n",
      "================================3564===================================\n",
      "3564/10000: train_loss: 3.926740081310272 train_error 51.62% test_error 56.50%\n",
      "================================3565===================================\n",
      "3565/10000: train_loss: 3.926577445268631 train_error 51.62% test_error 56.50%\n",
      "================================3566===================================\n",
      "3566/10000: train_loss: 3.926414714232087 train_error 51.62% test_error 56.50%\n",
      "================================3567===================================\n",
      "3567/10000: train_loss: 3.926252222806215 train_error 51.62% test_error 56.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3568===================================\n",
      "3568/10000: train_loss: 3.926089512780308 train_error 51.62% test_error 56.50%\n",
      "================================3569===================================\n",
      "3569/10000: train_loss: 3.925926704108715 train_error 51.62% test_error 56.50%\n",
      "================================3570===================================\n",
      "3570/10000: train_loss: 3.9257637320458887 train_error 51.62% test_error 56.00%\n",
      "================================3571===================================\n",
      "3571/10000: train_loss: 3.925600576028228 train_error 51.62% test_error 56.00%\n",
      "================================3572===================================\n",
      "3572/10000: train_loss: 3.9254372838139533 train_error 51.62% test_error 56.00%\n",
      "================================3573===================================\n",
      "3573/10000: train_loss: 3.9252738846838477 train_error 51.62% test_error 56.00%\n",
      "================================3574===================================\n",
      "3574/10000: train_loss: 3.9251105029881 train_error 51.62% test_error 56.00%\n",
      "================================3575===================================\n",
      "3575/10000: train_loss: 3.924947236403823 train_error 51.62% test_error 56.00%\n",
      "================================3576===================================\n",
      "3576/10000: train_loss: 3.9247838547825813 train_error 51.62% test_error 56.00%\n",
      "================================3577===================================\n",
      "3577/10000: train_loss: 3.9246203485131264 train_error 51.62% test_error 56.00%\n",
      "================================3578===================================\n",
      "3578/10000: train_loss: 3.9244564648717644 train_error 51.62% test_error 56.50%\n",
      "================================3579===================================\n",
      "3579/10000: train_loss: 3.924292432442307 train_error 51.62% test_error 56.50%\n",
      "================================3580===================================\n",
      "3580/10000: train_loss: 3.924128757044673 train_error 51.62% test_error 56.50%\n",
      "================================3581===================================\n",
      "3581/10000: train_loss: 3.923964804932475 train_error 51.62% test_error 56.50%\n",
      "================================3582===================================\n",
      "3582/10000: train_loss: 3.923800762742758 train_error 51.62% test_error 56.50%\n",
      "================================3583===================================\n",
      "3583/10000: train_loss: 3.9236366883665323 train_error 51.62% test_error 56.50%\n",
      "================================3584===================================\n",
      "3584/10000: train_loss: 3.9234726565331224 train_error 51.62% test_error 56.50%\n",
      "================================3585===================================\n",
      "3585/10000: train_loss: 3.9233082818239926 train_error 51.62% test_error 56.00%\n",
      "================================3586===================================\n",
      "3586/10000: train_loss: 3.923142958432436 train_error 51.62% test_error 56.00%\n",
      "================================3587===================================\n",
      "3587/10000: train_loss: 3.9229769758135076 train_error 51.62% test_error 56.00%\n",
      "================================3588===================================\n",
      "3588/10000: train_loss: 3.9228108095377685 train_error 51.62% test_error 56.00%\n",
      "================================3589===================================\n",
      "3589/10000: train_loss: 3.922644055560231 train_error 51.62% test_error 56.00%\n",
      "================================3590===================================\n",
      "3590/10000: train_loss: 3.9224763005226855 train_error 51.62% test_error 56.00%\n",
      "================================3591===================================\n",
      "3591/10000: train_loss: 3.9223093420267103 train_error 51.62% test_error 56.00%\n",
      "================================3592===================================\n",
      "3592/10000: train_loss: 3.9221422537416215 train_error 51.62% test_error 56.00%\n",
      "================================3593===================================\n",
      "3593/10000: train_loss: 3.921975124329329 train_error 51.38% test_error 56.00%\n",
      "================================3594===================================\n",
      "3594/10000: train_loss: 3.9218079592287545 train_error 51.38% test_error 56.00%\n",
      "================================3595===================================\n",
      "3595/10000: train_loss: 3.9216407036781313 train_error 51.38% test_error 56.00%\n",
      "================================3596===================================\n",
      "3596/10000: train_loss: 3.921473333388567 train_error 51.38% test_error 56.00%\n",
      "================================3597===================================\n",
      "3597/10000: train_loss: 3.921305862441659 train_error 51.25% test_error 56.00%\n",
      "================================3598===================================\n",
      "3598/10000: train_loss: 3.9211378213763237 train_error 51.25% test_error 56.00%\n",
      "================================3599===================================\n",
      "3599/10000: train_loss: 3.920969504788518 train_error 51.25% test_error 56.00%\n",
      "================================3600===================================\n",
      "3600/10000: train_loss: 3.9208011168241503 train_error 51.25% test_error 56.00%\n",
      "================================3601===================================\n",
      "3601/10000: train_loss: 3.9206326261907813 train_error 51.25% test_error 56.00%\n",
      "================================3602===================================\n",
      "3602/10000: train_loss: 3.9204646034538744 train_error 51.25% test_error 56.00%\n",
      "================================3603===================================\n",
      "3603/10000: train_loss: 3.9202968482673164 train_error 51.25% test_error 56.00%\n",
      "================================3604===================================\n",
      "3604/10000: train_loss: 3.9201298372447493 train_error 51.25% test_error 56.00%\n",
      "================================3605===================================\n",
      "3605/10000: train_loss: 3.919963633939624 train_error 51.25% test_error 56.00%\n",
      "================================3606===================================\n",
      "3606/10000: train_loss: 3.919797345548868 train_error 51.25% test_error 56.00%\n",
      "================================3607===================================\n",
      "3607/10000: train_loss: 3.919630928486586 train_error 51.25% test_error 56.00%\n",
      "================================3608===================================\n",
      "3608/10000: train_loss: 3.91946435213089 train_error 51.25% test_error 56.00%\n",
      "================================3609===================================\n",
      "3609/10000: train_loss: 3.91929771669209 train_error 51.25% test_error 56.00%\n",
      "================================3610===================================\n",
      "3610/10000: train_loss: 3.919131086245179 train_error 51.12% test_error 56.00%\n",
      "================================3611===================================\n",
      "3611/10000: train_loss: 3.918964670374989 train_error 51.12% test_error 56.00%\n",
      "================================3612===================================\n",
      "3612/10000: train_loss: 3.9187982349842785 train_error 51.12% test_error 56.00%\n",
      "================================3613===================================\n",
      "3613/10000: train_loss: 3.918631693795323 train_error 51.00% test_error 56.00%\n",
      "================================3614===================================\n",
      "3614/10000: train_loss: 3.91846505664289 train_error 51.00% test_error 56.00%\n",
      "================================3615===================================\n",
      "3615/10000: train_loss: 3.918298357650638 train_error 51.00% test_error 56.00%\n",
      "================================3616===================================\n",
      "3616/10000: train_loss: 3.9181315355002884 train_error 51.00% test_error 56.00%\n",
      "================================3617===================================\n",
      "3617/10000: train_loss: 3.91796462573111 train_error 51.00% test_error 56.00%\n",
      "================================3618===================================\n",
      "3618/10000: train_loss: 3.917797315344214 train_error 51.00% test_error 56.00%\n",
      "================================3619===================================\n",
      "3619/10000: train_loss: 3.91762954197824 train_error 51.00% test_error 56.00%\n",
      "================================3620===================================\n",
      "3620/10000: train_loss: 3.917461759522557 train_error 51.00% test_error 56.00%\n",
      "================================3621===================================\n",
      "3621/10000: train_loss: 3.9172932431846856 train_error 51.00% test_error 56.00%\n",
      "================================3622===================================\n",
      "3622/10000: train_loss: 3.9171241010725497 train_error 51.00% test_error 56.00%\n",
      "================================3623===================================\n",
      "3623/10000: train_loss: 3.916955121532083 train_error 51.00% test_error 56.00%\n",
      "================================3624===================================\n",
      "3624/10000: train_loss: 3.916786723956466 train_error 50.88% test_error 56.00%\n",
      "================================3625===================================\n",
      "3625/10000: train_loss: 3.916618220359087 train_error 50.88% test_error 56.00%\n",
      "================================3626===================================\n",
      "3626/10000: train_loss: 3.916449687182903 train_error 50.88% test_error 56.00%\n",
      "================================3627===================================\n",
      "3627/10000: train_loss: 3.9162812104821203 train_error 50.88% test_error 56.00%\n",
      "================================3628===================================\n",
      "3628/10000: train_loss: 3.9161131066828965 train_error 50.88% test_error 56.00%\n",
      "================================3629===================================\n",
      "3629/10000: train_loss: 3.915944832712412 train_error 50.88% test_error 56.00%\n",
      "================================3630===================================\n",
      "3630/10000: train_loss: 3.915776466503739 train_error 50.88% test_error 56.00%\n",
      "================================3631===================================\n",
      "3631/10000: train_loss: 3.9156074295192953 train_error 50.75% test_error 55.50%\n",
      "================================3632===================================\n",
      "3632/10000: train_loss: 3.9154376248270273 train_error 50.75% test_error 55.50%\n",
      "================================3633===================================\n",
      "3633/10000: train_loss: 3.9152671631425617 train_error 50.75% test_error 55.50%\n",
      "================================3634===================================\n",
      "3634/10000: train_loss: 3.9150965605676173 train_error 50.62% test_error 55.50%\n",
      "================================3635===================================\n",
      "3635/10000: train_loss: 3.9149266124516724 train_error 50.62% test_error 55.50%\n",
      "================================3636===================================\n",
      "3636/10000: train_loss: 3.9147568744421 train_error 50.62% test_error 55.50%\n",
      "================================3637===================================\n",
      "3637/10000: train_loss: 3.9145869477838278 train_error 50.62% test_error 55.50%\n",
      "================================3638===================================\n",
      "3638/10000: train_loss: 3.9144164725393056 train_error 50.62% test_error 55.50%\n",
      "================================3639===================================\n",
      "3639/10000: train_loss: 3.9142459359765054 train_error 50.62% test_error 55.50%\n",
      "================================3640===================================\n",
      "3640/10000: train_loss: 3.9140753079950814 train_error 50.62% test_error 55.50%\n",
      "================================3641===================================\n",
      "3641/10000: train_loss: 3.91390452131629 train_error 50.75% test_error 55.00%\n",
      "================================3642===================================\n",
      "3642/10000: train_loss: 3.9137336983531714 train_error 50.75% test_error 55.00%\n",
      "================================3643===================================\n",
      "3643/10000: train_loss: 3.9135628782212732 train_error 50.75% test_error 55.00%\n",
      "================================3644===================================\n",
      "3644/10000: train_loss: 3.913391973674297 train_error 50.75% test_error 54.50%\n",
      "================================3645===================================\n",
      "3645/10000: train_loss: 3.9132207687199116 train_error 50.75% test_error 54.50%\n",
      "================================3646===================================\n",
      "3646/10000: train_loss: 3.913049308434129 train_error 50.75% test_error 54.50%\n",
      "================================3647===================================\n",
      "3647/10000: train_loss: 3.912876964583993 train_error 50.75% test_error 54.50%\n",
      "================================3648===================================\n",
      "3648/10000: train_loss: 3.9127040721476076 train_error 50.75% test_error 54.50%\n",
      "================================3649===================================\n",
      "3649/10000: train_loss: 3.9125309801101684 train_error 50.75% test_error 54.50%\n",
      "================================3650===================================\n",
      "3650/10000: train_loss: 3.9123581449687483 train_error 50.75% test_error 54.50%\n",
      "================================3651===================================\n",
      "3651/10000: train_loss: 3.9121860859543083 train_error 50.75% test_error 54.50%\n",
      "================================3652===================================\n",
      "3652/10000: train_loss: 3.91201369985938 train_error 50.62% test_error 54.00%\n",
      "================================3653===================================\n",
      "3653/10000: train_loss: 3.911841033622623 train_error 50.62% test_error 54.00%\n",
      "================================3654===================================\n",
      "3654/10000: train_loss: 3.9116683603078126 train_error 50.62% test_error 54.00%\n",
      "================================3655===================================\n",
      "3655/10000: train_loss: 3.9114952082931995 train_error 50.75% test_error 54.00%\n",
      "================================3656===================================\n",
      "3656/10000: train_loss: 3.911321850195527 train_error 50.75% test_error 54.00%\n",
      "================================3657===================================\n",
      "3657/10000: train_loss: 3.9111483810096983 train_error 50.88% test_error 54.00%\n",
      "================================3658===================================\n",
      "3658/10000: train_loss: 3.910973781421781 train_error 51.00% test_error 54.00%\n",
      "================================3659===================================\n",
      "3659/10000: train_loss: 3.9107987128943207 train_error 51.00% test_error 54.00%\n",
      "================================3660===================================\n",
      "3660/10000: train_loss: 3.910624086782336 train_error 51.00% test_error 54.00%\n",
      "================================3661===================================\n",
      "3661/10000: train_loss: 3.9104508507996796 train_error 51.00% test_error 54.00%\n",
      "================================3662===================================\n",
      "3662/10000: train_loss: 3.910278299674392 train_error 51.00% test_error 54.00%\n",
      "================================3663===================================\n",
      "3663/10000: train_loss: 3.9101055194437504 train_error 51.00% test_error 54.00%\n",
      "================================3664===================================\n",
      "3664/10000: train_loss: 3.909932600930333 train_error 51.00% test_error 54.00%\n",
      "================================3665===================================\n",
      "3665/10000: train_loss: 3.9097596702724693 train_error 51.00% test_error 54.00%\n",
      "================================3666===================================\n",
      "3666/10000: train_loss: 3.909586601629853 train_error 51.00% test_error 54.00%\n",
      "================================3667===================================\n",
      "3667/10000: train_loss: 3.9094134303182364 train_error 51.00% test_error 54.00%\n",
      "================================3668===================================\n",
      "3668/10000: train_loss: 3.9092407179623843 train_error 51.00% test_error 54.00%\n",
      "================================3669===================================\n",
      "3669/10000: train_loss: 3.909068428725004 train_error 51.00% test_error 54.00%\n",
      "================================3670===================================\n",
      "3670/10000: train_loss: 3.908895977213979 train_error 51.00% test_error 54.00%\n",
      "================================3671===================================\n",
      "3671/10000: train_loss: 3.9087233140319584 train_error 50.88% test_error 54.00%\n",
      "================================3672===================================\n",
      "3672/10000: train_loss: 3.9085508904606105 train_error 50.88% test_error 54.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3673===================================\n",
      "3673/10000: train_loss: 3.908378769978881 train_error 50.88% test_error 54.00%\n",
      "================================3674===================================\n",
      "3674/10000: train_loss: 3.9082065636664627 train_error 50.88% test_error 54.00%\n",
      "================================3675===================================\n",
      "3675/10000: train_loss: 3.9080342496931553 train_error 51.00% test_error 54.00%\n",
      "================================3676===================================\n",
      "3676/10000: train_loss: 3.9078618558496236 train_error 51.00% test_error 54.00%\n",
      "================================3677===================================\n",
      "3677/10000: train_loss: 3.9076900555938483 train_error 50.88% test_error 54.00%\n",
      "================================3678===================================\n",
      "3678/10000: train_loss: 3.907517850995064 train_error 50.88% test_error 54.00%\n",
      "================================3679===================================\n",
      "3679/10000: train_loss: 3.9073444125801324 train_error 50.88% test_error 54.00%\n",
      "================================3680===================================\n",
      "3680/10000: train_loss: 3.907170554548502 train_error 50.88% test_error 54.00%\n",
      "================================3681===================================\n",
      "3681/10000: train_loss: 3.9069964233785868 train_error 50.88% test_error 54.00%\n",
      "================================3682===================================\n",
      "3682/10000: train_loss: 3.906822041645646 train_error 50.88% test_error 54.00%\n",
      "================================3683===================================\n",
      "3683/10000: train_loss: 3.9066475031524894 train_error 50.88% test_error 54.00%\n",
      "================================3684===================================\n",
      "3684/10000: train_loss: 3.9064728858321907 train_error 50.75% test_error 54.00%\n",
      "================================3685===================================\n",
      "3685/10000: train_loss: 3.906298503577709 train_error 50.75% test_error 54.00%\n",
      "================================3686===================================\n",
      "3686/10000: train_loss: 3.906124889403581 train_error 50.75% test_error 54.00%\n",
      "================================3687===================================\n",
      "3687/10000: train_loss: 3.9059511859714986 train_error 50.75% test_error 54.00%\n",
      "================================3688===================================\n",
      "3688/10000: train_loss: 3.9057775148004295 train_error 50.75% test_error 54.00%\n",
      "================================3689===================================\n",
      "3689/10000: train_loss: 3.9056039341539144 train_error 50.75% test_error 54.00%\n",
      "================================3690===================================\n",
      "3690/10000: train_loss: 3.9054303083568813 train_error 50.75% test_error 54.00%\n",
      "================================3691===================================\n",
      "3691/10000: train_loss: 3.905257233679295 train_error 50.62% test_error 54.00%\n",
      "================================3692===================================\n",
      "3692/10000: train_loss: 3.9050845180451867 train_error 50.62% test_error 54.00%\n",
      "================================3693===================================\n",
      "3693/10000: train_loss: 3.9049125171452763 train_error 50.62% test_error 54.00%\n",
      "================================3694===================================\n",
      "3694/10000: train_loss: 3.904740303605795 train_error 50.62% test_error 54.00%\n",
      "================================3695===================================\n",
      "3695/10000: train_loss: 3.9045680023729803 train_error 50.75% test_error 54.00%\n",
      "================================3696===================================\n",
      "3696/10000: train_loss: 3.904395105317235 train_error 50.75% test_error 54.00%\n",
      "================================3697===================================\n",
      "3697/10000: train_loss: 3.9042217932641505 train_error 50.88% test_error 54.00%\n",
      "================================3698===================================\n",
      "3698/10000: train_loss: 3.9040484055131675 train_error 50.75% test_error 54.00%\n",
      "================================3699===================================\n",
      "3699/10000: train_loss: 3.9038749807327986 train_error 50.62% test_error 54.00%\n",
      "================================3700===================================\n",
      "3700/10000: train_loss: 3.9037016725540163 train_error 50.50% test_error 54.00%\n",
      "================================3701===================================\n",
      "3701/10000: train_loss: 3.9035282620042566 train_error 50.50% test_error 54.00%\n",
      "================================3702===================================\n",
      "3702/10000: train_loss: 3.903354162573814 train_error 50.50% test_error 54.00%\n",
      "================================3703===================================\n",
      "3703/10000: train_loss: 3.903180067390204 train_error 50.50% test_error 54.00%\n",
      "================================3704===================================\n",
      "3704/10000: train_loss: 3.903005961924791 train_error 50.50% test_error 54.00%\n",
      "================================3705===================================\n",
      "3705/10000: train_loss: 3.90283239915967 train_error 50.50% test_error 54.00%\n",
      "================================3706===================================\n",
      "3706/10000: train_loss: 3.9026589708775283 train_error 50.38% test_error 54.00%\n",
      "================================3707===================================\n",
      "3707/10000: train_loss: 3.90248545050621 train_error 50.38% test_error 54.00%\n",
      "================================3708===================================\n",
      "3708/10000: train_loss: 3.902312273159623 train_error 50.38% test_error 54.00%\n",
      "================================3709===================================\n",
      "3709/10000: train_loss: 3.902139602005482 train_error 50.38% test_error 54.00%\n",
      "================================3710===================================\n",
      "3710/10000: train_loss: 3.9019667368382214 train_error 50.38% test_error 54.00%\n",
      "================================3711===================================\n",
      "3711/10000: train_loss: 3.901793758049607 train_error 50.38% test_error 54.00%\n",
      "================================3712===================================\n",
      "3712/10000: train_loss: 3.90162130959332 train_error 50.38% test_error 54.00%\n",
      "================================3713===================================\n",
      "3713/10000: train_loss: 3.9014495874196293 train_error 50.38% test_error 54.00%\n",
      "================================3714===================================\n",
      "3714/10000: train_loss: 3.901277040541172 train_error 50.38% test_error 54.00%\n",
      "================================3715===================================\n",
      "3715/10000: train_loss: 3.9011037129163744 train_error 50.38% test_error 54.00%\n",
      "================================3716===================================\n",
      "3716/10000: train_loss: 3.9009301273524764 train_error 50.38% test_error 54.00%\n",
      "================================3717===================================\n",
      "3717/10000: train_loss: 3.9007564027607438 train_error 50.38% test_error 54.00%\n",
      "================================3718===================================\n",
      "3718/10000: train_loss: 3.9005825881659986 train_error 50.38% test_error 53.50%\n",
      "================================3719===================================\n",
      "3719/10000: train_loss: 3.900408696606755 train_error 50.38% test_error 53.50%\n",
      "================================3720===================================\n",
      "3720/10000: train_loss: 3.900234639942646 train_error 50.25% test_error 53.50%\n",
      "================================3721===================================\n",
      "3721/10000: train_loss: 3.900060682371259 train_error 50.25% test_error 53.50%\n",
      "================================3722===================================\n",
      "3722/10000: train_loss: 3.8998871380090714 train_error 50.12% test_error 53.50%\n",
      "================================3723===================================\n",
      "3723/10000: train_loss: 3.8997130934894084 train_error 50.12% test_error 53.50%\n",
      "================================3724===================================\n",
      "3724/10000: train_loss: 3.899538993239403 train_error 50.25% test_error 53.00%\n",
      "================================3725===================================\n",
      "3725/10000: train_loss: 3.899364807084203 train_error 50.25% test_error 53.00%\n",
      "================================3726===================================\n",
      "3726/10000: train_loss: 3.899190494045615 train_error 50.25% test_error 53.00%\n",
      "================================3727===================================\n",
      "3727/10000: train_loss: 3.899016140922904 train_error 50.25% test_error 53.00%\n",
      "================================3728===================================\n",
      "3728/10000: train_loss: 3.8988416912406687 train_error 50.25% test_error 53.00%\n",
      "================================3729===================================\n",
      "3729/10000: train_loss: 3.8986672511696816 train_error 50.25% test_error 53.00%\n",
      "================================3730===================================\n",
      "3730/10000: train_loss: 3.89849287725985 train_error 50.25% test_error 53.00%\n",
      "================================3731===================================\n",
      "3731/10000: train_loss: 3.8983184034377336 train_error 50.25% test_error 53.00%\n",
      "================================3732===================================\n",
      "3732/10000: train_loss: 3.898143556788564 train_error 50.25% test_error 53.00%\n",
      "================================3733===================================\n",
      "3733/10000: train_loss: 3.8979683662205935 train_error 50.25% test_error 53.00%\n",
      "================================3734===================================\n",
      "3734/10000: train_loss: 3.8977927267551418 train_error 50.12% test_error 53.00%\n",
      "================================3735===================================\n",
      "3735/10000: train_loss: 3.897616266310215 train_error 50.00% test_error 53.00%\n",
      "================================3736===================================\n",
      "3736/10000: train_loss: 3.8974397175014017 train_error 50.00% test_error 53.00%\n",
      "================================3737===================================\n",
      "3737/10000: train_loss: 3.897263128012419 train_error 50.00% test_error 53.00%\n",
      "================================3738===================================\n",
      "3738/10000: train_loss: 3.8970866832137108 train_error 50.00% test_error 53.00%\n",
      "================================3739===================================\n",
      "3739/10000: train_loss: 3.896909942477941 train_error 50.00% test_error 53.00%\n",
      "================================3740===================================\n",
      "3740/10000: train_loss: 3.8967334649711844 train_error 50.00% test_error 53.00%\n",
      "================================3741===================================\n",
      "3741/10000: train_loss: 3.896557769104838 train_error 50.00% test_error 53.00%\n",
      "================================3742===================================\n",
      "3742/10000: train_loss: 3.8963820208609103 train_error 50.00% test_error 53.00%\n",
      "================================3743===================================\n",
      "3743/10000: train_loss: 3.8962065342813728 train_error 50.00% test_error 53.00%\n",
      "================================3744===================================\n",
      "3744/10000: train_loss: 3.896031581014395 train_error 50.00% test_error 53.00%\n",
      "================================3745===================================\n",
      "3745/10000: train_loss: 3.8958564005047083 train_error 50.00% test_error 53.00%\n",
      "================================3746===================================\n",
      "3746/10000: train_loss: 3.8956799267977473 train_error 50.12% test_error 53.00%\n",
      "================================3747===================================\n",
      "3747/10000: train_loss: 3.895502676665783 train_error 50.12% test_error 53.00%\n",
      "================================3748===================================\n",
      "3748/10000: train_loss: 3.8953253513574597 train_error 50.12% test_error 53.00%\n",
      "================================3749===================================\n",
      "3749/10000: train_loss: 3.8951480512320997 train_error 50.00% test_error 53.00%\n",
      "================================3750===================================\n",
      "3750/10000: train_loss: 3.8949709041416645 train_error 50.00% test_error 53.00%\n",
      "================================3751===================================\n",
      "3751/10000: train_loss: 3.894793519601226 train_error 50.00% test_error 53.00%\n",
      "================================3752===================================\n",
      "3752/10000: train_loss: 3.8946162310987713 train_error 50.00% test_error 53.00%\n",
      "================================3753===================================\n",
      "3753/10000: train_loss: 3.894438755586743 train_error 50.00% test_error 53.00%\n",
      "================================3754===================================\n",
      "3754/10000: train_loss: 3.8942610301077365 train_error 50.00% test_error 53.00%\n",
      "================================3755===================================\n",
      "3755/10000: train_loss: 3.894083187431097 train_error 50.00% test_error 53.00%\n",
      "================================3756===================================\n",
      "3756/10000: train_loss: 3.8939060135930776 train_error 50.00% test_error 53.00%\n",
      "================================3757===================================\n",
      "3757/10000: train_loss: 3.893729104474187 train_error 50.00% test_error 53.00%\n",
      "================================3758===================================\n",
      "3758/10000: train_loss: 3.8935520377755166 train_error 49.88% test_error 53.00%\n",
      "================================3759===================================\n",
      "3759/10000: train_loss: 3.8933740273863076 train_error 49.75% test_error 53.00%\n",
      "================================3760===================================\n",
      "3760/10000: train_loss: 3.8931955981999637 train_error 49.75% test_error 53.00%\n",
      "================================3761===================================\n",
      "3761/10000: train_loss: 3.8930169557780028 train_error 49.75% test_error 53.00%\n",
      "================================3762===================================\n",
      "3762/10000: train_loss: 3.892837272211909 train_error 49.75% test_error 53.00%\n",
      "================================3763===================================\n",
      "3763/10000: train_loss: 3.8926562613993885 train_error 49.75% test_error 53.00%\n",
      "================================3764===================================\n",
      "3764/10000: train_loss: 3.89247555591166 train_error 49.62% test_error 53.00%\n",
      "================================3765===================================\n",
      "3765/10000: train_loss: 3.892294772490859 train_error 49.62% test_error 53.00%\n",
      "================================3766===================================\n",
      "3766/10000: train_loss: 3.892113892659545 train_error 49.62% test_error 53.00%\n",
      "================================3767===================================\n",
      "3767/10000: train_loss: 3.8919330846518276 train_error 49.62% test_error 53.00%\n",
      "================================3768===================================\n",
      "3768/10000: train_loss: 3.891752342134714 train_error 49.62% test_error 53.00%\n",
      "================================3769===================================\n",
      "3769/10000: train_loss: 3.891571554169059 train_error 49.50% test_error 53.00%\n",
      "================================3770===================================\n",
      "3770/10000: train_loss: 3.891390695273876 train_error 49.50% test_error 53.00%\n",
      "================================3771===================================\n",
      "3771/10000: train_loss: 3.891209603995085 train_error 49.50% test_error 53.00%\n",
      "================================3772===================================\n",
      "3772/10000: train_loss: 3.8910282191634176 train_error 49.50% test_error 53.00%\n",
      "================================3773===================================\n",
      "3773/10000: train_loss: 3.8908463867008685 train_error 49.50% test_error 53.00%\n",
      "================================3774===================================\n",
      "3774/10000: train_loss: 3.8906645773351194 train_error 49.50% test_error 53.00%\n",
      "================================3775===================================\n",
      "3775/10000: train_loss: 3.890481585562229 train_error 49.50% test_error 53.00%\n",
      "================================3776===================================\n",
      "3776/10000: train_loss: 3.8902971425652506 train_error 49.50% test_error 53.00%\n",
      "================================3777===================================\n",
      "3777/10000: train_loss: 3.8901120971143244 train_error 49.50% test_error 53.00%\n",
      "================================3778===================================\n",
      "3778/10000: train_loss: 3.889926428124309 train_error 49.50% test_error 53.00%\n",
      "================================3779===================================\n",
      "3779/10000: train_loss: 3.8897414892911915 train_error 49.50% test_error 53.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3780===================================\n",
      "3780/10000: train_loss: 3.8895570838451383 train_error 49.50% test_error 53.00%\n",
      "================================3781===================================\n",
      "3781/10000: train_loss: 3.889372984543443 train_error 49.50% test_error 53.00%\n",
      "================================3782===================================\n",
      "3782/10000: train_loss: 3.889188773408532 train_error 49.50% test_error 53.00%\n",
      "================================3783===================================\n",
      "3783/10000: train_loss: 3.889004504531622 train_error 49.50% test_error 53.00%\n",
      "================================3784===================================\n",
      "3784/10000: train_loss: 3.8888201685994863 train_error 49.50% test_error 53.00%\n",
      "================================3785===================================\n",
      "3785/10000: train_loss: 3.8886357416957615 train_error 49.50% test_error 53.00%\n",
      "================================3786===================================\n",
      "3786/10000: train_loss: 3.8884511963278054 train_error 49.50% test_error 53.00%\n",
      "================================3787===================================\n",
      "3787/10000: train_loss: 3.88826626509428 train_error 49.50% test_error 53.00%\n",
      "================================3788===================================\n",
      "3788/10000: train_loss: 3.8880801746249194 train_error 49.50% test_error 53.00%\n",
      "================================3789===================================\n",
      "3789/10000: train_loss: 3.887893999516964 train_error 49.50% test_error 52.50%\n",
      "================================3790===================================\n",
      "3790/10000: train_loss: 3.8877076257765295 train_error 49.38% test_error 52.50%\n",
      "================================3791===================================\n",
      "3791/10000: train_loss: 3.887521186694503 train_error 49.38% test_error 52.50%\n",
      "================================3792===================================\n",
      "3792/10000: train_loss: 3.887334515079856 train_error 49.38% test_error 52.50%\n",
      "================================3793===================================\n",
      "3793/10000: train_loss: 3.8871476505696774 train_error 49.38% test_error 52.50%\n",
      "================================3794===================================\n",
      "3794/10000: train_loss: 3.88696022413671 train_error 49.38% test_error 52.50%\n",
      "================================3795===================================\n",
      "3795/10000: train_loss: 3.886772599518299 train_error 49.25% test_error 52.50%\n",
      "================================3796===================================\n",
      "3796/10000: train_loss: 3.8865847804397347 train_error 49.25% test_error 52.50%\n",
      "================================3797===================================\n",
      "3797/10000: train_loss: 3.886397400647402 train_error 49.25% test_error 52.50%\n",
      "================================3798===================================\n",
      "3798/10000: train_loss: 3.8862104485183955 train_error 49.25% test_error 52.00%\n",
      "================================3799===================================\n",
      "3799/10000: train_loss: 3.886024276837707 train_error 49.25% test_error 52.00%\n",
      "================================3800===================================\n",
      "3800/10000: train_loss: 3.885838174149394 train_error 49.25% test_error 52.00%\n",
      "================================3801===================================\n",
      "3801/10000: train_loss: 3.88564919911325 train_error 49.25% test_error 52.00%\n",
      "================================3802===================================\n",
      "3802/10000: train_loss: 3.885459567978978 train_error 49.25% test_error 52.00%\n",
      "================================3803===================================\n",
      "3803/10000: train_loss: 3.8852700397372244 train_error 49.25% test_error 52.00%\n",
      "================================3804===================================\n",
      "3804/10000: train_loss: 3.885080405920744 train_error 49.25% test_error 52.00%\n",
      "================================3805===================================\n",
      "3805/10000: train_loss: 3.884890600591898 train_error 49.25% test_error 52.00%\n",
      "================================3806===================================\n",
      "3806/10000: train_loss: 3.884701427295804 train_error 49.25% test_error 52.00%\n",
      "================================3807===================================\n",
      "3807/10000: train_loss: 3.8845127713680268 train_error 49.25% test_error 52.00%\n",
      "================================3808===================================\n",
      "3808/10000: train_loss: 3.884324334263802 train_error 49.25% test_error 52.00%\n",
      "================================3809===================================\n",
      "3809/10000: train_loss: 3.884135198444128 train_error 49.25% test_error 52.00%\n",
      "================================3810===================================\n",
      "3810/10000: train_loss: 3.883945059031248 train_error 49.25% test_error 52.00%\n",
      "================================3811===================================\n",
      "3811/10000: train_loss: 3.8837548431009057 train_error 49.12% test_error 52.00%\n",
      "================================3812===================================\n",
      "3812/10000: train_loss: 3.8835650697350506 train_error 49.12% test_error 52.00%\n",
      "================================3813===================================\n",
      "3813/10000: train_loss: 3.8833757331222296 train_error 49.12% test_error 52.00%\n",
      "================================3814===================================\n",
      "3814/10000: train_loss: 3.883186321035028 train_error 49.12% test_error 52.00%\n",
      "================================3815===================================\n",
      "3815/10000: train_loss: 3.8829962183535103 train_error 49.12% test_error 52.00%\n",
      "================================3816===================================\n",
      "3816/10000: train_loss: 3.882805385515094 train_error 49.12% test_error 52.00%\n",
      "================================3817===================================\n",
      "3817/10000: train_loss: 3.8826144068688153 train_error 49.12% test_error 52.00%\n",
      "================================3818===================================\n",
      "3818/10000: train_loss: 3.8824231495708226 train_error 49.12% test_error 52.00%\n",
      "================================3819===================================\n",
      "3819/10000: train_loss: 3.88223178036511 train_error 49.12% test_error 52.00%\n",
      "================================3820===================================\n",
      "3820/10000: train_loss: 3.882040309011936 train_error 49.12% test_error 52.00%\n",
      "================================3821===================================\n",
      "3821/10000: train_loss: 3.881849201619625 train_error 49.12% test_error 52.00%\n",
      "================================3822===================================\n",
      "3822/10000: train_loss: 3.8816582895070315 train_error 49.12% test_error 52.00%\n",
      "================================3823===================================\n",
      "3823/10000: train_loss: 3.8814673068374397 train_error 49.12% test_error 52.00%\n",
      "================================3824===================================\n",
      "3824/10000: train_loss: 3.881276660785079 train_error 49.12% test_error 52.00%\n",
      "================================3825===================================\n",
      "3825/10000: train_loss: 3.8810864617675542 train_error 49.12% test_error 52.00%\n",
      "================================3826===================================\n",
      "3826/10000: train_loss: 3.8808961848169563 train_error 49.12% test_error 52.00%\n",
      "================================3827===================================\n",
      "3827/10000: train_loss: 3.8807059599459173 train_error 49.12% test_error 52.00%\n",
      "================================3828===================================\n",
      "3828/10000: train_loss: 3.8805154041945933 train_error 49.00% test_error 52.00%\n",
      "================================3829===================================\n",
      "3829/10000: train_loss: 3.880324457138777 train_error 49.00% test_error 52.00%\n",
      "================================3830===================================\n",
      "3830/10000: train_loss: 3.8801329408586027 train_error 49.00% test_error 52.00%\n",
      "================================3831===================================\n",
      "3831/10000: train_loss: 3.8799409855902196 train_error 49.00% test_error 52.00%\n",
      "================================3832===================================\n",
      "3832/10000: train_loss: 3.879748999923468 train_error 49.00% test_error 52.00%\n",
      "================================3833===================================\n",
      "3833/10000: train_loss: 3.879556948468089 train_error 49.00% test_error 52.00%\n",
      "================================3834===================================\n",
      "3834/10000: train_loss: 3.879365380704403 train_error 49.00% test_error 52.00%\n",
      "================================3835===================================\n",
      "3835/10000: train_loss: 3.8791737720370296 train_error 49.12% test_error 52.00%\n",
      "================================3836===================================\n",
      "3836/10000: train_loss: 3.8789818454533815 train_error 49.12% test_error 52.00%\n",
      "================================3837===================================\n",
      "3837/10000: train_loss: 3.878789848014712 train_error 49.12% test_error 52.00%\n",
      "================================3838===================================\n",
      "3838/10000: train_loss: 3.878597756922245 train_error 49.12% test_error 52.00%\n",
      "================================3839===================================\n",
      "3839/10000: train_loss: 3.8784055805951354 train_error 49.00% test_error 52.00%\n",
      "================================3840===================================\n",
      "3840/10000: train_loss: 3.878213745057583 train_error 49.00% test_error 52.00%\n",
      "================================3841===================================\n",
      "3841/10000: train_loss: 3.8780227042734623 train_error 49.00% test_error 52.00%\n",
      "================================3842===================================\n",
      "3842/10000: train_loss: 3.8778312119841574 train_error 48.75% test_error 52.00%\n",
      "================================3843===================================\n",
      "3843/10000: train_loss: 3.87763952434063 train_error 48.75% test_error 52.00%\n",
      "================================3844===================================\n",
      "3844/10000: train_loss: 3.8774481935054066 train_error 48.75% test_error 52.00%\n",
      "================================3845===================================\n",
      "3845/10000: train_loss: 3.877257489413023 train_error 48.75% test_error 52.00%\n",
      "================================3846===================================\n",
      "3846/10000: train_loss: 3.8770680068433285 train_error 48.75% test_error 52.00%\n",
      "================================3847===================================\n",
      "3847/10000: train_loss: 3.8768784449249507 train_error 48.75% test_error 52.00%\n",
      "================================3848===================================\n",
      "3848/10000: train_loss: 3.876687802523375 train_error 48.75% test_error 52.00%\n",
      "================================3849===================================\n",
      "3849/10000: train_loss: 3.8764968435466294 train_error 48.75% test_error 52.00%\n",
      "================================3850===================================\n",
      "3850/10000: train_loss: 3.876306544020772 train_error 48.75% test_error 52.00%\n",
      "================================3851===================================\n",
      "3851/10000: train_loss: 3.876116157323122 train_error 48.75% test_error 52.00%\n",
      "================================3852===================================\n",
      "3852/10000: train_loss: 3.8759258590638637 train_error 48.75% test_error 52.00%\n",
      "================================3853===================================\n",
      "3853/10000: train_loss: 3.8757343935966495 train_error 48.75% test_error 52.00%\n",
      "================================3854===================================\n",
      "3854/10000: train_loss: 3.8755426024645567 train_error 48.75% test_error 52.00%\n",
      "================================3855===================================\n",
      "3855/10000: train_loss: 3.8753513388335707 train_error 48.75% test_error 52.00%\n",
      "================================3856===================================\n",
      "3856/10000: train_loss: 3.875160229057074 train_error 48.75% test_error 52.00%\n",
      "================================3857===================================\n",
      "3857/10000: train_loss: 3.874968092218041 train_error 48.75% test_error 52.00%\n",
      "================================3858===================================\n",
      "3858/10000: train_loss: 3.8747758551687 train_error 48.75% test_error 51.50%\n",
      "================================3859===================================\n",
      "3859/10000: train_loss: 3.874583917483687 train_error 48.75% test_error 51.50%\n",
      "================================3860===================================\n",
      "3860/10000: train_loss: 3.8743934310227632 train_error 48.75% test_error 51.50%\n",
      "================================3861===================================\n",
      "3861/10000: train_loss: 3.8742029720544813 train_error 48.75% test_error 51.50%\n",
      "================================3862===================================\n",
      "3862/10000: train_loss: 3.8740125321596866 train_error 48.75% test_error 51.50%\n",
      "================================3863===================================\n",
      "3863/10000: train_loss: 3.8738213320821524 train_error 48.75% test_error 51.50%\n",
      "================================3864===================================\n",
      "3864/10000: train_loss: 3.8736292841285467 train_error 48.75% test_error 51.50%\n",
      "================================3865===================================\n",
      "3865/10000: train_loss: 3.8734371630847457 train_error 48.75% test_error 51.50%\n",
      "================================3866===================================\n",
      "3866/10000: train_loss: 3.8732449590414766 train_error 48.75% test_error 51.50%\n",
      "================================3867===================================\n",
      "3867/10000: train_loss: 3.873053272813559 train_error 48.75% test_error 51.50%\n",
      "================================3868===================================\n",
      "3868/10000: train_loss: 3.8728633867949247 train_error 48.75% test_error 51.50%\n",
      "================================3869===================================\n",
      "3869/10000: train_loss: 3.872673383131623 train_error 48.75% test_error 51.50%\n",
      "================================3870===================================\n",
      "3870/10000: train_loss: 3.872484063655138 train_error 48.75% test_error 51.50%\n",
      "================================3871===================================\n",
      "3871/10000: train_loss: 3.8722949150204657 train_error 48.88% test_error 51.50%\n",
      "================================3872===================================\n",
      "3872/10000: train_loss: 3.8721056837588548 train_error 49.00% test_error 51.50%\n",
      "================================3873===================================\n",
      "3873/10000: train_loss: 3.871916509568691 train_error 49.00% test_error 51.50%\n",
      "================================3874===================================\n",
      "3874/10000: train_loss: 3.871727308630943 train_error 49.00% test_error 51.50%\n",
      "================================3875===================================\n",
      "3875/10000: train_loss: 3.8715384016186 train_error 48.88% test_error 51.50%\n",
      "================================3876===================================\n",
      "3876/10000: train_loss: 3.8713494210690262 train_error 48.88% test_error 51.50%\n",
      "================================3877===================================\n",
      "3877/10000: train_loss: 3.8711605402082205 train_error 48.88% test_error 51.50%\n",
      "================================3878===================================\n",
      "3878/10000: train_loss: 3.8709720308333635 train_error 48.88% test_error 51.50%\n",
      "================================3879===================================\n",
      "3879/10000: train_loss: 3.870781945735216 train_error 48.88% test_error 51.50%\n",
      "================================3880===================================\n",
      "3880/10000: train_loss: 3.8705916034430268 train_error 48.88% test_error 51.50%\n",
      "================================3881===================================\n",
      "3881/10000: train_loss: 3.8704010924696925 train_error 48.75% test_error 51.50%\n",
      "================================3882===================================\n",
      "3882/10000: train_loss: 3.870210548713803 train_error 48.75% test_error 51.50%\n",
      "================================3883===================================\n",
      "3883/10000: train_loss: 3.8700213661044836 train_error 48.75% test_error 51.50%\n",
      "================================3884===================================\n",
      "3884/10000: train_loss: 3.86983293004334 train_error 48.75% test_error 51.50%\n",
      "================================3885===================================\n",
      "3885/10000: train_loss: 3.869645529091358 train_error 48.62% test_error 51.50%\n",
      "================================3886===================================\n",
      "3886/10000: train_loss: 3.8694591984897855 train_error 48.62% test_error 51.50%\n",
      "================================3887===================================\n",
      "3887/10000: train_loss: 3.869272553622723 train_error 48.62% test_error 51.50%\n",
      "================================3888===================================\n",
      "3888/10000: train_loss: 3.8690853498876097 train_error 48.62% test_error 51.50%\n",
      "================================3889===================================\n",
      "3889/10000: train_loss: 3.8688980337232346 train_error 48.62% test_error 51.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3890===================================\n",
      "3890/10000: train_loss: 3.868710970133543 train_error 48.62% test_error 51.50%\n",
      "================================3891===================================\n",
      "3891/10000: train_loss: 3.8685225013643505 train_error 48.62% test_error 51.50%\n",
      "================================3892===================================\n",
      "3892/10000: train_loss: 3.868331689015031 train_error 48.50% test_error 51.50%\n",
      "================================3893===================================\n",
      "3893/10000: train_loss: 3.8681400971859694 train_error 48.50% test_error 51.50%\n",
      "================================3894===================================\n",
      "3894/10000: train_loss: 3.867948410511017 train_error 48.50% test_error 51.50%\n",
      "================================3895===================================\n",
      "3895/10000: train_loss: 3.867756599262357 train_error 48.50% test_error 51.50%\n",
      "================================3896===================================\n",
      "3896/10000: train_loss: 3.8675645931810143 train_error 48.50% test_error 51.50%\n",
      "================================3897===================================\n",
      "3897/10000: train_loss: 3.8673734293878077 train_error 48.50% test_error 51.50%\n",
      "================================3898===================================\n",
      "3898/10000: train_loss: 3.867182352095842 train_error 48.50% test_error 51.50%\n",
      "================================3899===================================\n",
      "3899/10000: train_loss: 3.8669911298155784 train_error 48.50% test_error 51.50%\n",
      "================================3900===================================\n",
      "3900/10000: train_loss: 3.866800143197179 train_error 48.50% test_error 51.50%\n",
      "================================3901===================================\n",
      "3901/10000: train_loss: 3.866610406264663 train_error 48.50% test_error 51.50%\n",
      "================================3902===================================\n",
      "3902/10000: train_loss: 3.866420874595642 train_error 48.50% test_error 51.50%\n",
      "================================3903===================================\n",
      "3903/10000: train_loss: 3.8662313117831943 train_error 48.50% test_error 51.50%\n",
      "================================3904===================================\n",
      "3904/10000: train_loss: 3.8660415231436493 train_error 48.50% test_error 51.50%\n",
      "================================3905===================================\n",
      "3905/10000: train_loss: 3.865851432681084 train_error 48.50% test_error 51.50%\n",
      "================================3906===================================\n",
      "3906/10000: train_loss: 3.8656622003763914 train_error 48.50% test_error 51.50%\n",
      "================================3907===================================\n",
      "3907/10000: train_loss: 3.865473713129759 train_error 48.50% test_error 51.50%\n",
      "================================3908===================================\n",
      "3908/10000: train_loss: 3.865284637436271 train_error 48.50% test_error 51.50%\n",
      "================================3909===================================\n",
      "3909/10000: train_loss: 3.865095399916172 train_error 48.50% test_error 51.50%\n",
      "================================3910===================================\n",
      "3910/10000: train_loss: 3.8649067372083663 train_error 48.50% test_error 51.50%\n",
      "================================3911===================================\n",
      "3911/10000: train_loss: 3.864718282818794 train_error 48.62% test_error 51.50%\n",
      "================================3912===================================\n",
      "3912/10000: train_loss: 3.8645297147333624 train_error 48.62% test_error 51.50%\n",
      "================================3913===================================\n",
      "3913/10000: train_loss: 3.864341057687998 train_error 48.62% test_error 51.50%\n",
      "================================3914===================================\n",
      "3914/10000: train_loss: 3.8641522747278216 train_error 48.62% test_error 51.50%\n",
      "================================3915===================================\n",
      "3915/10000: train_loss: 3.8639634527266025 train_error 48.62% test_error 51.50%\n",
      "================================3916===================================\n",
      "3916/10000: train_loss: 3.8637745450437073 train_error 48.62% test_error 51.50%\n",
      "================================3917===================================\n",
      "3917/10000: train_loss: 3.863585505485535 train_error 48.62% test_error 51.50%\n",
      "================================3918===================================\n",
      "3918/10000: train_loss: 3.8633966045081616 train_error 48.62% test_error 51.50%\n",
      "================================3919===================================\n",
      "3919/10000: train_loss: 3.8632086638361214 train_error 48.75% test_error 51.50%\n",
      "================================3920===================================\n",
      "3920/10000: train_loss: 3.863020421713591 train_error 48.75% test_error 51.50%\n",
      "================================3921===================================\n",
      "3921/10000: train_loss: 3.862831193879247 train_error 48.75% test_error 51.50%\n",
      "================================3922===================================\n",
      "3922/10000: train_loss: 3.862641931623221 train_error 48.75% test_error 51.50%\n",
      "================================3923===================================\n",
      "3923/10000: train_loss: 3.862452557012439 train_error 48.75% test_error 51.50%\n",
      "================================3924===================================\n",
      "3924/10000: train_loss: 3.8622630546242 train_error 48.75% test_error 51.50%\n",
      "================================3925===================================\n",
      "3925/10000: train_loss: 3.8620734399557115 train_error 48.62% test_error 51.50%\n",
      "================================3926===================================\n",
      "3926/10000: train_loss: 3.861883759945631 train_error 48.62% test_error 51.50%\n",
      "================================3927===================================\n",
      "3927/10000: train_loss: 3.8616940366476773 train_error 48.62% test_error 51.50%\n",
      "================================3928===================================\n",
      "3928/10000: train_loss: 3.8615042319893838 train_error 48.62% test_error 51.50%\n",
      "================================3929===================================\n",
      "3929/10000: train_loss: 3.8613143442571163 train_error 48.62% test_error 51.50%\n",
      "================================3930===================================\n",
      "3930/10000: train_loss: 3.861124526113272 train_error 48.62% test_error 51.50%\n",
      "================================3931===================================\n",
      "3931/10000: train_loss: 3.8609349040687087 train_error 48.62% test_error 51.50%\n",
      "================================3932===================================\n",
      "3932/10000: train_loss: 3.860746182575822 train_error 48.62% test_error 51.50%\n",
      "================================3933===================================\n",
      "3933/10000: train_loss: 3.860558130443096 train_error 48.62% test_error 51.50%\n",
      "================================3934===================================\n",
      "3934/10000: train_loss: 3.860370521247387 train_error 48.62% test_error 51.50%\n",
      "================================3935===================================\n",
      "3935/10000: train_loss: 3.8601829002797605 train_error 48.50% test_error 51.50%\n",
      "================================3936===================================\n",
      "3936/10000: train_loss: 3.859995338022709 train_error 48.50% test_error 51.50%\n",
      "================================3937===================================\n",
      "3937/10000: train_loss: 3.85980792708695 train_error 48.50% test_error 51.50%\n",
      "================================3938===================================\n",
      "3938/10000: train_loss: 3.85962050318718 train_error 48.50% test_error 51.50%\n",
      "================================3939===================================\n",
      "3939/10000: train_loss: 3.859433022215962 train_error 48.38% test_error 51.50%\n",
      "================================3940===================================\n",
      "3940/10000: train_loss: 3.859245456159115 train_error 48.38% test_error 51.50%\n",
      "================================3941===================================\n",
      "3941/10000: train_loss: 3.859058149307966 train_error 48.38% test_error 51.50%\n",
      "================================3942===================================\n",
      "3942/10000: train_loss: 3.858872009813785 train_error 48.38% test_error 51.50%\n",
      "================================3943===================================\n",
      "3943/10000: train_loss: 3.8586861004680397 train_error 48.38% test_error 51.50%\n",
      "================================3944===================================\n",
      "3944/10000: train_loss: 3.858500094786286 train_error 48.38% test_error 51.50%\n",
      "================================3945===================================\n",
      "3945/10000: train_loss: 3.858313978463411 train_error 48.38% test_error 51.50%\n",
      "================================3946===================================\n",
      "3946/10000: train_loss: 3.8581278850883245 train_error 48.38% test_error 51.50%\n",
      "================================3947===================================\n",
      "3947/10000: train_loss: 3.8579418626427655 train_error 48.38% test_error 51.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================3948===================================\n",
      "3948/10000: train_loss: 3.8577558769285676 train_error 48.38% test_error 51.50%\n",
      "================================3949===================================\n",
      "3949/10000: train_loss: 3.8575709020346403 train_error 48.38% test_error 51.50%\n",
      "================================3950===================================\n",
      "3950/10000: train_loss: 3.8573860083520413 train_error 48.38% test_error 51.50%\n",
      "================================3951===================================\n",
      "3951/10000: train_loss: 3.857201025933027 train_error 48.38% test_error 51.50%\n",
      "================================3952===================================\n",
      "3952/10000: train_loss: 3.8570158955454827 train_error 48.38% test_error 51.50%\n",
      "================================3953===================================\n",
      "3953/10000: train_loss: 3.856830662190914 train_error 48.38% test_error 51.50%\n",
      "================================3954===================================\n",
      "3954/10000: train_loss: 3.8566451881080868 train_error 48.38% test_error 51.50%\n",
      "================================3955===================================\n",
      "3955/10000: train_loss: 3.856459587290883 train_error 48.50% test_error 51.00%\n",
      "================================3956===================================\n",
      "3956/10000: train_loss: 3.856273447200656 train_error 48.50% test_error 51.00%\n",
      "================================3957===================================\n",
      "3957/10000: train_loss: 3.856087041646242 train_error 48.50% test_error 51.00%\n",
      "================================3958===================================\n",
      "3958/10000: train_loss: 3.855902761593461 train_error 48.50% test_error 51.00%\n",
      "================================3959===================================\n",
      "3959/10000: train_loss: 3.8557192327827217 train_error 48.50% test_error 51.00%\n",
      "================================3960===================================\n",
      "3960/10000: train_loss: 3.855534794107079 train_error 48.50% test_error 51.00%\n",
      "================================3961===================================\n",
      "3961/10000: train_loss: 3.8553499168902636 train_error 48.50% test_error 51.00%\n",
      "================================3962===================================\n",
      "3962/10000: train_loss: 3.855164957866073 train_error 48.50% test_error 50.50%\n",
      "================================3963===================================\n",
      "3963/10000: train_loss: 3.8549799238145352 train_error 48.50% test_error 50.50%\n",
      "================================3964===================================\n",
      "3964/10000: train_loss: 3.8547947953641413 train_error 48.50% test_error 50.50%\n",
      "================================3965===================================\n",
      "3965/10000: train_loss: 3.85460967130959 train_error 48.50% test_error 50.50%\n",
      "================================3966===================================\n",
      "3966/10000: train_loss: 3.8544243080168963 train_error 48.50% test_error 50.50%\n",
      "================================3967===================================\n",
      "3967/10000: train_loss: 3.8542389345169066 train_error 48.50% test_error 50.50%\n",
      "================================3968===================================\n",
      "3968/10000: train_loss: 3.8540546546876433 train_error 48.38% test_error 50.50%\n",
      "================================3969===================================\n",
      "3969/10000: train_loss: 3.853870732858777 train_error 48.25% test_error 50.50%\n",
      "================================3970===================================\n",
      "3970/10000: train_loss: 3.853686603605747 train_error 48.25% test_error 50.50%\n",
      "================================3971===================================\n",
      "3971/10000: train_loss: 3.853503182679415 train_error 48.25% test_error 50.50%\n",
      "================================3972===================================\n",
      "3972/10000: train_loss: 3.8533196502923968 train_error 48.25% test_error 50.50%\n",
      "================================3973===================================\n",
      "3973/10000: train_loss: 3.853134718388319 train_error 48.25% test_error 50.50%\n",
      "================================3974===================================\n",
      "3974/10000: train_loss: 3.8529489144682882 train_error 48.25% test_error 50.50%\n",
      "================================3975===================================\n",
      "3975/10000: train_loss: 3.8527636513113976 train_error 48.25% test_error 50.50%\n",
      "================================3976===================================\n",
      "3976/10000: train_loss: 3.8525782825052737 train_error 48.25% test_error 50.50%\n",
      "================================3977===================================\n",
      "3977/10000: train_loss: 3.8523920237272975 train_error 48.25% test_error 50.50%\n",
      "================================3978===================================\n",
      "3978/10000: train_loss: 3.852204753085971 train_error 48.25% test_error 50.50%\n",
      "================================3979===================================\n",
      "3979/10000: train_loss: 3.8520174337923523 train_error 48.25% test_error 50.50%\n",
      "================================3980===================================\n",
      "3980/10000: train_loss: 3.8518300133943564 train_error 48.25% test_error 50.50%\n",
      "================================3981===================================\n",
      "3981/10000: train_loss: 3.851642989590764 train_error 48.25% test_error 50.50%\n",
      "================================3982===================================\n",
      "3982/10000: train_loss: 3.8514566603302955 train_error 48.25% test_error 50.50%\n",
      "================================3983===================================\n",
      "3983/10000: train_loss: 3.851270785406232 train_error 48.25% test_error 50.50%\n",
      "================================3984===================================\n",
      "3984/10000: train_loss: 3.8510852697491647 train_error 48.25% test_error 50.50%\n",
      "================================3985===================================\n",
      "3985/10000: train_loss: 3.8508996582776307 train_error 48.25% test_error 50.50%\n",
      "================================3986===================================\n",
      "3986/10000: train_loss: 3.850714145600796 train_error 48.12% test_error 50.50%\n",
      "================================3987===================================\n",
      "3987/10000: train_loss: 3.850528649017215 train_error 48.12% test_error 50.50%\n",
      "================================3988===================================\n",
      "3988/10000: train_loss: 3.85034281373024 train_error 48.00% test_error 50.50%\n",
      "================================3989===================================\n",
      "3989/10000: train_loss: 3.8501566798985003 train_error 48.00% test_error 50.50%\n",
      "================================3990===================================\n",
      "3990/10000: train_loss: 3.8499707130342724 train_error 48.00% test_error 50.50%\n",
      "================================3991===================================\n",
      "3991/10000: train_loss: 3.8497849261015653 train_error 48.00% test_error 50.50%\n",
      "================================3992===================================\n",
      "3992/10000: train_loss: 3.849599386230111 train_error 48.00% test_error 50.50%\n",
      "================================3993===================================\n",
      "3993/10000: train_loss: 3.849413839876652 train_error 48.00% test_error 50.50%\n",
      "================================3994===================================\n",
      "3994/10000: train_loss: 3.8492283447086812 train_error 48.00% test_error 50.50%\n",
      "================================3995===================================\n",
      "3995/10000: train_loss: 3.8490439208596943 train_error 48.00% test_error 50.50%\n",
      "================================3996===================================\n",
      "3996/10000: train_loss: 3.848859441578388 train_error 48.00% test_error 50.50%\n",
      "================================3997===================================\n",
      "3997/10000: train_loss: 3.848675366416573 train_error 48.00% test_error 50.50%\n",
      "================================3998===================================\n",
      "3998/10000: train_loss: 3.8484921465814117 train_error 48.00% test_error 50.50%\n",
      "================================3999===================================\n",
      "3999/10000: train_loss: 3.848309119045734 train_error 48.00% test_error 50.50%\n",
      "================================4000===================================\n",
      "4000/10000: train_loss: 3.848127099201083 train_error 48.00% test_error 50.50%\n",
      "================================4001===================================\n",
      "4001/10000: train_loss: 3.8479454670101405 train_error 48.00% test_error 50.50%\n",
      "================================4002===================================\n",
      "4002/10000: train_loss: 3.8477631621807817 train_error 48.00% test_error 50.00%\n",
      "================================4003===================================\n",
      "4003/10000: train_loss: 3.847580109760165 train_error 48.00% test_error 50.00%\n",
      "================================4004===================================\n",
      "4004/10000: train_loss: 3.847397704720497 train_error 48.00% test_error 50.00%\n",
      "================================4005===================================\n",
      "4005/10000: train_loss: 3.8472155879437926 train_error 48.00% test_error 50.00%\n",
      "================================4006===================================\n",
      "4006/10000: train_loss: 3.847033727094531 train_error 48.00% test_error 50.00%\n",
      "================================4007===================================\n",
      "4007/10000: train_loss: 3.84685188755393 train_error 48.00% test_error 50.00%\n",
      "================================4008===================================\n",
      "4008/10000: train_loss: 3.8466699058562517 train_error 48.00% test_error 50.00%\n",
      "================================4009===================================\n",
      "4009/10000: train_loss: 3.846487311273813 train_error 48.00% test_error 50.00%\n",
      "================================4010===================================\n",
      "4010/10000: train_loss: 3.846303106620908 train_error 48.00% test_error 50.00%\n",
      "================================4011===================================\n",
      "4011/10000: train_loss: 3.8461189067363737 train_error 48.00% test_error 50.00%\n",
      "================================4012===================================\n",
      "4012/10000: train_loss: 3.8459345122426747 train_error 48.00% test_error 50.00%\n",
      "================================4013===================================\n",
      "4013/10000: train_loss: 3.8457509631663562 train_error 48.00% test_error 50.00%\n",
      "================================4014===================================\n",
      "4014/10000: train_loss: 3.8455672823637723 train_error 48.00% test_error 50.00%\n",
      "================================4015===================================\n",
      "4015/10000: train_loss: 3.8453837713599204 train_error 48.00% test_error 50.00%\n",
      "================================4016===================================\n",
      "4016/10000: train_loss: 3.845200024172664 train_error 48.00% test_error 50.00%\n",
      "================================4017===================================\n",
      "4017/10000: train_loss: 3.845015018880367 train_error 48.00% test_error 50.00%\n",
      "================================4018===================================\n",
      "4018/10000: train_loss: 3.844828691259026 train_error 48.00% test_error 50.00%\n",
      "================================4019===================================\n",
      "4019/10000: train_loss: 3.844642344340682 train_error 48.00% test_error 50.00%\n",
      "================================4020===================================\n",
      "4020/10000: train_loss: 3.8444561517238616 train_error 47.88% test_error 50.00%\n",
      "================================4021===================================\n",
      "4021/10000: train_loss: 3.844269994944334 train_error 47.88% test_error 50.00%\n",
      "================================4022===================================\n",
      "4022/10000: train_loss: 3.8440846998244522 train_error 47.88% test_error 50.00%\n",
      "================================4023===================================\n",
      "4023/10000: train_loss: 3.8438998287916184 train_error 47.88% test_error 50.00%\n",
      "================================4024===================================\n",
      "4024/10000: train_loss: 3.8437147177010775 train_error 47.88% test_error 50.00%\n",
      "================================4025===================================\n",
      "4025/10000: train_loss: 3.8435296171903612 train_error 47.88% test_error 50.00%\n",
      "================================4026===================================\n",
      "4026/10000: train_loss: 3.8433444090932607 train_error 47.88% test_error 50.00%\n",
      "================================4027===================================\n",
      "4027/10000: train_loss: 3.8431585900485516 train_error 47.88% test_error 50.00%\n",
      "================================4028===================================\n",
      "4028/10000: train_loss: 3.84297179736197 train_error 47.88% test_error 50.00%\n",
      "================================4029===================================\n",
      "4029/10000: train_loss: 3.842785007059574 train_error 47.88% test_error 50.00%\n",
      "================================4030===================================\n",
      "4030/10000: train_loss: 3.8425979898124933 train_error 47.88% test_error 50.00%\n",
      "================================4031===================================\n",
      "4031/10000: train_loss: 3.842410588413477 train_error 47.88% test_error 50.00%\n",
      "================================4032===================================\n",
      "4032/10000: train_loss: 3.842223119661212 train_error 47.88% test_error 50.00%\n",
      "================================4033===================================\n",
      "4033/10000: train_loss: 3.8420356795936823 train_error 47.88% test_error 50.00%\n",
      "================================4034===================================\n",
      "4034/10000: train_loss: 3.8418484055250883 train_error 47.88% test_error 50.00%\n",
      "================================4035===================================\n",
      "4035/10000: train_loss: 3.8416617105901243 train_error 47.88% test_error 50.00%\n",
      "================================4036===================================\n",
      "4036/10000: train_loss: 3.841475422605872 train_error 47.88% test_error 50.00%\n",
      "================================4037===================================\n",
      "4037/10000: train_loss: 3.8412894243746996 train_error 47.88% test_error 50.00%\n",
      "================================4038===================================\n",
      "4038/10000: train_loss: 3.841102021113038 train_error 47.88% test_error 50.00%\n",
      "================================4039===================================\n",
      "4039/10000: train_loss: 3.8409146413952113 train_error 47.88% test_error 50.00%\n",
      "================================4040===================================\n",
      "4040/10000: train_loss: 3.840727830901742 train_error 47.88% test_error 50.00%\n",
      "================================4041===================================\n",
      "4041/10000: train_loss: 3.840541145056486 train_error 48.00% test_error 50.00%\n",
      "================================4042===================================\n",
      "4042/10000: train_loss: 3.840355324968696 train_error 48.00% test_error 50.00%\n",
      "================================4043===================================\n",
      "4043/10000: train_loss: 3.840169628337026 train_error 48.00% test_error 50.00%\n",
      "================================4044===================================\n",
      "4044/10000: train_loss: 3.839984175190329 train_error 47.88% test_error 50.00%\n",
      "================================4045===================================\n",
      "4045/10000: train_loss: 3.839798809662461 train_error 47.88% test_error 50.00%\n",
      "================================4046===================================\n",
      "4046/10000: train_loss: 3.839613497853279 train_error 47.88% test_error 50.00%\n",
      "================================4047===================================\n",
      "4047/10000: train_loss: 3.8394280795007942 train_error 47.75% test_error 49.50%\n",
      "================================4048===================================\n",
      "4048/10000: train_loss: 3.8392425914853807 train_error 47.75% test_error 49.50%\n",
      "================================4049===================================\n",
      "4049/10000: train_loss: 3.8390563274174925 train_error 47.75% test_error 49.50%\n",
      "================================4050===================================\n",
      "4050/10000: train_loss: 3.838868874311447 train_error 47.75% test_error 49.50%\n",
      "================================4051===================================\n",
      "4051/10000: train_loss: 3.838680884093046 train_error 47.75% test_error 49.50%\n",
      "================================4052===================================\n",
      "4052/10000: train_loss: 3.8384937972575424 train_error 47.75% test_error 49.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4053===================================\n",
      "4053/10000: train_loss: 3.8383077396452423 train_error 47.75% test_error 49.50%\n",
      "================================4054===================================\n",
      "4054/10000: train_loss: 3.8381223096698522 train_error 47.75% test_error 49.50%\n",
      "================================4055===================================\n",
      "4055/10000: train_loss: 3.8379365880042315 train_error 47.88% test_error 49.50%\n",
      "================================4056===================================\n",
      "4056/10000: train_loss: 3.8377516476809976 train_error 47.88% test_error 49.50%\n",
      "================================4057===================================\n",
      "4057/10000: train_loss: 3.8375666164606805 train_error 47.88% test_error 49.50%\n",
      "================================4058===================================\n",
      "4058/10000: train_loss: 3.8373815555870534 train_error 47.88% test_error 49.50%\n",
      "================================4059===================================\n",
      "4059/10000: train_loss: 3.8371964827924967 train_error 47.88% test_error 49.50%\n",
      "================================4060===================================\n",
      "4060/10000: train_loss: 3.8370114751160145 train_error 47.88% test_error 49.50%\n",
      "================================4061===================================\n",
      "4061/10000: train_loss: 3.83682692527771 train_error 47.88% test_error 49.50%\n",
      "================================4062===================================\n",
      "4062/10000: train_loss: 3.8366434960067273 train_error 47.88% test_error 49.50%\n",
      "================================4063===================================\n",
      "4063/10000: train_loss: 3.836460450217128 train_error 47.88% test_error 49.50%\n",
      "================================4064===================================\n",
      "4064/10000: train_loss: 3.8362773138284685 train_error 47.88% test_error 49.50%\n",
      "================================4065===================================\n",
      "4065/10000: train_loss: 3.836094162836671 train_error 47.88% test_error 49.50%\n",
      "================================4066===================================\n",
      "4066/10000: train_loss: 3.8359109450876714 train_error 47.88% test_error 49.50%\n",
      "================================4067===================================\n",
      "4067/10000: train_loss: 3.8357281198352573 train_error 48.00% test_error 49.50%\n",
      "================================4068===================================\n",
      "4068/10000: train_loss: 3.8355460065603255 train_error 48.00% test_error 49.50%\n",
      "================================4069===================================\n",
      "4069/10000: train_loss: 3.835364504307509 train_error 48.00% test_error 49.50%\n",
      "================================4070===================================\n",
      "4070/10000: train_loss: 3.835182675048709 train_error 48.00% test_error 49.50%\n",
      "================================4071===================================\n",
      "4071/10000: train_loss: 3.835001135766506 train_error 48.00% test_error 49.50%\n",
      "================================4072===================================\n",
      "4072/10000: train_loss: 3.834819710552692 train_error 48.00% test_error 49.50%\n",
      "================================4073===================================\n",
      "4073/10000: train_loss: 3.834638100787997 train_error 48.00% test_error 49.50%\n",
      "================================4074===================================\n",
      "4074/10000: train_loss: 3.834456349164247 train_error 48.00% test_error 49.50%\n",
      "================================4075===================================\n",
      "4075/10000: train_loss: 3.8342738772928713 train_error 48.00% test_error 49.50%\n",
      "================================4076===================================\n",
      "4076/10000: train_loss: 3.834091166034341 train_error 48.00% test_error 49.50%\n",
      "================================4077===================================\n",
      "4077/10000: train_loss: 3.8339092320948835 train_error 48.00% test_error 49.50%\n",
      "================================4078===================================\n",
      "4078/10000: train_loss: 3.833727284148335 train_error 48.00% test_error 49.50%\n",
      "================================4079===================================\n",
      "4079/10000: train_loss: 3.833545280098915 train_error 48.00% test_error 49.50%\n",
      "================================4080===================================\n",
      "4080/10000: train_loss: 3.833363308534026 train_error 48.00% test_error 49.50%\n",
      "================================4081===================================\n",
      "4081/10000: train_loss: 3.833181283250451 train_error 48.00% test_error 49.50%\n",
      "================================4082===================================\n",
      "4082/10000: train_loss: 3.8329991334676743 train_error 48.00% test_error 49.50%\n",
      "================================4083===================================\n",
      "4083/10000: train_loss: 3.8328168977051975 train_error 48.00% test_error 49.50%\n",
      "================================4084===================================\n",
      "4084/10000: train_loss: 3.832634655162692 train_error 48.00% test_error 49.50%\n",
      "================================4085===================================\n",
      "4085/10000: train_loss: 3.8324525285512214 train_error 48.00% test_error 49.50%\n",
      "================================4086===================================\n",
      "4086/10000: train_loss: 3.832270357608795 train_error 48.00% test_error 49.50%\n",
      "================================4087===================================\n",
      "4087/10000: train_loss: 3.83208796903491 train_error 48.00% test_error 49.50%\n",
      "================================4088===================================\n",
      "4088/10000: train_loss: 3.8319044699519877 train_error 48.00% test_error 49.50%\n",
      "================================4089===================================\n",
      "4089/10000: train_loss: 3.831719853430986 train_error 47.75% test_error 49.50%\n",
      "================================4090===================================\n",
      "4090/10000: train_loss: 3.8315352605283257 train_error 47.75% test_error 49.50%\n",
      "================================4091===================================\n",
      "4091/10000: train_loss: 3.8313505816459656 train_error 47.75% test_error 49.50%\n",
      "================================4092===================================\n",
      "4092/10000: train_loss: 3.831164224073291 train_error 47.75% test_error 49.50%\n",
      "================================4093===================================\n",
      "4093/10000: train_loss: 3.8309781254827975 train_error 47.75% test_error 49.50%\n",
      "================================4094===================================\n",
      "4094/10000: train_loss: 3.830793552324176 train_error 47.75% test_error 49.50%\n",
      "================================4095===================================\n",
      "4095/10000: train_loss: 3.8306089072674516 train_error 47.75% test_error 49.50%\n",
      "================================4096===================================\n",
      "4096/10000: train_loss: 3.830424164757132 train_error 47.75% test_error 49.50%\n",
      "================================4097===================================\n",
      "4097/10000: train_loss: 3.830240091979504 train_error 47.75% test_error 49.50%\n",
      "================================4098===================================\n",
      "4098/10000: train_loss: 3.830057407692075 train_error 47.75% test_error 49.50%\n",
      "================================4099===================================\n",
      "4099/10000: train_loss: 3.829874544665217 train_error 47.75% test_error 49.50%\n",
      "================================4100===================================\n",
      "4100/10000: train_loss: 3.82969142973423 train_error 47.75% test_error 49.50%\n",
      "================================4101===================================\n",
      "4101/10000: train_loss: 3.8295080816745757 train_error 47.75% test_error 49.50%\n",
      "================================4102===================================\n",
      "4102/10000: train_loss: 3.8293247043341396 train_error 47.75% test_error 49.50%\n",
      "================================4103===================================\n",
      "4103/10000: train_loss: 3.8291412411630157 train_error 47.75% test_error 49.50%\n",
      "================================4104===================================\n",
      "4104/10000: train_loss: 3.828957760632038 train_error 47.75% test_error 49.50%\n",
      "================================4105===================================\n",
      "4105/10000: train_loss: 3.828775061517954 train_error 47.75% test_error 49.00%\n",
      "================================4106===================================\n",
      "4106/10000: train_loss: 3.8285923255980014 train_error 47.75% test_error 49.00%\n",
      "================================4107===================================\n",
      "4107/10000: train_loss: 3.828409966677427 train_error 47.75% test_error 49.00%\n",
      "================================4108===================================\n",
      "4108/10000: train_loss: 3.828227462023497 train_error 47.75% test_error 49.00%\n",
      "================================4109===================================\n",
      "4109/10000: train_loss: 3.828044984266162 train_error 47.75% test_error 49.00%\n",
      "================================4110===================================\n",
      "4110/10000: train_loss: 3.8278632742911576 train_error 47.75% test_error 49.00%\n",
      "================================4111===================================\n",
      "4111/10000: train_loss: 3.827681417539716 train_error 47.75% test_error 49.00%\n",
      "================================4112===================================\n",
      "4112/10000: train_loss: 3.827500435933471 train_error 47.75% test_error 49.00%\n",
      "================================4113===================================\n",
      "4113/10000: train_loss: 3.827319640144706 train_error 47.75% test_error 49.00%\n",
      "================================4114===================================\n",
      "4114/10000: train_loss: 3.827138825505972 train_error 47.75% test_error 49.00%\n",
      "================================4115===================================\n",
      "4115/10000: train_loss: 3.8269582997262477 train_error 47.75% test_error 49.00%\n",
      "================================4116===================================\n",
      "4116/10000: train_loss: 3.826778259947896 train_error 47.62% test_error 48.50%\n",
      "================================4117===================================\n",
      "4117/10000: train_loss: 3.8265989585220814 train_error 47.62% test_error 48.50%\n",
      "================================4118===================================\n",
      "4118/10000: train_loss: 3.8264196331053975 train_error 47.62% test_error 48.50%\n",
      "================================4119===================================\n",
      "4119/10000: train_loss: 3.8262402441352603 train_error 47.62% test_error 48.50%\n",
      "================================4120===================================\n",
      "4120/10000: train_loss: 3.826060725003481 train_error 47.62% test_error 48.50%\n",
      "================================4121===================================\n",
      "4121/10000: train_loss: 3.8258809384703634 train_error 47.62% test_error 48.50%\n",
      "================================4122===================================\n",
      "4122/10000: train_loss: 3.8257011438161133 train_error 47.62% test_error 48.50%\n",
      "================================4123===================================\n",
      "4123/10000: train_loss: 3.8255213658511638 train_error 47.62% test_error 48.00%\n",
      "================================4124===================================\n",
      "4124/10000: train_loss: 3.8253415662050245 train_error 47.62% test_error 48.00%\n",
      "================================4125===================================\n",
      "4125/10000: train_loss: 3.825161654651165 train_error 47.62% test_error 48.00%\n",
      "================================4126===================================\n",
      "4126/10000: train_loss: 3.8249817448109384 train_error 47.62% test_error 48.00%\n",
      "================================4127===================================\n",
      "4127/10000: train_loss: 3.8248018937557937 train_error 47.62% test_error 48.00%\n",
      "================================4128===================================\n",
      "4128/10000: train_loss: 3.8246220555156474 train_error 47.62% test_error 48.00%\n",
      "================================4129===================================\n",
      "4129/10000: train_loss: 3.82444173745811 train_error 47.50% test_error 48.00%\n",
      "================================4130===================================\n",
      "4130/10000: train_loss: 3.8242606604099274 train_error 47.50% test_error 48.00%\n",
      "================================4131===================================\n",
      "4131/10000: train_loss: 3.8240796712785956 train_error 47.50% test_error 48.00%\n",
      "================================4132===================================\n",
      "4132/10000: train_loss: 3.8238988792151214 train_error 47.50% test_error 48.00%\n",
      "================================4133===================================\n",
      "4133/10000: train_loss: 3.8237191952764986 train_error 47.50% test_error 48.00%\n",
      "================================4134===================================\n",
      "4134/10000: train_loss: 3.8235400836914777 train_error 47.50% test_error 48.00%\n",
      "================================4135===================================\n",
      "4135/10000: train_loss: 3.823360934630036 train_error 47.50% test_error 48.00%\n",
      "================================4136===================================\n",
      "4136/10000: train_loss: 3.823181646168232 train_error 47.50% test_error 48.00%\n",
      "================================4137===================================\n",
      "4137/10000: train_loss: 3.8230024482309815 train_error 47.50% test_error 48.00%\n",
      "================================4138===================================\n",
      "4138/10000: train_loss: 3.822824412211776 train_error 47.50% test_error 48.00%\n",
      "================================4139===================================\n",
      "4139/10000: train_loss: 3.8226462990790604 train_error 47.50% test_error 48.00%\n",
      "================================4140===================================\n",
      "4140/10000: train_loss: 3.822467908263206 train_error 47.50% test_error 48.00%\n",
      "================================4141===================================\n",
      "4141/10000: train_loss: 3.8222895044833423 train_error 47.50% test_error 48.00%\n",
      "================================4142===================================\n",
      "4142/10000: train_loss: 3.8221110083162784 train_error 47.38% test_error 48.00%\n",
      "================================4143===================================\n",
      "4143/10000: train_loss: 3.8219318635761734 train_error 47.38% test_error 48.00%\n",
      "================================4144===================================\n",
      "4144/10000: train_loss: 3.821752161458135 train_error 47.38% test_error 48.00%\n",
      "================================4145===================================\n",
      "4145/10000: train_loss: 3.8215723501145837 train_error 47.38% test_error 48.00%\n",
      "================================4146===================================\n",
      "4146/10000: train_loss: 3.82139248020947 train_error 47.38% test_error 48.00%\n",
      "================================4147===================================\n",
      "4147/10000: train_loss: 3.821212629973888 train_error 47.38% test_error 48.00%\n",
      "================================4148===================================\n",
      "4148/10000: train_loss: 3.8210326995700603 train_error 47.38% test_error 48.00%\n",
      "================================4149===================================\n",
      "4149/10000: train_loss: 3.8208527145534754 train_error 47.38% test_error 48.00%\n",
      "================================4150===================================\n",
      "4150/10000: train_loss: 3.820673281177878 train_error 47.38% test_error 48.00%\n",
      "================================4151===================================\n",
      "4151/10000: train_loss: 3.8204951025545597 train_error 47.38% test_error 48.00%\n",
      "================================4152===================================\n",
      "4152/10000: train_loss: 3.8203178536891937 train_error 47.25% test_error 48.00%\n",
      "================================4153===================================\n",
      "4153/10000: train_loss: 3.8201410506665705 train_error 47.25% test_error 48.00%\n",
      "================================4154===================================\n",
      "4154/10000: train_loss: 3.8199648748338224 train_error 47.25% test_error 48.00%\n",
      "================================4155===================================\n",
      "4155/10000: train_loss: 3.8197899124026296 train_error 47.25% test_error 48.00%\n",
      "================================4156===================================\n",
      "4156/10000: train_loss: 3.819615542590618 train_error 47.25% test_error 48.00%\n",
      "================================4157===================================\n",
      "4157/10000: train_loss: 3.819441173002124 train_error 47.25% test_error 48.00%\n",
      "================================4158===================================\n",
      "4158/10000: train_loss: 3.8192667897790673 train_error 47.12% test_error 48.00%\n",
      "================================4159===================================\n",
      "4159/10000: train_loss: 3.8190921170264485 train_error 47.12% test_error 48.00%\n",
      "================================4160===================================\n",
      "4160/10000: train_loss: 3.818916793912649 train_error 47.12% test_error 48.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4161===================================\n",
      "4161/10000: train_loss: 3.8187408792972564 train_error 47.12% test_error 48.00%\n",
      "================================4162===================================\n",
      "4162/10000: train_loss: 3.8185644379258155 train_error 47.12% test_error 48.00%\n",
      "================================4163===================================\n",
      "4163/10000: train_loss: 3.8183887764066458 train_error 47.12% test_error 48.00%\n",
      "================================4164===================================\n",
      "4164/10000: train_loss: 3.818213554471731 train_error 47.12% test_error 48.00%\n",
      "================================4165===================================\n",
      "4165/10000: train_loss: 3.8180382314324377 train_error 47.12% test_error 48.00%\n",
      "================================4166===================================\n",
      "4166/10000: train_loss: 3.817862892150879 train_error 47.12% test_error 48.00%\n",
      "================================4167===================================\n",
      "4167/10000: train_loss: 3.8176874351501464 train_error 47.12% test_error 48.00%\n",
      "================================4168===================================\n",
      "4168/10000: train_loss: 3.817511803880334 train_error 47.12% test_error 47.50%\n",
      "================================4169===================================\n",
      "4169/10000: train_loss: 3.81733602963388 train_error 47.12% test_error 47.50%\n",
      "================================4170===================================\n",
      "4170/10000: train_loss: 3.817160250917077 train_error 47.00% test_error 47.50%\n",
      "================================4171===================================\n",
      "4171/10000: train_loss: 3.816985418945551 train_error 47.00% test_error 47.50%\n",
      "================================4172===================================\n",
      "4172/10000: train_loss: 3.8168108297139405 train_error 47.00% test_error 47.50%\n",
      "================================4173===================================\n",
      "4173/10000: train_loss: 3.8166362794488666 train_error 47.00% test_error 47.50%\n",
      "================================4174===================================\n",
      "4174/10000: train_loss: 3.816461631730199 train_error 47.00% test_error 47.50%\n",
      "================================4175===================================\n",
      "4175/10000: train_loss: 3.816286931782961 train_error 47.00% test_error 47.50%\n",
      "================================4176===================================\n",
      "4176/10000: train_loss: 3.8161121436953542 train_error 47.00% test_error 47.50%\n",
      "================================4177===================================\n",
      "4177/10000: train_loss: 3.815937546044588 train_error 47.00% test_error 47.50%\n",
      "================================4178===================================\n",
      "4178/10000: train_loss: 3.8157632247358557 train_error 47.00% test_error 47.50%\n",
      "================================4179===================================\n",
      "4179/10000: train_loss: 3.8155887980759142 train_error 47.00% test_error 47.50%\n",
      "================================4180===================================\n",
      "4180/10000: train_loss: 3.815414085239172 train_error 47.00% test_error 47.50%\n",
      "================================4181===================================\n",
      "4181/10000: train_loss: 3.815239334478974 train_error 47.00% test_error 47.50%\n",
      "================================4182===================================\n",
      "4182/10000: train_loss: 3.81506451331079 train_error 47.00% test_error 47.50%\n",
      "================================4183===================================\n",
      "4183/10000: train_loss: 3.8148898119479417 train_error 47.12% test_error 47.50%\n",
      "================================4184===================================\n",
      "4184/10000: train_loss: 3.8147149778902527 train_error 47.12% test_error 47.50%\n",
      "================================4185===================================\n",
      "4185/10000: train_loss: 3.814540244191885 train_error 47.12% test_error 47.50%\n",
      "================================4186===================================\n",
      "4186/10000: train_loss: 3.814365606531501 train_error 47.12% test_error 47.50%\n",
      "================================4187===================================\n",
      "4187/10000: train_loss: 3.8141909590363503 train_error 47.12% test_error 47.50%\n",
      "================================4188===================================\n",
      "4188/10000: train_loss: 3.8140165888518096 train_error 47.12% test_error 47.50%\n",
      "================================4189===================================\n",
      "4189/10000: train_loss: 3.813842315450311 train_error 47.12% test_error 47.50%\n",
      "================================4190===================================\n",
      "4190/10000: train_loss: 3.8136684535443783 train_error 47.12% test_error 47.50%\n",
      "================================4191===================================\n",
      "4191/10000: train_loss: 3.813496015071869 train_error 47.12% test_error 47.50%\n",
      "================================4192===================================\n",
      "4192/10000: train_loss: 3.813323921263218 train_error 47.12% test_error 47.50%\n",
      "================================4193===================================\n",
      "4193/10000: train_loss: 3.813152073994279 train_error 47.12% test_error 47.50%\n",
      "================================4194===================================\n",
      "4194/10000: train_loss: 3.8129802513867617 train_error 47.12% test_error 47.50%\n",
      "================================4195===================================\n",
      "4195/10000: train_loss: 3.8128086144477127 train_error 47.12% test_error 47.50%\n",
      "================================4196===================================\n",
      "4196/10000: train_loss: 3.8126370584964753 train_error 47.12% test_error 47.50%\n",
      "================================4197===================================\n",
      "4197/10000: train_loss: 3.8124655830860137 train_error 47.12% test_error 47.50%\n",
      "================================4198===================================\n",
      "4198/10000: train_loss: 3.812293762490153 train_error 47.00% test_error 47.50%\n",
      "================================4199===================================\n",
      "4199/10000: train_loss: 3.8121216353029013 train_error 47.00% test_error 47.50%\n",
      "================================4200===================================\n",
      "4200/10000: train_loss: 3.811949444413185 train_error 47.00% test_error 47.50%\n",
      "================================4201===================================\n",
      "4201/10000: train_loss: 3.8117771930247546 train_error 47.00% test_error 47.50%\n",
      "================================4202===================================\n",
      "4202/10000: train_loss: 3.81160461820662 train_error 47.00% test_error 47.50%\n",
      "================================4203===================================\n",
      "4203/10000: train_loss: 3.811430947482586 train_error 47.00% test_error 47.50%\n",
      "================================4204===================================\n",
      "4204/10000: train_loss: 3.811258240491152 train_error 47.00% test_error 47.50%\n",
      "================================4205===================================\n",
      "4205/10000: train_loss: 3.8110854314267635 train_error 47.00% test_error 47.50%\n",
      "================================4206===================================\n",
      "4206/10000: train_loss: 3.810912413522601 train_error 47.00% test_error 47.50%\n",
      "================================4207===================================\n",
      "4207/10000: train_loss: 3.810739811733365 train_error 47.00% test_error 47.50%\n",
      "================================4208===================================\n",
      "4208/10000: train_loss: 3.8105680610239507 train_error 46.88% test_error 47.50%\n",
      "================================4209===================================\n",
      "4209/10000: train_loss: 3.810396320521831 train_error 46.88% test_error 47.50%\n",
      "================================4210===================================\n",
      "4210/10000: train_loss: 3.8102244680374864 train_error 46.88% test_error 47.50%\n",
      "================================4211===================================\n",
      "4211/10000: train_loss: 3.810052452161908 train_error 46.88% test_error 47.50%\n",
      "================================4212===================================\n",
      "4212/10000: train_loss: 3.809880408644676 train_error 46.88% test_error 47.50%\n",
      "================================4213===================================\n",
      "4213/10000: train_loss: 3.8097084958851335 train_error 46.88% test_error 47.50%\n",
      "================================4214===================================\n",
      "4214/10000: train_loss: 3.809536456912756 train_error 46.88% test_error 47.50%\n",
      "================================4215===================================\n",
      "4215/10000: train_loss: 3.8093644212931395 train_error 46.88% test_error 47.50%\n",
      "================================4216===================================\n",
      "4216/10000: train_loss: 3.8091928066313265 train_error 46.88% test_error 47.50%\n",
      "================================4217===================================\n",
      "4217/10000: train_loss: 3.809021320715546 train_error 46.88% test_error 47.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4218===================================\n",
      "4218/10000: train_loss: 3.808849801272154 train_error 46.88% test_error 47.50%\n",
      "================================4219===================================\n",
      "4219/10000: train_loss: 3.808678622692823 train_error 46.88% test_error 47.50%\n",
      "================================4220===================================\n",
      "4220/10000: train_loss: 3.8085083083063367 train_error 46.75% test_error 47.50%\n",
      "================================4221===================================\n",
      "4221/10000: train_loss: 3.808337941989303 train_error 46.75% test_error 47.50%\n",
      "================================4222===================================\n",
      "4222/10000: train_loss: 3.808167550563812 train_error 46.75% test_error 47.50%\n",
      "================================4223===================================\n",
      "4223/10000: train_loss: 3.8079974476993086 train_error 46.75% test_error 47.50%\n",
      "================================4224===================================\n",
      "4224/10000: train_loss: 3.8078278335928917 train_error 46.75% test_error 47.50%\n",
      "================================4225===================================\n",
      "4225/10000: train_loss: 3.8076584213972087 train_error 46.75% test_error 47.50%\n",
      "================================4226===================================\n",
      "4226/10000: train_loss: 3.8074889954924585 train_error 46.75% test_error 47.50%\n",
      "================================4227===================================\n",
      "4227/10000: train_loss: 3.8073196775466203 train_error 46.75% test_error 47.50%\n",
      "================================4228===================================\n",
      "4228/10000: train_loss: 3.807150303348899 train_error 46.75% test_error 47.50%\n",
      "================================4229===================================\n",
      "4229/10000: train_loss: 3.8069808623939747 train_error 46.75% test_error 47.50%\n",
      "================================4230===================================\n",
      "4230/10000: train_loss: 3.806810846999287 train_error 46.75% test_error 47.50%\n",
      "================================4231===================================\n",
      "4231/10000: train_loss: 3.806640483289957 train_error 46.75% test_error 47.50%\n",
      "================================4232===================================\n",
      "4232/10000: train_loss: 3.806469666063786 train_error 46.75% test_error 47.50%\n",
      "================================4233===================================\n",
      "4233/10000: train_loss: 3.80629892103374 train_error 46.75% test_error 47.50%\n",
      "================================4234===================================\n",
      "4234/10000: train_loss: 3.8061281590163705 train_error 46.75% test_error 47.50%\n",
      "================================4235===================================\n",
      "4235/10000: train_loss: 3.805958177521825 train_error 46.75% test_error 47.50%\n",
      "================================4236===================================\n",
      "4236/10000: train_loss: 3.80578821003437 train_error 46.75% test_error 47.50%\n",
      "================================4237===================================\n",
      "4237/10000: train_loss: 3.805619083419442 train_error 46.75% test_error 47.50%\n",
      "================================4238===================================\n",
      "4238/10000: train_loss: 3.8054503870010374 train_error 46.75% test_error 47.50%\n",
      "================================4239===================================\n",
      "4239/10000: train_loss: 3.8052821916341784 train_error 46.75% test_error 47.50%\n",
      "================================4240===================================\n",
      "4240/10000: train_loss: 3.8051139032095675 train_error 46.75% test_error 47.50%\n",
      "================================4241===================================\n",
      "4241/10000: train_loss: 3.8049463933706287 train_error 46.75% test_error 47.50%\n",
      "================================4242===================================\n",
      "4242/10000: train_loss: 3.8047788914293053 train_error 46.75% test_error 47.50%\n",
      "================================4243===================================\n",
      "4243/10000: train_loss: 3.8046113011986016 train_error 46.75% test_error 47.50%\n",
      "================================4244===================================\n",
      "4244/10000: train_loss: 3.804443413838744 train_error 46.75% test_error 47.50%\n",
      "================================4245===================================\n",
      "4245/10000: train_loss: 3.804275552481413 train_error 46.75% test_error 47.50%\n",
      "================================4246===================================\n",
      "4246/10000: train_loss: 3.804108468219638 train_error 46.75% test_error 47.50%\n",
      "================================4247===================================\n",
      "4247/10000: train_loss: 3.803941931948066 train_error 46.75% test_error 47.50%\n",
      "================================4248===================================\n",
      "4248/10000: train_loss: 3.80377534173429 train_error 46.75% test_error 47.50%\n",
      "================================4249===================================\n",
      "4249/10000: train_loss: 3.803608659282327 train_error 46.75% test_error 47.50%\n",
      "================================4250===================================\n",
      "4250/10000: train_loss: 3.803442249447107 train_error 46.75% test_error 47.50%\n",
      "================================4251===================================\n",
      "4251/10000: train_loss: 3.8032767134159804 train_error 46.75% test_error 47.50%\n",
      "================================4252===================================\n",
      "4252/10000: train_loss: 3.8031120276451107 train_error 46.75% test_error 47.50%\n",
      "================================4253===================================\n",
      "4253/10000: train_loss: 3.8029472769796846 train_error 46.75% test_error 47.50%\n",
      "================================4254===================================\n",
      "4254/10000: train_loss: 3.802782502099872 train_error 46.75% test_error 47.50%\n",
      "================================4255===================================\n",
      "4255/10000: train_loss: 3.8026178225874903 train_error 46.75% test_error 47.50%\n",
      "================================4256===================================\n",
      "4256/10000: train_loss: 3.8024533873051403 train_error 46.75% test_error 47.50%\n",
      "================================4257===================================\n",
      "4257/10000: train_loss: 3.8022894621640444 train_error 46.75% test_error 47.50%\n",
      "================================4258===================================\n",
      "4258/10000: train_loss: 3.8021257833391426 train_error 46.75% test_error 47.50%\n",
      "================================4259===================================\n",
      "4259/10000: train_loss: 3.8019627482444047 train_error 46.75% test_error 47.50%\n",
      "================================4260===================================\n",
      "4260/10000: train_loss: 3.801799689605832 train_error 46.75% test_error 47.50%\n",
      "================================4261===================================\n",
      "4261/10000: train_loss: 3.8016367841511967 train_error 46.75% test_error 47.50%\n",
      "================================4262===================================\n",
      "4262/10000: train_loss: 3.8014737274497747 train_error 46.75% test_error 47.50%\n",
      "================================4263===================================\n",
      "4263/10000: train_loss: 3.8013105767965314 train_error 46.75% test_error 47.50%\n",
      "================================4264===================================\n",
      "4264/10000: train_loss: 3.8011473634094 train_error 46.75% test_error 47.50%\n",
      "================================4265===================================\n",
      "4265/10000: train_loss: 3.800984121263027 train_error 46.75% test_error 47.50%\n",
      "================================4266===================================\n",
      "4266/10000: train_loss: 3.80082113660872 train_error 46.75% test_error 47.50%\n",
      "================================4267===================================\n",
      "4267/10000: train_loss: 3.8006581369787455 train_error 46.75% test_error 47.50%\n",
      "================================4268===================================\n",
      "4268/10000: train_loss: 3.8004949946701525 train_error 46.75% test_error 47.50%\n",
      "================================4269===================================\n",
      "4269/10000: train_loss: 3.8003316517174244 train_error 46.75% test_error 47.50%\n",
      "================================4270===================================\n",
      "4270/10000: train_loss: 3.80016792178154 train_error 46.75% test_error 47.50%\n",
      "================================4271===================================\n",
      "4271/10000: train_loss: 3.800004240870476 train_error 46.75% test_error 47.50%\n",
      "================================4272===================================\n",
      "4272/10000: train_loss: 3.799840677827597 train_error 46.75% test_error 47.50%\n",
      "================================4273===================================\n",
      "4273/10000: train_loss: 3.7996772595494983 train_error 46.75% test_error 47.50%\n",
      "================================4274===================================\n",
      "4274/10000: train_loss: 3.7995146138221023 train_error 46.75% test_error 47.50%\n",
      "================================4275===================================\n",
      "4275/10000: train_loss: 3.799351880028844 train_error 46.75% test_error 47.50%\n",
      "================================4276===================================\n",
      "4276/10000: train_loss: 3.799190141707659 train_error 46.75% test_error 47.50%\n",
      "================================4277===================================\n",
      "4277/10000: train_loss: 3.799029929637909 train_error 46.75% test_error 47.50%\n",
      "================================4278===================================\n",
      "4278/10000: train_loss: 3.798869975581765 train_error 46.75% test_error 47.50%\n",
      "================================4279===================================\n",
      "4279/10000: train_loss: 3.798710510283709 train_error 46.75% test_error 47.50%\n",
      "================================4280===================================\n",
      "4280/10000: train_loss: 3.7985511608421803 train_error 46.75% test_error 47.50%\n",
      "================================4281===================================\n",
      "4281/10000: train_loss: 3.7983915298432107 train_error 46.75% test_error 47.50%\n",
      "================================4282===================================\n",
      "4282/10000: train_loss: 3.798232722133398 train_error 46.75% test_error 47.50%\n",
      "================================4283===================================\n",
      "4283/10000: train_loss: 3.798076103106141 train_error 46.75% test_error 47.50%\n",
      "================================4284===================================\n",
      "4284/10000: train_loss: 3.797921115309 train_error 46.75% test_error 47.50%\n",
      "================================4285===================================\n",
      "4285/10000: train_loss: 3.7977669722586866 train_error 46.75% test_error 47.50%\n",
      "================================4286===================================\n",
      "4286/10000: train_loss: 3.7976127472519874 train_error 46.75% test_error 47.50%\n",
      "================================4287===================================\n",
      "4287/10000: train_loss: 3.797458394318819 train_error 46.75% test_error 47.50%\n",
      "================================4288===================================\n",
      "4288/10000: train_loss: 3.797303910553455 train_error 46.75% test_error 47.50%\n",
      "================================4289===================================\n",
      "4289/10000: train_loss: 3.7971492989361284 train_error 46.75% test_error 47.50%\n",
      "================================4290===================================\n",
      "4290/10000: train_loss: 3.7969948611408473 train_error 46.75% test_error 47.50%\n",
      "================================4291===================================\n",
      "4291/10000: train_loss: 3.79684032022953 train_error 46.75% test_error 47.50%\n",
      "================================4292===================================\n",
      "4292/10000: train_loss: 3.796685693785548 train_error 46.75% test_error 47.50%\n",
      "================================4293===================================\n",
      "4293/10000: train_loss: 3.796531516239047 train_error 46.75% test_error 47.00%\n",
      "================================4294===================================\n",
      "4294/10000: train_loss: 3.796377800926566 train_error 46.75% test_error 47.00%\n",
      "================================4295===================================\n",
      "4295/10000: train_loss: 3.796223904639483 train_error 46.62% test_error 47.00%\n",
      "================================4296===================================\n",
      "4296/10000: train_loss: 3.796069866269827 train_error 46.62% test_error 47.00%\n",
      "================================4297===================================\n",
      "4297/10000: train_loss: 3.7959159322083 train_error 46.62% test_error 47.00%\n",
      "================================4298===================================\n",
      "4298/10000: train_loss: 3.795763013809919 train_error 46.62% test_error 47.00%\n",
      "================================4299===================================\n",
      "4299/10000: train_loss: 3.7956106079369785 train_error 46.62% test_error 47.00%\n",
      "================================4300===================================\n",
      "4300/10000: train_loss: 3.795458708703518 train_error 46.62% test_error 47.00%\n",
      "================================4301===================================\n",
      "4301/10000: train_loss: 3.795306729376316 train_error 46.62% test_error 47.00%\n",
      "================================4302===================================\n",
      "4302/10000: train_loss: 3.795154503658414 train_error 46.62% test_error 47.00%\n",
      "================================4303===================================\n",
      "4303/10000: train_loss: 3.795002075582743 train_error 46.62% test_error 47.00%\n",
      "================================4304===================================\n",
      "4304/10000: train_loss: 3.7948495231568815 train_error 46.62% test_error 47.00%\n",
      "================================4305===================================\n",
      "4305/10000: train_loss: 3.794697046279907 train_error 46.62% test_error 47.00%\n",
      "================================4306===================================\n",
      "4306/10000: train_loss: 3.7945453894883396 train_error 46.62% test_error 47.00%\n",
      "================================4307===================================\n",
      "4307/10000: train_loss: 3.794395097866654 train_error 46.62% test_error 47.00%\n",
      "================================4308===================================\n",
      "4308/10000: train_loss: 3.794245057180524 train_error 46.62% test_error 47.00%\n",
      "================================4309===================================\n",
      "4309/10000: train_loss: 3.794094914123416 train_error 46.62% test_error 47.00%\n",
      "================================4310===================================\n",
      "4310/10000: train_loss: 3.7939452420920134 train_error 46.62% test_error 47.00%\n",
      "================================4311===================================\n",
      "4311/10000: train_loss: 3.7937965529412034 train_error 46.62% test_error 47.00%\n",
      "================================4312===================================\n",
      "4312/10000: train_loss: 3.7936478512734175 train_error 46.62% test_error 47.00%\n",
      "================================4313===================================\n",
      "4313/10000: train_loss: 3.793499533906579 train_error 46.50% test_error 47.00%\n",
      "================================4314===================================\n",
      "4314/10000: train_loss: 3.793351720422507 train_error 46.50% test_error 47.00%\n",
      "================================4315===================================\n",
      "4315/10000: train_loss: 3.7932038442045446 train_error 46.50% test_error 47.00%\n",
      "================================4316===================================\n",
      "4316/10000: train_loss: 3.7930560228973627 train_error 46.50% test_error 47.00%\n",
      "================================4317===================================\n",
      "4317/10000: train_loss: 3.7929088059067726 train_error 46.50% test_error 47.00%\n",
      "================================4318===================================\n",
      "4318/10000: train_loss: 3.792762105688453 train_error 46.50% test_error 47.00%\n",
      "================================4319===================================\n",
      "4319/10000: train_loss: 3.7926159407943487 train_error 46.50% test_error 47.00%\n",
      "================================4320===================================\n",
      "4320/10000: train_loss: 3.792470220029354 train_error 46.50% test_error 47.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4321===================================\n",
      "4321/10000: train_loss: 3.792324458733201 train_error 46.50% test_error 47.00%\n",
      "================================4322===================================\n",
      "4322/10000: train_loss: 3.7921779498457906 train_error 46.50% test_error 47.00%\n",
      "================================4323===================================\n",
      "4323/10000: train_loss: 3.792031106799841 train_error 46.50% test_error 47.00%\n",
      "================================4324===================================\n",
      "4324/10000: train_loss: 3.7918843081593514 train_error 46.50% test_error 47.00%\n",
      "================================4325===================================\n",
      "4325/10000: train_loss: 3.791737441048026 train_error 46.50% test_error 47.00%\n",
      "================================4326===================================\n",
      "4326/10000: train_loss: 3.791590507850051 train_error 46.50% test_error 47.00%\n",
      "================================4327===================================\n",
      "4327/10000: train_loss: 3.7914441053569314 train_error 46.50% test_error 47.00%\n",
      "================================4328===================================\n",
      "4328/10000: train_loss: 3.791298093423247 train_error 46.50% test_error 47.00%\n",
      "================================4329===================================\n",
      "4329/10000: train_loss: 3.791152677759528 train_error 46.50% test_error 46.50%\n",
      "================================4330===================================\n",
      "4330/10000: train_loss: 3.791007163077593 train_error 46.38% test_error 46.50%\n",
      "================================4331===================================\n",
      "4331/10000: train_loss: 3.7908611349761485 train_error 46.12% test_error 46.50%\n",
      "================================4332===================================\n",
      "4332/10000: train_loss: 3.790714705735445 train_error 46.12% test_error 46.50%\n",
      "================================4333===================================\n",
      "4333/10000: train_loss: 3.7905680785328153 train_error 46.00% test_error 46.50%\n",
      "================================4334===================================\n",
      "4334/10000: train_loss: 3.790420881286263 train_error 46.00% test_error 46.50%\n",
      "================================4335===================================\n",
      "4335/10000: train_loss: 3.7902736429125072 train_error 46.00% test_error 46.50%\n",
      "================================4336===================================\n",
      "4336/10000: train_loss: 3.7901262634247543 train_error 46.00% test_error 46.50%\n",
      "================================4337===================================\n",
      "4337/10000: train_loss: 3.789978934600949 train_error 46.00% test_error 46.50%\n",
      "================================4338===================================\n",
      "4338/10000: train_loss: 3.789831320345402 train_error 46.00% test_error 46.50%\n",
      "================================4339===================================\n",
      "4339/10000: train_loss: 3.7896836856007576 train_error 46.00% test_error 46.50%\n",
      "================================4340===================================\n",
      "4340/10000: train_loss: 3.7895359560102224 train_error 46.00% test_error 46.50%\n",
      "================================4341===================================\n",
      "4341/10000: train_loss: 3.789388276264072 train_error 46.00% test_error 46.00%\n",
      "================================4342===================================\n",
      "4342/10000: train_loss: 3.789240671172738 train_error 46.00% test_error 46.00%\n",
      "================================4343===================================\n",
      "4343/10000: train_loss: 3.7890941771119833 train_error 46.00% test_error 46.00%\n",
      "================================4344===================================\n",
      "4344/10000: train_loss: 3.7889482374489307 train_error 46.00% test_error 46.00%\n",
      "================================4345===================================\n",
      "4345/10000: train_loss: 3.7888022898137574 train_error 46.00% test_error 46.00%\n",
      "================================4346===================================\n",
      "4346/10000: train_loss: 3.7886563006043437 train_error 46.00% test_error 46.00%\n",
      "================================4347===================================\n",
      "4347/10000: train_loss: 3.788511095196009 train_error 45.88% test_error 46.00%\n",
      "================================4348===================================\n",
      "4348/10000: train_loss: 3.788366169631481 train_error 45.88% test_error 46.00%\n",
      "================================4349===================================\n",
      "4349/10000: train_loss: 3.78822105973959 train_error 45.88% test_error 46.00%\n",
      "================================4350===================================\n",
      "4350/10000: train_loss: 3.788076408654451 train_error 45.88% test_error 46.00%\n",
      "================================4351===================================\n",
      "4351/10000: train_loss: 3.7879318793118 train_error 45.88% test_error 45.50%\n",
      "================================4352===================================\n",
      "4352/10000: train_loss: 3.787787338942289 train_error 45.88% test_error 45.50%\n",
      "================================4353===================================\n",
      "4353/10000: train_loss: 3.7876432017236947 train_error 45.88% test_error 45.50%\n",
      "================================4354===================================\n",
      "4354/10000: train_loss: 3.787499200180173 train_error 45.88% test_error 45.50%\n",
      "================================4355===================================\n",
      "4355/10000: train_loss: 3.78735514074564 train_error 45.88% test_error 45.50%\n",
      "================================4356===================================\n",
      "4356/10000: train_loss: 3.7872110303491353 train_error 45.88% test_error 45.50%\n",
      "================================4357===================================\n",
      "4357/10000: train_loss: 3.7870669683814047 train_error 45.88% test_error 45.50%\n",
      "================================4358===================================\n",
      "4358/10000: train_loss: 3.7869229379296305 train_error 45.88% test_error 45.50%\n",
      "================================4359===================================\n",
      "4359/10000: train_loss: 3.7867787975817917 train_error 45.88% test_error 45.50%\n",
      "================================4360===================================\n",
      "4360/10000: train_loss: 3.7866347797214988 train_error 45.88% test_error 45.50%\n",
      "================================4361===================================\n",
      "4361/10000: train_loss: 3.7864908738434315 train_error 45.88% test_error 45.50%\n",
      "================================4362===================================\n",
      "4362/10000: train_loss: 3.786347023919225 train_error 45.88% test_error 45.50%\n",
      "================================4363===================================\n",
      "4363/10000: train_loss: 3.786203071251512 train_error 45.88% test_error 45.50%\n",
      "================================4364===================================\n",
      "4364/10000: train_loss: 3.7860589776933193 train_error 45.88% test_error 45.50%\n",
      "================================4365===================================\n",
      "4365/10000: train_loss: 3.785914725512266 train_error 45.88% test_error 45.50%\n",
      "================================4366===================================\n",
      "4366/10000: train_loss: 3.7857704024761913 train_error 45.88% test_error 45.50%\n",
      "================================4367===================================\n",
      "4367/10000: train_loss: 3.785626065954566 train_error 45.88% test_error 45.50%\n",
      "================================4368===================================\n",
      "4368/10000: train_loss: 3.7854817130416634 train_error 45.88% test_error 45.50%\n",
      "================================4369===================================\n",
      "4369/10000: train_loss: 3.785337376967073 train_error 45.88% test_error 45.50%\n",
      "================================4370===================================\n",
      "4370/10000: train_loss: 3.7851928375661372 train_error 45.88% test_error 45.50%\n",
      "================================4371===================================\n",
      "4371/10000: train_loss: 3.7850487262010577 train_error 45.88% test_error 45.50%\n",
      "================================4372===================================\n",
      "4372/10000: train_loss: 3.7849047722667453 train_error 45.88% test_error 45.50%\n",
      "================================4373===================================\n",
      "4373/10000: train_loss: 3.784760389775038 train_error 45.88% test_error 45.50%\n",
      "================================4374===================================\n",
      "4374/10000: train_loss: 3.7846159529685974 train_error 45.88% test_error 45.50%\n",
      "================================4375===================================\n",
      "4375/10000: train_loss: 3.78447098441422 train_error 46.00% test_error 45.50%\n",
      "================================4376===================================\n",
      "4376/10000: train_loss: 3.7843259992450475 train_error 46.00% test_error 45.50%\n",
      "================================4377===================================\n",
      "4377/10000: train_loss: 3.7841810616105795 train_error 46.00% test_error 45.50%\n",
      "================================4378===================================\n",
      "4378/10000: train_loss: 3.7840361239016054 train_error 46.00% test_error 45.50%\n",
      "================================4379===================================\n",
      "4379/10000: train_loss: 3.78389143191278 train_error 46.00% test_error 45.50%\n",
      "================================4380===================================\n",
      "4380/10000: train_loss: 3.7837474272400136 train_error 46.00% test_error 45.50%\n",
      "================================4381===================================\n",
      "4381/10000: train_loss: 3.78360386826098 train_error 45.88% test_error 45.50%\n",
      "================================4382===================================\n",
      "4382/10000: train_loss: 3.783461314663291 train_error 45.88% test_error 45.50%\n",
      "================================4383===================================\n",
      "4383/10000: train_loss: 3.783318988755345 train_error 45.88% test_error 45.50%\n",
      "================================4384===================================\n",
      "4384/10000: train_loss: 3.783177476450801 train_error 45.88% test_error 45.50%\n",
      "================================4385===================================\n",
      "4385/10000: train_loss: 3.7830359251797203 train_error 45.88% test_error 45.50%\n",
      "================================4386===================================\n",
      "4386/10000: train_loss: 3.7828950477391485 train_error 45.88% test_error 45.50%\n",
      "================================4387===================================\n",
      "4387/10000: train_loss: 3.7827546765655278 train_error 45.88% test_error 45.50%\n",
      "================================4388===================================\n",
      "4388/10000: train_loss: 3.7826142202317716 train_error 45.88% test_error 45.50%\n",
      "================================4389===================================\n",
      "4389/10000: train_loss: 3.7824737078696486 train_error 45.88% test_error 45.50%\n",
      "================================4390===================================\n",
      "4390/10000: train_loss: 3.782333156466484 train_error 45.88% test_error 45.50%\n",
      "================================4391===================================\n",
      "4391/10000: train_loss: 3.782192653939128 train_error 45.88% test_error 45.50%\n",
      "================================4392===================================\n",
      "4392/10000: train_loss: 3.7820525790750983 train_error 45.88% test_error 45.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4393===================================\n",
      "4393/10000: train_loss: 3.7819126918911934 train_error 45.88% test_error 45.50%\n",
      "================================4394===================================\n",
      "4394/10000: train_loss: 3.7817727445065974 train_error 45.88% test_error 45.50%\n",
      "================================4395===================================\n",
      "4395/10000: train_loss: 3.781632805392146 train_error 45.88% test_error 45.50%\n",
      "================================4396===================================\n",
      "4396/10000: train_loss: 3.7814930127561093 train_error 45.88% test_error 45.50%\n",
      "================================4397===================================\n",
      "4397/10000: train_loss: 3.781353101283312 train_error 45.88% test_error 45.50%\n",
      "================================4398===================================\n",
      "4398/10000: train_loss: 3.7812138375639917 train_error 45.88% test_error 45.50%\n",
      "================================4399===================================\n",
      "4399/10000: train_loss: 3.7810751793533566 train_error 45.88% test_error 45.50%\n",
      "================================4400===================================\n",
      "4400/10000: train_loss: 3.780937365964055 train_error 45.75% test_error 45.50%\n",
      "================================4401===================================\n",
      "4401/10000: train_loss: 3.780799988657236 train_error 45.75% test_error 45.50%\n",
      "================================4402===================================\n",
      "4402/10000: train_loss: 3.780663202702999 train_error 45.75% test_error 45.50%\n",
      "================================4403===================================\n",
      "4403/10000: train_loss: 3.780525721609593 train_error 45.75% test_error 45.50%\n",
      "================================4404===================================\n",
      "4404/10000: train_loss: 3.7803880394995213 train_error 45.75% test_error 45.50%\n",
      "================================4405===================================\n",
      "4405/10000: train_loss: 3.780250135064125 train_error 45.75% test_error 45.50%\n",
      "================================4406===================================\n",
      "4406/10000: train_loss: 3.7801122253388164 train_error 45.62% test_error 45.50%\n",
      "================================4407===================================\n",
      "4407/10000: train_loss: 3.7799744847416874 train_error 45.62% test_error 45.50%\n",
      "================================4408===================================\n",
      "4408/10000: train_loss: 3.7798367738723755 train_error 45.62% test_error 45.50%\n",
      "================================4409===================================\n",
      "4409/10000: train_loss: 3.7796991419792176 train_error 45.62% test_error 45.50%\n",
      "================================4410===================================\n",
      "4410/10000: train_loss: 3.77956160351634 train_error 45.62% test_error 45.50%\n",
      "================================4411===================================\n",
      "4411/10000: train_loss: 3.7794241181761024 train_error 45.62% test_error 45.50%\n",
      "================================4412===================================\n",
      "4412/10000: train_loss: 3.7792868885397914 train_error 45.50% test_error 45.50%\n",
      "================================4413===================================\n",
      "4413/10000: train_loss: 3.7791495433449747 train_error 45.50% test_error 45.50%\n",
      "================================4414===================================\n",
      "4414/10000: train_loss: 3.7790127517282963 train_error 45.50% test_error 45.50%\n",
      "================================4415===================================\n",
      "4415/10000: train_loss: 3.7788766451925038 train_error 45.50% test_error 45.50%\n",
      "================================4416===================================\n",
      "4416/10000: train_loss: 3.778740273192525 train_error 45.50% test_error 45.50%\n",
      "================================4417===================================\n",
      "4417/10000: train_loss: 3.778604183122516 train_error 45.50% test_error 45.50%\n",
      "================================4418===================================\n",
      "4418/10000: train_loss: 3.778469337373972 train_error 45.50% test_error 45.50%\n",
      "================================4419===================================\n",
      "4419/10000: train_loss: 3.778334612175822 train_error 45.50% test_error 45.50%\n",
      "================================4420===================================\n",
      "4420/10000: train_loss: 3.7781998521834614 train_error 45.50% test_error 45.50%\n",
      "================================4421===================================\n",
      "4421/10000: train_loss: 3.7780651842057704 train_error 45.50% test_error 45.50%\n",
      "================================4422===================================\n",
      "4422/10000: train_loss: 3.7779307102411983 train_error 45.50% test_error 45.50%\n",
      "================================4423===================================\n",
      "4423/10000: train_loss: 3.777797151654959 train_error 45.50% test_error 45.50%\n",
      "================================4424===================================\n",
      "4424/10000: train_loss: 3.777664140686393 train_error 45.50% test_error 45.50%\n",
      "================================4425===================================\n",
      "4425/10000: train_loss: 3.777531823962927 train_error 45.50% test_error 45.50%\n",
      "================================4426===================================\n",
      "4426/10000: train_loss: 3.7773998010903593 train_error 45.50% test_error 45.50%\n",
      "================================4427===================================\n",
      "4427/10000: train_loss: 3.7772677820175886 train_error 45.50% test_error 45.50%\n",
      "================================4428===================================\n",
      "4428/10000: train_loss: 3.7771356717497113 train_error 45.50% test_error 45.50%\n",
      "================================4429===================================\n",
      "4429/10000: train_loss: 3.777003118470311 train_error 45.62% test_error 45.50%\n",
      "================================4430===================================\n",
      "4430/10000: train_loss: 3.7768705673515797 train_error 45.50% test_error 45.50%\n",
      "================================4431===================================\n",
      "4431/10000: train_loss: 3.776738987565041 train_error 45.50% test_error 45.50%\n",
      "================================4432===================================\n",
      "4432/10000: train_loss: 3.7766074644029137 train_error 45.50% test_error 45.00%\n",
      "================================4433===================================\n",
      "4433/10000: train_loss: 3.7764771839976308 train_error 45.50% test_error 45.00%\n",
      "================================4434===================================\n",
      "4434/10000: train_loss: 3.776346913352609 train_error 45.50% test_error 45.00%\n",
      "================================4435===================================\n",
      "4435/10000: train_loss: 3.7762167810648677 train_error 45.50% test_error 45.00%\n",
      "================================4436===================================\n",
      "4436/10000: train_loss: 3.7760869027674193 train_error 45.50% test_error 45.00%\n",
      "================================4437===================================\n",
      "4437/10000: train_loss: 3.7759566612541677 train_error 45.50% test_error 45.00%\n",
      "================================4438===================================\n",
      "4438/10000: train_loss: 3.7758262617886063 train_error 45.50% test_error 45.00%\n",
      "================================4439===================================\n",
      "4439/10000: train_loss: 3.775696106776595 train_error 45.50% test_error 45.00%\n",
      "================================4440===================================\n",
      "4440/10000: train_loss: 3.775566283985973 train_error 45.50% test_error 45.00%\n",
      "================================4441===================================\n",
      "4441/10000: train_loss: 3.775437060818076 train_error 45.50% test_error 45.00%\n",
      "================================4442===================================\n",
      "4442/10000: train_loss: 3.7753081131726502 train_error 45.50% test_error 45.00%\n",
      "================================4443===================================\n",
      "4443/10000: train_loss: 3.7751791715621947 train_error 45.50% test_error 45.00%\n",
      "================================4444===================================\n",
      "4444/10000: train_loss: 3.7750509940832857 train_error 45.50% test_error 45.00%\n",
      "================================4445===================================\n",
      "4445/10000: train_loss: 3.77492290943861 train_error 45.50% test_error 45.00%\n",
      "================================4446===================================\n",
      "4446/10000: train_loss: 3.774794739857316 train_error 45.50% test_error 45.00%\n",
      "================================4447===================================\n",
      "4447/10000: train_loss: 3.774666316360235 train_error 45.50% test_error 45.00%\n",
      "================================4448===================================\n",
      "4448/10000: train_loss: 3.7745378047227858 train_error 45.38% test_error 45.00%\n",
      "================================4449===================================\n",
      "4449/10000: train_loss: 3.774409260526299 train_error 45.38% test_error 45.00%\n",
      "================================4450===================================\n",
      "4450/10000: train_loss: 3.7742806346714497 train_error 45.38% test_error 45.00%\n",
      "================================4451===================================\n",
      "4451/10000: train_loss: 3.7741521480679516 train_error 45.38% test_error 45.00%\n",
      "================================4452===================================\n",
      "4452/10000: train_loss: 3.7740245953947307 train_error 45.38% test_error 45.00%\n",
      "================================4453===================================\n",
      "4453/10000: train_loss: 3.7738980941474436 train_error 45.38% test_error 45.00%\n",
      "================================4454===================================\n",
      "4454/10000: train_loss: 3.7737718531489373 train_error 45.38% test_error 45.00%\n",
      "================================4455===================================\n",
      "4455/10000: train_loss: 3.773645602911711 train_error 45.38% test_error 45.00%\n",
      "================================4456===================================\n",
      "4456/10000: train_loss: 3.773519237861037 train_error 45.38% test_error 45.00%\n",
      "================================4457===================================\n",
      "4457/10000: train_loss: 3.7733927597105503 train_error 45.38% test_error 45.00%\n",
      "================================4458===================================\n",
      "4458/10000: train_loss: 3.7732667734473946 train_error 45.38% test_error 45.00%\n",
      "================================4459===================================\n",
      "4459/10000: train_loss: 3.773141385987401 train_error 45.38% test_error 45.00%\n",
      "================================4460===================================\n",
      "4460/10000: train_loss: 3.773016063421965 train_error 45.38% test_error 45.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4461===================================\n",
      "4461/10000: train_loss: 3.772890582233668 train_error 45.38% test_error 45.00%\n",
      "================================4462===================================\n",
      "4462/10000: train_loss: 3.7727651466429233 train_error 45.25% test_error 45.00%\n",
      "================================4463===================================\n",
      "4463/10000: train_loss: 3.772639657407999 train_error 45.38% test_error 45.00%\n",
      "================================4464===================================\n",
      "4464/10000: train_loss: 3.7725139842927455 train_error 45.38% test_error 45.00%\n",
      "================================4465===================================\n",
      "4465/10000: train_loss: 3.7723887185752396 train_error 45.38% test_error 45.00%\n",
      "================================4466===================================\n",
      "4466/10000: train_loss: 3.772263753041625 train_error 45.38% test_error 45.00%\n",
      "================================4467===================================\n",
      "4467/10000: train_loss: 3.7721387914568187 train_error 45.50% test_error 45.00%\n",
      "================================4468===================================\n",
      "4468/10000: train_loss: 3.772013827264309 train_error 45.50% test_error 45.00%\n",
      "================================4469===================================\n",
      "4469/10000: train_loss: 3.7718888383358715 train_error 45.50% test_error 45.00%\n",
      "================================4470===================================\n",
      "4470/10000: train_loss: 3.7717639242857697 train_error 45.50% test_error 45.00%\n",
      "================================4471===================================\n",
      "4471/10000: train_loss: 3.771639306619763 train_error 45.50% test_error 45.00%\n",
      "================================4472===================================\n",
      "4472/10000: train_loss: 3.771514650136232 train_error 45.50% test_error 45.00%\n",
      "================================4473===================================\n",
      "4473/10000: train_loss: 3.771389756500721 train_error 45.50% test_error 45.00%\n",
      "================================4474===================================\n",
      "4474/10000: train_loss: 3.771265108510852 train_error 45.50% test_error 45.00%\n",
      "================================4475===================================\n",
      "4475/10000: train_loss: 3.7711404801905153 train_error 45.50% test_error 45.00%\n",
      "================================4476===================================\n",
      "4476/10000: train_loss: 3.771015962958336 train_error 45.50% test_error 45.00%\n",
      "================================4477===================================\n",
      "4477/10000: train_loss: 3.7708914119005206 train_error 45.50% test_error 45.00%\n",
      "================================4478===================================\n",
      "4478/10000: train_loss: 3.770766835808754 train_error 45.50% test_error 45.00%\n",
      "================================4479===================================\n",
      "4479/10000: train_loss: 3.770641858652234 train_error 45.50% test_error 45.00%\n",
      "================================4480===================================\n",
      "4480/10000: train_loss: 3.7705173393338915 train_error 45.50% test_error 45.00%\n",
      "================================4481===================================\n",
      "4481/10000: train_loss: 3.7703926998376844 train_error 45.50% test_error 45.00%\n",
      "================================4482===================================\n",
      "4482/10000: train_loss: 3.770268046706915 train_error 45.50% test_error 45.00%\n",
      "================================4483===================================\n",
      "4483/10000: train_loss: 3.770143146067858 train_error 45.50% test_error 45.00%\n",
      "================================4484===================================\n",
      "4484/10000: train_loss: 3.770018946677446 train_error 45.50% test_error 45.00%\n",
      "================================4485===================================\n",
      "4485/10000: train_loss: 3.7698945986479524 train_error 45.50% test_error 45.00%\n",
      "================================4486===================================\n",
      "4486/10000: train_loss: 3.769770686104894 train_error 45.50% test_error 45.00%\n",
      "================================4487===================================\n",
      "4487/10000: train_loss: 3.769647039398551 train_error 45.50% test_error 45.00%\n",
      "================================4488===================================\n",
      "4488/10000: train_loss: 3.7695236434042454 train_error 45.50% test_error 45.00%\n",
      "================================4489===================================\n",
      "4489/10000: train_loss: 3.769400228410959 train_error 45.50% test_error 45.00%\n",
      "================================4490===================================\n",
      "4490/10000: train_loss: 3.76927664346993 train_error 45.50% test_error 45.00%\n",
      "================================4491===================================\n",
      "4491/10000: train_loss: 3.7691525962948798 train_error 45.50% test_error 45.00%\n",
      "================================4492===================================\n",
      "4492/10000: train_loss: 3.769028672426939 train_error 45.50% test_error 45.00%\n",
      "================================4493===================================\n",
      "4493/10000: train_loss: 3.7689048346877096 train_error 45.50% test_error 45.00%\n",
      "================================4494===================================\n",
      "4494/10000: train_loss: 3.768781132847071 train_error 45.50% test_error 45.00%\n",
      "================================4495===================================\n",
      "4495/10000: train_loss: 3.768657268732786 train_error 45.38% test_error 45.00%\n",
      "================================4496===================================\n",
      "4496/10000: train_loss: 3.7685331884026523 train_error 45.38% test_error 45.00%\n",
      "================================4497===================================\n",
      "4497/10000: train_loss: 3.768409364372492 train_error 45.50% test_error 45.00%\n",
      "================================4498===================================\n",
      "4498/10000: train_loss: 3.7682857368886475 train_error 45.50% test_error 45.00%\n",
      "================================4499===================================\n",
      "4499/10000: train_loss: 3.768162312209606 train_error 45.50% test_error 45.00%\n",
      "================================4500===================================\n",
      "4500/10000: train_loss: 3.7680390685796734 train_error 45.50% test_error 45.00%\n",
      "================================4501===================================\n",
      "4501/10000: train_loss: 3.7679158333688973 train_error 45.50% test_error 45.00%\n",
      "================================4502===================================\n",
      "4502/10000: train_loss: 3.767792952135205 train_error 45.50% test_error 45.00%\n",
      "================================4503===================================\n",
      "4503/10000: train_loss: 3.767670697718859 train_error 45.50% test_error 45.00%\n",
      "================================4504===================================\n",
      "4504/10000: train_loss: 3.7675484766811134 train_error 45.50% test_error 44.50%\n",
      "================================4505===================================\n",
      "4505/10000: train_loss: 3.767426260560751 train_error 45.50% test_error 44.50%\n",
      "================================4506===================================\n",
      "4506/10000: train_loss: 3.7673040047287945 train_error 45.50% test_error 44.50%\n",
      "================================4507===================================\n",
      "4507/10000: train_loss: 3.7671817354112864 train_error 45.50% test_error 44.50%\n",
      "================================4508===================================\n",
      "4508/10000: train_loss: 3.7670593626797197 train_error 45.50% test_error 44.50%\n",
      "================================4509===================================\n",
      "4509/10000: train_loss: 3.7669369853287935 train_error 45.50% test_error 44.50%\n",
      "================================4510===================================\n",
      "4510/10000: train_loss: 3.766814292222261 train_error 45.50% test_error 44.50%\n",
      "================================4511===================================\n",
      "4511/10000: train_loss: 3.7666918598115444 train_error 45.50% test_error 44.50%\n",
      "================================4512===================================\n",
      "4512/10000: train_loss: 3.7665693525969983 train_error 45.50% test_error 44.50%\n",
      "================================4513===================================\n",
      "4513/10000: train_loss: 3.7664471142739058 train_error 45.50% test_error 44.50%\n",
      "================================4514===================================\n",
      "4514/10000: train_loss: 3.766324910223484 train_error 45.62% test_error 44.50%\n",
      "================================4515===================================\n",
      "4515/10000: train_loss: 3.7662028908729557 train_error 45.62% test_error 44.50%\n",
      "================================4516===================================\n",
      "4516/10000: train_loss: 3.7660817793011665 train_error 45.62% test_error 44.50%\n",
      "================================4517===================================\n",
      "4517/10000: train_loss: 3.7659608033299445 train_error 45.62% test_error 44.50%\n",
      "================================4518===================================\n",
      "4518/10000: train_loss: 3.76584003187716 train_error 45.75% test_error 44.50%\n",
      "================================4519===================================\n",
      "4519/10000: train_loss: 3.765719275996089 train_error 45.75% test_error 44.50%\n",
      "================================4520===================================\n",
      "4520/10000: train_loss: 3.765598561316729 train_error 45.75% test_error 44.50%\n",
      "================================4521===================================\n",
      "4521/10000: train_loss: 3.7654781097173693 train_error 45.75% test_error 44.50%\n",
      "================================4522===================================\n",
      "4522/10000: train_loss: 3.765357825830579 train_error 45.75% test_error 44.50%\n",
      "================================4523===================================\n",
      "4523/10000: train_loss: 3.765237416177988 train_error 45.75% test_error 44.50%\n",
      "================================4524===================================\n",
      "4524/10000: train_loss: 3.765117053687572 train_error 45.75% test_error 44.50%\n",
      "================================4525===================================\n",
      "4525/10000: train_loss: 3.764996984899044 train_error 45.75% test_error 44.50%\n",
      "================================4526===================================\n",
      "4526/10000: train_loss: 3.7648770122230055 train_error 45.75% test_error 44.50%\n",
      "================================4527===================================\n",
      "4527/10000: train_loss: 3.7647570528089997 train_error 45.75% test_error 44.50%\n",
      "================================4528===================================\n",
      "4528/10000: train_loss: 3.7646370874345303 train_error 45.75% test_error 44.50%\n",
      "================================4529===================================\n",
      "4529/10000: train_loss: 3.7645174600183964 train_error 45.75% test_error 44.50%\n",
      "================================4530===================================\n",
      "4530/10000: train_loss: 3.7643990982323885 train_error 45.75% test_error 44.50%\n",
      "================================4531===================================\n",
      "4531/10000: train_loss: 3.764281231537461 train_error 45.75% test_error 44.50%\n",
      "================================4532===================================\n",
      "4532/10000: train_loss: 3.764163144379854 train_error 45.62% test_error 44.50%\n",
      "================================4533===================================\n",
      "4533/10000: train_loss: 3.764044646397233 train_error 45.62% test_error 44.50%\n",
      "================================4534===================================\n",
      "4534/10000: train_loss: 3.763926094993949 train_error 45.62% test_error 44.00%\n",
      "================================4535===================================\n",
      "4535/10000: train_loss: 3.763807830065489 train_error 45.62% test_error 44.00%\n",
      "================================4536===================================\n",
      "4536/10000: train_loss: 3.7636902472376823 train_error 45.62% test_error 44.00%\n",
      "================================4537===================================\n",
      "4537/10000: train_loss: 3.7635726340115068 train_error 45.62% test_error 44.00%\n",
      "================================4538===================================\n",
      "4538/10000: train_loss: 3.7634551136195658 train_error 45.75% test_error 44.00%\n",
      "================================4539===================================\n",
      "4539/10000: train_loss: 3.76333770044148 train_error 45.75% test_error 44.00%\n",
      "================================4540===================================\n",
      "4540/10000: train_loss: 3.7632203594595195 train_error 45.75% test_error 44.00%\n",
      "================================4541===================================\n",
      "4541/10000: train_loss: 3.763102805092931 train_error 45.75% test_error 44.00%\n",
      "================================4542===================================\n",
      "4542/10000: train_loss: 3.762984981909394 train_error 45.75% test_error 44.00%\n",
      "================================4543===================================\n",
      "4543/10000: train_loss: 3.762867220789194 train_error 45.75% test_error 44.00%\n",
      "================================4544===================================\n",
      "4544/10000: train_loss: 3.7627494559437036 train_error 45.75% test_error 44.00%\n",
      "================================4545===================================\n",
      "4545/10000: train_loss: 3.7626315134018657 train_error 45.75% test_error 44.00%\n",
      "================================4546===================================\n",
      "4546/10000: train_loss: 3.762513394653797 train_error 45.75% test_error 44.00%\n",
      "================================4547===================================\n",
      "4547/10000: train_loss: 3.7623953399062158 train_error 45.75% test_error 44.00%\n",
      "================================4548===================================\n",
      "4548/10000: train_loss: 3.7622775816172362 train_error 45.75% test_error 44.00%\n",
      "================================4549===================================\n",
      "4549/10000: train_loss: 3.762159694880247 train_error 45.75% test_error 44.00%\n",
      "================================4550===================================\n",
      "4550/10000: train_loss: 3.762041919231415 train_error 45.75% test_error 44.00%\n",
      "================================4551===================================\n",
      "4551/10000: train_loss: 3.7619241039454936 train_error 45.75% test_error 44.00%\n",
      "================================4552===================================\n",
      "4552/10000: train_loss: 3.7618069728463888 train_error 45.75% test_error 44.00%\n",
      "================================4553===================================\n",
      "4553/10000: train_loss: 3.7616901725530627 train_error 45.75% test_error 44.00%\n",
      "================================4554===================================\n",
      "4554/10000: train_loss: 3.7615731884539128 train_error 45.75% test_error 44.00%\n",
      "================================4555===================================\n",
      "4555/10000: train_loss: 3.7614569563418625 train_error 45.75% test_error 44.00%\n",
      "================================4556===================================\n",
      "4556/10000: train_loss: 3.7613406855612994 train_error 45.75% test_error 44.00%\n",
      "================================4557===================================\n",
      "4557/10000: train_loss: 3.7612243394553664 train_error 45.75% test_error 44.00%\n",
      "================================4558===================================\n",
      "4558/10000: train_loss: 3.7611080015450713 train_error 45.75% test_error 44.00%\n",
      "================================4559===================================\n",
      "4559/10000: train_loss: 3.7609912530332803 train_error 45.75% test_error 44.00%\n",
      "================================4560===================================\n",
      "4560/10000: train_loss: 3.7608741277456286 train_error 45.75% test_error 44.00%\n",
      "================================4561===================================\n",
      "4561/10000: train_loss: 3.7607569532096385 train_error 45.62% test_error 44.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4562===================================\n",
      "4562/10000: train_loss: 3.760639751777053 train_error 45.62% test_error 44.00%\n",
      "================================4563===================================\n",
      "4563/10000: train_loss: 3.760522488579154 train_error 45.62% test_error 44.00%\n",
      "================================4564===================================\n",
      "4564/10000: train_loss: 3.7604052324593065 train_error 45.62% test_error 44.00%\n",
      "================================4565===================================\n",
      "4565/10000: train_loss: 3.76028800047934 train_error 45.62% test_error 44.00%\n",
      "================================4566===================================\n",
      "4566/10000: train_loss: 3.760170677825809 train_error 45.62% test_error 44.00%\n",
      "================================4567===================================\n",
      "4567/10000: train_loss: 3.7600532872974872 train_error 45.62% test_error 43.50%\n",
      "================================4568===================================\n",
      "4568/10000: train_loss: 3.7599359270930286 train_error 45.50% test_error 43.50%\n",
      "================================4569===================================\n",
      "4569/10000: train_loss: 3.759818838313222 train_error 45.50% test_error 43.50%\n",
      "================================4570===================================\n",
      "4570/10000: train_loss: 3.759703058376908 train_error 45.50% test_error 43.50%\n",
      "================================4571===================================\n",
      "4571/10000: train_loss: 3.7595872639119627 train_error 45.50% test_error 43.50%\n",
      "================================4572===================================\n",
      "4572/10000: train_loss: 3.759472745805979 train_error 45.50% test_error 43.50%\n",
      "================================4573===================================\n",
      "4573/10000: train_loss: 3.7593595054000613 train_error 45.50% test_error 43.50%\n",
      "================================4574===================================\n",
      "4574/10000: train_loss: 3.7592465533316135 train_error 45.50% test_error 43.50%\n",
      "================================4575===================================\n",
      "4575/10000: train_loss: 3.759133558943868 train_error 45.50% test_error 43.50%\n",
      "================================4576===================================\n",
      "4576/10000: train_loss: 3.7590213933587076 train_error 45.50% test_error 43.50%\n",
      "================================4577===================================\n",
      "4577/10000: train_loss: 3.758909540474415 train_error 45.50% test_error 43.00%\n",
      "================================4578===================================\n",
      "4578/10000: train_loss: 3.7587972915917636 train_error 45.50% test_error 43.00%\n",
      "================================4579===================================\n",
      "4579/10000: train_loss: 3.7586850963532923 train_error 45.50% test_error 43.00%\n",
      "================================4580===================================\n",
      "4580/10000: train_loss: 3.7585731505602595 train_error 45.50% test_error 43.00%\n",
      "================================4581===================================\n",
      "4581/10000: train_loss: 3.758460980430245 train_error 45.50% test_error 43.00%\n",
      "================================4582===================================\n",
      "4582/10000: train_loss: 3.758348582908511 train_error 45.50% test_error 43.00%\n",
      "================================4583===================================\n",
      "4583/10000: train_loss: 3.7582362294197083 train_error 45.50% test_error 43.00%\n",
      "================================4584===================================\n",
      "4584/10000: train_loss: 3.7581238298118116 train_error 45.50% test_error 43.00%\n",
      "================================4585===================================\n",
      "4585/10000: train_loss: 3.7580115988850595 train_error 45.50% test_error 43.00%\n",
      "================================4586===================================\n",
      "4586/10000: train_loss: 3.757899633720517 train_error 45.38% test_error 43.00%\n",
      "================================4587===================================\n",
      "4587/10000: train_loss: 3.7577876461297275 train_error 45.38% test_error 43.00%\n",
      "================================4588===================================\n",
      "4588/10000: train_loss: 3.7576758111268282 train_error 45.38% test_error 43.00%\n",
      "================================4589===================================\n",
      "4589/10000: train_loss: 3.757564186826348 train_error 45.38% test_error 43.00%\n",
      "================================4590===================================\n",
      "4590/10000: train_loss: 3.757452592626214 train_error 45.38% test_error 43.00%\n",
      "================================4591===================================\n",
      "4591/10000: train_loss: 3.7573411663621665 train_error 45.38% test_error 43.00%\n",
      "================================4592===================================\n",
      "4592/10000: train_loss: 3.7572295229882005 train_error 45.25% test_error 43.00%\n",
      "================================4593===================================\n",
      "4593/10000: train_loss: 3.7571179561316965 train_error 45.25% test_error 43.00%\n",
      "================================4594===================================\n",
      "4594/10000: train_loss: 3.757006310671568 train_error 45.25% test_error 43.00%\n",
      "================================4595===================================\n",
      "4595/10000: train_loss: 3.756894503757357 train_error 45.25% test_error 43.00%\n",
      "================================4596===================================\n",
      "4596/10000: train_loss: 3.7567824993282555 train_error 45.25% test_error 43.00%\n",
      "================================4597===================================\n",
      "4597/10000: train_loss: 3.7566710751503702 train_error 45.25% test_error 43.00%\n",
      "================================4598===================================\n",
      "4598/10000: train_loss: 3.756559754759073 train_error 45.25% test_error 43.00%\n",
      "================================4599===================================\n",
      "4599/10000: train_loss: 3.7564484427124265 train_error 45.25% test_error 43.00%\n",
      "================================4600===================================\n",
      "4600/10000: train_loss: 3.7563369750231503 train_error 45.25% test_error 43.00%\n",
      "================================4601===================================\n",
      "4601/10000: train_loss: 3.7562249845266344 train_error 45.25% test_error 43.00%\n",
      "================================4602===================================\n",
      "4602/10000: train_loss: 3.75611299097538 train_error 45.25% test_error 43.00%\n",
      "================================4603===================================\n",
      "4603/10000: train_loss: 3.756000896170735 train_error 45.25% test_error 43.00%\n",
      "================================4604===================================\n",
      "4604/10000: train_loss: 3.755888528674841 train_error 45.25% test_error 43.00%\n",
      "================================4605===================================\n",
      "4605/10000: train_loss: 3.7557765312492846 train_error 45.25% test_error 43.00%\n",
      "================================4606===================================\n",
      "4606/10000: train_loss: 3.755664900913835 train_error 45.25% test_error 43.00%\n",
      "================================4607===================================\n",
      "4607/10000: train_loss: 3.7555532156676055 train_error 45.25% test_error 43.00%\n",
      "================================4608===================================\n",
      "4608/10000: train_loss: 3.7554416272044184 train_error 45.25% test_error 43.00%\n",
      "================================4609===================================\n",
      "4609/10000: train_loss: 3.7553302624821665 train_error 45.25% test_error 43.00%\n",
      "================================4610===================================\n",
      "4610/10000: train_loss: 3.755218841060996 train_error 45.25% test_error 43.00%\n",
      "================================4611===================================\n",
      "4611/10000: train_loss: 3.755107568800449 train_error 45.25% test_error 43.00%\n",
      "================================4612===================================\n",
      "4612/10000: train_loss: 3.754996377825737 train_error 45.25% test_error 43.00%\n",
      "================================4613===================================\n",
      "4613/10000: train_loss: 3.754885095283389 train_error 45.25% test_error 43.00%\n",
      "================================4614===================================\n",
      "4614/10000: train_loss: 3.7547737830877304 train_error 45.25% test_error 43.00%\n",
      "================================4615===================================\n",
      "4615/10000: train_loss: 3.7546624413132665 train_error 45.25% test_error 43.00%\n",
      "================================4616===================================\n",
      "4616/10000: train_loss: 3.754551189467311 train_error 45.25% test_error 43.00%\n",
      "================================4617===================================\n",
      "4617/10000: train_loss: 3.754439951181412 train_error 45.25% test_error 43.00%\n",
      "================================4618===================================\n",
      "4618/10000: train_loss: 3.7543286201357846 train_error 45.25% test_error 43.00%\n",
      "================================4619===================================\n",
      "4619/10000: train_loss: 3.7542172574251893 train_error 45.25% test_error 43.00%\n",
      "================================4620===================================\n",
      "4620/10000: train_loss: 3.754105761498213 train_error 45.25% test_error 43.00%\n",
      "================================4621===================================\n",
      "4621/10000: train_loss: 3.7539938193559648 train_error 45.25% test_error 43.00%\n",
      "================================4622===================================\n",
      "4622/10000: train_loss: 3.7538816553354266 train_error 45.25% test_error 43.00%\n",
      "================================4623===================================\n",
      "4623/10000: train_loss: 3.7537695494294168 train_error 45.25% test_error 43.00%\n",
      "================================4624===================================\n",
      "4624/10000: train_loss: 3.75365748077631 train_error 45.25% test_error 43.00%\n",
      "================================4625===================================\n",
      "4625/10000: train_loss: 3.7535455078631634 train_error 45.25% test_error 43.00%\n",
      "================================4626===================================\n",
      "4626/10000: train_loss: 3.753434020727873 train_error 45.25% test_error 43.00%\n",
      "================================4627===================================\n",
      "4627/10000: train_loss: 3.7533228807151318 train_error 45.25% test_error 43.00%\n",
      "================================4628===================================\n",
      "4628/10000: train_loss: 3.753211787417531 train_error 45.25% test_error 43.00%\n",
      "================================4629===================================\n",
      "4629/10000: train_loss: 3.7530995082110166 train_error 45.25% test_error 43.00%\n",
      "================================4630===================================\n",
      "4630/10000: train_loss: 3.7529872814565897 train_error 45.25% test_error 43.00%\n",
      "================================4631===================================\n",
      "4631/10000: train_loss: 3.7528750717639925 train_error 45.25% test_error 43.00%\n",
      "================================4632===================================\n",
      "4632/10000: train_loss: 3.752763017863035 train_error 45.25% test_error 43.00%\n",
      "================================4633===================================\n",
      "4633/10000: train_loss: 3.7526514811813834 train_error 45.25% test_error 43.00%\n",
      "================================4634===================================\n",
      "4634/10000: train_loss: 3.752539750188589 train_error 45.25% test_error 43.00%\n",
      "================================4635===================================\n",
      "4635/10000: train_loss: 3.7524280270934107 train_error 45.25% test_error 43.00%\n",
      "================================4636===================================\n",
      "4636/10000: train_loss: 3.7523161891847847 train_error 45.12% test_error 43.00%\n",
      "================================4637===================================\n",
      "4637/10000: train_loss: 3.7522038403898477 train_error 45.12% test_error 43.00%\n",
      "================================4638===================================\n",
      "4638/10000: train_loss: 3.752090654671192 train_error 45.12% test_error 43.00%\n",
      "================================4639===================================\n",
      "4639/10000: train_loss: 3.7519765632599595 train_error 45.12% test_error 43.00%\n",
      "================================4640===================================\n",
      "4640/10000: train_loss: 3.751862332969904 train_error 45.12% test_error 43.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4641===================================\n",
      "4641/10000: train_loss: 3.751748173683882 train_error 45.12% test_error 43.00%\n",
      "================================4642===================================\n",
      "4642/10000: train_loss: 3.751634082198143 train_error 45.12% test_error 43.00%\n",
      "================================4643===================================\n",
      "4643/10000: train_loss: 3.7515202515572312 train_error 45.12% test_error 43.00%\n",
      "================================4644===================================\n",
      "4644/10000: train_loss: 3.751406833603978 train_error 45.12% test_error 43.00%\n",
      "================================4645===================================\n",
      "4645/10000: train_loss: 3.7512934600561856 train_error 45.12% test_error 43.00%\n",
      "================================4646===================================\n",
      "4646/10000: train_loss: 3.7511807080358266 train_error 45.12% test_error 43.00%\n",
      "================================4647===================================\n",
      "4647/10000: train_loss: 3.7510681488364934 train_error 45.12% test_error 43.00%\n",
      "================================4648===================================\n",
      "4648/10000: train_loss: 3.75095522031188 train_error 45.12% test_error 43.00%\n",
      "================================4649===================================\n",
      "4649/10000: train_loss: 3.750842103883624 train_error 45.12% test_error 43.00%\n",
      "================================4650===================================\n",
      "4650/10000: train_loss: 3.7507289741188288 train_error 45.12% test_error 43.00%\n",
      "================================4651===================================\n",
      "4651/10000: train_loss: 3.750616289228201 train_error 45.12% test_error 43.00%\n",
      "================================4652===================================\n",
      "4652/10000: train_loss: 3.750504273623228 train_error 45.12% test_error 43.00%\n",
      "================================4653===================================\n",
      "4653/10000: train_loss: 3.750392082184553 train_error 45.12% test_error 43.00%\n",
      "================================4654===================================\n",
      "4654/10000: train_loss: 3.750279815420508 train_error 45.12% test_error 43.00%\n",
      "================================4655===================================\n",
      "4655/10000: train_loss: 3.75016764447093 train_error 45.12% test_error 43.00%\n",
      "================================4656===================================\n",
      "4656/10000: train_loss: 3.7500558457523585 train_error 45.12% test_error 43.00%\n",
      "================================4657===================================\n",
      "4657/10000: train_loss: 3.7499449937045575 train_error 45.12% test_error 43.00%\n",
      "================================4658===================================\n",
      "4658/10000: train_loss: 3.7498336473852394 train_error 45.12% test_error 43.00%\n",
      "================================4659===================================\n",
      "4659/10000: train_loss: 3.74972213961184 train_error 45.12% test_error 43.00%\n",
      "================================4660===================================\n",
      "4660/10000: train_loss: 3.749610810950398 train_error 45.12% test_error 43.00%\n",
      "================================4661===================================\n",
      "4661/10000: train_loss: 3.749499623328447 train_error 45.12% test_error 43.00%\n",
      "================================4662===================================\n",
      "4662/10000: train_loss: 3.7493883957713843 train_error 45.12% test_error 43.00%\n",
      "================================4663===================================\n",
      "4663/10000: train_loss: 3.7492771372944116 train_error 45.12% test_error 43.00%\n",
      "================================4664===================================\n",
      "4664/10000: train_loss: 3.7491658364981415 train_error 45.12% test_error 43.00%\n",
      "================================4665===================================\n",
      "4665/10000: train_loss: 3.7490545004606246 train_error 45.12% test_error 43.00%\n",
      "================================4666===================================\n",
      "4666/10000: train_loss: 3.748943005874753 train_error 45.12% test_error 43.00%\n",
      "================================4667===================================\n",
      "4667/10000: train_loss: 3.74883125975728 train_error 45.12% test_error 43.00%\n",
      "================================4668===================================\n",
      "4668/10000: train_loss: 3.7487194304913283 train_error 45.12% test_error 43.00%\n",
      "================================4669===================================\n",
      "4669/10000: train_loss: 3.7486078107357024 train_error 45.12% test_error 43.00%\n",
      "================================4670===================================\n",
      "4670/10000: train_loss: 3.74849622040987 train_error 45.12% test_error 43.00%\n",
      "================================4671===================================\n",
      "4671/10000: train_loss: 3.7483843910694126 train_error 45.12% test_error 43.00%\n",
      "================================4672===================================\n",
      "4672/10000: train_loss: 3.7482720126211646 train_error 45.12% test_error 43.00%\n",
      "================================4673===================================\n",
      "4673/10000: train_loss: 3.7481609439104795 train_error 45.12% test_error 43.00%\n",
      "================================4674===================================\n",
      "4674/10000: train_loss: 3.7480501753091815 train_error 45.12% test_error 43.00%\n",
      "================================4675===================================\n",
      "4675/10000: train_loss: 3.747939560115338 train_error 45.12% test_error 43.00%\n",
      "================================4676===================================\n",
      "4676/10000: train_loss: 3.747828598469496 train_error 45.12% test_error 43.00%\n",
      "================================4677===================================\n",
      "4677/10000: train_loss: 3.7477171869575976 train_error 45.12% test_error 43.00%\n",
      "================================4678===================================\n",
      "4678/10000: train_loss: 3.747605730965734 train_error 45.12% test_error 43.00%\n",
      "================================4679===================================\n",
      "4679/10000: train_loss: 3.7474942986667155 train_error 45.12% test_error 43.00%\n",
      "================================4680===================================\n",
      "4680/10000: train_loss: 3.7473829451948406 train_error 45.12% test_error 43.00%\n",
      "================================4681===================================\n",
      "4681/10000: train_loss: 3.7472715689986944 train_error 45.12% test_error 43.00%\n",
      "================================4682===================================\n",
      "4682/10000: train_loss: 3.747160110324621 train_error 45.12% test_error 43.00%\n",
      "================================4683===================================\n",
      "4683/10000: train_loss: 3.7470485677570102 train_error 45.12% test_error 43.00%\n",
      "================================4684===================================\n",
      "4684/10000: train_loss: 3.7469376303255557 train_error 45.12% test_error 43.00%\n",
      "================================4685===================================\n",
      "4685/10000: train_loss: 3.7468267361074687 train_error 45.12% test_error 43.00%\n",
      "================================4686===================================\n",
      "4686/10000: train_loss: 3.746715768277645 train_error 45.12% test_error 43.00%\n",
      "================================4687===================================\n",
      "4687/10000: train_loss: 3.7466047349572182 train_error 45.12% test_error 43.00%\n",
      "================================4688===================================\n",
      "4688/10000: train_loss: 3.7464938267320393 train_error 45.12% test_error 42.50%\n",
      "================================4689===================================\n",
      "4689/10000: train_loss: 3.7463829565048217 train_error 45.12% test_error 42.50%\n",
      "================================4690===================================\n",
      "4690/10000: train_loss: 3.7462718637287615 train_error 45.12% test_error 42.50%\n",
      "================================4691===================================\n",
      "4691/10000: train_loss: 3.7461606203764677 train_error 45.12% test_error 42.50%\n",
      "================================4692===================================\n",
      "4692/10000: train_loss: 3.746049360111356 train_error 45.12% test_error 42.50%\n",
      "================================4693===================================\n",
      "4693/10000: train_loss: 3.745938066020608 train_error 45.12% test_error 42.50%\n",
      "================================4694===================================\n",
      "4694/10000: train_loss: 3.7458265660703183 train_error 45.12% test_error 42.50%\n",
      "================================4695===================================\n",
      "4695/10000: train_loss: 3.745714973285794 train_error 45.12% test_error 42.50%\n",
      "================================4696===================================\n",
      "4696/10000: train_loss: 3.7456036055833097 train_error 45.12% test_error 42.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4697===================================\n",
      "4697/10000: train_loss: 3.7454922810941937 train_error 45.12% test_error 42.50%\n",
      "================================4698===================================\n",
      "4698/10000: train_loss: 3.745381405130029 train_error 45.12% test_error 42.50%\n",
      "================================4699===================================\n",
      "4699/10000: train_loss: 3.7452714455872775 train_error 45.12% test_error 42.50%\n",
      "================================4700===================================\n",
      "4700/10000: train_loss: 3.745161444395781 train_error 45.12% test_error 42.50%\n",
      "================================4701===================================\n",
      "4701/10000: train_loss: 3.7450514709949494 train_error 45.12% test_error 42.50%\n",
      "================================4702===================================\n",
      "4702/10000: train_loss: 3.7449416579306125 train_error 45.12% test_error 42.50%\n",
      "================================4703===================================\n",
      "4703/10000: train_loss: 3.7448323500156397 train_error 45.12% test_error 42.50%\n",
      "================================4704===================================\n",
      "4704/10000: train_loss: 3.7447235279530284 train_error 45.12% test_error 42.50%\n",
      "================================4705===================================\n",
      "4705/10000: train_loss: 3.7446148686856033 train_error 45.12% test_error 42.50%\n",
      "================================4706===================================\n",
      "4706/10000: train_loss: 3.7445068836212156 train_error 45.12% test_error 42.50%\n",
      "================================4707===================================\n",
      "4707/10000: train_loss: 3.744398565366864 train_error 45.12% test_error 42.50%\n",
      "================================4708===================================\n",
      "4708/10000: train_loss: 3.7442901903390884 train_error 45.12% test_error 42.50%\n",
      "================================4709===================================\n",
      "4709/10000: train_loss: 3.7441818979382515 train_error 45.12% test_error 42.50%\n",
      "================================4710===================================\n",
      "4710/10000: train_loss: 3.744073231741786 train_error 45.12% test_error 42.50%\n",
      "================================4711===================================\n",
      "4711/10000: train_loss: 3.7439646509289743 train_error 45.12% test_error 42.50%\n",
      "================================4712===================================\n",
      "4712/10000: train_loss: 3.743856047093868 train_error 45.12% test_error 42.50%\n",
      "================================4713===================================\n",
      "4713/10000: train_loss: 3.743747340664268 train_error 45.12% test_error 42.50%\n",
      "================================4714===================================\n",
      "4714/10000: train_loss: 3.743638557121158 train_error 45.12% test_error 42.50%\n",
      "================================4715===================================\n",
      "4715/10000: train_loss: 3.74352973729372 train_error 45.12% test_error 42.50%\n",
      "================================4716===================================\n",
      "4716/10000: train_loss: 3.743420807495713 train_error 45.12% test_error 42.50%\n",
      "================================4717===================================\n",
      "4717/10000: train_loss: 3.743311555460095 train_error 45.12% test_error 42.50%\n",
      "================================4718===================================\n",
      "4718/10000: train_loss: 3.743202295303345 train_error 45.12% test_error 42.50%\n",
      "================================4719===================================\n",
      "4719/10000: train_loss: 3.7430931779742243 train_error 45.12% test_error 42.50%\n",
      "================================4720===================================\n",
      "4720/10000: train_loss: 3.7429844553023575 train_error 45.12% test_error 42.50%\n",
      "================================4721===================================\n",
      "4721/10000: train_loss: 3.742875977307558 train_error 45.12% test_error 42.50%\n",
      "================================4722===================================\n",
      "4722/10000: train_loss: 3.7427671717852355 train_error 45.12% test_error 42.50%\n",
      "================================4723===================================\n",
      "4723/10000: train_loss: 3.7426582325994966 train_error 45.00% test_error 42.50%\n",
      "================================4724===================================\n",
      "4724/10000: train_loss: 3.7425492540746927 train_error 45.00% test_error 42.50%\n",
      "================================4725===================================\n",
      "4725/10000: train_loss: 3.7424402629584077 train_error 45.00% test_error 42.50%\n",
      "================================4726===================================\n",
      "4726/10000: train_loss: 3.7423314648121595 train_error 45.00% test_error 42.50%\n",
      "================================4727===================================\n",
      "4727/10000: train_loss: 3.7422227169573308 train_error 45.00% test_error 42.50%\n",
      "================================4728===================================\n",
      "4728/10000: train_loss: 3.742114071920514 train_error 45.00% test_error 42.50%\n",
      "================================4729===================================\n",
      "4729/10000: train_loss: 3.7420067855715757 train_error 44.88% test_error 42.50%\n",
      "================================4730===================================\n",
      "4730/10000: train_loss: 3.7418995666503907 train_error 44.88% test_error 42.50%\n",
      "================================4731===================================\n",
      "4731/10000: train_loss: 3.741792467236519 train_error 44.75% test_error 42.50%\n",
      "================================4732===================================\n",
      "4732/10000: train_loss: 3.741685344427824 train_error 44.50% test_error 42.50%\n",
      "================================4733===================================\n",
      "4733/10000: train_loss: 3.741578135937452 train_error 44.50% test_error 42.50%\n",
      "================================4734===================================\n",
      "4734/10000: train_loss: 3.7414708705991506 train_error 44.50% test_error 42.50%\n",
      "================================4735===================================\n",
      "4735/10000: train_loss: 3.7413635301589965 train_error 44.50% test_error 42.50%\n",
      "================================4736===================================\n",
      "4736/10000: train_loss: 3.7412561888247726 train_error 44.50% test_error 42.50%\n",
      "================================4737===================================\n",
      "4737/10000: train_loss: 3.741149650886655 train_error 44.50% test_error 42.50%\n",
      "================================4738===================================\n",
      "4738/10000: train_loss: 3.7410431692004207 train_error 44.50% test_error 42.50%\n",
      "================================4739===================================\n",
      "4739/10000: train_loss: 3.7409367802739144 train_error 44.50% test_error 42.50%\n",
      "================================4740===================================\n",
      "4740/10000: train_loss: 3.7408305471390486 train_error 44.50% test_error 42.50%\n",
      "================================4741===================================\n",
      "4741/10000: train_loss: 3.7407243628054863 train_error 44.50% test_error 42.50%\n",
      "================================4742===================================\n",
      "4742/10000: train_loss: 3.740618950650096 train_error 44.50% test_error 42.50%\n",
      "================================4743===================================\n",
      "4743/10000: train_loss: 3.740513574108481 train_error 44.50% test_error 42.50%\n",
      "================================4744===================================\n",
      "4744/10000: train_loss: 3.7404086373746397 train_error 44.50% test_error 42.50%\n",
      "================================4745===================================\n",
      "4745/10000: train_loss: 3.7403038950264453 train_error 44.50% test_error 42.50%\n",
      "================================4746===================================\n",
      "4746/10000: train_loss: 3.7401991316676138 train_error 44.50% test_error 42.50%\n",
      "================================4747===================================\n",
      "4747/10000: train_loss: 3.740094447657466 train_error 44.38% test_error 42.50%\n",
      "================================4748===================================\n",
      "4748/10000: train_loss: 3.7399899173527955 train_error 44.25% test_error 42.50%\n",
      "================================4749===================================\n",
      "4749/10000: train_loss: 3.7398854082822797 train_error 44.25% test_error 42.50%\n",
      "================================4750===================================\n",
      "4750/10000: train_loss: 3.7397807412594557 train_error 44.25% test_error 42.50%\n",
      "================================4751===================================\n",
      "4751/10000: train_loss: 3.73967586144805 train_error 44.25% test_error 42.50%\n",
      "================================4752===================================\n",
      "4752/10000: train_loss: 3.7395709462463853 train_error 44.12% test_error 42.50%\n",
      "================================4753===================================\n",
      "4753/10000: train_loss: 3.7394663932174446 train_error 44.12% test_error 42.50%\n",
      "================================4754===================================\n",
      "4754/10000: train_loss: 3.739362576827407 train_error 44.12% test_error 42.50%\n",
      "================================4755===================================\n",
      "4755/10000: train_loss: 3.7392586312443017 train_error 44.12% test_error 42.50%\n",
      "================================4756===================================\n",
      "4756/10000: train_loss: 3.7391548672318464 train_error 44.12% test_error 42.50%\n",
      "================================4757===================================\n",
      "4757/10000: train_loss: 3.739051108211279 train_error 44.12% test_error 42.50%\n",
      "================================4758===================================\n",
      "4758/10000: train_loss: 3.738947417065501 train_error 44.12% test_error 42.50%\n",
      "================================4759===================================\n",
      "4759/10000: train_loss: 3.7388436530530456 train_error 44.12% test_error 42.50%\n",
      "================================4760===================================\n",
      "4760/10000: train_loss: 3.738739631548524 train_error 44.12% test_error 42.50%\n",
      "================================4761===================================\n",
      "4761/10000: train_loss: 3.738635708019138 train_error 44.00% test_error 42.50%\n",
      "================================4762===================================\n",
      "4762/10000: train_loss: 3.7385320914536715 train_error 44.00% test_error 42.50%\n",
      "================================4763===================================\n",
      "4763/10000: train_loss: 3.7384287323057652 train_error 43.88% test_error 42.50%\n",
      "================================4764===================================\n",
      "4764/10000: train_loss: 3.7383256897330286 train_error 43.88% test_error 42.50%\n",
      "================================4765===================================\n",
      "4765/10000: train_loss: 3.738222633972764 train_error 43.88% test_error 42.50%\n",
      "================================4766===================================\n",
      "4766/10000: train_loss: 3.7381195421516895 train_error 43.88% test_error 42.50%\n",
      "================================4767===================================\n",
      "4767/10000: train_loss: 3.7380165246129033 train_error 43.88% test_error 42.50%\n",
      "================================4768===================================\n",
      "4768/10000: train_loss: 3.7379144858568907 train_error 43.75% test_error 42.50%\n",
      "================================4769===================================\n",
      "4769/10000: train_loss: 3.7378126907348634 train_error 43.75% test_error 42.50%\n",
      "================================4770===================================\n",
      "4770/10000: train_loss: 3.7377110870182513 train_error 43.75% test_error 42.50%\n",
      "================================4771===================================\n",
      "4771/10000: train_loss: 3.7376097715646033 train_error 43.75% test_error 42.50%\n",
      "================================4772===================================\n",
      "4772/10000: train_loss: 3.7375084982812403 train_error 43.75% test_error 42.50%\n",
      "================================4773===================================\n",
      "4773/10000: train_loss: 3.7374071181565522 train_error 43.75% test_error 42.50%\n",
      "================================4774===================================\n",
      "4774/10000: train_loss: 3.7373056933283806 train_error 43.75% test_error 42.50%\n",
      "================================4775===================================\n",
      "4775/10000: train_loss: 3.737204311713576 train_error 43.75% test_error 42.50%\n",
      "================================4776===================================\n",
      "4776/10000: train_loss: 3.737102748826146 train_error 43.75% test_error 42.50%\n",
      "================================4777===================================\n",
      "4777/10000: train_loss: 3.737000960856676 train_error 43.75% test_error 42.50%\n",
      "================================4778===================================\n",
      "4778/10000: train_loss: 3.7368991081416603 train_error 43.62% test_error 42.50%\n",
      "================================4779===================================\n",
      "4779/10000: train_loss: 3.7367968683689834 train_error 43.62% test_error 42.50%\n",
      "================================4780===================================\n",
      "4780/10000: train_loss: 3.736694659367204 train_error 43.62% test_error 42.50%\n",
      "================================4781===================================\n",
      "4781/10000: train_loss: 3.736592334806919 train_error 43.62% test_error 42.50%\n",
      "================================4782===================================\n",
      "4782/10000: train_loss: 3.736489839479327 train_error 43.62% test_error 42.50%\n",
      "================================4783===================================\n",
      "4783/10000: train_loss: 3.7363871338963506 train_error 43.62% test_error 42.50%\n",
      "================================4784===================================\n",
      "4784/10000: train_loss: 3.7362843442708256 train_error 43.50% test_error 42.50%\n",
      "================================4785===================================\n",
      "4785/10000: train_loss: 3.7361816015839575 train_error 43.50% test_error 42.50%\n",
      "================================4786===================================\n",
      "4786/10000: train_loss: 3.7360786893963813 train_error 43.50% test_error 42.50%\n",
      "================================4787===================================\n",
      "4787/10000: train_loss: 3.7359757590293885 train_error 43.50% test_error 42.50%\n",
      "================================4788===================================\n",
      "4788/10000: train_loss: 3.735872962102294 train_error 43.50% test_error 42.50%\n",
      "================================4789===================================\n",
      "4789/10000: train_loss: 3.7357704033702612 train_error 43.50% test_error 42.50%\n",
      "================================4790===================================\n",
      "4790/10000: train_loss: 3.7356677972525354 train_error 43.50% test_error 42.50%\n",
      "================================4791===================================\n",
      "4791/10000: train_loss: 3.7355651159584524 train_error 43.50% test_error 42.50%\n",
      "================================4792===================================\n",
      "4792/10000: train_loss: 3.7354621465504168 train_error 43.50% test_error 42.50%\n",
      "================================4793===================================\n",
      "4793/10000: train_loss: 3.7353591752797364 train_error 43.50% test_error 42.00%\n",
      "================================4794===================================\n",
      "4794/10000: train_loss: 3.7352560802549126 train_error 43.50% test_error 42.00%\n",
      "================================4795===================================\n",
      "4795/10000: train_loss: 3.7351534556597468 train_error 43.50% test_error 42.00%\n",
      "================================4796===================================\n",
      "4796/10000: train_loss: 3.735050872191787 train_error 43.50% test_error 42.00%\n",
      "================================4797===================================\n",
      "4797/10000: train_loss: 3.7349477995187046 train_error 43.50% test_error 42.00%\n",
      "================================4798===================================\n",
      "4798/10000: train_loss: 3.734844696894288 train_error 43.50% test_error 42.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4799===================================\n",
      "4799/10000: train_loss: 3.7347415474802257 train_error 43.50% test_error 42.00%\n",
      "================================4800===================================\n",
      "4800/10000: train_loss: 3.7346383037418125 train_error 43.50% test_error 42.00%\n",
      "================================4801===================================\n",
      "4801/10000: train_loss: 3.734535033032298 train_error 43.38% test_error 42.00%\n",
      "================================4802===================================\n",
      "4802/10000: train_loss: 3.7344318481534717 train_error 43.38% test_error 42.00%\n",
      "================================4803===================================\n",
      "4803/10000: train_loss: 3.7343291064351796 train_error 43.38% test_error 42.00%\n",
      "================================4804===================================\n",
      "4804/10000: train_loss: 3.7342262333631515 train_error 43.38% test_error 42.00%\n",
      "================================4805===================================\n",
      "4805/10000: train_loss: 3.734123374298215 train_error 43.25% test_error 42.00%\n",
      "================================4806===================================\n",
      "4806/10000: train_loss: 3.7340206995606424 train_error 43.25% test_error 42.00%\n",
      "================================4807===================================\n",
      "4807/10000: train_loss: 3.733918308839202 train_error 43.25% test_error 42.00%\n",
      "================================4808===================================\n",
      "4808/10000: train_loss: 3.7338155242800712 train_error 43.25% test_error 42.00%\n",
      "================================4809===================================\n",
      "4809/10000: train_loss: 3.733712559789419 train_error 43.25% test_error 42.00%\n",
      "================================4810===================================\n",
      "4810/10000: train_loss: 3.733609520420432 train_error 43.25% test_error 42.00%\n",
      "================================4811===================================\n",
      "4811/10000: train_loss: 3.7335067357122895 train_error 43.12% test_error 42.00%\n",
      "================================4812===================================\n",
      "4812/10000: train_loss: 3.7334038322418928 train_error 43.12% test_error 42.00%\n",
      "================================4813===================================\n",
      "4813/10000: train_loss: 3.7333006194233893 train_error 43.12% test_error 42.00%\n",
      "================================4814===================================\n",
      "4814/10000: train_loss: 3.733198008090258 train_error 43.00% test_error 42.00%\n",
      "================================4815===================================\n",
      "4815/10000: train_loss: 3.733095396757126 train_error 43.00% test_error 42.00%\n",
      "================================4816===================================\n",
      "4816/10000: train_loss: 3.732992878332734 train_error 43.00% test_error 42.00%\n",
      "================================4817===================================\n",
      "4817/10000: train_loss: 3.732890760526061 train_error 43.00% test_error 42.00%\n",
      "================================4818===================================\n",
      "4818/10000: train_loss: 3.7327890645712616 train_error 43.00% test_error 42.00%\n",
      "================================4819===================================\n",
      "4819/10000: train_loss: 3.732688309699297 train_error 43.00% test_error 42.00%\n",
      "================================4820===================================\n",
      "4820/10000: train_loss: 3.7325875449925663 train_error 42.88% test_error 42.00%\n",
      "================================4821===================================\n",
      "4821/10000: train_loss: 3.7324867360293865 train_error 42.88% test_error 42.00%\n",
      "================================4822===================================\n",
      "4822/10000: train_loss: 3.7323860135674476 train_error 42.88% test_error 42.00%\n",
      "================================4823===================================\n",
      "4823/10000: train_loss: 3.7322848854213952 train_error 42.88% test_error 42.00%\n",
      "================================4824===================================\n",
      "4824/10000: train_loss: 3.7321834313124422 train_error 42.88% test_error 42.00%\n",
      "================================4825===================================\n",
      "4825/10000: train_loss: 3.732081137597561 train_error 42.88% test_error 42.00%\n",
      "================================4826===================================\n",
      "4826/10000: train_loss: 3.731978979855776 train_error 42.88% test_error 42.00%\n",
      "================================4827===================================\n",
      "4827/10000: train_loss: 3.7318769196420907 train_error 42.88% test_error 42.00%\n",
      "================================4828===================================\n",
      "4828/10000: train_loss: 3.731774870604277 train_error 42.88% test_error 42.00%\n",
      "================================4829===================================\n",
      "4829/10000: train_loss: 3.731673728898168 train_error 42.88% test_error 42.00%\n",
      "================================4830===================================\n",
      "4830/10000: train_loss: 3.7315732467174527 train_error 42.88% test_error 42.00%\n",
      "================================4831===================================\n",
      "4831/10000: train_loss: 3.731472756266594 train_error 42.88% test_error 42.00%\n",
      "================================4832===================================\n",
      "4832/10000: train_loss: 3.7313723429292445 train_error 42.75% test_error 42.00%\n",
      "================================4833===================================\n",
      "4833/10000: train_loss: 3.7312718499451876 train_error 42.75% test_error 42.00%\n",
      "================================4834===================================\n",
      "4834/10000: train_loss: 3.7311707872152327 train_error 42.75% test_error 42.00%\n",
      "================================4835===================================\n",
      "4835/10000: train_loss: 3.7310697443783285 train_error 42.75% test_error 42.00%\n",
      "================================4836===================================\n",
      "4836/10000: train_loss: 3.7309689197689293 train_error 42.50% test_error 42.00%\n",
      "================================4837===================================\n",
      "4837/10000: train_loss: 3.730867875739932 train_error 42.50% test_error 42.00%\n",
      "================================4838===================================\n",
      "4838/10000: train_loss: 3.7307670682668688 train_error 42.50% test_error 42.00%\n",
      "================================4839===================================\n",
      "4839/10000: train_loss: 3.7306663274765017 train_error 42.50% test_error 42.00%\n",
      "================================4840===================================\n",
      "4840/10000: train_loss: 3.7305655082315208 train_error 42.50% test_error 42.00%\n",
      "================================4841===================================\n",
      "4841/10000: train_loss: 3.730464749708772 train_error 42.50% test_error 42.00%\n",
      "================================4842===================================\n",
      "4842/10000: train_loss: 3.730363742336631 train_error 42.50% test_error 42.00%\n",
      "================================4843===================================\n",
      "4843/10000: train_loss: 3.730262695774436 train_error 42.50% test_error 42.00%\n",
      "================================4844===================================\n",
      "4844/10000: train_loss: 3.730161641687155 train_error 42.50% test_error 42.00%\n",
      "================================4845===================================\n",
      "4845/10000: train_loss: 3.7300607073307037 train_error 42.50% test_error 42.00%\n",
      "================================4846===================================\n",
      "4846/10000: train_loss: 3.72995960265398 train_error 42.62% test_error 42.00%\n",
      "================================4847===================================\n",
      "4847/10000: train_loss: 3.729858206212521 train_error 42.50% test_error 42.00%\n",
      "================================4848===================================\n",
      "4848/10000: train_loss: 3.729756576195359 train_error 42.38% test_error 42.00%\n",
      "================================4849===================================\n",
      "4849/10000: train_loss: 3.7296550278365608 train_error 42.38% test_error 42.00%\n",
      "================================4850===================================\n",
      "4850/10000: train_loss: 3.7295533890277146 train_error 42.38% test_error 42.00%\n",
      "================================4851===================================\n",
      "4851/10000: train_loss: 3.729451720789075 train_error 42.38% test_error 42.00%\n",
      "================================4852===================================\n",
      "4852/10000: train_loss: 3.7293499868363145 train_error 42.38% test_error 42.00%\n",
      "================================4853===================================\n",
      "4853/10000: train_loss: 3.7292478320002553 train_error 42.38% test_error 42.00%\n",
      "================================4854===================================\n",
      "4854/10000: train_loss: 3.7291455766558648 train_error 42.50% test_error 42.00%\n",
      "================================4855===================================\n",
      "4855/10000: train_loss: 3.7290432857722045 train_error 42.50% test_error 42.00%\n",
      "================================4856===================================\n",
      "4856/10000: train_loss: 3.728941281735897 train_error 42.50% test_error 42.00%\n",
      "================================4857===================================\n",
      "4857/10000: train_loss: 3.7288386998325587 train_error 42.50% test_error 42.00%\n",
      "================================4858===================================\n",
      "4858/10000: train_loss: 3.7287361516058444 train_error 42.50% test_error 42.00%\n",
      "================================4859===================================\n",
      "4859/10000: train_loss: 3.7286339791864154 train_error 42.50% test_error 42.00%\n",
      "================================4860===================================\n",
      "4860/10000: train_loss: 3.7285323603451253 train_error 42.50% test_error 42.00%\n",
      "================================4861===================================\n",
      "4861/10000: train_loss: 3.7284308329224585 train_error 42.50% test_error 42.00%\n",
      "================================4862===================================\n",
      "4862/10000: train_loss: 3.7283292473852634 train_error 42.50% test_error 42.00%\n",
      "================================4863===================================\n",
      "4863/10000: train_loss: 3.7282277196645737 train_error 42.50% test_error 42.00%\n",
      "================================4864===================================\n",
      "4864/10000: train_loss: 3.7281261527538296 train_error 42.50% test_error 42.00%\n",
      "================================4865===================================\n",
      "4865/10000: train_loss: 3.728024540171027 train_error 42.50% test_error 42.00%\n",
      "================================4866===================================\n",
      "4866/10000: train_loss: 3.727923196032643 train_error 42.50% test_error 42.00%\n",
      "================================4867===================================\n",
      "4867/10000: train_loss: 3.7278218279778956 train_error 42.38% test_error 42.00%\n",
      "================================4868===================================\n",
      "4868/10000: train_loss: 3.7277205636352297 train_error 42.38% test_error 42.00%\n",
      "================================4869===================================\n",
      "4869/10000: train_loss: 3.7276192333549263 train_error 42.38% test_error 42.00%\n",
      "================================4870===================================\n",
      "4870/10000: train_loss: 3.7275178404152394 train_error 42.38% test_error 42.00%\n",
      "================================4871===================================\n",
      "4871/10000: train_loss: 3.727416447028518 train_error 42.38% test_error 42.00%\n",
      "================================4872===================================\n",
      "4872/10000: train_loss: 3.7273151047527793 train_error 42.38% test_error 42.00%\n",
      "================================4873===================================\n",
      "4873/10000: train_loss: 3.7272139220684766 train_error 42.38% test_error 42.00%\n",
      "================================4874===================================\n",
      "4874/10000: train_loss: 3.7271123879402874 train_error 42.38% test_error 42.00%\n",
      "================================4875===================================\n",
      "4875/10000: train_loss: 3.7270110696554184 train_error 42.38% test_error 42.00%\n",
      "================================4876===================================\n",
      "4876/10000: train_loss: 3.7269098687171933 train_error 42.38% test_error 42.00%\n",
      "================================4877===================================\n",
      "4877/10000: train_loss: 3.726808183118701 train_error 42.38% test_error 42.00%\n",
      "================================4878===================================\n",
      "4878/10000: train_loss: 3.72670622959733 train_error 42.38% test_error 42.00%\n",
      "================================4879===================================\n",
      "4879/10000: train_loss: 3.726604196950793 train_error 42.38% test_error 42.00%\n",
      "================================4880===================================\n",
      "4880/10000: train_loss: 3.7265030390024187 train_error 42.38% test_error 42.00%\n",
      "================================4881===================================\n",
      "4881/10000: train_loss: 3.7264019867032765 train_error 42.38% test_error 42.00%\n",
      "================================4882===================================\n",
      "4882/10000: train_loss: 3.726300837397575 train_error 42.38% test_error 42.00%\n",
      "================================4883===================================\n",
      "4883/10000: train_loss: 3.72619957767427 train_error 42.38% test_error 42.00%\n",
      "================================4884===================================\n",
      "4884/10000: train_loss: 3.7260984193533657 train_error 42.38% test_error 42.00%\n",
      "================================4885===================================\n",
      "4885/10000: train_loss: 3.7259972657263276 train_error 42.38% test_error 42.00%\n",
      "================================4886===================================\n",
      "4886/10000: train_loss: 3.725896184369922 train_error 42.38% test_error 42.00%\n",
      "================================4887===================================\n",
      "4887/10000: train_loss: 3.725795197635889 train_error 42.38% test_error 42.00%\n",
      "================================4888===================================\n",
      "4888/10000: train_loss: 3.72569403745234 train_error 42.38% test_error 42.00%\n",
      "================================4889===================================\n",
      "4889/10000: train_loss: 3.7255927787721155 train_error 42.25% test_error 42.00%\n",
      "================================4890===================================\n",
      "4890/10000: train_loss: 3.7254918380826707 train_error 42.25% test_error 42.00%\n",
      "================================4891===================================\n",
      "4891/10000: train_loss: 3.725390850827098 train_error 42.25% test_error 42.00%\n",
      "================================4892===================================\n",
      "4892/10000: train_loss: 3.725290380865336 train_error 42.25% test_error 42.00%\n",
      "================================4893===================================\n",
      "4893/10000: train_loss: 3.7251898878812786 train_error 42.25% test_error 42.00%\n",
      "================================4894===================================\n",
      "4894/10000: train_loss: 3.7250897835940124 train_error 42.25% test_error 42.00%\n",
      "================================4895===================================\n",
      "4895/10000: train_loss: 3.7249897394329308 train_error 42.25% test_error 42.00%\n",
      "================================4896===================================\n",
      "4896/10000: train_loss: 3.724889803752303 train_error 42.25% test_error 42.00%\n",
      "================================4897===================================\n",
      "4897/10000: train_loss: 3.724790229201317 train_error 42.25% test_error 42.00%\n",
      "================================4898===================================\n",
      "4898/10000: train_loss: 3.724690623804927 train_error 42.25% test_error 42.00%\n",
      "================================4899===================================\n",
      "4899/10000: train_loss: 3.724591189175844 train_error 42.25% test_error 42.00%\n",
      "================================4900===================================\n",
      "4900/10000: train_loss: 3.7244918494671584 train_error 42.25% test_error 42.00%\n",
      "================================4901===================================\n",
      "4901/10000: train_loss: 3.7243925119936465 train_error 42.25% test_error 42.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================4902===================================\n",
      "4902/10000: train_loss: 3.724293198660016 train_error 42.25% test_error 42.00%\n",
      "================================4903===================================\n",
      "4903/10000: train_loss: 3.7241934575140476 train_error 42.25% test_error 41.50%\n",
      "================================4904===================================\n",
      "4904/10000: train_loss: 3.724093416854739 train_error 42.25% test_error 41.50%\n",
      "================================4905===================================\n",
      "4905/10000: train_loss: 3.72399333037436 train_error 42.25% test_error 41.50%\n",
      "================================4906===================================\n",
      "4906/10000: train_loss: 3.723892963305116 train_error 42.25% test_error 41.50%\n",
      "================================4907===================================\n",
      "4907/10000: train_loss: 3.7237925995886325 train_error 42.25% test_error 41.50%\n",
      "================================4908===================================\n",
      "4908/10000: train_loss: 3.7236924341320994 train_error 42.25% test_error 41.50%\n",
      "================================4909===================================\n",
      "4909/10000: train_loss: 3.7235923125594854 train_error 42.25% test_error 41.50%\n",
      "================================4910===================================\n",
      "4910/10000: train_loss: 3.7234927172213794 train_error 42.25% test_error 41.50%\n",
      "================================4911===================================\n",
      "4911/10000: train_loss: 3.7233931346237656 train_error 42.25% test_error 41.50%\n",
      "================================4912===================================\n",
      "4912/10000: train_loss: 3.723293701261282 train_error 42.25% test_error 41.50%\n",
      "================================4913===================================\n",
      "4913/10000: train_loss: 3.7231941369920967 train_error 42.12% test_error 41.50%\n",
      "================================4914===================================\n",
      "4914/10000: train_loss: 3.7230943358689546 train_error 42.12% test_error 41.50%\n",
      "================================4915===================================\n",
      "4915/10000: train_loss: 3.722994148284197 train_error 42.12% test_error 41.50%\n",
      "================================4916===================================\n",
      "4916/10000: train_loss: 3.722893835902214 train_error 42.12% test_error 41.50%\n",
      "================================4917===================================\n",
      "4917/10000: train_loss: 3.722793512120843 train_error 42.12% test_error 41.50%\n",
      "================================4918===================================\n",
      "4918/10000: train_loss: 3.7226930614560843 train_error 42.12% test_error 41.50%\n",
      "================================4919===================================\n",
      "4919/10000: train_loss: 3.7225925355404614 train_error 42.12% test_error 41.50%\n",
      "================================4920===================================\n",
      "4920/10000: train_loss: 3.722491818368435 train_error 42.12% test_error 41.50%\n",
      "================================4921===================================\n",
      "4921/10000: train_loss: 3.722391796782613 train_error 42.12% test_error 41.50%\n",
      "================================4922===================================\n",
      "4922/10000: train_loss: 3.722291692197323 train_error 42.12% test_error 41.50%\n",
      "================================4923===================================\n",
      "4923/10000: train_loss: 3.7221912916749718 train_error 42.12% test_error 41.50%\n",
      "================================4924===================================\n",
      "4924/10000: train_loss: 3.7220909282565113 train_error 42.12% test_error 41.50%\n",
      "================================4925===================================\n",
      "4925/10000: train_loss: 3.721990518793464 train_error 42.12% test_error 40.50%\n",
      "================================4926===================================\n",
      "4926/10000: train_loss: 3.7218901168555023 train_error 42.12% test_error 40.50%\n",
      "================================4927===================================\n",
      "4927/10000: train_loss: 3.7217901373654603 train_error 42.12% test_error 40.50%\n",
      "================================4928===================================\n",
      "4928/10000: train_loss: 3.721690708473325 train_error 42.12% test_error 40.50%\n",
      "================================4929===================================\n",
      "4929/10000: train_loss: 3.7215915060788394 train_error 42.12% test_error 40.50%\n",
      "================================4930===================================\n",
      "4930/10000: train_loss: 3.721492467373609 train_error 42.12% test_error 40.50%\n",
      "================================4931===================================\n",
      "4931/10000: train_loss: 3.7213938550651076 train_error 42.00% test_error 40.50%\n",
      "================================4932===================================\n",
      "4932/10000: train_loss: 3.721295126676559 train_error 42.00% test_error 40.50%\n",
      "================================4933===================================\n",
      "4933/10000: train_loss: 3.7211963327974082 train_error 42.00% test_error 40.50%\n",
      "================================4934===================================\n",
      "4934/10000: train_loss: 3.72109740562737 train_error 42.00% test_error 40.50%\n",
      "================================4935===================================\n",
      "4935/10000: train_loss: 3.7209983148425816 train_error 42.00% test_error 40.50%\n",
      "================================4936===================================\n",
      "4936/10000: train_loss: 3.720899008363485 train_error 42.00% test_error 40.50%\n",
      "================================4937===================================\n",
      "4937/10000: train_loss: 3.720799805223942 train_error 42.00% test_error 40.50%\n",
      "================================4938===================================\n",
      "4938/10000: train_loss: 3.7207007952407003 train_error 42.00% test_error 40.50%\n",
      "================================4939===================================\n",
      "4939/10000: train_loss: 3.7206022739037876 train_error 42.00% test_error 40.50%\n",
      "================================4940===================================\n",
      "4940/10000: train_loss: 3.7205039886385203 train_error 41.88% test_error 40.50%\n",
      "================================4941===================================\n",
      "4941/10000: train_loss: 3.720405600816011 train_error 41.88% test_error 40.50%\n",
      "================================4942===================================\n",
      "4942/10000: train_loss: 3.7203073880448936 train_error 41.88% test_error 40.50%\n",
      "================================4943===================================\n",
      "4943/10000: train_loss: 3.720209056325257 train_error 41.88% test_error 40.50%\n",
      "================================4944===================================\n",
      "4944/10000: train_loss: 3.720110735595226 train_error 41.88% test_error 40.50%\n",
      "================================4945===================================\n",
      "4945/10000: train_loss: 3.7200124999880795 train_error 41.88% test_error 40.50%\n",
      "================================4946===================================\n",
      "4946/10000: train_loss: 3.7199143146723506 train_error 41.88% test_error 40.50%\n",
      "================================4947===================================\n",
      "4947/10000: train_loss: 3.7198158856108785 train_error 41.88% test_error 40.50%\n",
      "================================4948===================================\n",
      "4948/10000: train_loss: 3.719717309512198 train_error 41.88% test_error 40.50%\n",
      "================================4949===================================\n",
      "4949/10000: train_loss: 3.719618736989796 train_error 41.88% test_error 41.00%\n",
      "================================4950===================================\n",
      "4950/10000: train_loss: 3.7195198978856205 train_error 41.88% test_error 41.00%\n",
      "================================4951===================================\n",
      "4951/10000: train_loss: 3.7194210313633085 train_error 41.88% test_error 41.00%\n",
      "================================4952===================================\n",
      "4952/10000: train_loss: 3.719322176836431 train_error 41.88% test_error 41.00%\n",
      "================================4953===================================\n",
      "4953/10000: train_loss: 3.719223230481148 train_error 41.88% test_error 41.00%\n",
      "================================4954===================================\n",
      "4954/10000: train_loss: 3.719124293550849 train_error 41.88% test_error 41.00%\n",
      "================================4955===================================\n",
      "4955/10000: train_loss: 3.7190255663916467 train_error 41.88% test_error 41.00%\n",
      "================================4956===================================\n",
      "4956/10000: train_loss: 3.718926876150072 train_error 41.88% test_error 41.00%\n",
      "================================4957===================================\n",
      "4957/10000: train_loss: 3.7188280054926874 train_error 41.88% test_error 41.00%\n",
      "================================4958===================================\n",
      "4958/10000: train_loss: 3.718728797771037 train_error 41.75% test_error 41.00%\n",
      "================================4959===================================\n",
      "4959/10000: train_loss: 3.7186293083429334 train_error 41.75% test_error 41.00%\n",
      "================================4960===================================\n",
      "4960/10000: train_loss: 3.7185296786203983 train_error 41.75% test_error 41.00%\n",
      "================================4961===================================\n",
      "4961/10000: train_loss: 3.7184301367774606 train_error 41.75% test_error 41.00%\n",
      "================================4962===================================\n",
      "4962/10000: train_loss: 3.7183305674418805 train_error 41.75% test_error 41.00%\n",
      "================================4963===================================\n",
      "4963/10000: train_loss: 3.7182309990003706 train_error 41.75% test_error 41.00%\n",
      "================================4964===================================\n",
      "4964/10000: train_loss: 3.7181314254179596 train_error 41.75% test_error 41.00%\n",
      "================================4965===================================\n",
      "4965/10000: train_loss: 3.7180318664014336 train_error 41.75% test_error 41.00%\n",
      "================================4966===================================\n",
      "4966/10000: train_loss: 3.7179323743656276 train_error 41.75% test_error 41.00%\n",
      "================================4967===================================\n",
      "4967/10000: train_loss: 3.717832700498402 train_error 41.75% test_error 41.00%\n",
      "================================4968===================================\n",
      "4968/10000: train_loss: 3.7177329915016886 train_error 41.75% test_error 41.00%\n",
      "================================4969===================================\n",
      "4969/10000: train_loss: 3.717633412666619 train_error 41.75% test_error 41.00%\n",
      "================================4970===================================\n",
      "4970/10000: train_loss: 3.7175338742509485 train_error 41.75% test_error 41.00%\n",
      "================================4971===================================\n",
      "4971/10000: train_loss: 3.717434263452888 train_error 41.75% test_error 41.00%\n",
      "================================4972===================================\n",
      "4972/10000: train_loss: 3.7173346550390125 train_error 41.75% test_error 41.00%\n",
      "================================4973===================================\n",
      "4973/10000: train_loss: 3.7172347847372293 train_error 41.75% test_error 41.00%\n",
      "================================4974===================================\n",
      "4974/10000: train_loss: 3.717135082781315 train_error 41.75% test_error 41.00%\n",
      "================================4975===================================\n",
      "4975/10000: train_loss: 3.7170353819429875 train_error 41.75% test_error 41.00%\n",
      "================================4976===================================\n",
      "4976/10000: train_loss: 3.7169356993213296 train_error 41.75% test_error 41.00%\n",
      "================================4977===================================\n",
      "4977/10000: train_loss: 3.7168366479873653 train_error 41.75% test_error 41.00%\n",
      "================================4978===================================\n",
      "4978/10000: train_loss: 3.7167378712072967 train_error 41.75% test_error 41.00%\n",
      "================================4979===================================\n",
      "4979/10000: train_loss: 3.716638890653849 train_error 41.75% test_error 41.00%\n",
      "================================4980===================================\n",
      "4980/10000: train_loss: 3.7165400445461274 train_error 41.75% test_error 41.00%\n",
      "================================4981===================================\n",
      "4981/10000: train_loss: 3.7164417323842645 train_error 41.75% test_error 41.00%\n",
      "================================4982===================================\n",
      "4982/10000: train_loss: 3.7163430285453796 train_error 41.75% test_error 41.00%\n",
      "================================4983===================================\n",
      "4983/10000: train_loss: 3.716244131848216 train_error 41.75% test_error 41.00%\n",
      "================================4984===================================\n",
      "4984/10000: train_loss: 3.716144845969975 train_error 41.75% test_error 41.00%\n",
      "================================4985===================================\n",
      "4985/10000: train_loss: 3.7160449438542127 train_error 41.75% test_error 41.00%\n",
      "================================4986===================================\n",
      "4986/10000: train_loss: 3.715944105349481 train_error 41.62% test_error 41.00%\n",
      "================================4987===================================\n",
      "4987/10000: train_loss: 3.7158426102250814 train_error 41.62% test_error 41.00%\n",
      "================================4988===================================\n",
      "4988/10000: train_loss: 3.7157412492111326 train_error 41.62% test_error 41.00%\n",
      "================================4989===================================\n",
      "4989/10000: train_loss: 3.7156404492631556 train_error 41.62% test_error 41.00%\n",
      "================================4990===================================\n",
      "4990/10000: train_loss: 3.715540574416518 train_error 41.62% test_error 41.00%\n",
      "================================4991===================================\n",
      "4991/10000: train_loss: 3.7154409850016235 train_error 41.62% test_error 41.00%\n",
      "================================4992===================================\n",
      "4992/10000: train_loss: 3.7153413802385327 train_error 41.75% test_error 41.00%\n",
      "================================4993===================================\n",
      "4993/10000: train_loss: 3.7152414023131133 train_error 41.75% test_error 41.00%\n",
      "================================4994===================================\n",
      "4994/10000: train_loss: 3.715141097716987 train_error 41.75% test_error 41.00%\n",
      "================================4995===================================\n",
      "4995/10000: train_loss: 3.715040797144175 train_error 41.75% test_error 41.00%\n",
      "================================4996===================================\n",
      "4996/10000: train_loss: 3.714939998835325 train_error 41.75% test_error 41.00%\n",
      "================================4997===================================\n",
      "4997/10000: train_loss: 3.7148388347402213 train_error 41.75% test_error 41.00%\n",
      "================================4998===================================\n",
      "4998/10000: train_loss: 3.7147384833917023 train_error 41.75% test_error 41.00%\n",
      "================================4999===================================\n",
      "4999/10000: train_loss: 3.7146382367238404 train_error 41.62% test_error 41.00%\n",
      "================================5000===================================\n",
      "5000/10000: train_loss: 3.714538197889924 train_error 41.62% test_error 41.00%\n",
      "================================5001===================================\n",
      "5001/10000: train_loss: 3.7144377666339277 train_error 41.62% test_error 41.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5002===================================\n",
      "5002/10000: train_loss: 3.7143369092792273 train_error 41.62% test_error 41.00%\n",
      "================================5003===================================\n",
      "5003/10000: train_loss: 3.714235594719648 train_error 41.62% test_error 41.00%\n",
      "================================5004===================================\n",
      "5004/10000: train_loss: 3.7141349139809607 train_error 41.62% test_error 41.00%\n",
      "================================5005===================================\n",
      "5005/10000: train_loss: 3.714035342372954 train_error 41.50% test_error 41.00%\n",
      "================================5006===================================\n",
      "5006/10000: train_loss: 3.713936005793512 train_error 41.50% test_error 41.00%\n",
      "================================5007===================================\n",
      "5007/10000: train_loss: 3.71383690521121 train_error 41.50% test_error 41.00%\n",
      "================================5008===================================\n",
      "5008/10000: train_loss: 3.7137371800839905 train_error 41.50% test_error 41.00%\n",
      "================================5009===================================\n",
      "5009/10000: train_loss: 3.713637280985713 train_error 41.50% test_error 41.00%\n",
      "================================5010===================================\n",
      "5010/10000: train_loss: 3.7135374768450857 train_error 41.50% test_error 41.00%\n",
      "================================5011===================================\n",
      "5011/10000: train_loss: 3.713437373563647 train_error 41.50% test_error 41.00%\n",
      "================================5012===================================\n",
      "5012/10000: train_loss: 3.713337266556919 train_error 41.50% test_error 41.00%\n",
      "================================5013===================================\n",
      "5013/10000: train_loss: 3.7132370849326253 train_error 41.50% test_error 41.00%\n",
      "================================5014===================================\n",
      "5014/10000: train_loss: 3.713136609494686 train_error 41.50% test_error 41.00%\n",
      "================================5015===================================\n",
      "5015/10000: train_loss: 3.7130368179827924 train_error 41.50% test_error 41.00%\n",
      "================================5016===================================\n",
      "5016/10000: train_loss: 3.7129369430989025 train_error 41.50% test_error 41.00%\n",
      "================================5017===================================\n",
      "5017/10000: train_loss: 3.7128370103985073 train_error 41.50% test_error 41.00%\n",
      "================================5018===================================\n",
      "5018/10000: train_loss: 3.712737051285803 train_error 41.50% test_error 41.00%\n",
      "================================5019===================================\n",
      "5019/10000: train_loss: 3.7126374594867233 train_error 41.50% test_error 41.00%\n",
      "================================5020===================================\n",
      "5020/10000: train_loss: 3.712537953853607 train_error 41.50% test_error 41.00%\n",
      "================================5021===================================\n",
      "5021/10000: train_loss: 3.712438379749656 train_error 41.50% test_error 41.00%\n",
      "================================5022===================================\n",
      "5022/10000: train_loss: 3.712338381186128 train_error 41.50% test_error 41.00%\n",
      "================================5023===================================\n",
      "5023/10000: train_loss: 3.712238283678889 train_error 41.50% test_error 41.00%\n",
      "================================5024===================================\n",
      "5024/10000: train_loss: 3.7121383520960807 train_error 41.50% test_error 41.00%\n",
      "================================5025===================================\n",
      "5025/10000: train_loss: 3.712039052657783 train_error 41.50% test_error 41.00%\n",
      "================================5026===================================\n",
      "5026/10000: train_loss: 3.7119395838305356 train_error 41.50% test_error 41.50%\n",
      "================================5027===================================\n",
      "5027/10000: train_loss: 3.71183999247849 train_error 41.50% test_error 41.50%\n",
      "================================5028===================================\n",
      "5028/10000: train_loss: 3.7117404293268916 train_error 41.50% test_error 41.50%\n",
      "================================5029===================================\n",
      "5029/10000: train_loss: 3.7116408578306435 train_error 41.50% test_error 41.50%\n",
      "================================5030===================================\n",
      "5030/10000: train_loss: 3.7115415981411934 train_error 41.50% test_error 41.50%\n",
      "================================5031===================================\n",
      "5031/10000: train_loss: 3.711442091539502 train_error 41.50% test_error 41.50%\n",
      "================================5032===================================\n",
      "5032/10000: train_loss: 3.7113426094874735 train_error 41.50% test_error 41.50%\n",
      "================================5033===================================\n",
      "5033/10000: train_loss: 3.711243217885494 train_error 41.50% test_error 41.00%\n",
      "================================5034===================================\n",
      "5034/10000: train_loss: 3.7111438913643364 train_error 41.50% test_error 41.00%\n",
      "================================5035===================================\n",
      "5035/10000: train_loss: 3.7110446985065937 train_error 41.50% test_error 41.00%\n",
      "================================5036===================================\n",
      "5036/10000: train_loss: 3.710945694446564 train_error 41.50% test_error 41.00%\n",
      "================================5037===================================\n",
      "5037/10000: train_loss: 3.7108469917997717 train_error 41.50% test_error 41.00%\n",
      "================================5038===================================\n",
      "5038/10000: train_loss: 3.7107480419799685 train_error 41.50% test_error 41.00%\n",
      "================================5039===================================\n",
      "5039/10000: train_loss: 3.710648911632598 train_error 41.50% test_error 41.00%\n",
      "================================5040===================================\n",
      "5040/10000: train_loss: 3.7105496077239515 train_error 41.38% test_error 41.00%\n",
      "================================5041===================================\n",
      "5041/10000: train_loss: 3.7104507640749214 train_error 41.38% test_error 41.00%\n",
      "================================5042===================================\n",
      "5042/10000: train_loss: 3.7103524036705497 train_error 41.38% test_error 41.00%\n",
      "================================5043===================================\n",
      "5043/10000: train_loss: 3.7102545011416073 train_error 41.38% test_error 41.00%\n",
      "================================5044===================================\n",
      "5044/10000: train_loss: 3.710156523771584 train_error 41.38% test_error 41.00%\n",
      "================================5045===================================\n",
      "5045/10000: train_loss: 3.710059098750353 train_error 41.38% test_error 41.00%\n",
      "================================5046===================================\n",
      "5046/10000: train_loss: 3.709961642958224 train_error 41.38% test_error 41.00%\n",
      "================================5047===================================\n",
      "5047/10000: train_loss: 3.709864197447896 train_error 41.38% test_error 41.00%\n",
      "================================5048===================================\n",
      "5048/10000: train_loss: 3.709766335375607 train_error 41.38% test_error 41.00%\n",
      "================================5049===================================\n",
      "5049/10000: train_loss: 3.709668581970036 train_error 41.38% test_error 41.00%\n",
      "================================5050===================================\n",
      "5050/10000: train_loss: 3.7095710485056044 train_error 41.38% test_error 40.50%\n",
      "================================5051===================================\n",
      "5051/10000: train_loss: 3.709473409317434 train_error 41.38% test_error 40.50%\n",
      "================================5052===================================\n",
      "5052/10000: train_loss: 3.7093755232170222 train_error 41.38% test_error 40.50%\n",
      "================================5053===================================\n",
      "5053/10000: train_loss: 3.7092776537686585 train_error 41.25% test_error 40.50%\n",
      "================================5054===================================\n",
      "5054/10000: train_loss: 3.709179316610098 train_error 41.25% test_error 40.50%\n",
      "================================5055===================================\n",
      "5055/10000: train_loss: 3.70908072847873 train_error 41.25% test_error 40.50%\n",
      "================================5056===================================\n",
      "5056/10000: train_loss: 3.7089830567687754 train_error 41.25% test_error 40.00%\n",
      "================================5057===================================\n",
      "5057/10000: train_loss: 3.70888575963676 train_error 41.25% test_error 40.00%\n",
      "================================5058===================================\n",
      "5058/10000: train_loss: 3.7087887721136217 train_error 41.25% test_error 40.00%\n",
      "================================5059===================================\n",
      "5059/10000: train_loss: 3.7086920123174787 train_error 41.25% test_error 40.00%\n",
      "================================5060===================================\n",
      "5060/10000: train_loss: 3.7085947274789213 train_error 41.25% test_error 40.00%\n",
      "================================5061===================================\n",
      "5061/10000: train_loss: 3.70849744297564 train_error 41.25% test_error 40.00%\n",
      "================================5062===================================\n",
      "5062/10000: train_loss: 3.7083998879790308 train_error 41.25% test_error 40.00%\n",
      "================================5063===================================\n",
      "5063/10000: train_loss: 3.7083019429072737 train_error 41.25% test_error 40.00%\n",
      "================================5064===================================\n",
      "5064/10000: train_loss: 3.708203501813114 train_error 41.25% test_error 40.00%\n",
      "================================5065===================================\n",
      "5065/10000: train_loss: 3.708104548305273 train_error 41.25% test_error 40.00%\n",
      "================================5066===================================\n",
      "5066/10000: train_loss: 3.7080054291337725 train_error 41.25% test_error 40.00%\n",
      "================================5067===================================\n",
      "5067/10000: train_loss: 3.7079064039886 train_error 41.25% test_error 40.00%\n",
      "================================5068===================================\n",
      "5068/10000: train_loss: 3.707806736677885 train_error 41.25% test_error 40.00%\n",
      "================================5069===================================\n",
      "5069/10000: train_loss: 3.707706662900746 train_error 41.25% test_error 40.00%\n",
      "================================5070===================================\n",
      "5070/10000: train_loss: 3.7076066126301885 train_error 41.25% test_error 40.00%\n",
      "================================5071===================================\n",
      "5071/10000: train_loss: 3.7075071604177356 train_error 41.12% test_error 40.00%\n",
      "================================5072===================================\n",
      "5072/10000: train_loss: 3.7074071838706733 train_error 41.12% test_error 40.00%\n",
      "================================5073===================================\n",
      "5073/10000: train_loss: 3.7073067837953566 train_error 40.88% test_error 40.00%\n",
      "================================5074===================================\n",
      "5074/10000: train_loss: 3.7072069600969555 train_error 40.88% test_error 40.00%\n",
      "================================5075===================================\n",
      "5075/10000: train_loss: 3.7071071920916436 train_error 40.88% test_error 40.00%\n",
      "================================5076===================================\n",
      "5076/10000: train_loss: 3.7070076679438353 train_error 40.88% test_error 40.00%\n",
      "================================5077===================================\n",
      "5077/10000: train_loss: 3.7069083682820203 train_error 40.88% test_error 40.00%\n",
      "================================5078===================================\n",
      "5078/10000: train_loss: 3.7068090607598423 train_error 40.88% test_error 40.00%\n",
      "================================5079===================================\n",
      "5079/10000: train_loss: 3.7067099322006105 train_error 40.88% test_error 40.00%\n",
      "================================5080===================================\n",
      "5080/10000: train_loss: 3.7066111886873845 train_error 40.88% test_error 40.00%\n",
      "================================5081===================================\n",
      "5081/10000: train_loss: 3.706513116210699 train_error 40.88% test_error 40.00%\n",
      "================================5082===================================\n",
      "5082/10000: train_loss: 3.7064147284999494 train_error 40.88% test_error 40.00%\n",
      "================================5083===================================\n",
      "5083/10000: train_loss: 3.7063162298873062 train_error 40.88% test_error 40.00%\n",
      "================================5084===================================\n",
      "5084/10000: train_loss: 3.7062183008342977 train_error 40.88% test_error 40.00%\n",
      "================================5085===================================\n",
      "5085/10000: train_loss: 3.7061197663471104 train_error 40.75% test_error 40.00%\n",
      "================================5086===================================\n",
      "5086/10000: train_loss: 3.706020700894296 train_error 40.75% test_error 40.00%\n",
      "================================5087===================================\n",
      "5087/10000: train_loss: 3.7059202325716614 train_error 40.75% test_error 40.00%\n",
      "================================5088===================================\n",
      "5088/10000: train_loss: 3.705818792693317 train_error 40.75% test_error 40.00%\n",
      "================================5089===================================\n",
      "5089/10000: train_loss: 3.7057171845436097 train_error 40.75% test_error 39.50%\n",
      "================================5090===================================\n",
      "5090/10000: train_loss: 3.705615256689489 train_error 40.75% test_error 39.50%\n",
      "================================5091===================================\n",
      "5091/10000: train_loss: 3.705512786842883 train_error 40.75% test_error 39.50%\n",
      "================================5092===================================\n",
      "5092/10000: train_loss: 3.705409678332508 train_error 40.62% test_error 39.50%\n",
      "================================5093===================================\n",
      "5093/10000: train_loss: 3.7053063646331426 train_error 40.62% test_error 39.50%\n",
      "================================5094===================================\n",
      "5094/10000: train_loss: 3.7052027950435877 train_error 40.62% test_error 39.50%\n",
      "================================5095===================================\n",
      "5095/10000: train_loss: 3.7050988583266733 train_error 40.62% test_error 39.50%\n",
      "================================5096===================================\n",
      "5096/10000: train_loss: 3.7049945417791608 train_error 40.62% test_error 39.50%\n",
      "================================5097===================================\n",
      "5097/10000: train_loss: 3.7048896691948174 train_error 40.62% test_error 39.50%\n",
      "================================5098===================================\n",
      "5098/10000: train_loss: 3.7047836290672422 train_error 40.62% test_error 39.50%\n",
      "================================5099===================================\n",
      "5099/10000: train_loss: 3.7046759803965688 train_error 40.62% test_error 39.50%\n",
      "================================5100===================================\n",
      "5100/10000: train_loss: 3.7045684466138478 train_error 40.62% test_error 39.50%\n",
      "================================5101===================================\n",
      "5101/10000: train_loss: 3.7044593305140734 train_error 40.62% test_error 39.00%\n",
      "================================5102===================================\n",
      "5102/10000: train_loss: 3.7043498225882647 train_error 40.50% test_error 39.00%\n",
      "================================5103===================================\n",
      "5103/10000: train_loss: 3.7042396964132784 train_error 40.50% test_error 39.00%\n",
      "================================5104===================================\n",
      "5104/10000: train_loss: 3.70412953030318 train_error 40.50% test_error 39.00%\n",
      "================================5105===================================\n",
      "5105/10000: train_loss: 3.7040194018930195 train_error 40.50% test_error 39.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5106===================================\n",
      "5106/10000: train_loss: 3.7039093390479687 train_error 40.50% test_error 39.00%\n",
      "================================5107===================================\n",
      "5107/10000: train_loss: 3.703799012117088 train_error 40.50% test_error 39.00%\n",
      "================================5108===================================\n",
      "5108/10000: train_loss: 3.703688555769622 train_error 40.50% test_error 39.00%\n",
      "================================5109===================================\n",
      "5109/10000: train_loss: 3.703577739335597 train_error 40.50% test_error 39.00%\n",
      "================================5110===================================\n",
      "5110/10000: train_loss: 3.703466566167772 train_error 40.50% test_error 39.00%\n",
      "================================5111===================================\n",
      "5111/10000: train_loss: 3.7033552327007055 train_error 40.50% test_error 39.00%\n",
      "================================5112===================================\n",
      "5112/10000: train_loss: 3.7032440373674036 train_error 40.38% test_error 39.00%\n",
      "================================5113===================================\n",
      "5113/10000: train_loss: 3.7031328786537054 train_error 40.38% test_error 39.00%\n",
      "================================5114===================================\n",
      "5114/10000: train_loss: 3.7030217019468545 train_error 40.38% test_error 39.00%\n",
      "================================5115===================================\n",
      "5115/10000: train_loss: 3.7029107274860142 train_error 40.38% test_error 39.00%\n",
      "================================5116===================================\n",
      "5116/10000: train_loss: 3.702800169400871 train_error 40.38% test_error 39.00%\n",
      "================================5117===================================\n",
      "5117/10000: train_loss: 3.7026890812814237 train_error 40.38% test_error 39.00%\n",
      "================================5118===================================\n",
      "5118/10000: train_loss: 3.702578085176647 train_error 40.38% test_error 39.00%\n",
      "================================5119===================================\n",
      "5119/10000: train_loss: 3.7024671164155003 train_error 40.38% test_error 39.00%\n",
      "================================5120===================================\n",
      "5120/10000: train_loss: 3.702356754094362 train_error 40.38% test_error 39.00%\n",
      "================================5121===================================\n",
      "5121/10000: train_loss: 3.7022470712289217 train_error 40.38% test_error 39.00%\n",
      "================================5122===================================\n",
      "5122/10000: train_loss: 3.7021376804634927 train_error 40.38% test_error 39.00%\n",
      "================================5123===================================\n",
      "5123/10000: train_loss: 3.7020279932767153 train_error 40.38% test_error 39.00%\n",
      "================================5124===================================\n",
      "5124/10000: train_loss: 3.7019178223237397 train_error 40.50% test_error 39.00%\n",
      "================================5125===================================\n",
      "5125/10000: train_loss: 3.7018072447553276 train_error 40.50% test_error 39.00%\n",
      "================================5126===================================\n",
      "5126/10000: train_loss: 3.701695733182132 train_error 40.50% test_error 39.00%\n",
      "================================5127===================================\n",
      "5127/10000: train_loss: 3.701583963148296 train_error 40.62% test_error 39.00%\n",
      "================================5128===================================\n",
      "5128/10000: train_loss: 3.701472415216267 train_error 40.62% test_error 39.00%\n",
      "================================5129===================================\n",
      "5129/10000: train_loss: 3.701361430101097 train_error 40.62% test_error 39.00%\n",
      "================================5130===================================\n",
      "5130/10000: train_loss: 3.70125038664788 train_error 40.62% test_error 39.00%\n",
      "================================5131===================================\n",
      "5131/10000: train_loss: 3.7011386846750978 train_error 40.62% test_error 39.00%\n",
      "================================5132===================================\n",
      "5132/10000: train_loss: 3.7010261361673473 train_error 40.62% test_error 39.00%\n",
      "================================5133===================================\n",
      "5133/10000: train_loss: 3.700913932286203 train_error 40.62% test_error 39.00%\n",
      "================================5134===================================\n",
      "5134/10000: train_loss: 3.700801655985415 train_error 40.50% test_error 39.00%\n",
      "================================5135===================================\n",
      "5135/10000: train_loss: 3.700689382739365 train_error 40.50% test_error 39.00%\n",
      "================================5136===================================\n",
      "5136/10000: train_loss: 3.700577216744423 train_error 40.50% test_error 39.00%\n",
      "================================5137===================================\n",
      "5137/10000: train_loss: 3.700465318188071 train_error 40.50% test_error 39.00%\n",
      "================================5138===================================\n",
      "5138/10000: train_loss: 3.7003540019318466 train_error 40.50% test_error 39.00%\n",
      "================================5139===================================\n",
      "5139/10000: train_loss: 3.700242894850671 train_error 40.50% test_error 39.00%\n",
      "================================5140===================================\n",
      "5140/10000: train_loss: 3.7001324444636703 train_error 40.50% test_error 39.00%\n",
      "================================5141===================================\n",
      "5141/10000: train_loss: 3.7000229448452595 train_error 40.50% test_error 39.00%\n",
      "================================5142===================================\n",
      "5142/10000: train_loss: 3.699913498349488 train_error 40.50% test_error 39.00%\n",
      "================================5143===================================\n",
      "5143/10000: train_loss: 3.6998039254918695 train_error 40.50% test_error 39.00%\n",
      "================================5144===================================\n",
      "5144/10000: train_loss: 3.699694336540997 train_error 40.50% test_error 39.00%\n",
      "================================5145===================================\n",
      "5145/10000: train_loss: 3.6995848365500574 train_error 40.50% test_error 39.00%\n",
      "================================5146===================================\n",
      "5146/10000: train_loss: 3.6994754686951636 train_error 40.50% test_error 39.00%\n",
      "================================5147===================================\n",
      "5147/10000: train_loss: 3.6993663107603787 train_error 40.50% test_error 39.00%\n",
      "================================5148===================================\n",
      "5148/10000: train_loss: 3.6992570525035267 train_error 40.50% test_error 39.00%\n",
      "================================5149===================================\n",
      "5149/10000: train_loss: 3.6991476617008447 train_error 40.50% test_error 39.00%\n",
      "================================5150===================================\n",
      "5150/10000: train_loss: 3.6990380835533143 train_error 40.50% test_error 39.00%\n",
      "================================5151===================================\n",
      "5151/10000: train_loss: 3.6989284811541436 train_error 40.50% test_error 39.00%\n",
      "================================5152===================================\n",
      "5152/10000: train_loss: 3.6988187908381223 train_error 40.38% test_error 39.00%\n",
      "================================5153===================================\n",
      "5153/10000: train_loss: 3.6987089639157054 train_error 40.38% test_error 39.00%\n",
      "================================5154===================================\n",
      "5154/10000: train_loss: 3.698599035926163 train_error 40.38% test_error 39.00%\n",
      "================================5155===================================\n",
      "5155/10000: train_loss: 3.698489471897483 train_error 40.38% test_error 39.00%\n",
      "================================5156===================================\n",
      "5156/10000: train_loss: 3.698379996940494 train_error 40.38% test_error 39.00%\n",
      "================================5157===================================\n",
      "5157/10000: train_loss: 3.698270695097744 train_error 40.38% test_error 39.00%\n",
      "================================5158===================================\n",
      "5158/10000: train_loss: 3.6981616635248065 train_error 40.50% test_error 39.00%\n",
      "================================5159===================================\n",
      "5159/10000: train_loss: 3.6980530106276275 train_error 40.50% test_error 39.00%\n",
      "================================5160===================================\n",
      "5160/10000: train_loss: 3.697944183014333 train_error 40.50% test_error 39.00%\n",
      "================================5161===================================\n",
      "5161/10000: train_loss: 3.6978343861922625 train_error 40.50% test_error 39.00%\n",
      "================================5162===================================\n",
      "5162/10000: train_loss: 3.697724825590849 train_error 40.50% test_error 39.00%\n",
      "================================5163===================================\n",
      "5163/10000: train_loss: 3.6976154205948113 train_error 40.50% test_error 39.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5164===================================\n",
      "5164/10000: train_loss: 3.697506203874946 train_error 40.50% test_error 39.00%\n",
      "================================5165===================================\n",
      "5165/10000: train_loss: 3.697397317476571 train_error 40.50% test_error 39.00%\n",
      "================================5166===================================\n",
      "5166/10000: train_loss: 3.697289082147181 train_error 40.50% test_error 39.00%\n",
      "================================5167===================================\n",
      "5167/10000: train_loss: 3.6971810986846685 train_error 40.50% test_error 39.00%\n",
      "================================5168===================================\n",
      "5168/10000: train_loss: 3.697072732411325 train_error 40.50% test_error 39.00%\n",
      "================================5169===================================\n",
      "5169/10000: train_loss: 3.696962996087968 train_error 40.50% test_error 39.00%\n",
      "================================5170===================================\n",
      "5170/10000: train_loss: 3.696853140443564 train_error 40.50% test_error 39.00%\n",
      "================================5171===================================\n",
      "5171/10000: train_loss: 3.6967429146170616 train_error 40.38% test_error 39.00%\n",
      "================================5172===================================\n",
      "5172/10000: train_loss: 3.696633038930595 train_error 40.38% test_error 39.00%\n",
      "================================5173===================================\n",
      "5173/10000: train_loss: 3.6965230184048417 train_error 40.38% test_error 39.00%\n",
      "================================5174===================================\n",
      "5174/10000: train_loss: 3.6964126850664614 train_error 40.38% test_error 39.00%\n",
      "================================5175===================================\n",
      "5175/10000: train_loss: 3.6963023634999987 train_error 40.38% test_error 39.00%\n",
      "================================5176===================================\n",
      "5176/10000: train_loss: 3.6961920573562383 train_error 40.38% test_error 39.00%\n",
      "================================5177===================================\n",
      "5177/10000: train_loss: 3.6960817479342225 train_error 40.38% test_error 39.00%\n",
      "================================5178===================================\n",
      "5178/10000: train_loss: 3.6959712863340974 train_error 40.38% test_error 39.00%\n",
      "================================5179===================================\n",
      "5179/10000: train_loss: 3.695860895514488 train_error 40.38% test_error 39.00%\n",
      "================================5180===================================\n",
      "5180/10000: train_loss: 3.695750289931894 train_error 40.38% test_error 39.00%\n",
      "================================5181===================================\n",
      "5181/10000: train_loss: 3.695639597065747 train_error 40.38% test_error 39.00%\n",
      "================================5182===================================\n",
      "5182/10000: train_loss: 3.6955285850167274 train_error 40.38% test_error 39.50%\n",
      "================================5183===================================\n",
      "5183/10000: train_loss: 3.6954170767962933 train_error 40.38% test_error 39.50%\n",
      "================================5184===================================\n",
      "5184/10000: train_loss: 3.6953049952164294 train_error 40.38% test_error 39.50%\n",
      "================================5185===================================\n",
      "5185/10000: train_loss: 3.695192673355341 train_error 40.38% test_error 39.50%\n",
      "================================5186===================================\n",
      "5186/10000: train_loss: 3.695080063305795 train_error 40.38% test_error 39.50%\n",
      "================================5187===================================\n",
      "5187/10000: train_loss: 3.6949674300849438 train_error 40.38% test_error 39.50%\n",
      "================================5188===================================\n",
      "5188/10000: train_loss: 3.694855862446129 train_error 40.38% test_error 39.00%\n",
      "================================5189===================================\n",
      "5189/10000: train_loss: 3.69474600456655 train_error 40.38% test_error 39.00%\n",
      "================================5190===================================\n",
      "5190/10000: train_loss: 3.6946360261738302 train_error 40.38% test_error 39.00%\n",
      "================================5191===================================\n",
      "5191/10000: train_loss: 3.694526605568826 train_error 40.38% test_error 39.00%\n",
      "================================5192===================================\n",
      "5192/10000: train_loss: 3.694417184256017 train_error 40.38% test_error 39.00%\n",
      "================================5193===================================\n",
      "5193/10000: train_loss: 3.694307678863406 train_error 40.38% test_error 39.00%\n",
      "================================5194===================================\n",
      "5194/10000: train_loss: 3.6941981312260035 train_error 40.38% test_error 39.00%\n",
      "================================5195===================================\n",
      "5195/10000: train_loss: 3.6940884700044987 train_error 40.38% test_error 39.00%\n",
      "================================5196===================================\n",
      "5196/10000: train_loss: 3.6939788335561747 train_error 40.38% test_error 39.00%\n",
      "================================5197===================================\n",
      "5197/10000: train_loss: 3.693869183957577 train_error 40.38% test_error 39.00%\n",
      "================================5198===================================\n",
      "5198/10000: train_loss: 3.6937593628838656 train_error 40.38% test_error 39.00%\n",
      "================================5199===================================\n",
      "5199/10000: train_loss: 3.693649099394679 train_error 40.25% test_error 39.00%\n",
      "================================5200===================================\n",
      "5200/10000: train_loss: 3.6935386936739087 train_error 40.25% test_error 39.00%\n",
      "================================5201===================================\n",
      "5201/10000: train_loss: 3.6934281028062106 train_error 40.25% test_error 39.00%\n",
      "================================5202===================================\n",
      "5202/10000: train_loss: 3.693317617699504 train_error 40.25% test_error 39.00%\n",
      "================================5203===================================\n",
      "5203/10000: train_loss: 3.6932068388164043 train_error 40.25% test_error 39.00%\n",
      "================================5204===================================\n",
      "5204/10000: train_loss: 3.693096051439643 train_error 40.25% test_error 39.00%\n",
      "================================5205===================================\n",
      "5205/10000: train_loss: 3.6929856982827185 train_error 40.25% test_error 39.00%\n",
      "================================5206===================================\n",
      "5206/10000: train_loss: 3.692875641360879 train_error 40.25% test_error 39.00%\n",
      "================================5207===================================\n",
      "5207/10000: train_loss: 3.6927657662332054 train_error 40.25% test_error 39.00%\n",
      "================================5208===================================\n",
      "5208/10000: train_loss: 3.6926553020626307 train_error 40.25% test_error 39.00%\n",
      "================================5209===================================\n",
      "5209/10000: train_loss: 3.6925426520779725 train_error 40.25% test_error 39.00%\n",
      "================================5210===================================\n",
      "5210/10000: train_loss: 3.6924301690235732 train_error 40.25% test_error 39.00%\n",
      "================================5211===================================\n",
      "5211/10000: train_loss: 3.6923174225911497 train_error 40.25% test_error 39.00%\n",
      "================================5212===================================\n",
      "5212/10000: train_loss: 3.692204736880958 train_error 40.25% test_error 39.00%\n",
      "================================5213===================================\n",
      "5213/10000: train_loss: 3.6920920307934284 train_error 40.25% test_error 39.00%\n",
      "================================5214===================================\n",
      "5214/10000: train_loss: 3.6919793152436613 train_error 40.25% test_error 39.00%\n",
      "================================5215===================================\n",
      "5215/10000: train_loss: 3.6918665264919404 train_error 40.25% test_error 39.00%\n",
      "================================5216===================================\n",
      "5216/10000: train_loss: 3.69175365742296 train_error 40.25% test_error 39.00%\n",
      "================================5217===================================\n",
      "5217/10000: train_loss: 3.6916407099738717 train_error 40.25% test_error 39.00%\n",
      "================================5218===================================\n",
      "5218/10000: train_loss: 3.6915278887376193 train_error 40.25% test_error 39.00%\n",
      "================================5219===================================\n",
      "5219/10000: train_loss: 3.6914153545722366 train_error 40.25% test_error 39.00%\n",
      "================================5220===================================\n",
      "5220/10000: train_loss: 3.6913019715994597 train_error 40.25% test_error 39.00%\n",
      "================================5221===================================\n",
      "5221/10000: train_loss: 3.691189160346985 train_error 40.25% test_error 39.00%\n",
      "================================5222===================================\n",
      "5222/10000: train_loss: 3.691077735833824 train_error 40.25% test_error 39.00%\n",
      "================================5223===================================\n",
      "5223/10000: train_loss: 3.6909665466099977 train_error 40.25% test_error 39.00%\n",
      "================================5224===================================\n",
      "5224/10000: train_loss: 3.690855241753161 train_error 40.25% test_error 39.00%\n",
      "================================5225===================================\n",
      "5225/10000: train_loss: 3.6907438459619875 train_error 40.25% test_error 39.00%\n",
      "================================5226===================================\n",
      "5226/10000: train_loss: 3.690632459484041 train_error 40.25% test_error 39.00%\n",
      "================================5227===================================\n",
      "5227/10000: train_loss: 3.690521131940186 train_error 40.25% test_error 39.00%\n",
      "================================5228===================================\n",
      "5228/10000: train_loss: 3.6904098711535336 train_error 40.25% test_error 39.00%\n",
      "================================5229===================================\n",
      "5229/10000: train_loss: 3.690299143530429 train_error 40.25% test_error 39.00%\n",
      "================================5230===================================\n",
      "5230/10000: train_loss: 3.690188884325325 train_error 40.25% test_error 39.00%\n",
      "================================5231===================================\n",
      "5231/10000: train_loss: 3.6900785230100155 train_error 40.25% test_error 39.00%\n",
      "================================5232===================================\n",
      "5232/10000: train_loss: 3.6899675000831484 train_error 40.25% test_error 38.50%\n",
      "================================5233===================================\n",
      "5233/10000: train_loss: 3.6898565863445403 train_error 40.25% test_error 38.50%\n",
      "================================5234===================================\n",
      "5234/10000: train_loss: 3.689745737425983 train_error 40.25% test_error 38.50%\n",
      "================================5235===================================\n",
      "5235/10000: train_loss: 3.689634911380708 train_error 40.12% test_error 38.50%\n",
      "================================5236===================================\n",
      "5236/10000: train_loss: 3.689523765146732 train_error 40.12% test_error 38.50%\n",
      "================================5237===================================\n",
      "5237/10000: train_loss: 3.6894122917577623 train_error 40.12% test_error 38.50%\n",
      "================================5238===================================\n",
      "5238/10000: train_loss: 3.6893005318567154 train_error 40.12% test_error 38.50%\n",
      "================================5239===================================\n",
      "5239/10000: train_loss: 3.6891884550079705 train_error 40.12% test_error 38.50%\n",
      "================================5240===================================\n",
      "5240/10000: train_loss: 3.6890759830176827 train_error 40.12% test_error 38.50%\n",
      "================================5241===================================\n",
      "5241/10000: train_loss: 3.688964252620935 train_error 40.12% test_error 38.50%\n",
      "================================5242===================================\n",
      "5242/10000: train_loss: 3.6888527903705834 train_error 40.25% test_error 38.50%\n",
      "================================5243===================================\n",
      "5243/10000: train_loss: 3.688741333335638 train_error 40.25% test_error 38.50%\n",
      "================================5244===================================\n",
      "5244/10000: train_loss: 3.688629874140024 train_error 40.25% test_error 38.50%\n",
      "================================5245===================================\n",
      "5245/10000: train_loss: 3.6885185327753423 train_error 40.25% test_error 39.00%\n",
      "================================5246===================================\n",
      "5246/10000: train_loss: 3.6884072954952716 train_error 40.25% test_error 39.00%\n",
      "================================5247===================================\n",
      "5247/10000: train_loss: 3.6882961101830003 train_error 40.25% test_error 39.00%\n",
      "================================5248===================================\n",
      "5248/10000: train_loss: 3.6881846393272277 train_error 40.25% test_error 39.00%\n",
      "================================5249===================================\n",
      "5249/10000: train_loss: 3.6880731654539702 train_error 40.25% test_error 39.00%\n",
      "================================5250===================================\n",
      "5250/10000: train_loss: 3.6879616812989116 train_error 40.25% test_error 39.00%\n",
      "================================5251===================================\n",
      "5251/10000: train_loss: 3.6878504808992143 train_error 40.25% test_error 39.00%\n",
      "================================5252===================================\n",
      "5252/10000: train_loss: 3.6877385675907135 train_error 40.25% test_error 39.00%\n",
      "================================5253===================================\n",
      "5253/10000: train_loss: 3.687626668065786 train_error 40.25% test_error 39.00%\n",
      "================================5254===================================\n",
      "5254/10000: train_loss: 3.6875148112326857 train_error 40.25% test_error 39.00%\n",
      "================================5255===================================\n",
      "5255/10000: train_loss: 3.687403302304447 train_error 40.25% test_error 38.50%\n",
      "================================5256===================================\n",
      "5256/10000: train_loss: 3.6872915130853654 train_error 40.25% test_error 38.50%\n",
      "================================5257===================================\n",
      "5257/10000: train_loss: 3.6871795512735845 train_error 40.25% test_error 38.50%\n",
      "================================5258===================================\n",
      "5258/10000: train_loss: 3.6870682360231877 train_error 40.25% test_error 38.50%\n",
      "================================5259===================================\n",
      "5259/10000: train_loss: 3.686957009881735 train_error 40.25% test_error 38.50%\n",
      "================================5260===================================\n",
      "5260/10000: train_loss: 3.6868455559015274 train_error 40.25% test_error 38.50%\n",
      "================================5261===================================\n",
      "5261/10000: train_loss: 3.686733968667686 train_error 40.25% test_error 38.50%\n",
      "================================5262===================================\n",
      "5262/10000: train_loss: 3.6866219766438006 train_error 40.25% test_error 38.50%\n",
      "================================5263===================================\n",
      "5263/10000: train_loss: 3.686510166749358 train_error 40.25% test_error 38.50%\n",
      "================================5264===================================\n",
      "5264/10000: train_loss: 3.6863985794037584 train_error 40.25% test_error 38.50%\n",
      "================================5265===================================\n",
      "5265/10000: train_loss: 3.686287656649947 train_error 40.12% test_error 38.50%\n",
      "================================5266===================================\n",
      "5266/10000: train_loss: 3.6861761784180995 train_error 40.12% test_error 38.50%\n",
      "================================5267===================================\n",
      "5267/10000: train_loss: 3.686063581965864 train_error 40.12% test_error 38.50%\n",
      "================================5268===================================\n",
      "5268/10000: train_loss: 3.685950392857194 train_error 40.12% test_error 38.50%\n",
      "================================5269===================================\n",
      "5269/10000: train_loss: 3.685837172456086 train_error 40.12% test_error 38.50%\n",
      "================================5270===================================\n",
      "5270/10000: train_loss: 3.6857244835793974 train_error 40.00% test_error 38.50%\n",
      "================================5271===================================\n",
      "5271/10000: train_loss: 3.6856116463989017 train_error 40.00% test_error 38.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5272===================================\n",
      "5272/10000: train_loss: 3.6854986972361807 train_error 40.00% test_error 38.50%\n",
      "================================5273===================================\n",
      "5273/10000: train_loss: 3.6853856558352707 train_error 40.00% test_error 38.50%\n",
      "================================5274===================================\n",
      "5274/10000: train_loss: 3.6852728194370865 train_error 40.00% test_error 38.50%\n",
      "================================5275===================================\n",
      "5275/10000: train_loss: 3.685160300284624 train_error 40.00% test_error 38.50%\n",
      "================================5276===================================\n",
      "5276/10000: train_loss: 3.68504776481539 train_error 40.00% test_error 38.50%\n",
      "================================5277===================================\n",
      "5277/10000: train_loss: 3.6849354746192695 train_error 40.00% test_error 38.50%\n",
      "================================5278===================================\n",
      "5278/10000: train_loss: 3.6848234426230193 train_error 40.00% test_error 38.50%\n",
      "================================5279===================================\n",
      "5279/10000: train_loss: 3.6847108004242184 train_error 40.00% test_error 38.50%\n",
      "================================5280===================================\n",
      "5280/10000: train_loss: 3.684597745127976 train_error 40.00% test_error 38.50%\n",
      "================================5281===================================\n",
      "5281/10000: train_loss: 3.684485055096448 train_error 40.00% test_error 38.50%\n",
      "================================5282===================================\n",
      "5282/10000: train_loss: 3.6843722658604383 train_error 40.00% test_error 38.50%\n",
      "================================5283===================================\n",
      "5283/10000: train_loss: 3.6842592807486656 train_error 40.00% test_error 38.50%\n",
      "================================5284===================================\n",
      "5284/10000: train_loss: 3.6841462524607778 train_error 40.00% test_error 38.50%\n",
      "================================5285===================================\n",
      "5285/10000: train_loss: 3.6840337644144894 train_error 40.00% test_error 38.50%\n",
      "================================5286===================================\n",
      "5286/10000: train_loss: 3.683921376466751 train_error 40.00% test_error 38.50%\n",
      "================================5287===================================\n",
      "5287/10000: train_loss: 3.6838089410960673 train_error 40.00% test_error 38.50%\n",
      "================================5288===================================\n",
      "5288/10000: train_loss: 3.683696302585304 train_error 40.00% test_error 38.50%\n",
      "================================5289===================================\n",
      "5289/10000: train_loss: 3.6835836830362676 train_error 40.00% test_error 38.50%\n",
      "================================5290===================================\n",
      "5290/10000: train_loss: 3.6834709399566052 train_error 40.00% test_error 38.50%\n",
      "================================5291===================================\n",
      "5291/10000: train_loss: 3.683358060605824 train_error 40.00% test_error 38.50%\n",
      "================================5292===================================\n",
      "5292/10000: train_loss: 3.6832451206073165 train_error 40.00% test_error 38.50%\n",
      "================================5293===================================\n",
      "5293/10000: train_loss: 3.683132187537849 train_error 40.00% test_error 38.50%\n",
      "================================5294===================================\n",
      "5294/10000: train_loss: 3.683019286319613 train_error 40.00% test_error 38.50%\n",
      "================================5295===================================\n",
      "5295/10000: train_loss: 3.682906479984522 train_error 40.00% test_error 38.50%\n",
      "================================5296===================================\n",
      "5296/10000: train_loss: 3.6827936741709713 train_error 40.00% test_error 38.50%\n",
      "================================5297===================================\n",
      "5297/10000: train_loss: 3.6826809388771653 train_error 40.00% test_error 38.50%\n",
      "================================5298===================================\n",
      "5298/10000: train_loss: 3.682568200342357 train_error 40.00% test_error 38.50%\n",
      "================================5299===================================\n",
      "5299/10000: train_loss: 3.682455482110381 train_error 40.00% test_error 38.50%\n",
      "================================5300===================================\n",
      "5300/10000: train_loss: 3.6823428792506454 train_error 40.00% test_error 38.50%\n",
      "================================5301===================================\n",
      "5301/10000: train_loss: 3.6822303786873816 train_error 40.00% test_error 38.50%\n",
      "================================5302===================================\n",
      "5302/10000: train_loss: 3.6821183126419785 train_error 40.00% test_error 38.50%\n",
      "================================5303===================================\n",
      "5303/10000: train_loss: 3.6820067247003316 train_error 40.00% test_error 38.50%\n",
      "================================5304===================================\n",
      "5304/10000: train_loss: 3.6818951986357566 train_error 40.00% test_error 38.50%\n",
      "================================5305===================================\n",
      "5305/10000: train_loss: 3.6817834070697426 train_error 40.00% test_error 38.50%\n",
      "================================5306===================================\n",
      "5306/10000: train_loss: 3.681671475470066 train_error 40.00% test_error 38.50%\n",
      "================================5307===================================\n",
      "5307/10000: train_loss: 3.6815597543120386 train_error 40.00% test_error 38.50%\n",
      "================================5308===================================\n",
      "5308/10000: train_loss: 3.6814481604099276 train_error 40.00% test_error 38.50%\n",
      "================================5309===================================\n",
      "5309/10000: train_loss: 3.681336652338505 train_error 40.00% test_error 38.50%\n",
      "================================5310===================================\n",
      "5310/10000: train_loss: 3.6812251409143206 train_error 40.00% test_error 38.50%\n",
      "================================5311===================================\n",
      "5311/10000: train_loss: 3.6811136185750364 train_error 40.00% test_error 38.50%\n",
      "================================5312===================================\n",
      "5312/10000: train_loss: 3.6810021093860263 train_error 40.00% test_error 38.50%\n",
      "================================5313===================================\n",
      "5313/10000: train_loss: 3.6808906807005406 train_error 39.88% test_error 38.50%\n",
      "================================5314===================================\n",
      "5314/10000: train_loss: 3.680779022984207 train_error 39.88% test_error 38.50%\n",
      "================================5315===================================\n",
      "5315/10000: train_loss: 3.680667365118861 train_error 39.88% test_error 38.50%\n",
      "================================5316===================================\n",
      "5316/10000: train_loss: 3.680555994398892 train_error 39.88% test_error 38.50%\n",
      "================================5317===================================\n",
      "5317/10000: train_loss: 3.680444865524769 train_error 39.88% test_error 38.50%\n",
      "================================5318===================================\n",
      "5318/10000: train_loss: 3.680333591550588 train_error 39.88% test_error 38.50%\n",
      "================================5319===================================\n",
      "5319/10000: train_loss: 3.680222296975553 train_error 39.88% test_error 38.50%\n",
      "================================5320===================================\n",
      "5320/10000: train_loss: 3.680111002475023 train_error 39.88% test_error 38.50%\n",
      "================================5321===================================\n",
      "5321/10000: train_loss: 3.6799998236075044 train_error 39.88% test_error 38.50%\n",
      "================================5322===================================\n",
      "5322/10000: train_loss: 3.6798887414485213 train_error 39.88% test_error 38.50%\n",
      "================================5323===================================\n",
      "5323/10000: train_loss: 3.679778316244483 train_error 39.88% test_error 38.50%\n",
      "================================5324===================================\n",
      "5324/10000: train_loss: 3.6796683087572455 train_error 39.88% test_error 38.50%\n",
      "================================5325===================================\n",
      "5325/10000: train_loss: 3.679558593854308 train_error 39.88% test_error 38.50%\n",
      "================================5326===================================\n",
      "5326/10000: train_loss: 3.6794488521292807 train_error 39.88% test_error 38.50%\n",
      "================================5327===================================\n",
      "5327/10000: train_loss: 3.6793396136909724 train_error 39.88% test_error 38.50%\n",
      "================================5328===================================\n",
      "5328/10000: train_loss: 3.6792307699844238 train_error 39.88% test_error 38.50%\n",
      "================================5329===================================\n",
      "5329/10000: train_loss: 3.679121862500906 train_error 39.88% test_error 38.50%\n",
      "================================5330===================================\n",
      "5330/10000: train_loss: 3.679012934453785 train_error 39.88% test_error 38.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5331===================================\n",
      "5331/10000: train_loss: 3.6789037776738405 train_error 39.88% test_error 38.50%\n",
      "================================5332===================================\n",
      "5332/10000: train_loss: 3.6787945909053086 train_error 39.88% test_error 38.50%\n",
      "================================5333===================================\n",
      "5333/10000: train_loss: 3.6786852256953715 train_error 39.88% test_error 38.50%\n",
      "================================5334===================================\n",
      "5334/10000: train_loss: 3.678575153686106 train_error 39.88% test_error 38.50%\n",
      "================================5335===================================\n",
      "5335/10000: train_loss: 3.678465357087553 train_error 39.88% test_error 38.50%\n",
      "================================5336===================================\n",
      "5336/10000: train_loss: 3.678355530537665 train_error 39.88% test_error 38.50%\n",
      "================================5337===================================\n",
      "5337/10000: train_loss: 3.6782458216696976 train_error 39.88% test_error 38.50%\n",
      "================================5338===================================\n",
      "5338/10000: train_loss: 3.678135639689863 train_error 39.88% test_error 38.50%\n",
      "================================5339===================================\n",
      "5339/10000: train_loss: 3.6780240657180547 train_error 39.88% test_error 38.50%\n",
      "================================5340===================================\n",
      "5340/10000: train_loss: 3.6779121645167474 train_error 39.75% test_error 38.50%\n",
      "================================5341===================================\n",
      "5341/10000: train_loss: 3.6778001052141187 train_error 39.62% test_error 38.50%\n",
      "================================5342===================================\n",
      "5342/10000: train_loss: 3.677687915228307 train_error 39.50% test_error 38.50%\n",
      "================================5343===================================\n",
      "5343/10000: train_loss: 3.6775762272626165 train_error 39.50% test_error 38.50%\n",
      "================================5344===================================\n",
      "5344/10000: train_loss: 3.6774648567661643 train_error 39.50% test_error 38.50%\n",
      "================================5345===================================\n",
      "5345/10000: train_loss: 3.677353543713689 train_error 39.50% test_error 38.50%\n",
      "================================5346===================================\n",
      "5346/10000: train_loss: 3.6772422682121397 train_error 39.50% test_error 38.50%\n",
      "================================5347===================================\n",
      "5347/10000: train_loss: 3.677131160534918 train_error 39.50% test_error 38.50%\n",
      "================================5348===================================\n",
      "5348/10000: train_loss: 3.677020100429654 train_error 39.50% test_error 38.50%\n",
      "================================5349===================================\n",
      "5349/10000: train_loss: 3.6769097085297107 train_error 39.50% test_error 38.50%\n",
      "================================5350===================================\n",
      "5350/10000: train_loss: 3.676799700595439 train_error 39.50% test_error 38.50%\n",
      "================================5351===================================\n",
      "5351/10000: train_loss: 3.6766897700726986 train_error 39.50% test_error 38.50%\n",
      "================================5352===================================\n",
      "5352/10000: train_loss: 3.6765795321390033 train_error 39.50% test_error 38.50%\n",
      "================================5353===================================\n",
      "5353/10000: train_loss: 3.6764709814265366 train_error 39.50% test_error 38.50%\n",
      "================================5354===================================\n",
      "5354/10000: train_loss: 3.6763625344634057 train_error 39.50% test_error 38.50%\n",
      "================================5355===================================\n",
      "5355/10000: train_loss: 3.6762534872815014 train_error 39.50% test_error 38.50%\n",
      "================================5356===================================\n",
      "5356/10000: train_loss: 3.676143385656178 train_error 39.50% test_error 38.50%\n",
      "================================5357===================================\n",
      "5357/10000: train_loss: 3.6760340153798463 train_error 39.50% test_error 38.50%\n",
      "================================5358===================================\n",
      "5358/10000: train_loss: 3.6759244283288717 train_error 39.50% test_error 38.50%\n",
      "================================5359===================================\n",
      "5359/10000: train_loss: 3.675815007649362 train_error 39.50% test_error 38.50%\n",
      "================================5360===================================\n",
      "5360/10000: train_loss: 3.6757060373574495 train_error 39.50% test_error 38.50%\n",
      "================================5361===================================\n",
      "5361/10000: train_loss: 3.675597245916724 train_error 39.50% test_error 38.50%\n",
      "================================5362===================================\n",
      "5362/10000: train_loss: 3.675488364696503 train_error 39.50% test_error 38.50%\n",
      "================================5363===================================\n",
      "5363/10000: train_loss: 3.6753794666752224 train_error 39.50% test_error 38.50%\n",
      "================================5364===================================\n",
      "5364/10000: train_loss: 3.6752704907208678 train_error 39.38% test_error 38.50%\n",
      "================================5365===================================\n",
      "5365/10000: train_loss: 3.6751612344384195 train_error 39.38% test_error 38.50%\n",
      "================================5366===================================\n",
      "5366/10000: train_loss: 3.67505246527493 train_error 39.50% test_error 38.50%\n",
      "================================5367===================================\n",
      "5367/10000: train_loss: 3.674944231212139 train_error 39.50% test_error 38.50%\n",
      "================================5368===================================\n",
      "5368/10000: train_loss: 3.674836221896112 train_error 39.50% test_error 38.50%\n",
      "================================5369===================================\n",
      "5369/10000: train_loss: 3.6747285040840505 train_error 39.50% test_error 38.50%\n",
      "================================5370===================================\n",
      "5370/10000: train_loss: 3.674621001444757 train_error 39.50% test_error 38.50%\n",
      "================================5371===================================\n",
      "5371/10000: train_loss: 3.6745134912058712 train_error 39.50% test_error 38.50%\n",
      "================================5372===================================\n",
      "5372/10000: train_loss: 3.6744057413563134 train_error 39.50% test_error 38.50%\n",
      "================================5373===================================\n",
      "5373/10000: train_loss: 3.674297475628555 train_error 39.50% test_error 38.50%\n",
      "================================5374===================================\n",
      "5374/10000: train_loss: 3.6741895887255667 train_error 39.50% test_error 38.50%\n",
      "================================5375===================================\n",
      "5375/10000: train_loss: 3.674082060419023 train_error 39.50% test_error 38.50%\n",
      "================================5376===================================\n",
      "5376/10000: train_loss: 3.6739742910116915 train_error 39.50% test_error 38.50%\n",
      "================================5377===================================\n",
      "5377/10000: train_loss: 3.6738660968467594 train_error 39.50% test_error 38.50%\n",
      "================================5378===================================\n",
      "5378/10000: train_loss: 3.6737581551447507 train_error 39.50% test_error 38.50%\n",
      "================================5379===================================\n",
      "5379/10000: train_loss: 3.673649995774031 train_error 39.50% test_error 38.50%\n",
      "================================5380===================================\n",
      "5380/10000: train_loss: 3.6735419226437807 train_error 39.50% test_error 38.50%\n",
      "================================5381===================================\n",
      "5381/10000: train_loss: 3.673434134945273 train_error 39.50% test_error 38.50%\n",
      "================================5382===================================\n",
      "5382/10000: train_loss: 3.673326185680926 train_error 39.50% test_error 38.50%\n",
      "================================5383===================================\n",
      "5383/10000: train_loss: 3.6732179776951672 train_error 39.50% test_error 38.50%\n",
      "================================5384===================================\n",
      "5384/10000: train_loss: 3.67311021193862 train_error 39.50% test_error 38.50%\n",
      "================================5385===================================\n",
      "5385/10000: train_loss: 3.673002446591854 train_error 39.50% test_error 38.50%\n",
      "================================5386===================================\n",
      "5386/10000: train_loss: 3.672894808277488 train_error 39.38% test_error 38.50%\n",
      "================================5387===================================\n",
      "5387/10000: train_loss: 3.6727874955162405 train_error 39.38% test_error 38.50%\n",
      "================================5388===================================\n",
      "5388/10000: train_loss: 3.6726801844686268 train_error 39.25% test_error 38.50%\n",
      "================================5389===================================\n",
      "5389/10000: train_loss: 3.67257294498384 train_error 39.25% test_error 38.50%\n",
      "================================5390===================================\n",
      "5390/10000: train_loss: 3.6724655272811653 train_error 39.25% test_error 38.50%\n",
      "================================5391===================================\n",
      "5391/10000: train_loss: 3.6723581748083234 train_error 39.25% test_error 38.50%\n",
      "================================5392===================================\n",
      "5392/10000: train_loss: 3.672251457422972 train_error 39.25% test_error 38.50%\n",
      "================================5393===================================\n",
      "5393/10000: train_loss: 3.6721445631608365 train_error 39.25% test_error 38.50%\n",
      "================================5394===================================\n",
      "5394/10000: train_loss: 3.6720374314859514 train_error 39.25% test_error 38.50%\n",
      "================================5395===================================\n",
      "5395/10000: train_loss: 3.6719304621219635 train_error 39.25% test_error 38.50%\n",
      "================================5396===================================\n",
      "5396/10000: train_loss: 3.671823462322354 train_error 39.25% test_error 38.50%\n",
      "================================5397===================================\n",
      "5397/10000: train_loss: 3.6717163641005754 train_error 39.25% test_error 38.50%\n",
      "================================5398===================================\n",
      "5398/10000: train_loss: 3.671609486080706 train_error 39.25% test_error 38.50%\n",
      "================================5399===================================\n",
      "5399/10000: train_loss: 3.6715033904090526 train_error 39.12% test_error 38.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5400===================================\n",
      "5400/10000: train_loss: 3.6713972797617314 train_error 39.12% test_error 38.50%\n",
      "================================5401===================================\n",
      "5401/10000: train_loss: 3.6712909734249113 train_error 39.12% test_error 38.50%\n",
      "================================5402===================================\n",
      "5402/10000: train_loss: 3.6711846378445623 train_error 39.12% test_error 38.50%\n",
      "================================5403===================================\n",
      "5403/10000: train_loss: 3.6710781960561873 train_error 39.12% test_error 38.50%\n",
      "================================5404===================================\n",
      "5404/10000: train_loss: 3.6709718333184718 train_error 39.12% test_error 38.50%\n",
      "================================5405===================================\n",
      "5405/10000: train_loss: 3.6708659034222366 train_error 39.12% test_error 38.50%\n",
      "================================5406===================================\n",
      "5406/10000: train_loss: 3.6707601999863986 train_error 39.12% test_error 38.50%\n",
      "================================5407===================================\n",
      "5407/10000: train_loss: 3.670654225759208 train_error 39.12% test_error 38.50%\n",
      "================================5408===================================\n",
      "5408/10000: train_loss: 3.6705479208379987 train_error 39.12% test_error 38.50%\n",
      "================================5409===================================\n",
      "5409/10000: train_loss: 3.6704418454691767 train_error 39.12% test_error 38.50%\n",
      "================================5410===================================\n",
      "5410/10000: train_loss: 3.6703357123211027 train_error 39.00% test_error 38.50%\n",
      "================================5411===================================\n",
      "5411/10000: train_loss: 3.6702292855829004 train_error 39.00% test_error 38.50%\n",
      "================================5412===================================\n",
      "5412/10000: train_loss: 3.6701223906129594 train_error 38.88% test_error 38.50%\n",
      "================================5413===================================\n",
      "5413/10000: train_loss: 3.6700153947994116 train_error 38.88% test_error 38.50%\n",
      "================================5414===================================\n",
      "5414/10000: train_loss: 3.6699084475263954 train_error 38.88% test_error 38.50%\n",
      "================================5415===================================\n",
      "5415/10000: train_loss: 3.669801656492054 train_error 38.88% test_error 38.00%\n",
      "================================5416===================================\n",
      "5416/10000: train_loss: 3.66969485912472 train_error 38.75% test_error 38.00%\n",
      "================================5417===================================\n",
      "5417/10000: train_loss: 3.6695880772173406 train_error 38.75% test_error 38.00%\n",
      "================================5418===================================\n",
      "5418/10000: train_loss: 3.6694831620529293 train_error 38.75% test_error 38.00%\n",
      "================================5419===================================\n",
      "5419/10000: train_loss: 3.669378354139626 train_error 38.75% test_error 38.00%\n",
      "================================5420===================================\n",
      "5420/10000: train_loss: 3.669273377433419 train_error 38.75% test_error 38.00%\n",
      "================================5421===================================\n",
      "5421/10000: train_loss: 3.669168340303004 train_error 38.75% test_error 38.00%\n",
      "================================5422===================================\n",
      "5422/10000: train_loss: 3.6690634261816744 train_error 38.75% test_error 38.00%\n",
      "================================5423===================================\n",
      "5423/10000: train_loss: 3.668959755972028 train_error 38.75% test_error 38.00%\n",
      "================================5424===================================\n",
      "5424/10000: train_loss: 3.668855741806328 train_error 38.75% test_error 38.00%\n",
      "================================5425===================================\n",
      "5425/10000: train_loss: 3.668751168549061 train_error 38.75% test_error 38.00%\n",
      "================================5426===================================\n",
      "5426/10000: train_loss: 3.668646443784237 train_error 38.75% test_error 38.00%\n",
      "================================5427===================================\n",
      "5427/10000: train_loss: 3.6685416888073084 train_error 38.75% test_error 38.00%\n",
      "================================5428===================================\n",
      "5428/10000: train_loss: 3.6684369067102667 train_error 38.75% test_error 38.00%\n",
      "================================5429===================================\n",
      "5429/10000: train_loss: 3.66833209592849 train_error 38.75% test_error 38.00%\n",
      "================================5430===================================\n",
      "5430/10000: train_loss: 3.6682273347303274 train_error 38.75% test_error 38.00%\n",
      "================================5431===================================\n",
      "5431/10000: train_loss: 3.6681224055588246 train_error 38.75% test_error 38.00%\n",
      "================================5432===================================\n",
      "5432/10000: train_loss: 3.668017341457307 train_error 38.75% test_error 38.00%\n",
      "================================5433===================================\n",
      "5433/10000: train_loss: 3.6679133598506453 train_error 38.75% test_error 38.00%\n",
      "================================5434===================================\n",
      "5434/10000: train_loss: 3.6678098098933702 train_error 38.75% test_error 38.00%\n",
      "================================5435===================================\n",
      "5435/10000: train_loss: 3.6677064868435263 train_error 38.75% test_error 38.00%\n",
      "================================5436===================================\n",
      "5436/10000: train_loss: 3.6676033943518993 train_error 38.75% test_error 38.00%\n",
      "================================5437===================================\n",
      "5437/10000: train_loss: 3.6675003477558494 train_error 38.75% test_error 38.00%\n",
      "================================5438===================================\n",
      "5438/10000: train_loss: 3.6673972302675244 train_error 38.75% test_error 38.00%\n",
      "================================5439===================================\n",
      "5439/10000: train_loss: 3.6672940637171267 train_error 38.75% test_error 38.00%\n",
      "================================5440===================================\n",
      "5440/10000: train_loss: 3.6671908780559894 train_error 38.75% test_error 38.00%\n",
      "================================5441===================================\n",
      "5441/10000: train_loss: 3.6670877039805054 train_error 38.75% test_error 38.00%\n",
      "================================5442===================================\n",
      "5442/10000: train_loss: 3.666984728462994 train_error 38.88% test_error 38.00%\n",
      "================================5443===================================\n",
      "5443/10000: train_loss: 3.6668822891265154 train_error 38.88% test_error 38.00%\n",
      "================================5444===================================\n",
      "5444/10000: train_loss: 3.6667798234894873 train_error 38.88% test_error 38.00%\n",
      "================================5445===================================\n",
      "5445/10000: train_loss: 3.6666788163408635 train_error 38.88% test_error 38.00%\n",
      "================================5446===================================\n",
      "5446/10000: train_loss: 3.6665783670172094 train_error 38.88% test_error 38.00%\n",
      "================================5447===================================\n",
      "5447/10000: train_loss: 3.666477784179151 train_error 38.88% test_error 38.00%\n",
      "================================5448===================================\n",
      "5448/10000: train_loss: 3.666377161815763 train_error 38.75% test_error 38.00%\n",
      "================================5449===================================\n",
      "5449/10000: train_loss: 3.666276775822044 train_error 38.75% test_error 38.00%\n",
      "================================5450===================================\n",
      "5450/10000: train_loss: 3.6661765652149914 train_error 38.75% test_error 38.00%\n",
      "================================5451===================================\n",
      "5451/10000: train_loss: 3.6660759480297567 train_error 38.75% test_error 38.00%\n",
      "================================5452===================================\n",
      "5452/10000: train_loss: 3.665975501835346 train_error 38.75% test_error 38.00%\n",
      "================================5453===================================\n",
      "5453/10000: train_loss: 3.6658753573894503 train_error 38.75% test_error 38.00%\n",
      "================================5454===================================\n",
      "5454/10000: train_loss: 3.6657758698239924 train_error 38.75% test_error 38.00%\n",
      "================================5455===================================\n",
      "5455/10000: train_loss: 3.6656762459874157 train_error 38.75% test_error 38.00%\n",
      "================================5456===================================\n",
      "5456/10000: train_loss: 3.665576869994402 train_error 38.75% test_error 38.00%\n",
      "================================5457===================================\n",
      "5457/10000: train_loss: 3.6654773712158204 train_error 38.75% test_error 38.00%\n",
      "================================5458===================================\n",
      "5458/10000: train_loss: 3.665377169437707 train_error 38.75% test_error 38.00%\n",
      "================================5459===================================\n",
      "5459/10000: train_loss: 3.6652772609516977 train_error 38.75% test_error 38.00%\n",
      "================================5460===================================\n",
      "5460/10000: train_loss: 3.665177875943482 train_error 38.62% test_error 38.00%\n",
      "================================5461===================================\n",
      "5461/10000: train_loss: 3.6650787292048337 train_error 38.62% test_error 38.00%\n",
      "================================5462===================================\n",
      "5462/10000: train_loss: 3.6649796018004417 train_error 38.50% test_error 38.00%\n",
      "================================5463===================================\n",
      "5463/10000: train_loss: 3.664880535341799 train_error 38.50% test_error 38.00%\n",
      "================================5464===================================\n",
      "5464/10000: train_loss: 3.66478149741888 train_error 38.38% test_error 38.00%\n",
      "================================5465===================================\n",
      "5465/10000: train_loss: 3.6646825391054154 train_error 38.38% test_error 38.00%\n",
      "================================5466===================================\n",
      "5466/10000: train_loss: 3.664583837427199 train_error 38.38% test_error 38.00%\n",
      "================================5467===================================\n",
      "5467/10000: train_loss: 3.664485168531537 train_error 38.38% test_error 38.00%\n",
      "================================5468===================================\n",
      "5468/10000: train_loss: 3.6643865244463085 train_error 38.38% test_error 38.00%\n",
      "================================5469===================================\n",
      "5469/10000: train_loss: 3.6642877546697856 train_error 38.38% test_error 38.00%\n",
      "================================5470===================================\n",
      "5470/10000: train_loss: 3.6641891290619966 train_error 38.38% test_error 38.00%\n",
      "================================5471===================================\n",
      "5471/10000: train_loss: 3.664090752415359 train_error 38.38% test_error 38.00%\n",
      "================================5472===================================\n",
      "5472/10000: train_loss: 3.6639927435666317 train_error 38.38% test_error 38.00%\n",
      "================================5473===================================\n",
      "5473/10000: train_loss: 3.6638946448266507 train_error 38.38% test_error 38.00%\n",
      "================================5474===================================\n",
      "5474/10000: train_loss: 3.6637965830788017 train_error 38.38% test_error 38.00%\n",
      "================================5475===================================\n",
      "5475/10000: train_loss: 3.6636983222886923 train_error 38.38% test_error 38.00%\n",
      "================================5476===================================\n",
      "5476/10000: train_loss: 3.663600047342479 train_error 38.38% test_error 38.00%\n",
      "================================5477===================================\n",
      "5477/10000: train_loss: 3.6635020546242596 train_error 38.38% test_error 38.00%\n",
      "================================5478===================================\n",
      "5478/10000: train_loss: 3.6634050015732647 train_error 38.38% test_error 38.00%\n",
      "================================5479===================================\n",
      "5479/10000: train_loss: 3.6633081338927145 train_error 38.38% test_error 38.00%\n",
      "================================5480===================================\n",
      "5480/10000: train_loss: 3.663211727812886 train_error 38.38% test_error 38.00%\n",
      "================================5481===================================\n",
      "5481/10000: train_loss: 3.663114887624979 train_error 38.38% test_error 38.00%\n",
      "================================5482===================================\n",
      "5482/10000: train_loss: 3.6630181120708585 train_error 38.38% test_error 38.00%\n",
      "================================5483===================================\n",
      "5483/10000: train_loss: 3.6629214123636484 train_error 38.25% test_error 38.00%\n",
      "================================5484===================================\n",
      "5484/10000: train_loss: 3.662824795655906 train_error 38.25% test_error 38.00%\n",
      "================================5485===================================\n",
      "5485/10000: train_loss: 3.6627283288538455 train_error 38.25% test_error 38.00%\n",
      "================================5486===================================\n",
      "5486/10000: train_loss: 3.662632475309074 train_error 38.25% test_error 38.00%\n",
      "================================5487===================================\n",
      "5487/10000: train_loss: 3.6625363390147685 train_error 38.25% test_error 38.00%\n",
      "================================5488===================================\n",
      "5488/10000: train_loss: 3.662440478242934 train_error 38.25% test_error 38.00%\n",
      "================================5489===================================\n",
      "5489/10000: train_loss: 3.6623462329432366 train_error 38.25% test_error 38.00%\n",
      "================================5490===================================\n",
      "5490/10000: train_loss: 3.6622532466426496 train_error 38.38% test_error 38.00%\n",
      "================================5491===================================\n",
      "5491/10000: train_loss: 3.662162745781243 train_error 38.38% test_error 38.00%\n",
      "================================5492===================================\n",
      "5492/10000: train_loss: 3.6620723231509333 train_error 38.38% test_error 38.00%\n",
      "================================5493===================================\n",
      "5493/10000: train_loss: 3.6619818461686373 train_error 38.38% test_error 38.00%\n",
      "================================5494===================================\n",
      "5494/10000: train_loss: 3.6618913778290154 train_error 38.38% test_error 38.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5495===================================\n",
      "5495/10000: train_loss: 3.661800868585706 train_error 38.38% test_error 38.00%\n",
      "================================5496===================================\n",
      "5496/10000: train_loss: 3.661708755232394 train_error 38.38% test_error 38.00%\n",
      "================================5497===================================\n",
      "5497/10000: train_loss: 3.6616164054721594 train_error 38.38% test_error 38.00%\n",
      "================================5498===================================\n",
      "5498/10000: train_loss: 3.661523715592921 train_error 38.38% test_error 38.00%\n",
      "================================5499===================================\n",
      "5499/10000: train_loss: 3.6614309356361625 train_error 38.38% test_error 38.00%\n",
      "================================5500===================================\n",
      "5500/10000: train_loss: 3.6613381786644457 train_error 38.38% test_error 38.00%\n",
      "================================5501===================================\n",
      "5501/10000: train_loss: 3.661245585083962 train_error 38.38% test_error 38.00%\n",
      "================================5502===================================\n",
      "5502/10000: train_loss: 3.661153254769742 train_error 38.38% test_error 38.00%\n",
      "================================5503===================================\n",
      "5503/10000: train_loss: 3.661061028763652 train_error 38.38% test_error 38.00%\n",
      "================================5504===================================\n",
      "5504/10000: train_loss: 3.660968728065491 train_error 38.38% test_error 38.00%\n",
      "================================5505===================================\n",
      "5505/10000: train_loss: 3.6608765164762733 train_error 38.38% test_error 38.00%\n",
      "================================5506===================================\n",
      "5506/10000: train_loss: 3.6607838680595157 train_error 38.38% test_error 38.00%\n",
      "================================5507===================================\n",
      "5507/10000: train_loss: 3.660691091045737 train_error 38.38% test_error 38.00%\n",
      "================================5508===================================\n",
      "5508/10000: train_loss: 3.6605983576178547 train_error 38.38% test_error 38.00%\n",
      "================================5509===================================\n",
      "5509/10000: train_loss: 3.660505841858685 train_error 38.50% test_error 38.00%\n",
      "================================5510===================================\n",
      "5510/10000: train_loss: 3.660413387268781 train_error 38.50% test_error 38.00%\n",
      "================================5511===================================\n",
      "5511/10000: train_loss: 3.660321065671742 train_error 38.50% test_error 38.00%\n",
      "================================5512===================================\n",
      "5512/10000: train_loss: 3.660228796266019 train_error 38.50% test_error 38.00%\n",
      "================================5513===================================\n",
      "5513/10000: train_loss: 3.6601365107297896 train_error 38.50% test_error 38.00%\n",
      "================================5514===================================\n",
      "5514/10000: train_loss: 3.660044549629092 train_error 38.50% test_error 38.00%\n",
      "================================5515===================================\n",
      "5515/10000: train_loss: 3.659953322894871 train_error 38.50% test_error 38.00%\n",
      "================================5516===================================\n",
      "5516/10000: train_loss: 3.6598621432855727 train_error 38.50% test_error 38.00%\n",
      "================================5517===================================\n",
      "5517/10000: train_loss: 3.659771426729858 train_error 38.50% test_error 38.00%\n",
      "================================5518===================================\n",
      "5518/10000: train_loss: 3.659680919386447 train_error 38.50% test_error 38.00%\n",
      "================================5519===================================\n",
      "5519/10000: train_loss: 3.6595909819006924 train_error 38.50% test_error 38.00%\n",
      "================================5520===================================\n",
      "5520/10000: train_loss: 3.659501041918993 train_error 38.50% test_error 38.00%\n",
      "================================5521===================================\n",
      "5521/10000: train_loss: 3.659411123879254 train_error 38.50% test_error 38.00%\n",
      "================================5522===================================\n",
      "5522/10000: train_loss: 3.659321188107133 train_error 38.50% test_error 38.00%\n",
      "================================5523===================================\n",
      "5523/10000: train_loss: 3.6592311919108034 train_error 38.50% test_error 38.00%\n",
      "================================5524===================================\n",
      "5524/10000: train_loss: 3.65914130281657 train_error 38.50% test_error 38.00%\n",
      "================================5525===================================\n",
      "5525/10000: train_loss: 3.6590513307228685 train_error 38.50% test_error 38.00%\n",
      "================================5526===================================\n",
      "5526/10000: train_loss: 3.6589611925929786 train_error 38.38% test_error 38.00%\n",
      "================================5527===================================\n",
      "5527/10000: train_loss: 3.658870669081807 train_error 38.38% test_error 38.00%\n",
      "================================5528===================================\n",
      "5528/10000: train_loss: 3.6587780803442 train_error 38.38% test_error 38.00%\n",
      "================================5529===================================\n",
      "5529/10000: train_loss: 3.6586854639276862 train_error 38.38% test_error 38.00%\n",
      "================================5530===================================\n",
      "5530/10000: train_loss: 3.6585929748043418 train_error 38.38% test_error 38.00%\n",
      "================================5531===================================\n",
      "5531/10000: train_loss: 3.6585002187639475 train_error 38.38% test_error 38.00%\n",
      "================================5532===================================\n",
      "5532/10000: train_loss: 3.6584074879065156 train_error 38.38% test_error 38.00%\n",
      "================================5533===================================\n",
      "5533/10000: train_loss: 3.6583150870352985 train_error 38.38% test_error 38.00%\n",
      "================================5534===================================\n",
      "5534/10000: train_loss: 3.6582232142612336 train_error 38.38% test_error 38.00%\n",
      "================================5535===================================\n",
      "5535/10000: train_loss: 3.658130900897086 train_error 38.38% test_error 38.00%\n",
      "================================5536===================================\n",
      "5536/10000: train_loss: 3.6580394301190973 train_error 38.38% test_error 38.00%\n",
      "================================5537===================================\n",
      "5537/10000: train_loss: 3.6579477860033514 train_error 38.38% test_error 38.00%\n",
      "================================5538===================================\n",
      "5538/10000: train_loss: 3.657856127023697 train_error 38.38% test_error 38.00%\n",
      "================================5539===================================\n",
      "5539/10000: train_loss: 3.657764605209232 train_error 38.38% test_error 38.00%\n",
      "================================5540===================================\n",
      "5540/10000: train_loss: 3.6576732423529026 train_error 38.38% test_error 38.00%\n",
      "================================5541===================================\n",
      "5541/10000: train_loss: 3.6575818345695734 train_error 38.38% test_error 37.50%\n",
      "================================5542===================================\n",
      "5542/10000: train_loss: 3.657490263022482 train_error 38.38% test_error 37.50%\n",
      "================================5543===================================\n",
      "5543/10000: train_loss: 3.6573987241089343 train_error 38.38% test_error 37.50%\n",
      "================================5544===================================\n",
      "5544/10000: train_loss: 3.657307583130896 train_error 38.38% test_error 37.50%\n",
      "================================5545===================================\n",
      "5545/10000: train_loss: 3.657216371670365 train_error 38.38% test_error 37.50%\n",
      "================================5546===================================\n",
      "5546/10000: train_loss: 3.6571252401918173 train_error 38.38% test_error 37.50%\n",
      "================================5547===================================\n",
      "5547/10000: train_loss: 3.6570342429354787 train_error 38.38% test_error 37.50%\n",
      "================================5548===================================\n",
      "5548/10000: train_loss: 3.6569433223083614 train_error 38.25% test_error 37.50%\n",
      "================================5549===================================\n",
      "5549/10000: train_loss: 3.656852266453207 train_error 38.25% test_error 37.50%\n",
      "================================5550===================================\n",
      "5550/10000: train_loss: 3.656761522963643 train_error 38.25% test_error 37.50%\n",
      "================================5551===================================\n",
      "5551/10000: train_loss: 3.65667116407305 train_error 38.25% test_error 37.50%\n",
      "================================5552===================================\n",
      "5552/10000: train_loss: 3.656580971442163 train_error 38.25% test_error 37.50%\n",
      "================================5553===================================\n",
      "5553/10000: train_loss: 3.6564916671812537 train_error 38.12% test_error 37.50%\n",
      "================================5554===================================\n",
      "5554/10000: train_loss: 3.6564028832688926 train_error 38.12% test_error 37.50%\n",
      "================================5555===================================\n",
      "5555/10000: train_loss: 3.6563141846656797 train_error 38.12% test_error 37.50%\n",
      "================================5556===================================\n",
      "5556/10000: train_loss: 3.65622561160475 train_error 38.12% test_error 37.50%\n",
      "================================5557===================================\n",
      "5557/10000: train_loss: 3.6561370554938915 train_error 38.12% test_error 37.50%\n",
      "================================5558===================================\n",
      "5558/10000: train_loss: 3.6560483304038645 train_error 38.12% test_error 37.50%\n",
      "================================5559===================================\n",
      "5559/10000: train_loss: 3.655959599725902 train_error 38.12% test_error 37.50%\n",
      "================================5560===================================\n",
      "5560/10000: train_loss: 3.6558710883930328 train_error 38.12% test_error 37.50%\n",
      "================================5561===================================\n",
      "5561/10000: train_loss: 3.6557829080149533 train_error 38.12% test_error 37.50%\n",
      "================================5562===================================\n",
      "5562/10000: train_loss: 3.655694575756788 train_error 38.12% test_error 37.50%\n",
      "================================5563===================================\n",
      "5563/10000: train_loss: 3.6556064388900995 train_error 38.12% test_error 37.50%\n",
      "================================5564===================================\n",
      "5564/10000: train_loss: 3.6555183963850135 train_error 38.12% test_error 37.50%\n",
      "================================5565===================================\n",
      "5565/10000: train_loss: 3.6554307042062284 train_error 38.12% test_error 37.50%\n",
      "================================5566===================================\n",
      "5566/10000: train_loss: 3.655342596322298 train_error 38.12% test_error 37.50%\n",
      "================================5567===================================\n",
      "5567/10000: train_loss: 3.6552542873471974 train_error 38.12% test_error 37.50%\n",
      "================================5568===================================\n",
      "5568/10000: train_loss: 3.655165960639715 train_error 38.12% test_error 37.50%\n",
      "================================5569===================================\n",
      "5569/10000: train_loss: 3.6550776205956934 train_error 38.00% test_error 37.50%\n",
      "================================5570===================================\n",
      "5570/10000: train_loss: 3.654990145117045 train_error 38.00% test_error 37.50%\n",
      "================================5571===================================\n",
      "5571/10000: train_loss: 3.6549023516103625 train_error 38.00% test_error 37.50%\n",
      "================================5572===================================\n",
      "5572/10000: train_loss: 3.6548143612220882 train_error 38.00% test_error 37.50%\n",
      "================================5573===================================\n",
      "5573/10000: train_loss: 3.654726478606462 train_error 38.00% test_error 37.50%\n",
      "================================5574===================================\n",
      "5574/10000: train_loss: 3.6546385980769993 train_error 38.00% test_error 37.50%\n",
      "================================5575===================================\n",
      "5575/10000: train_loss: 3.6545507219806312 train_error 38.12% test_error 37.50%\n",
      "================================5576===================================\n",
      "5576/10000: train_loss: 3.6544628705829383 train_error 38.12% test_error 37.50%\n",
      "================================5577===================================\n",
      "5577/10000: train_loss: 3.654375011362135 train_error 38.12% test_error 37.50%\n",
      "================================5578===================================\n",
      "5578/10000: train_loss: 3.6542871123924856 train_error 38.12% test_error 37.50%\n",
      "================================5579===================================\n",
      "5579/10000: train_loss: 3.6541993859410287 train_error 38.12% test_error 37.50%\n",
      "================================5580===================================\n",
      "5580/10000: train_loss: 3.6541118662059304 train_error 38.12% test_error 37.00%\n",
      "================================5581===================================\n",
      "5581/10000: train_loss: 3.654024342149496 train_error 38.12% test_error 37.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5582===================================\n",
      "5582/10000: train_loss: 3.653936862163246 train_error 38.12% test_error 37.00%\n",
      "================================5583===================================\n",
      "5583/10000: train_loss: 3.653849581629038 train_error 38.12% test_error 37.00%\n",
      "================================5584===================================\n",
      "5584/10000: train_loss: 3.653762400634587 train_error 38.12% test_error 37.00%\n",
      "================================5585===================================\n",
      "5585/10000: train_loss: 3.653675215058029 train_error 38.12% test_error 37.00%\n",
      "================================5586===================================\n",
      "5586/10000: train_loss: 3.653588187992573 train_error 38.12% test_error 37.00%\n",
      "================================5587===================================\n",
      "5587/10000: train_loss: 3.65350117970258 train_error 38.12% test_error 37.00%\n",
      "================================5588===================================\n",
      "5588/10000: train_loss: 3.6534142269194128 train_error 38.12% test_error 37.50%\n",
      "================================5589===================================\n",
      "5589/10000: train_loss: 3.6533271393179896 train_error 38.12% test_error 37.50%\n",
      "================================5590===================================\n",
      "5590/10000: train_loss: 3.653239510431886 train_error 38.12% test_error 37.50%\n",
      "================================5591===================================\n",
      "5591/10000: train_loss: 3.653151897750795 train_error 38.12% test_error 37.50%\n",
      "================================5592===================================\n",
      "5592/10000: train_loss: 3.6530644821003078 train_error 38.12% test_error 37.50%\n",
      "================================5593===================================\n",
      "5593/10000: train_loss: 3.652977511100471 train_error 38.12% test_error 37.50%\n",
      "================================5594===================================\n",
      "5594/10000: train_loss: 3.652890452258289 train_error 38.00% test_error 37.50%\n",
      "================================5595===================================\n",
      "5595/10000: train_loss: 3.6528044496476646 train_error 38.00% test_error 37.50%\n",
      "================================5596===================================\n",
      "5596/10000: train_loss: 3.6527191280573605 train_error 38.00% test_error 37.50%\n",
      "================================5597===================================\n",
      "5597/10000: train_loss: 3.6526343584805723 train_error 38.00% test_error 37.50%\n",
      "================================5598===================================\n",
      "5598/10000: train_loss: 3.6525500498712065 train_error 38.00% test_error 37.50%\n",
      "================================5599===================================\n",
      "5599/10000: train_loss: 3.652465756610036 train_error 38.00% test_error 37.50%\n",
      "================================5600===================================\n",
      "5600/10000: train_loss: 3.652381968796253 train_error 38.00% test_error 37.50%\n",
      "================================5601===================================\n",
      "5601/10000: train_loss: 3.652298138253391 train_error 38.00% test_error 37.50%\n",
      "================================5602===================================\n",
      "5602/10000: train_loss: 3.6522143257781865 train_error 38.00% test_error 37.50%\n",
      "================================5603===================================\n",
      "5603/10000: train_loss: 3.652130462415516 train_error 38.00% test_error 37.50%\n",
      "================================5604===================================\n",
      "5604/10000: train_loss: 3.6520464348420503 train_error 38.00% test_error 37.50%\n",
      "================================5605===================================\n",
      "5605/10000: train_loss: 3.6519626312330367 train_error 38.00% test_error 37.50%\n",
      "================================5606===================================\n",
      "5606/10000: train_loss: 3.6518789322301743 train_error 38.00% test_error 37.50%\n",
      "================================5607===================================\n",
      "5607/10000: train_loss: 3.6517953170090913 train_error 38.00% test_error 37.50%\n",
      "================================5608===================================\n",
      "5608/10000: train_loss: 3.651711607724428 train_error 37.88% test_error 37.50%\n",
      "================================5609===================================\n",
      "5609/10000: train_loss: 3.6516278986632824 train_error 37.88% test_error 37.50%\n",
      "================================5610===================================\n",
      "5610/10000: train_loss: 3.6515441195666787 train_error 37.88% test_error 38.00%\n",
      "================================5611===================================\n",
      "5611/10000: train_loss: 3.6514603648334742 train_error 37.88% test_error 38.00%\n",
      "================================5612===================================\n",
      "5612/10000: train_loss: 3.651376557312906 train_error 37.88% test_error 38.00%\n",
      "================================5613===================================\n",
      "5613/10000: train_loss: 3.6512932474166155 train_error 38.00% test_error 38.00%\n",
      "================================5614===================================\n",
      "5614/10000: train_loss: 3.651209474056959 train_error 38.00% test_error 38.00%\n",
      "================================5615===================================\n",
      "5615/10000: train_loss: 3.6511256553605196 train_error 38.00% test_error 38.00%\n",
      "================================5616===================================\n",
      "5616/10000: train_loss: 3.6510419403016567 train_error 38.00% test_error 38.00%\n",
      "================================5617===================================\n",
      "5617/10000: train_loss: 3.650958223231137 train_error 38.00% test_error 38.00%\n",
      "================================5618===================================\n",
      "5618/10000: train_loss: 3.650874474644661 train_error 38.00% test_error 38.00%\n",
      "================================5619===================================\n",
      "5619/10000: train_loss: 3.6507908529415727 train_error 38.00% test_error 38.00%\n",
      "================================5620===================================\n",
      "5620/10000: train_loss: 3.6507074162736535 train_error 38.00% test_error 38.00%\n",
      "================================5621===================================\n",
      "5621/10000: train_loss: 3.6506234342604875 train_error 38.25% test_error 38.00%\n",
      "================================5622===================================\n",
      "5622/10000: train_loss: 3.650536854229867 train_error 38.25% test_error 38.00%\n",
      "================================5623===================================\n",
      "5623/10000: train_loss: 3.6504500469192864 train_error 38.25% test_error 38.00%\n",
      "================================5624===================================\n",
      "5624/10000: train_loss: 3.6503633368387822 train_error 38.25% test_error 38.00%\n",
      "================================5625===================================\n",
      "5625/10000: train_loss: 3.650276517160237 train_error 38.25% test_error 38.00%\n",
      "================================5626===================================\n",
      "5626/10000: train_loss: 3.6501894777268173 train_error 38.25% test_error 38.00%\n",
      "================================5627===================================\n",
      "5627/10000: train_loss: 3.65010239046067 train_error 38.25% test_error 38.00%\n",
      "================================5628===================================\n",
      "5628/10000: train_loss: 3.6500152259320022 train_error 38.25% test_error 38.00%\n",
      "================================5629===================================\n",
      "5629/10000: train_loss: 3.6499285591021176 train_error 38.25% test_error 38.00%\n",
      "================================5630===================================\n",
      "5630/10000: train_loss: 3.649842095784843 train_error 38.25% test_error 38.00%\n",
      "================================5631===================================\n",
      "5631/10000: train_loss: 3.649754818640649 train_error 38.25% test_error 38.00%\n",
      "================================5632===================================\n",
      "5632/10000: train_loss: 3.6496675888448955 train_error 38.25% test_error 38.00%\n",
      "================================5633===================================\n",
      "5633/10000: train_loss: 3.649580316059291 train_error 38.25% test_error 38.00%\n",
      "================================5634===================================\n",
      "5634/10000: train_loss: 3.6494933971762653 train_error 38.25% test_error 38.00%\n",
      "================================5635===================================\n",
      "5635/10000: train_loss: 3.649406396336854 train_error 38.12% test_error 38.00%\n",
      "================================5636===================================\n",
      "5636/10000: train_loss: 3.6493192313984038 train_error 38.12% test_error 38.00%\n",
      "================================5637===================================\n",
      "5637/10000: train_loss: 3.6492325127869845 train_error 38.00% test_error 38.00%\n",
      "================================5638===================================\n",
      "5638/10000: train_loss: 3.6491453832015392 train_error 38.00% test_error 38.00%\n",
      "================================5639===================================\n",
      "5639/10000: train_loss: 3.6490598049387333 train_error 38.00% test_error 38.00%\n",
      "================================5640===================================\n",
      "5640/10000: train_loss: 3.648974180482328 train_error 38.00% test_error 37.50%\n",
      "================================5641===================================\n",
      "5641/10000: train_loss: 3.6488886384665964 train_error 38.00% test_error 37.50%\n",
      "================================5642===================================\n",
      "5642/10000: train_loss: 3.648803012445569 train_error 38.00% test_error 37.50%\n",
      "================================5643===================================\n",
      "5643/10000: train_loss: 3.6487177341803907 train_error 38.00% test_error 37.50%\n",
      "================================5644===================================\n",
      "5644/10000: train_loss: 3.6486323986947538 train_error 37.88% test_error 37.50%\n",
      "================================5645===================================\n",
      "5645/10000: train_loss: 3.6485469168797136 train_error 37.88% test_error 37.50%\n",
      "================================5646===================================\n",
      "5646/10000: train_loss: 3.648461528420448 train_error 37.88% test_error 37.50%\n",
      "================================5647===================================\n",
      "5647/10000: train_loss: 3.648376420214772 train_error 37.88% test_error 37.50%\n",
      "================================5648===================================\n",
      "5648/10000: train_loss: 3.6482912404090166 train_error 37.88% test_error 37.50%\n",
      "================================5649===================================\n",
      "5649/10000: train_loss: 3.6482060553878544 train_error 37.88% test_error 37.50%\n",
      "================================5650===================================\n",
      "5650/10000: train_loss: 3.6481208327785133 train_error 37.88% test_error 37.50%\n",
      "================================5651===================================\n",
      "5651/10000: train_loss: 3.6480357253924014 train_error 37.88% test_error 37.50%\n",
      "================================5652===================================\n",
      "5652/10000: train_loss: 3.647951287031174 train_error 37.88% test_error 37.50%\n",
      "================================5653===================================\n",
      "5653/10000: train_loss: 3.6478670459240674 train_error 37.88% test_error 37.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5654===================================\n",
      "5654/10000: train_loss: 3.647782791480422 train_error 37.88% test_error 37.00%\n",
      "================================5655===================================\n",
      "5655/10000: train_loss: 3.6476985048875212 train_error 37.88% test_error 37.00%\n",
      "================================5656===================================\n",
      "5656/10000: train_loss: 3.6476142178848385 train_error 37.88% test_error 37.00%\n",
      "================================5657===================================\n",
      "5657/10000: train_loss: 3.647529818601906 train_error 37.88% test_error 37.00%\n",
      "================================5658===================================\n",
      "5658/10000: train_loss: 3.64744512680918 train_error 37.88% test_error 37.00%\n",
      "================================5659===================================\n",
      "5659/10000: train_loss: 3.6473597867414354 train_error 37.88% test_error 37.00%\n",
      "================================5660===================================\n",
      "5660/10000: train_loss: 3.6472744689136745 train_error 37.88% test_error 37.00%\n",
      "================================5661===================================\n",
      "5661/10000: train_loss: 3.6471891354024413 train_error 37.88% test_error 37.00%\n",
      "================================5662===================================\n",
      "5662/10000: train_loss: 3.6471033842489122 train_error 37.88% test_error 37.00%\n",
      "================================5663===================================\n",
      "5663/10000: train_loss: 3.6470172461122274 train_error 37.88% test_error 37.00%\n",
      "================================5664===================================\n",
      "5664/10000: train_loss: 3.646931514851749 train_error 37.88% test_error 37.00%\n",
      "================================5665===================================\n",
      "5665/10000: train_loss: 3.646846107505262 train_error 37.88% test_error 37.00%\n",
      "================================5666===================================\n",
      "5666/10000: train_loss: 3.6467605958133937 train_error 37.88% test_error 37.00%\n",
      "================================5667===================================\n",
      "5667/10000: train_loss: 3.6466747355088596 train_error 37.88% test_error 37.00%\n",
      "================================5668===================================\n",
      "5668/10000: train_loss: 3.6465890430659056 train_error 37.88% test_error 37.00%\n",
      "================================5669===================================\n",
      "5669/10000: train_loss: 3.646503433585167 train_error 37.88% test_error 37.00%\n",
      "================================5670===================================\n",
      "5670/10000: train_loss: 3.646417724341154 train_error 37.88% test_error 37.00%\n",
      "================================5671===================================\n",
      "5671/10000: train_loss: 3.6463318846374753 train_error 37.88% test_error 37.00%\n",
      "================================5672===================================\n",
      "5672/10000: train_loss: 3.646245769225061 train_error 37.88% test_error 37.00%\n",
      "================================5673===================================\n",
      "5673/10000: train_loss: 3.646159279197454 train_error 37.88% test_error 37.00%\n",
      "================================5674===================================\n",
      "5674/10000: train_loss: 3.646072341054678 train_error 37.88% test_error 37.00%\n",
      "================================5675===================================\n",
      "5675/10000: train_loss: 3.6459850642830136 train_error 37.88% test_error 37.00%\n",
      "================================5676===================================\n",
      "5676/10000: train_loss: 3.64589813772589 train_error 37.88% test_error 37.00%\n",
      "================================5677===================================\n",
      "5677/10000: train_loss: 3.6458121120557188 train_error 37.88% test_error 37.00%\n",
      "================================5678===================================\n",
      "5678/10000: train_loss: 3.645727921277285 train_error 37.88% test_error 37.00%\n",
      "================================5679===================================\n",
      "5679/10000: train_loss: 3.6456441078335047 train_error 37.88% test_error 37.00%\n",
      "================================5680===================================\n",
      "5680/10000: train_loss: 3.6455600433796644 train_error 37.88% test_error 37.00%\n",
      "================================5681===================================\n",
      "5681/10000: train_loss: 3.64547567371279 train_error 37.88% test_error 37.00%\n",
      "================================5682===================================\n",
      "5682/10000: train_loss: 3.6453911240026358 train_error 37.75% test_error 37.00%\n",
      "================================5683===================================\n",
      "5683/10000: train_loss: 3.64530641682446 train_error 37.75% test_error 37.00%\n",
      "================================5684===================================\n",
      "5684/10000: train_loss: 3.645221735984087 train_error 37.75% test_error 37.00%\n",
      "================================5685===================================\n",
      "5685/10000: train_loss: 3.6451377891749144 train_error 37.75% test_error 37.00%\n",
      "================================5686===================================\n",
      "5686/10000: train_loss: 3.645054540708661 train_error 37.75% test_error 37.00%\n",
      "================================5687===================================\n",
      "5687/10000: train_loss: 3.6449713603407146 train_error 37.75% test_error 37.00%\n",
      "================================5688===================================\n",
      "5688/10000: train_loss: 3.6448879726231094 train_error 37.75% test_error 37.00%\n",
      "================================5689===================================\n",
      "5689/10000: train_loss: 3.644804671108722 train_error 37.75% test_error 37.00%\n",
      "================================5690===================================\n",
      "5690/10000: train_loss: 3.6447219039872287 train_error 37.75% test_error 37.00%\n",
      "================================5691===================================\n",
      "5691/10000: train_loss: 3.644638806544244 train_error 37.75% test_error 37.00%\n",
      "================================5692===================================\n",
      "5692/10000: train_loss: 3.644556161239743 train_error 37.75% test_error 37.00%\n",
      "================================5693===================================\n",
      "5693/10000: train_loss: 3.6444735725596544 train_error 37.75% test_error 37.00%\n",
      "================================5694===================================\n",
      "5694/10000: train_loss: 3.64439094837755 train_error 37.75% test_error 37.00%\n",
      "================================5695===================================\n",
      "5695/10000: train_loss: 3.6443079014495012 train_error 37.75% test_error 37.00%\n",
      "================================5696===================================\n",
      "5696/10000: train_loss: 3.6442252118512988 train_error 37.75% test_error 37.00%\n",
      "================================5697===================================\n",
      "5697/10000: train_loss: 3.6441436428204175 train_error 37.75% test_error 37.00%\n",
      "================================5698===================================\n",
      "5698/10000: train_loss: 3.644062067568302 train_error 37.62% test_error 37.00%\n",
      "================================5699===================================\n",
      "5699/10000: train_loss: 3.6439823032543064 train_error 37.62% test_error 37.00%\n",
      "================================5700===================================\n",
      "5700/10000: train_loss: 3.6439028535038234 train_error 37.62% test_error 37.00%\n",
      "================================5701===================================\n",
      "5701/10000: train_loss: 3.6438235027715566 train_error 37.62% test_error 37.00%\n",
      "================================5702===================================\n",
      "5702/10000: train_loss: 3.64374455254525 train_error 37.62% test_error 37.00%\n",
      "================================5703===================================\n",
      "5703/10000: train_loss: 3.643665810003877 train_error 37.62% test_error 37.00%\n",
      "================================5704===================================\n",
      "5704/10000: train_loss: 3.643587295114994 train_error 37.62% test_error 37.00%\n",
      "================================5705===================================\n",
      "5705/10000: train_loss: 3.6435089633613824 train_error 37.62% test_error 37.00%\n",
      "================================5706===================================\n",
      "5706/10000: train_loss: 3.643430007956922 train_error 37.62% test_error 37.00%\n",
      "================================5707===================================\n",
      "5707/10000: train_loss: 3.6433508349582553 train_error 37.62% test_error 37.00%\n",
      "================================5708===================================\n",
      "5708/10000: train_loss: 3.6432716056331995 train_error 37.62% test_error 37.00%\n",
      "================================5709===================================\n",
      "5709/10000: train_loss: 3.643192309513688 train_error 37.62% test_error 37.00%\n",
      "================================5710===================================\n",
      "5710/10000: train_loss: 3.643113055303693 train_error 37.62% test_error 37.00%\n",
      "================================5711===================================\n",
      "5711/10000: train_loss: 3.6430355964973566 train_error 37.62% test_error 37.00%\n",
      "================================5712===================================\n",
      "5712/10000: train_loss: 3.642958770170808 train_error 37.62% test_error 37.00%\n",
      "================================5713===================================\n",
      "5713/10000: train_loss: 3.6428821651265024 train_error 37.62% test_error 37.00%\n",
      "================================5714===================================\n",
      "5714/10000: train_loss: 3.6428062550723554 train_error 37.62% test_error 37.00%\n",
      "================================5715===================================\n",
      "5715/10000: train_loss: 3.6427305395156147 train_error 37.62% test_error 37.00%\n",
      "================================5716===================================\n",
      "5716/10000: train_loss: 3.642654937393963 train_error 37.62% test_error 37.00%\n",
      "================================5717===================================\n",
      "5717/10000: train_loss: 3.6425787770748137 train_error 37.62% test_error 37.00%\n",
      "================================5718===================================\n",
      "5718/10000: train_loss: 3.642502502538264 train_error 37.62% test_error 37.00%\n",
      "================================5719===================================\n",
      "5719/10000: train_loss: 3.6424257769808177 train_error 37.62% test_error 37.00%\n",
      "================================5720===================================\n",
      "5720/10000: train_loss: 3.6423490319773553 train_error 37.50% test_error 37.00%\n",
      "================================5721===================================\n",
      "5721/10000: train_loss: 3.642272340208292 train_error 37.50% test_error 37.00%\n",
      "================================5722===================================\n",
      "5722/10000: train_loss: 3.6421956371888515 train_error 37.50% test_error 37.00%\n",
      "================================5723===================================\n",
      "5723/10000: train_loss: 3.6421189672499894 train_error 37.50% test_error 37.00%\n",
      "================================5724===================================\n",
      "5724/10000: train_loss: 3.6420430520921947 train_error 37.62% test_error 37.00%\n",
      "================================5725===================================\n",
      "5725/10000: train_loss: 3.641967388726771 train_error 37.62% test_error 37.00%\n",
      "================================5726===================================\n",
      "5726/10000: train_loss: 3.641892083287239 train_error 37.62% test_error 37.00%\n",
      "================================5727===================================\n",
      "5727/10000: train_loss: 3.6418177843466397 train_error 37.62% test_error 37.00%\n",
      "================================5728===================================\n",
      "5728/10000: train_loss: 3.641743644364178 train_error 37.62% test_error 37.00%\n",
      "================================5729===================================\n",
      "5729/10000: train_loss: 3.641668850295246 train_error 37.62% test_error 37.00%\n",
      "================================5730===================================\n",
      "5730/10000: train_loss: 3.641594148389995 train_error 37.62% test_error 37.00%\n",
      "================================5731===================================\n",
      "5731/10000: train_loss: 3.6415195097401734 train_error 37.62% test_error 37.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5732===================================\n",
      "5732/10000: train_loss: 3.6414449951425194 train_error 37.62% test_error 37.00%\n",
      "================================5733===================================\n",
      "5733/10000: train_loss: 3.641370472796261 train_error 37.50% test_error 37.00%\n",
      "================================5734===================================\n",
      "5734/10000: train_loss: 3.6412959918379784 train_error 37.50% test_error 37.00%\n",
      "================================5735===================================\n",
      "5735/10000: train_loss: 3.641221908852458 train_error 37.50% test_error 37.00%\n",
      "================================5736===================================\n",
      "5736/10000: train_loss: 3.641147811450064 train_error 37.50% test_error 37.00%\n",
      "================================5737===================================\n",
      "5737/10000: train_loss: 3.641073724590242 train_error 37.50% test_error 37.00%\n",
      "================================5738===================================\n",
      "5738/10000: train_loss: 3.6409998560324315 train_error 37.50% test_error 36.50%\n",
      "================================5739===================================\n",
      "5739/10000: train_loss: 3.640925942435861 train_error 37.50% test_error 36.50%\n",
      "================================5740===================================\n",
      "5740/10000: train_loss: 3.640851183459163 train_error 37.50% test_error 36.50%\n",
      "================================5741===================================\n",
      "5741/10000: train_loss: 3.640776233486831 train_error 37.50% test_error 36.50%\n",
      "================================5742===================================\n",
      "5742/10000: train_loss: 3.6407017950713634 train_error 37.50% test_error 36.50%\n",
      "================================5743===================================\n",
      "5743/10000: train_loss: 3.6406282083690167 train_error 37.50% test_error 36.50%\n",
      "================================5744===================================\n",
      "5744/10000: train_loss: 3.640554521605372 train_error 37.50% test_error 36.50%\n",
      "================================5745===================================\n",
      "5745/10000: train_loss: 3.6404808934405444 train_error 37.50% test_error 36.50%\n",
      "================================5746===================================\n",
      "5746/10000: train_loss: 3.64040804091841 train_error 37.50% test_error 36.50%\n",
      "================================5747===================================\n",
      "5747/10000: train_loss: 3.6403349313512443 train_error 37.50% test_error 36.50%\n",
      "================================5748===================================\n",
      "5748/10000: train_loss: 3.640262644477189 train_error 37.50% test_error 36.50%\n",
      "================================5749===================================\n",
      "5749/10000: train_loss: 3.640190850645304 train_error 37.50% test_error 36.50%\n",
      "================================5750===================================\n",
      "5750/10000: train_loss: 3.640119099877775 train_error 37.50% test_error 36.50%\n",
      "================================5751===================================\n",
      "5751/10000: train_loss: 3.6400474427267913 train_error 37.50% test_error 36.50%\n",
      "================================5752===================================\n",
      "5752/10000: train_loss: 3.639977073185146 train_error 37.50% test_error 36.50%\n",
      "================================5753===================================\n",
      "5753/10000: train_loss: 3.6399063901975754 train_error 37.38% test_error 36.50%\n",
      "================================5754===================================\n",
      "5754/10000: train_loss: 3.6398356265947225 train_error 37.38% test_error 36.50%\n",
      "================================5755===================================\n",
      "5755/10000: train_loss: 3.6397650484368205 train_error 37.38% test_error 36.50%\n",
      "================================5756===================================\n",
      "5756/10000: train_loss: 3.6396942738071085 train_error 37.38% test_error 36.50%\n",
      "================================5757===================================\n",
      "5757/10000: train_loss: 3.639622672535479 train_error 37.38% test_error 36.50%\n",
      "================================5758===================================\n",
      "5758/10000: train_loss: 3.6395511808246375 train_error 37.38% test_error 36.50%\n",
      "================================5759===================================\n",
      "5759/10000: train_loss: 3.639480242133141 train_error 37.38% test_error 36.50%\n",
      "================================5760===================================\n",
      "5760/10000: train_loss: 3.6394095963239668 train_error 37.38% test_error 36.50%\n",
      "================================5761===================================\n",
      "5761/10000: train_loss: 3.6393389340117577 train_error 37.38% test_error 36.50%\n",
      "================================5762===================================\n",
      "5762/10000: train_loss: 3.639268260300159 train_error 37.38% test_error 36.50%\n",
      "================================5763===================================\n",
      "5763/10000: train_loss: 3.6391966400295495 train_error 37.38% test_error 36.50%\n",
      "================================5764===================================\n",
      "5764/10000: train_loss: 3.6391247357800602 train_error 37.38% test_error 36.50%\n",
      "================================5765===================================\n",
      "5765/10000: train_loss: 3.6390527852624652 train_error 37.38% test_error 36.50%\n",
      "================================5766===================================\n",
      "5766/10000: train_loss: 3.6389802940934897 train_error 37.38% test_error 36.50%\n",
      "================================5767===================================\n",
      "5767/10000: train_loss: 3.6389073038473727 train_error 37.38% test_error 36.50%\n",
      "================================5768===================================\n",
      "5768/10000: train_loss: 3.6388337014988066 train_error 37.38% test_error 36.50%\n",
      "================================5769===================================\n",
      "5769/10000: train_loss: 3.6387591976299882 train_error 37.38% test_error 36.50%\n",
      "================================5770===================================\n",
      "5770/10000: train_loss: 3.638684805855155 train_error 37.38% test_error 36.50%\n",
      "================================5771===================================\n",
      "5771/10000: train_loss: 3.6386091400682927 train_error 37.38% test_error 36.50%\n",
      "================================5772===================================\n",
      "5772/10000: train_loss: 3.638532672598958 train_error 37.38% test_error 36.50%\n",
      "================================5773===================================\n",
      "5773/10000: train_loss: 3.6384563231468197 train_error 37.38% test_error 36.50%\n",
      "================================5774===================================\n",
      "5774/10000: train_loss: 3.6383797228708863 train_error 37.38% test_error 36.50%\n",
      "================================5775===================================\n",
      "5775/10000: train_loss: 3.638303170055151 train_error 37.38% test_error 36.50%\n",
      "================================5776===================================\n",
      "5776/10000: train_loss: 3.6382270135357975 train_error 37.38% test_error 36.50%\n",
      "================================5777===================================\n",
      "5777/10000: train_loss: 3.6381508618593217 train_error 37.38% test_error 36.50%\n",
      "================================5778===================================\n",
      "5778/10000: train_loss: 3.6380747397616506 train_error 37.38% test_error 36.50%\n",
      "================================5779===================================\n",
      "5779/10000: train_loss: 3.637998593784869 train_error 37.38% test_error 36.50%\n",
      "================================5780===================================\n",
      "5780/10000: train_loss: 3.6379224138334396 train_error 37.38% test_error 36.50%\n",
      "================================5781===================================\n",
      "5781/10000: train_loss: 3.6378462575003505 train_error 37.38% test_error 36.50%\n",
      "================================5782===================================\n",
      "5782/10000: train_loss: 3.637769969254732 train_error 37.38% test_error 36.50%\n",
      "================================5783===================================\n",
      "5783/10000: train_loss: 3.6376940711587666 train_error 37.38% test_error 36.50%\n",
      "================================5784===================================\n",
      "5784/10000: train_loss: 3.6376188040524724 train_error 37.38% test_error 36.50%\n",
      "================================5785===================================\n",
      "5785/10000: train_loss: 3.6375440595299007 train_error 37.25% test_error 36.50%\n",
      "================================5786===================================\n",
      "5786/10000: train_loss: 3.637469342239201 train_error 37.25% test_error 36.50%\n",
      "================================5787===================================\n",
      "5787/10000: train_loss: 3.637394613698125 train_error 37.12% test_error 36.50%\n",
      "================================5788===================================\n",
      "5788/10000: train_loss: 3.6373199431970713 train_error 37.12% test_error 36.00%\n",
      "================================5789===================================\n",
      "5789/10000: train_loss: 3.637245760858059 train_error 37.12% test_error 36.00%\n",
      "================================5790===================================\n",
      "5790/10000: train_loss: 3.6371719506382942 train_error 37.12% test_error 36.00%\n",
      "================================5791===================================\n",
      "5791/10000: train_loss: 3.6370972514897586 train_error 37.12% test_error 36.50%\n",
      "================================5792===================================\n",
      "5792/10000: train_loss: 3.637022302858531 train_error 37.12% test_error 36.50%\n",
      "================================5793===================================\n",
      "5793/10000: train_loss: 3.6369475551322106 train_error 37.12% test_error 36.50%\n",
      "================================5794===================================\n",
      "5794/10000: train_loss: 3.636872110106051 train_error 37.12% test_error 36.50%\n",
      "================================5795===================================\n",
      "5795/10000: train_loss: 3.636796668432653 train_error 37.00% test_error 36.50%\n",
      "================================5796===================================\n",
      "5796/10000: train_loss: 3.6367201481387017 train_error 37.00% test_error 36.50%\n",
      "================================5797===================================\n",
      "5797/10000: train_loss: 3.6366431249678137 train_error 37.00% test_error 36.50%\n",
      "================================5798===================================\n",
      "5798/10000: train_loss: 3.636566294878721 train_error 37.00% test_error 36.50%\n",
      "================================5799===================================\n",
      "5799/10000: train_loss: 3.6364898298308255 train_error 37.00% test_error 36.50%\n",
      "================================5800===================================\n",
      "5800/10000: train_loss: 3.6364132618159055 train_error 37.00% test_error 36.50%\n",
      "================================5801===================================\n",
      "5801/10000: train_loss: 3.636336765177548 train_error 37.00% test_error 36.50%\n",
      "================================5802===================================\n",
      "5802/10000: train_loss: 3.636259966157377 train_error 37.00% test_error 36.50%\n",
      "================================5803===================================\n",
      "5803/10000: train_loss: 3.636182906776667 train_error 37.00% test_error 36.50%\n",
      "================================5804===================================\n",
      "5804/10000: train_loss: 3.6361066138744356 train_error 36.88% test_error 36.50%\n",
      "================================5805===================================\n",
      "5805/10000: train_loss: 3.6360316478088492 train_error 36.88% test_error 36.50%\n",
      "================================5806===================================\n",
      "5806/10000: train_loss: 3.635955833084881 train_error 36.88% test_error 36.50%\n",
      "================================5807===================================\n",
      "5807/10000: train_loss: 3.635879563689232 train_error 36.88% test_error 36.50%\n",
      "================================5808===================================\n",
      "5808/10000: train_loss: 3.6358028978109362 train_error 36.88% test_error 36.50%\n",
      "================================5809===================================\n",
      "5809/10000: train_loss: 3.6357257802411915 train_error 36.88% test_error 36.50%\n",
      "================================5810===================================\n",
      "5810/10000: train_loss: 3.6356490560993553 train_error 36.88% test_error 36.50%\n",
      "================================5811===================================\n",
      "5811/10000: train_loss: 3.6355733244493607 train_error 36.88% test_error 36.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5812===================================\n",
      "5812/10000: train_loss: 3.635495869368315 train_error 36.88% test_error 36.50%\n",
      "================================5813===================================\n",
      "5813/10000: train_loss: 3.6354193556681276 train_error 36.88% test_error 36.50%\n",
      "================================5814===================================\n",
      "5814/10000: train_loss: 3.6353433036804197 train_error 36.88% test_error 36.50%\n",
      "================================5815===================================\n",
      "5815/10000: train_loss: 3.63527001157403 train_error 36.88% test_error 36.50%\n",
      "================================5816===================================\n",
      "5816/10000: train_loss: 3.6351977907493715 train_error 36.88% test_error 36.50%\n",
      "================================5817===================================\n",
      "5817/10000: train_loss: 3.6351269258186223 train_error 36.88% test_error 36.50%\n",
      "================================5818===================================\n",
      "5818/10000: train_loss: 3.63505615375936 train_error 36.88% test_error 36.50%\n",
      "================================5819===================================\n",
      "5819/10000: train_loss: 3.6349854262918235 train_error 36.88% test_error 36.50%\n",
      "================================5820===================================\n",
      "5820/10000: train_loss: 3.6349149249121546 train_error 36.88% test_error 36.50%\n",
      "================================5821===================================\n",
      "5821/10000: train_loss: 3.634843566715717 train_error 36.88% test_error 36.50%\n",
      "================================5822===================================\n",
      "5822/10000: train_loss: 3.6347720550000666 train_error 36.88% test_error 36.50%\n",
      "================================5823===================================\n",
      "5823/10000: train_loss: 3.6347006503120065 train_error 36.88% test_error 36.50%\n",
      "================================5824===================================\n",
      "5824/10000: train_loss: 3.634628728106618 train_error 36.88% test_error 36.50%\n",
      "================================5825===================================\n",
      "5825/10000: train_loss: 3.63455627925694 train_error 36.88% test_error 36.50%\n",
      "================================5826===================================\n",
      "5826/10000: train_loss: 3.6344827087968588 train_error 36.88% test_error 36.50%\n",
      "================================5827===================================\n",
      "5827/10000: train_loss: 3.6344092512130737 train_error 36.88% test_error 36.50%\n",
      "================================5828===================================\n",
      "5828/10000: train_loss: 3.6343358962610366 train_error 36.88% test_error 36.50%\n",
      "================================5829===================================\n",
      "5829/10000: train_loss: 3.634262494072318 train_error 36.88% test_error 36.50%\n",
      "================================5830===================================\n",
      "5830/10000: train_loss: 3.6341887440532448 train_error 36.88% test_error 36.50%\n",
      "================================5831===================================\n",
      "5831/10000: train_loss: 3.634114480279386 train_error 36.75% test_error 36.50%\n",
      "================================5832===================================\n",
      "5832/10000: train_loss: 3.6340397361665966 train_error 36.75% test_error 36.00%\n",
      "================================5833===================================\n",
      "5833/10000: train_loss: 3.63396495051682 train_error 36.75% test_error 36.00%\n",
      "================================5834===================================\n",
      "5834/10000: train_loss: 3.6338902252167467 train_error 36.75% test_error 36.00%\n",
      "================================5835===================================\n",
      "5835/10000: train_loss: 3.6338154438510535 train_error 36.75% test_error 36.00%\n",
      "================================5836===================================\n",
      "5836/10000: train_loss: 3.633740213252604 train_error 36.75% test_error 36.00%\n",
      "================================5837===================================\n",
      "5837/10000: train_loss: 3.633664602711797 train_error 36.75% test_error 36.00%\n",
      "================================5838===================================\n",
      "5838/10000: train_loss: 3.6335886408388616 train_error 36.88% test_error 36.00%\n",
      "================================5839===================================\n",
      "5839/10000: train_loss: 3.633513134792447 train_error 36.88% test_error 36.00%\n",
      "================================5840===================================\n",
      "5840/10000: train_loss: 3.6334383536502717 train_error 36.88% test_error 36.00%\n",
      "================================5841===================================\n",
      "5841/10000: train_loss: 3.6333635910972957 train_error 36.88% test_error 36.00%\n",
      "================================5842===================================\n",
      "5842/10000: train_loss: 3.6332889483496547 train_error 36.88% test_error 36.00%\n",
      "================================5843===================================\n",
      "5843/10000: train_loss: 3.633214210160077 train_error 36.88% test_error 36.00%\n",
      "================================5844===================================\n",
      "5844/10000: train_loss: 3.6331391365081074 train_error 36.88% test_error 36.00%\n",
      "================================5845===================================\n",
      "5845/10000: train_loss: 3.6330646649375558 train_error 36.88% test_error 36.00%\n",
      "================================5846===================================\n",
      "5846/10000: train_loss: 3.6329894733056425 train_error 36.88% test_error 36.00%\n",
      "================================5847===================================\n",
      "5847/10000: train_loss: 3.6329142420738934 train_error 36.88% test_error 36.00%\n",
      "================================5848===================================\n",
      "5848/10000: train_loss: 3.6328379432857036 train_error 36.75% test_error 36.00%\n",
      "================================5849===================================\n",
      "5849/10000: train_loss: 3.632761615253985 train_error 36.62% test_error 36.00%\n",
      "================================5850===================================\n",
      "5850/10000: train_loss: 3.632685301117599 train_error 36.62% test_error 36.00%\n",
      "================================5851===================================\n",
      "5851/10000: train_loss: 3.6326093870028853 train_error 36.62% test_error 36.00%\n",
      "================================5852===================================\n",
      "5852/10000: train_loss: 3.632533650361001 train_error 36.62% test_error 36.00%\n",
      "================================5853===================================\n",
      "5853/10000: train_loss: 3.6324574863165617 train_error 36.62% test_error 36.00%\n",
      "================================5854===================================\n",
      "5854/10000: train_loss: 3.632378861568868 train_error 36.62% test_error 36.00%\n",
      "================================5855===================================\n",
      "5855/10000: train_loss: 3.632300798073411 train_error 36.62% test_error 36.00%\n",
      "================================5856===================================\n",
      "5856/10000: train_loss: 3.632223011031747 train_error 36.62% test_error 36.00%\n",
      "================================5857===================================\n",
      "5857/10000: train_loss: 3.6321444124355913 train_error 36.62% test_error 36.00%\n",
      "================================5858===================================\n",
      "5858/10000: train_loss: 3.6320647474378345 train_error 36.62% test_error 36.00%\n",
      "================================5859===================================\n",
      "5859/10000: train_loss: 3.631985447108746 train_error 36.62% test_error 36.00%\n",
      "================================5860===================================\n",
      "5860/10000: train_loss: 3.631906288191676 train_error 36.62% test_error 36.00%\n",
      "================================5861===================================\n",
      "5861/10000: train_loss: 3.6318271743506196 train_error 36.62% test_error 36.00%\n",
      "================================5862===================================\n",
      "5862/10000: train_loss: 3.6317485194280743 train_error 36.62% test_error 36.00%\n",
      "================================5863===================================\n",
      "5863/10000: train_loss: 3.6316705616936087 train_error 36.62% test_error 36.00%\n",
      "================================5864===================================\n",
      "5864/10000: train_loss: 3.631592682301998 train_error 36.62% test_error 36.00%\n",
      "================================5865===================================\n",
      "5865/10000: train_loss: 3.6315143145993356 train_error 36.50% test_error 36.00%\n",
      "================================5866===================================\n",
      "5866/10000: train_loss: 3.6314369352906946 train_error 36.50% test_error 36.00%\n",
      "================================5867===================================\n",
      "5867/10000: train_loss: 3.631359503567219 train_error 36.50% test_error 36.00%\n",
      "================================5868===================================\n",
      "5868/10000: train_loss: 3.631281333565712 train_error 36.50% test_error 36.00%\n",
      "================================5869===================================\n",
      "5869/10000: train_loss: 3.6312036326900126 train_error 36.50% test_error 36.00%\n",
      "================================5870===================================\n",
      "5870/10000: train_loss: 3.631126045100391 train_error 36.50% test_error 36.00%\n",
      "================================5871===================================\n",
      "5871/10000: train_loss: 3.6310489583760504 train_error 36.50% test_error 36.00%\n",
      "================================5872===================================\n",
      "5872/10000: train_loss: 3.630972478426993 train_error 36.50% test_error 36.00%\n",
      "================================5873===================================\n",
      "5873/10000: train_loss: 3.6308960799127816 train_error 36.50% test_error 36.00%\n",
      "================================5874===================================\n",
      "5874/10000: train_loss: 3.6308199035003783 train_error 36.50% test_error 36.00%\n",
      "================================5875===================================\n",
      "5875/10000: train_loss: 3.6307434577122333 train_error 36.50% test_error 36.00%\n",
      "================================5876===================================\n",
      "5876/10000: train_loss: 3.6306670317426324 train_error 36.50% test_error 36.00%\n",
      "================================5877===================================\n",
      "5877/10000: train_loss: 3.630590943321586 train_error 36.50% test_error 36.00%\n",
      "================================5878===================================\n",
      "5878/10000: train_loss: 3.630515819080174 train_error 36.62% test_error 36.00%\n",
      "================================5879===================================\n",
      "5879/10000: train_loss: 3.630440615713596 train_error 36.62% test_error 36.00%\n",
      "================================5880===================================\n",
      "5880/10000: train_loss: 3.6303648327291014 train_error 36.62% test_error 36.00%\n",
      "================================5881===================================\n",
      "5881/10000: train_loss: 3.6302880887687206 train_error 36.50% test_error 36.00%\n",
      "================================5882===================================\n",
      "5882/10000: train_loss: 3.6302107334136964 train_error 36.50% test_error 36.00%\n",
      "================================5883===================================\n",
      "5883/10000: train_loss: 3.6301330573856827 train_error 36.50% test_error 36.00%\n",
      "================================5884===================================\n",
      "5884/10000: train_loss: 3.6300550809130074 train_error 36.38% test_error 36.00%\n",
      "================================5885===================================\n",
      "5885/10000: train_loss: 3.6299764720350503 train_error 36.50% test_error 36.00%\n",
      "================================5886===================================\n",
      "5886/10000: train_loss: 3.6298981899768115 train_error 36.50% test_error 36.00%\n",
      "================================5887===================================\n",
      "5887/10000: train_loss: 3.6298198288679124 train_error 36.50% test_error 36.00%\n",
      "================================5888===================================\n",
      "5888/10000: train_loss: 3.6297425031661987 train_error 36.50% test_error 36.00%\n",
      "================================5889===================================\n",
      "5889/10000: train_loss: 3.629666321091354 train_error 36.50% test_error 36.00%\n",
      "================================5890===================================\n",
      "5890/10000: train_loss: 3.62959027454257 train_error 36.50% test_error 36.00%\n",
      "================================5891===================================\n",
      "5891/10000: train_loss: 3.6295150401815777 train_error 36.50% test_error 36.00%\n",
      "================================5892===================================\n",
      "5892/10000: train_loss: 3.629440137781203 train_error 36.50% test_error 36.00%\n",
      "================================5893===================================\n",
      "5893/10000: train_loss: 3.6293650978431105 train_error 36.50% test_error 36.00%\n",
      "================================5894===================================\n",
      "5894/10000: train_loss: 3.629289858825505 train_error 36.50% test_error 36.00%\n",
      "================================5895===================================\n",
      "5895/10000: train_loss: 3.6292146553844216 train_error 36.50% test_error 36.00%\n",
      "================================5896===================================\n",
      "5896/10000: train_loss: 3.629139454290271 train_error 36.50% test_error 36.00%\n",
      "================================5897===================================\n",
      "5897/10000: train_loss: 3.6290643655136225 train_error 36.50% test_error 36.00%\n",
      "================================5898===================================\n",
      "5898/10000: train_loss: 3.628989426791668 train_error 36.38% test_error 36.00%\n",
      "================================5899===================================\n",
      "5899/10000: train_loss: 3.628914555311203 train_error 36.38% test_error 36.00%\n",
      "================================5900===================================\n",
      "5900/10000: train_loss: 3.6288401079550385 train_error 36.38% test_error 36.00%\n",
      "================================5901===================================\n",
      "5901/10000: train_loss: 3.6287657229602335 train_error 36.38% test_error 36.00%\n",
      "================================5902===================================\n",
      "5902/10000: train_loss: 3.62869133438915 train_error 36.38% test_error 36.00%\n",
      "================================5903===================================\n",
      "5903/10000: train_loss: 3.628617508225143 train_error 36.25% test_error 36.00%\n",
      "================================5904===================================\n",
      "5904/10000: train_loss: 3.6285440657287835 train_error 36.25% test_error 36.00%\n",
      "================================5905===================================\n",
      "5905/10000: train_loss: 3.628470724634826 train_error 36.25% test_error 36.00%\n",
      "================================5906===================================\n",
      "5906/10000: train_loss: 3.6283984475210307 train_error 36.25% test_error 36.00%\n",
      "================================5907===================================\n",
      "5907/10000: train_loss: 3.6283262315392495 train_error 36.25% test_error 36.00%\n",
      "================================5908===================================\n",
      "5908/10000: train_loss: 3.6282537661492826 train_error 36.25% test_error 36.00%\n",
      "================================5909===================================\n",
      "5909/10000: train_loss: 3.6281807219982145 train_error 36.25% test_error 36.00%\n",
      "================================5910===================================\n",
      "5910/10000: train_loss: 3.628107728511095 train_error 36.25% test_error 36.00%\n",
      "================================5911===================================\n",
      "5911/10000: train_loss: 3.628034503981471 train_error 36.25% test_error 36.00%\n",
      "================================5912===================================\n",
      "5912/10000: train_loss: 3.6279608496278524 train_error 36.25% test_error 36.00%\n",
      "================================5913===================================\n",
      "5913/10000: train_loss: 3.6278866335377096 train_error 36.25% test_error 36.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5914===================================\n",
      "5914/10000: train_loss: 3.627812144979835 train_error 36.25% test_error 36.00%\n",
      "================================5915===================================\n",
      "5915/10000: train_loss: 3.627737684994936 train_error 36.25% test_error 36.00%\n",
      "================================5916===================================\n",
      "5916/10000: train_loss: 3.627662970200181 train_error 36.25% test_error 36.00%\n",
      "================================5917===================================\n",
      "5917/10000: train_loss: 3.6275883563980456 train_error 36.25% test_error 36.00%\n",
      "================================5918===================================\n",
      "5918/10000: train_loss: 3.6275141282379626 train_error 36.25% test_error 36.00%\n",
      "================================5919===================================\n",
      "5919/10000: train_loss: 3.6274396431073543 train_error 36.25% test_error 36.00%\n",
      "================================5920===================================\n",
      "5920/10000: train_loss: 3.627363647855818 train_error 36.25% test_error 36.00%\n",
      "================================5921===================================\n",
      "5921/10000: train_loss: 3.6272872645780443 train_error 36.25% test_error 36.00%\n",
      "================================5922===================================\n",
      "5922/10000: train_loss: 3.62720989741385 train_error 36.25% test_error 36.00%\n",
      "================================5923===================================\n",
      "5923/10000: train_loss: 3.6271316345781086 train_error 36.25% test_error 36.00%\n",
      "================================5924===================================\n",
      "5924/10000: train_loss: 3.6270533372461795 train_error 36.25% test_error 36.00%\n",
      "================================5925===================================\n",
      "5925/10000: train_loss: 3.6269748878479007 train_error 36.25% test_error 36.00%\n",
      "================================5926===================================\n",
      "5926/10000: train_loss: 3.6268959878012534 train_error 36.38% test_error 36.00%\n",
      "================================5927===================================\n",
      "5927/10000: train_loss: 3.6268170358613134 train_error 36.38% test_error 36.00%\n",
      "================================5928===================================\n",
      "5928/10000: train_loss: 3.6267377267032863 train_error 36.38% test_error 35.50%\n",
      "================================5929===================================\n",
      "5929/10000: train_loss: 3.6266589028388263 train_error 36.38% test_error 35.50%\n",
      "================================5930===================================\n",
      "5930/10000: train_loss: 3.626579420566559 train_error 36.38% test_error 35.50%\n",
      "================================5931===================================\n",
      "5931/10000: train_loss: 3.6264979120716454 train_error 36.38% test_error 35.50%\n",
      "================================5932===================================\n",
      "5932/10000: train_loss: 3.626416678838432 train_error 36.38% test_error 35.50%\n",
      "================================5933===================================\n",
      "5933/10000: train_loss: 3.626334284245968 train_error 36.38% test_error 35.50%\n",
      "================================5934===================================\n",
      "5934/10000: train_loss: 3.6262509367614983 train_error 36.38% test_error 35.50%\n",
      "================================5935===================================\n",
      "5935/10000: train_loss: 3.6261675148457293 train_error 36.38% test_error 35.50%\n",
      "================================5936===================================\n",
      "5936/10000: train_loss: 3.6260838127881287 train_error 36.38% test_error 35.50%\n",
      "================================5937===================================\n",
      "5937/10000: train_loss: 3.625996776409447 train_error 36.38% test_error 35.50%\n",
      "================================5938===================================\n",
      "5938/10000: train_loss: 3.625910526365042 train_error 36.38% test_error 35.50%\n",
      "================================5939===================================\n",
      "5939/10000: train_loss: 3.62582364205271 train_error 36.38% test_error 35.50%\n",
      "================================5940===================================\n",
      "5940/10000: train_loss: 3.625736736506224 train_error 36.38% test_error 35.50%\n",
      "================================5941===================================\n",
      "5941/10000: train_loss: 3.6256511694937945 train_error 36.38% test_error 35.50%\n",
      "================================5942===================================\n",
      "5942/10000: train_loss: 3.6255660390853883 train_error 36.38% test_error 35.50%\n",
      "================================5943===================================\n",
      "5943/10000: train_loss: 3.6254815331846473 train_error 36.38% test_error 35.50%\n",
      "================================5944===================================\n",
      "5944/10000: train_loss: 3.6253952999040484 train_error 36.38% test_error 35.50%\n",
      "================================5945===================================\n",
      "5945/10000: train_loss: 3.6253073182702065 train_error 36.38% test_error 35.50%\n",
      "================================5946===================================\n",
      "5946/10000: train_loss: 3.6252191253378987 train_error 36.25% test_error 35.50%\n",
      "================================5947===================================\n",
      "5947/10000: train_loss: 3.6251309630274773 train_error 36.25% test_error 35.50%\n",
      "================================5948===================================\n",
      "5948/10000: train_loss: 3.6250429225713012 train_error 36.12% test_error 35.50%\n",
      "================================5949===================================\n",
      "5949/10000: train_loss: 3.624955269955098 train_error 36.12% test_error 35.50%\n",
      "================================5950===================================\n",
      "5950/10000: train_loss: 3.624868378639221 train_error 36.12% test_error 35.50%\n",
      "================================5951===================================\n",
      "5951/10000: train_loss: 3.6247814794257285 train_error 36.12% test_error 35.00%\n",
      "================================5952===================================\n",
      "5952/10000: train_loss: 3.6246953603252767 train_error 36.12% test_error 35.00%\n",
      "================================5953===================================\n",
      "5953/10000: train_loss: 3.624608966819942 train_error 36.12% test_error 35.00%\n",
      "================================5954===================================\n",
      "5954/10000: train_loss: 3.624522140659392 train_error 36.12% test_error 35.00%\n",
      "================================5955===================================\n",
      "5955/10000: train_loss: 3.624435269609094 train_error 36.12% test_error 35.00%\n",
      "================================5956===================================\n",
      "5956/10000: train_loss: 3.624348454289138 train_error 36.12% test_error 35.00%\n",
      "================================5957===================================\n",
      "5957/10000: train_loss: 3.6242614971846345 train_error 36.12% test_error 35.00%\n",
      "================================5958===================================\n",
      "5958/10000: train_loss: 3.6241733493655923 train_error 36.12% test_error 35.00%\n",
      "================================5959===================================\n",
      "5959/10000: train_loss: 3.6240852526575322 train_error 36.12% test_error 35.00%\n",
      "================================5960===================================\n",
      "5960/10000: train_loss: 3.6239973924309012 train_error 36.12% test_error 34.50%\n",
      "================================5961===================================\n",
      "5961/10000: train_loss: 3.623909009993076 train_error 36.12% test_error 34.50%\n",
      "================================5962===================================\n",
      "5962/10000: train_loss: 3.623820715248585 train_error 36.12% test_error 34.50%\n",
      "================================5963===================================\n",
      "5963/10000: train_loss: 3.623733887411654 train_error 36.12% test_error 34.50%\n",
      "================================5964===================================\n",
      "5964/10000: train_loss: 3.623647139929235 train_error 36.12% test_error 34.00%\n",
      "================================5965===================================\n",
      "5965/10000: train_loss: 3.6235604339838026 train_error 36.12% test_error 34.00%\n",
      "================================5966===================================\n",
      "5966/10000: train_loss: 3.623473064824939 train_error 36.12% test_error 34.00%\n",
      "================================5967===================================\n",
      "5967/10000: train_loss: 3.6233859371393917 train_error 36.12% test_error 34.00%\n",
      "================================5968===================================\n",
      "5968/10000: train_loss: 3.62329848986119 train_error 36.12% test_error 34.00%\n",
      "================================5969===================================\n",
      "5969/10000: train_loss: 3.6232108257710935 train_error 36.00% test_error 34.00%\n",
      "================================5970===================================\n",
      "5970/10000: train_loss: 3.6231231885403394 train_error 36.00% test_error 34.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================5971===================================\n",
      "5971/10000: train_loss: 3.6230353958159682 train_error 36.00% test_error 34.00%\n",
      "================================5972===================================\n",
      "5972/10000: train_loss: 3.6229476622864603 train_error 36.00% test_error 34.00%\n",
      "================================5973===================================\n",
      "5973/10000: train_loss: 3.6228599870577454 train_error 36.00% test_error 34.00%\n",
      "================================5974===================================\n",
      "5974/10000: train_loss: 3.6227725003659725 train_error 36.00% test_error 34.00%\n",
      "================================5975===================================\n",
      "5975/10000: train_loss: 3.6226855609193445 train_error 36.00% test_error 34.00%\n",
      "================================5976===================================\n",
      "5976/10000: train_loss: 3.622598615437746 train_error 36.00% test_error 34.00%\n",
      "================================5977===================================\n",
      "5977/10000: train_loss: 3.6225121193751697 train_error 35.88% test_error 34.00%\n",
      "================================5978===================================\n",
      "5978/10000: train_loss: 3.62242386277765 train_error 35.88% test_error 34.00%\n",
      "================================5979===================================\n",
      "5979/10000: train_loss: 3.622336018420756 train_error 36.00% test_error 34.00%\n",
      "================================5980===================================\n",
      "5980/10000: train_loss: 3.622248639240861 train_error 36.00% test_error 34.00%\n",
      "================================5981===================================\n",
      "5981/10000: train_loss: 3.6221618163585663 train_error 36.00% test_error 34.00%\n",
      "================================5982===================================\n",
      "5982/10000: train_loss: 3.622071843333542 train_error 36.00% test_error 34.00%\n",
      "================================5983===================================\n",
      "5983/10000: train_loss: 3.6219816308096053 train_error 36.00% test_error 34.00%\n",
      "================================5984===================================\n",
      "5984/10000: train_loss: 3.6218914711102843 train_error 36.00% test_error 34.00%\n",
      "================================5985===================================\n",
      "5985/10000: train_loss: 3.621801112741232 train_error 36.00% test_error 34.00%\n",
      "================================5986===================================\n",
      "5986/10000: train_loss: 3.621710254587233 train_error 35.88% test_error 34.00%\n",
      "================================5987===================================\n",
      "5987/10000: train_loss: 3.6216175954043863 train_error 35.88% test_error 34.00%\n",
      "================================5988===================================\n",
      "5988/10000: train_loss: 3.6215237583965063 train_error 35.88% test_error 34.00%\n",
      "================================5989===================================\n",
      "5989/10000: train_loss: 3.6214300552010537 train_error 35.88% test_error 34.00%\n",
      "================================5990===================================\n",
      "5990/10000: train_loss: 3.6213348499685525 train_error 35.88% test_error 34.00%\n",
      "================================5991===================================\n",
      "5991/10000: train_loss: 3.6212363452464342 train_error 35.88% test_error 34.50%\n",
      "================================5992===================================\n",
      "5992/10000: train_loss: 3.6211360976472498 train_error 35.88% test_error 34.50%\n",
      "================================5993===================================\n",
      "5993/10000: train_loss: 3.621028705462813 train_error 35.88% test_error 34.50%\n",
      "================================5994===================================\n",
      "5994/10000: train_loss: 3.6209209886193277 train_error 35.88% test_error 34.50%\n",
      "================================5995===================================\n",
      "5995/10000: train_loss: 3.6208139342069625 train_error 35.75% test_error 34.50%\n",
      "================================5996===================================\n",
      "5996/10000: train_loss: 3.620706354342401 train_error 35.75% test_error 34.50%\n",
      "================================5997===================================\n",
      "5997/10000: train_loss: 3.620595615878701 train_error 35.75% test_error 34.50%\n",
      "================================5998===================================\n",
      "5998/10000: train_loss: 3.620484953261912 train_error 35.88% test_error 34.50%\n",
      "================================5999===================================\n",
      "5999/10000: train_loss: 3.62037409901619 train_error 35.88% test_error 34.50%\n",
      "================================6000===================================\n",
      "6000/10000: train_loss: 3.6202631257474422 train_error 35.88% test_error 34.50%\n",
      "================================6001===================================\n",
      "6001/10000: train_loss: 3.6201518687978385 train_error 35.88% test_error 34.50%\n",
      "================================6002===================================\n",
      "6002/10000: train_loss: 3.6200404163077473 train_error 35.88% test_error 34.50%\n",
      "================================6003===================================\n",
      "6003/10000: train_loss: 3.6199292070046067 train_error 35.75% test_error 34.50%\n",
      "================================6004===================================\n",
      "6004/10000: train_loss: 3.6198184329643843 train_error 35.75% test_error 34.50%\n",
      "================================6005===================================\n",
      "6005/10000: train_loss: 3.619707866720855 train_error 35.62% test_error 34.50%\n",
      "================================6006===================================\n",
      "6006/10000: train_loss: 3.6195973187312487 train_error 35.50% test_error 34.50%\n",
      "================================6007===================================\n",
      "6007/10000: train_loss: 3.6194867974147202 train_error 35.62% test_error 34.50%\n",
      "================================6008===================================\n",
      "6008/10000: train_loss: 3.6193766199797395 train_error 35.62% test_error 34.50%\n",
      "================================6009===================================\n",
      "6009/10000: train_loss: 3.619266539812088 train_error 35.62% test_error 34.50%\n",
      "================================6010===================================\n",
      "6010/10000: train_loss: 3.6191562170907856 train_error 35.62% test_error 34.50%\n",
      "================================6011===================================\n",
      "6011/10000: train_loss: 3.619045377112925 train_error 35.62% test_error 34.50%\n",
      "================================6012===================================\n",
      "6012/10000: train_loss: 3.6189337890595197 train_error 35.62% test_error 34.50%\n",
      "================================6013===================================\n",
      "6013/10000: train_loss: 3.6188232196122407 train_error 35.62% test_error 34.50%\n",
      "================================6014===================================\n",
      "6014/10000: train_loss: 3.6187127889320254 train_error 35.62% test_error 34.50%\n",
      "================================6015===================================\n",
      "6015/10000: train_loss: 3.6186015428602696 train_error 35.62% test_error 34.50%\n",
      "================================6016===================================\n",
      "6016/10000: train_loss: 3.6184888916835187 train_error 35.62% test_error 34.50%\n",
      "================================6017===================================\n",
      "6017/10000: train_loss: 3.6183769812062385 train_error 35.62% test_error 34.50%\n",
      "================================6018===================================\n",
      "6018/10000: train_loss: 3.6182648150995376 train_error 35.62% test_error 34.50%\n",
      "================================6019===================================\n",
      "6019/10000: train_loss: 3.6181532125920057 train_error 35.62% test_error 34.50%\n",
      "================================6020===================================\n",
      "6020/10000: train_loss: 3.6180423637107015 train_error 35.62% test_error 34.50%\n",
      "================================6021===================================\n",
      "6021/10000: train_loss: 3.617931629344821 train_error 35.62% test_error 34.50%\n",
      "================================6022===================================\n",
      "6022/10000: train_loss: 3.6178209000080823 train_error 35.62% test_error 34.50%\n",
      "================================6023===================================\n",
      "6023/10000: train_loss: 3.6177099956944585 train_error 35.62% test_error 34.50%\n",
      "================================6024===================================\n",
      "6024/10000: train_loss: 3.617598474659026 train_error 35.62% test_error 34.50%\n",
      "================================6025===================================\n",
      "6025/10000: train_loss: 3.617486512809992 train_error 35.62% test_error 34.50%\n",
      "================================6026===================================\n",
      "6026/10000: train_loss: 3.6173746814206242 train_error 35.62% test_error 34.50%\n",
      "================================6027===================================\n",
      "6027/10000: train_loss: 3.617262669466436 train_error 35.50% test_error 34.50%\n",
      "================================6028===================================\n",
      "6028/10000: train_loss: 3.61715113569051 train_error 35.50% test_error 34.50%\n",
      "================================6029===================================\n",
      "6029/10000: train_loss: 3.617040226012468 train_error 35.50% test_error 34.50%\n",
      "================================6030===================================\n",
      "6030/10000: train_loss: 3.616929006464779 train_error 35.50% test_error 34.50%\n",
      "================================6031===================================\n",
      "6031/10000: train_loss: 3.616815298832953 train_error 35.50% test_error 34.50%\n",
      "================================6032===================================\n",
      "6032/10000: train_loss: 3.6167015808448193 train_error 35.38% test_error 34.50%\n",
      "================================6033===================================\n",
      "6033/10000: train_loss: 3.6165880834683777 train_error 35.38% test_error 34.50%\n",
      "================================6034===================================\n",
      "6034/10000: train_loss: 3.6164745550602673 train_error 35.38% test_error 34.50%\n",
      "================================6035===================================\n",
      "6035/10000: train_loss: 3.6163594770431517 train_error 35.38% test_error 34.50%\n",
      "================================6036===================================\n",
      "6036/10000: train_loss: 3.616244702115655 train_error 35.38% test_error 34.50%\n",
      "================================6037===================================\n",
      "6037/10000: train_loss: 3.6161297452449794 train_error 35.38% test_error 34.50%\n",
      "================================6038===================================\n",
      "6038/10000: train_loss: 3.616014774292707 train_error 35.38% test_error 34.50%\n",
      "================================6039===================================\n",
      "6039/10000: train_loss: 3.615899481102824 train_error 35.38% test_error 34.50%\n",
      "================================6040===================================\n",
      "6040/10000: train_loss: 3.615784883014858 train_error 35.38% test_error 34.50%\n",
      "================================6041===================================\n",
      "6041/10000: train_loss: 3.6156721083074808 train_error 35.38% test_error 34.50%\n",
      "================================6042===================================\n",
      "6042/10000: train_loss: 3.6155612520873546 train_error 35.38% test_error 34.50%\n",
      "================================6043===================================\n",
      "6043/10000: train_loss: 3.6154492621496317 train_error 35.38% test_error 34.50%\n",
      "================================6044===================================\n",
      "6044/10000: train_loss: 3.615336975753307 train_error 35.38% test_error 34.50%\n",
      "================================6045===================================\n",
      "6045/10000: train_loss: 3.615224023796618 train_error 35.38% test_error 34.50%\n",
      "================================6046===================================\n",
      "6046/10000: train_loss: 3.6151111247763037 train_error 35.38% test_error 34.50%\n",
      "================================6047===================================\n",
      "6047/10000: train_loss: 3.614998512454331 train_error 35.50% test_error 34.50%\n",
      "================================6048===================================\n",
      "6048/10000: train_loss: 3.6148854657635088 train_error 35.50% test_error 34.50%\n",
      "================================6049===================================\n",
      "6049/10000: train_loss: 3.6147725726664066 train_error 35.38% test_error 34.50%\n",
      "================================6050===================================\n",
      "6050/10000: train_loss: 3.61466032832861 train_error 35.38% test_error 34.50%\n",
      "================================6051===================================\n",
      "6051/10000: train_loss: 3.614548358991742 train_error 35.38% test_error 34.50%\n",
      "================================6052===================================\n",
      "6052/10000: train_loss: 3.6144360748678444 train_error 35.38% test_error 34.50%\n",
      "================================6053===================================\n",
      "6053/10000: train_loss: 3.61432428304106 train_error 35.38% test_error 34.50%\n",
      "================================6054===================================\n",
      "6054/10000: train_loss: 3.614212686903775 train_error 35.38% test_error 34.50%\n",
      "================================6055===================================\n",
      "6055/10000: train_loss: 3.614101123325527 train_error 35.38% test_error 34.50%\n",
      "================================6056===================================\n",
      "6056/10000: train_loss: 3.6139896113425496 train_error 35.38% test_error 34.50%\n",
      "================================6057===================================\n",
      "6057/10000: train_loss: 3.613877995721996 train_error 35.12% test_error 34.00%\n",
      "================================6058===================================\n",
      "6058/10000: train_loss: 3.6137666408717637 train_error 35.12% test_error 34.00%\n",
      "================================6059===================================\n",
      "6059/10000: train_loss: 3.6136570001393555 train_error 35.12% test_error 34.00%\n",
      "================================6060===================================\n",
      "6060/10000: train_loss: 3.6135472527146337 train_error 35.12% test_error 34.00%\n",
      "================================6061===================================\n",
      "6061/10000: train_loss: 3.613437167033553 train_error 35.25% test_error 34.00%\n",
      "================================6062===================================\n",
      "6062/10000: train_loss: 3.6133263227343564 train_error 35.12% test_error 34.00%\n",
      "================================6063===================================\n",
      "6063/10000: train_loss: 3.613216124512255 train_error 35.12% test_error 34.00%\n",
      "================================6064===================================\n",
      "6064/10000: train_loss: 3.6131062411516903 train_error 35.12% test_error 34.00%\n",
      "================================6065===================================\n",
      "6065/10000: train_loss: 3.612996471449733 train_error 35.12% test_error 34.00%\n",
      "================================6066===================================\n",
      "6066/10000: train_loss: 3.612883387953043 train_error 35.12% test_error 34.00%\n",
      "================================6067===================================\n",
      "6067/10000: train_loss: 3.6127702517062423 train_error 35.12% test_error 34.00%\n",
      "================================6068===================================\n",
      "6068/10000: train_loss: 3.612657365612686 train_error 35.12% test_error 34.00%\n",
      "================================6069===================================\n",
      "6069/10000: train_loss: 3.612545376755297 train_error 35.12% test_error 34.00%\n",
      "================================6070===================================\n",
      "6070/10000: train_loss: 3.6124334551766513 train_error 35.12% test_error 34.00%\n",
      "================================6071===================================\n",
      "6071/10000: train_loss: 3.6123220923915507 train_error 35.12% test_error 34.00%\n",
      "================================6072===================================\n",
      "6072/10000: train_loss: 3.6122102859988807 train_error 35.12% test_error 34.00%\n",
      "================================6073===================================\n",
      "6073/10000: train_loss: 3.6120986971631646 train_error 35.12% test_error 34.00%\n",
      "================================6074===================================\n",
      "6074/10000: train_loss: 3.6119866532459857 train_error 35.12% test_error 33.50%\n",
      "================================6075===================================\n",
      "6075/10000: train_loss: 3.611873931698501 train_error 35.12% test_error 33.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6076===================================\n",
      "6076/10000: train_loss: 3.6117613049969077 train_error 35.12% test_error 33.50%\n",
      "================================6077===================================\n",
      "6077/10000: train_loss: 3.6116493044048545 train_error 35.00% test_error 33.50%\n",
      "================================6078===================================\n",
      "6078/10000: train_loss: 3.6115373431146143 train_error 35.00% test_error 33.50%\n",
      "================================6079===================================\n",
      "6079/10000: train_loss: 3.611425545886159 train_error 35.00% test_error 33.50%\n",
      "================================6080===================================\n",
      "6080/10000: train_loss: 3.6113126131147144 train_error 35.00% test_error 33.50%\n",
      "================================6081===================================\n",
      "6081/10000: train_loss: 3.6111994080990555 train_error 35.00% test_error 33.50%\n",
      "================================6082===================================\n",
      "6082/10000: train_loss: 3.6110862523689864 train_error 35.00% test_error 33.50%\n",
      "================================6083===================================\n",
      "6083/10000: train_loss: 3.610973490104079 train_error 35.00% test_error 33.50%\n",
      "================================6084===================================\n",
      "6084/10000: train_loss: 3.610861229225993 train_error 35.00% test_error 33.50%\n",
      "================================6085===================================\n",
      "6085/10000: train_loss: 3.6107489229738716 train_error 35.00% test_error 33.50%\n",
      "================================6086===================================\n",
      "6086/10000: train_loss: 3.6106363501772285 train_error 35.00% test_error 33.50%\n",
      "================================6087===================================\n",
      "6087/10000: train_loss: 3.6105242751538755 train_error 35.00% test_error 33.50%\n",
      "================================6088===================================\n",
      "6088/10000: train_loss: 3.6104121382534506 train_error 34.88% test_error 33.50%\n",
      "================================6089===================================\n",
      "6089/10000: train_loss: 3.6103003295511007 train_error 34.88% test_error 33.50%\n",
      "================================6090===================================\n",
      "6090/10000: train_loss: 3.610187185406685 train_error 34.88% test_error 33.50%\n",
      "================================6091===================================\n",
      "6091/10000: train_loss: 3.6100735948979854 train_error 34.88% test_error 33.50%\n",
      "================================6092===================================\n",
      "6092/10000: train_loss: 3.6099601972475646 train_error 34.88% test_error 33.50%\n",
      "================================6093===================================\n",
      "6093/10000: train_loss: 3.6098464762791993 train_error 34.88% test_error 33.50%\n",
      "================================6094===================================\n",
      "6094/10000: train_loss: 3.609733650535345 train_error 34.88% test_error 33.50%\n",
      "================================6095===================================\n",
      "6095/10000: train_loss: 3.609620697461069 train_error 34.88% test_error 33.50%\n",
      "================================6096===================================\n",
      "6096/10000: train_loss: 3.6095072117075326 train_error 34.88% test_error 33.50%\n",
      "================================6097===================================\n",
      "6097/10000: train_loss: 3.60939008127898 train_error 34.88% test_error 33.50%\n",
      "================================6098===================================\n",
      "6098/10000: train_loss: 3.609272088445723 train_error 34.88% test_error 33.50%\n",
      "================================6099===================================\n",
      "6099/10000: train_loss: 3.609154476411641 train_error 34.88% test_error 33.50%\n",
      "================================6100===================================\n",
      "6100/10000: train_loss: 3.6090369693934923 train_error 34.88% test_error 33.50%\n",
      "================================6101===================================\n",
      "6101/10000: train_loss: 3.608919256068766 train_error 34.88% test_error 33.50%\n",
      "================================6102===================================\n",
      "6102/10000: train_loss: 3.608801718428731 train_error 34.88% test_error 33.50%\n",
      "================================6103===================================\n",
      "6103/10000: train_loss: 3.608684247992933 train_error 34.88% test_error 33.50%\n",
      "================================6104===================================\n",
      "6104/10000: train_loss: 3.6085667515918614 train_error 34.88% test_error 33.50%\n",
      "================================6105===================================\n",
      "6105/10000: train_loss: 3.6084496815875173 train_error 34.88% test_error 33.50%\n",
      "================================6106===================================\n",
      "6106/10000: train_loss: 3.608332971073687 train_error 34.75% test_error 33.50%\n",
      "================================6107===================================\n",
      "6107/10000: train_loss: 3.608216244541109 train_error 34.75% test_error 33.50%\n",
      "================================6108===================================\n",
      "6108/10000: train_loss: 3.6080997197702525 train_error 34.75% test_error 33.50%\n",
      "================================6109===================================\n",
      "6109/10000: train_loss: 3.6079838231950996 train_error 34.75% test_error 33.50%\n",
      "================================6110===================================\n",
      "6110/10000: train_loss: 3.607867780774832 train_error 34.75% test_error 33.50%\n",
      "================================6111===================================\n",
      "6111/10000: train_loss: 3.607751792408526 train_error 34.75% test_error 33.50%\n",
      "================================6112===================================\n",
      "6112/10000: train_loss: 3.6076357181742784 train_error 34.75% test_error 33.50%\n",
      "================================6113===================================\n",
      "6113/10000: train_loss: 3.6075195768848065 train_error 34.62% test_error 33.50%\n",
      "================================6114===================================\n",
      "6114/10000: train_loss: 3.607404661551118 train_error 34.62% test_error 33.50%\n",
      "================================6115===================================\n",
      "6115/10000: train_loss: 3.6072896394878624 train_error 34.50% test_error 33.50%\n",
      "================================6116===================================\n",
      "6116/10000: train_loss: 3.6071743722260003 train_error 34.50% test_error 33.50%\n",
      "================================6117===================================\n",
      "6117/10000: train_loss: 3.607059152983129 train_error 34.50% test_error 33.50%\n",
      "================================6118===================================\n",
      "6118/10000: train_loss: 3.6069439135119317 train_error 34.50% test_error 33.50%\n",
      "================================6119===================================\n",
      "6119/10000: train_loss: 3.6068288498744367 train_error 34.50% test_error 33.50%\n",
      "================================6120===================================\n",
      "6120/10000: train_loss: 3.6067149540781975 train_error 34.50% test_error 33.50%\n",
      "================================6121===================================\n",
      "6121/10000: train_loss: 3.6065994891151787 train_error 34.50% test_error 33.50%\n",
      "================================6122===================================\n",
      "6122/10000: train_loss: 3.6064843998104332 train_error 34.50% test_error 33.50%\n",
      "================================6123===================================\n",
      "6123/10000: train_loss: 3.6063692906498908 train_error 34.50% test_error 33.50%\n",
      "================================6124===================================\n",
      "6124/10000: train_loss: 3.606253958567977 train_error 34.50% test_error 33.50%\n",
      "================================6125===================================\n",
      "6125/10000: train_loss: 3.606139739230275 train_error 34.50% test_error 33.50%\n",
      "================================6126===================================\n",
      "6126/10000: train_loss: 3.6060276388004424 train_error 34.50% test_error 33.50%\n",
      "================================6127===================================\n",
      "6127/10000: train_loss: 3.605917655937374 train_error 34.50% test_error 33.50%\n",
      "================================6128===================================\n",
      "6128/10000: train_loss: 3.605806584022939 train_error 34.50% test_error 33.50%\n",
      "================================6129===================================\n",
      "6129/10000: train_loss: 3.6056944243982434 train_error 34.50% test_error 33.50%\n",
      "================================6130===================================\n",
      "6130/10000: train_loss: 3.6055836928635836 train_error 34.50% test_error 33.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6131===================================\n",
      "6131/10000: train_loss: 3.605473064631224 train_error 34.50% test_error 33.50%\n",
      "================================6132===================================\n",
      "6132/10000: train_loss: 3.6053633534535767 train_error 34.38% test_error 33.50%\n",
      "================================6133===================================\n",
      "6133/10000: train_loss: 3.605253952220082 train_error 34.25% test_error 33.50%\n",
      "================================6134===================================\n",
      "6134/10000: train_loss: 3.60514528658241 train_error 34.25% test_error 33.50%\n",
      "================================6135===================================\n",
      "6135/10000: train_loss: 3.6050380923226473 train_error 34.25% test_error 33.50%\n",
      "================================6136===================================\n",
      "6136/10000: train_loss: 3.604930636808276 train_error 34.25% test_error 33.50%\n",
      "================================6137===================================\n",
      "6137/10000: train_loss: 3.604822892844677 train_error 34.25% test_error 33.50%\n",
      "================================6138===================================\n",
      "6138/10000: train_loss: 3.604714180678129 train_error 34.25% test_error 33.50%\n",
      "================================6139===================================\n",
      "6139/10000: train_loss: 3.6046048964932558 train_error 34.25% test_error 33.50%\n",
      "================================6140===================================\n",
      "6140/10000: train_loss: 3.6044953583180908 train_error 34.25% test_error 33.50%\n",
      "================================6141===================================\n",
      "6141/10000: train_loss: 3.6043860663101075 train_error 34.25% test_error 33.50%\n",
      "================================6142===================================\n",
      "6142/10000: train_loss: 3.60427712071687 train_error 34.25% test_error 33.50%\n",
      "================================6143===================================\n",
      "6143/10000: train_loss: 3.604168311730027 train_error 34.25% test_error 33.50%\n",
      "================================6144===================================\n",
      "6144/10000: train_loss: 3.604059837795794 train_error 34.25% test_error 33.50%\n",
      "================================6145===================================\n",
      "6145/10000: train_loss: 3.6039518690481778 train_error 34.25% test_error 33.50%\n",
      "================================6146===================================\n",
      "6146/10000: train_loss: 3.6038440168648957 train_error 34.38% test_error 33.50%\n",
      "================================6147===================================\n",
      "6147/10000: train_loss: 3.6037357879430054 train_error 34.38% test_error 33.50%\n",
      "================================6148===================================\n",
      "6148/10000: train_loss: 3.6036275685951114 train_error 34.38% test_error 33.50%\n",
      "================================6149===================================\n",
      "6149/10000: train_loss: 3.603519774079323 train_error 34.38% test_error 33.50%\n",
      "================================6150===================================\n",
      "6150/10000: train_loss: 3.6034119845181705 train_error 34.38% test_error 33.50%\n",
      "================================6151===================================\n",
      "6151/10000: train_loss: 3.603303326778114 train_error 34.38% test_error 33.50%\n",
      "================================6152===================================\n",
      "6152/10000: train_loss: 3.603194933384657 train_error 34.38% test_error 33.50%\n",
      "================================6153===================================\n",
      "6153/10000: train_loss: 3.603086974173784 train_error 34.38% test_error 33.50%\n",
      "================================6154===================================\n",
      "6154/10000: train_loss: 3.6029791677743197 train_error 34.38% test_error 33.00%\n",
      "================================6155===================================\n",
      "6155/10000: train_loss: 3.6028706993162634 train_error 34.38% test_error 33.00%\n",
      "================================6156===================================\n",
      "6156/10000: train_loss: 3.6027618527412413 train_error 34.38% test_error 33.00%\n",
      "================================6157===================================\n",
      "6157/10000: train_loss: 3.602652155458927 train_error 34.38% test_error 33.00%\n",
      "================================6158===================================\n",
      "6158/10000: train_loss: 3.60254119195044 train_error 34.38% test_error 33.00%\n",
      "================================6159===================================\n",
      "6159/10000: train_loss: 3.6024311012029653 train_error 34.38% test_error 33.00%\n",
      "================================6160===================================\n",
      "6160/10000: train_loss: 3.602322103381157 train_error 34.38% test_error 33.00%\n",
      "================================6161===================================\n",
      "6161/10000: train_loss: 3.602211851216853 train_error 34.38% test_error 33.00%\n",
      "================================6162===================================\n",
      "6162/10000: train_loss: 3.6021005081012847 train_error 34.38% test_error 33.00%\n",
      "================================6163===================================\n",
      "6163/10000: train_loss: 3.601989030763507 train_error 34.38% test_error 33.00%\n",
      "================================6164===================================\n",
      "6164/10000: train_loss: 3.601877399645746 train_error 34.38% test_error 33.00%\n",
      "================================6165===================================\n",
      "6165/10000: train_loss: 3.601765500381589 train_error 34.38% test_error 33.00%\n",
      "================================6166===================================\n",
      "6166/10000: train_loss: 3.6016560023277995 train_error 34.38% test_error 33.00%\n",
      "================================6167===================================\n",
      "6167/10000: train_loss: 3.601547254100442 train_error 34.38% test_error 33.00%\n",
      "================================6168===================================\n",
      "6168/10000: train_loss: 3.6014389232918624 train_error 34.38% test_error 33.00%\n",
      "================================6169===================================\n",
      "6169/10000: train_loss: 3.6013308081030844 train_error 34.38% test_error 33.00%\n",
      "================================6170===================================\n",
      "6170/10000: train_loss: 3.6012225234135986 train_error 34.38% test_error 32.50%\n",
      "================================6171===================================\n",
      "6171/10000: train_loss: 3.6011129738390446 train_error 34.38% test_error 32.50%\n",
      "================================6172===================================\n",
      "6172/10000: train_loss: 3.60100540895015 train_error 34.38% test_error 32.50%\n",
      "================================6173===================================\n",
      "6173/10000: train_loss: 3.6008987185359 train_error 34.38% test_error 32.50%\n",
      "================================6174===================================\n",
      "6174/10000: train_loss: 3.6007920731604095 train_error 34.38% test_error 32.50%\n",
      "================================6175===================================\n",
      "6175/10000: train_loss: 3.60068597830832 train_error 34.38% test_error 32.50%\n",
      "================================6176===================================\n",
      "6176/10000: train_loss: 3.6005802847817536 train_error 34.38% test_error 32.50%\n",
      "================================6177===================================\n",
      "6177/10000: train_loss: 3.6004747260734438 train_error 34.38% test_error 32.50%\n",
      "================================6178===================================\n",
      "6178/10000: train_loss: 3.600369173288345 train_error 34.38% test_error 32.50%\n",
      "================================6179===================================\n",
      "6179/10000: train_loss: 3.600263819769025 train_error 34.38% test_error 32.50%\n",
      "================================6180===================================\n",
      "6180/10000: train_loss: 3.6001577440649273 train_error 34.38% test_error 32.50%\n",
      "================================6181===================================\n",
      "6181/10000: train_loss: 3.600051897019148 train_error 34.38% test_error 32.50%\n",
      "================================6182===================================\n",
      "6182/10000: train_loss: 3.5999456581100824 train_error 34.38% test_error 32.50%\n",
      "================================6183===================================\n",
      "6183/10000: train_loss: 3.5998391076177363 train_error 34.38% test_error 32.50%\n",
      "================================6184===================================\n",
      "6184/10000: train_loss: 3.5997350972890856 train_error 34.38% test_error 32.50%\n",
      "================================6185===================================\n",
      "6185/10000: train_loss: 3.5996305256709458 train_error 34.38% test_error 32.50%\n",
      "================================6186===================================\n",
      "6186/10000: train_loss: 3.5995250594988466 train_error 34.50% test_error 32.50%\n",
      "================================6187===================================\n",
      "6187/10000: train_loss: 3.5994195275753738 train_error 34.50% test_error 32.50%\n",
      "================================6188===================================\n",
      "6188/10000: train_loss: 3.5993139447644356 train_error 34.50% test_error 32.00%\n",
      "================================6189===================================\n",
      "6189/10000: train_loss: 3.5992074200510977 train_error 34.50% test_error 32.00%\n",
      "================================6190===================================\n",
      "6190/10000: train_loss: 3.5991004983335735 train_error 34.50% test_error 32.00%\n",
      "================================6191===================================\n",
      "6191/10000: train_loss: 3.598993611112237 train_error 34.50% test_error 32.00%\n",
      "================================6192===================================\n",
      "6192/10000: train_loss: 3.5988857503980403 train_error 34.50% test_error 32.00%\n",
      "================================6193===================================\n",
      "6193/10000: train_loss: 3.5987778400629757 train_error 34.50% test_error 32.00%\n",
      "================================6194===================================\n",
      "6194/10000: train_loss: 3.5986703000962734 train_error 34.50% test_error 32.00%\n",
      "================================6195===================================\n",
      "6195/10000: train_loss: 3.5985629051551227 train_error 34.50% test_error 32.00%\n",
      "================================6196===================================\n",
      "6196/10000: train_loss: 3.5984556670486927 train_error 34.50% test_error 32.00%\n",
      "================================6197===================================\n",
      "6197/10000: train_loss: 3.598348260037601 train_error 34.50% test_error 32.00%\n",
      "================================6198===================================\n",
      "6198/10000: train_loss: 3.5982413394004107 train_error 34.50% test_error 32.00%\n",
      "================================6199===================================\n",
      "6199/10000: train_loss: 3.598134540133178 train_error 34.50% test_error 32.00%\n",
      "================================6200===================================\n",
      "6200/10000: train_loss: 3.5980276454612614 train_error 34.50% test_error 32.00%\n",
      "================================6201===================================\n",
      "6201/10000: train_loss: 3.5979203721135855 train_error 34.50% test_error 32.00%\n",
      "================================6202===================================\n",
      "6202/10000: train_loss: 3.5978133226186038 train_error 34.50% test_error 32.00%\n",
      "================================6203===================================\n",
      "6203/10000: train_loss: 3.5977063316479323 train_error 34.50% test_error 32.00%\n",
      "================================6204===================================\n",
      "6204/10000: train_loss: 3.5975990713760257 train_error 34.50% test_error 32.00%\n",
      "================================6205===================================\n",
      "6205/10000: train_loss: 3.5974918051064013 train_error 34.50% test_error 32.00%\n",
      "================================6206===================================\n",
      "6206/10000: train_loss: 3.597384485341608 train_error 34.50% test_error 32.00%\n",
      "================================6207===================================\n",
      "6207/10000: train_loss: 3.597277618981898 train_error 34.50% test_error 32.00%\n",
      "================================6208===================================\n",
      "6208/10000: train_loss: 3.597171746119857 train_error 34.50% test_error 32.00%\n",
      "================================6209===================================\n",
      "6209/10000: train_loss: 3.5970663414895534 train_error 34.50% test_error 32.00%\n",
      "================================6210===================================\n",
      "6210/10000: train_loss: 3.5969609926268458 train_error 34.50% test_error 32.00%\n",
      "================================6211===================================\n",
      "6211/10000: train_loss: 3.5968555496633052 train_error 34.50% test_error 32.00%\n",
      "================================6212===================================\n",
      "6212/10000: train_loss: 3.5967498913407323 train_error 34.50% test_error 32.00%\n",
      "================================6213===================================\n",
      "6213/10000: train_loss: 3.596644079685211 train_error 34.50% test_error 32.00%\n",
      "================================6214===================================\n",
      "6214/10000: train_loss: 3.596539025604725 train_error 34.50% test_error 32.00%\n",
      "================================6215===================================\n",
      "6215/10000: train_loss: 3.5964344955980776 train_error 34.38% test_error 32.00%\n",
      "================================6216===================================\n",
      "6216/10000: train_loss: 3.5963299400359388 train_error 34.38% test_error 32.00%\n",
      "================================6217===================================\n",
      "6217/10000: train_loss: 3.5962253583222625 train_error 34.38% test_error 32.00%\n",
      "================================6218===================================\n",
      "6218/10000: train_loss: 3.5961208100244404 train_error 34.38% test_error 32.00%\n",
      "================================6219===================================\n",
      "6219/10000: train_loss: 3.5960163585469123 train_error 34.38% test_error 32.00%\n",
      "================================6220===================================\n",
      "6220/10000: train_loss: 3.595913426503539 train_error 34.38% test_error 32.00%\n",
      "================================6221===================================\n",
      "6221/10000: train_loss: 3.595810114890337 train_error 34.38% test_error 32.00%\n",
      "================================6222===================================\n",
      "6222/10000: train_loss: 3.5957067736610773 train_error 34.38% test_error 32.00%\n",
      "================================6223===================================\n",
      "6223/10000: train_loss: 3.595603617765009 train_error 34.38% test_error 32.00%\n",
      "================================6224===================================\n",
      "6224/10000: train_loss: 3.5955006641149523 train_error 34.38% test_error 32.00%\n",
      "================================6225===================================\n",
      "6225/10000: train_loss: 3.595397999957204 train_error 34.38% test_error 32.00%\n",
      "================================6226===================================\n",
      "6226/10000: train_loss: 3.5952949005365373 train_error 34.38% test_error 31.50%\n",
      "================================6227===================================\n",
      "6227/10000: train_loss: 3.595190735682845 train_error 34.38% test_error 31.50%\n",
      "================================6228===================================\n",
      "6228/10000: train_loss: 3.5950866895169016 train_error 34.38% test_error 31.50%\n",
      "================================6229===================================\n",
      "6229/10000: train_loss: 3.5949829006567597 train_error 34.38% test_error 31.50%\n",
      "================================6230===================================\n",
      "6230/10000: train_loss: 3.594879424199462 train_error 34.25% test_error 31.50%\n",
      "================================6231===================================\n",
      "6231/10000: train_loss: 3.594773539379239 train_error 34.25% test_error 31.50%\n",
      "================================6232===================================\n",
      "6232/10000: train_loss: 3.594664788767696 train_error 34.25% test_error 31.50%\n",
      "================================6233===================================\n",
      "6233/10000: train_loss: 3.5945557854697108 train_error 34.25% test_error 31.50%\n",
      "================================6234===================================\n",
      "6234/10000: train_loss: 3.5944472553208473 train_error 34.25% test_error 31.50%\n",
      "================================6235===================================\n",
      "6235/10000: train_loss: 3.5943391359597445 train_error 34.25% test_error 31.50%\n",
      "================================6236===================================\n",
      "6236/10000: train_loss: 3.594231279306114 train_error 34.25% test_error 31.50%\n",
      "================================6237===================================\n",
      "6237/10000: train_loss: 3.594123244136572 train_error 34.25% test_error 31.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6238===================================\n",
      "6238/10000: train_loss: 3.594014935828745 train_error 34.12% test_error 31.00%\n",
      "================================6239===================================\n",
      "6239/10000: train_loss: 3.593907176181674 train_error 34.12% test_error 30.50%\n",
      "================================6240===================================\n",
      "6240/10000: train_loss: 3.5938004718348386 train_error 34.12% test_error 30.50%\n",
      "================================6241===================================\n",
      "6241/10000: train_loss: 3.5936933855712416 train_error 34.12% test_error 30.50%\n",
      "================================6242===================================\n",
      "6242/10000: train_loss: 3.5935863962396977 train_error 34.12% test_error 30.50%\n",
      "================================6243===================================\n",
      "6243/10000: train_loss: 3.5934803356230254 train_error 34.00% test_error 30.50%\n",
      "================================6244===================================\n",
      "6244/10000: train_loss: 3.5933743227645754 train_error 34.00% test_error 30.50%\n",
      "================================6245===================================\n",
      "6245/10000: train_loss: 3.5932677865773437 train_error 34.00% test_error 30.50%\n",
      "================================6246===================================\n",
      "6246/10000: train_loss: 3.5931605982780455 train_error 34.00% test_error 30.50%\n",
      "================================6247===================================\n",
      "6247/10000: train_loss: 3.5930533429980276 train_error 34.00% test_error 30.50%\n",
      "================================6248===================================\n",
      "6248/10000: train_loss: 3.5929462756589055 train_error 34.00% test_error 30.50%\n",
      "================================6249===================================\n",
      "6249/10000: train_loss: 3.5928393699601293 train_error 34.00% test_error 30.50%\n",
      "================================6250===================================\n",
      "6250/10000: train_loss: 3.5927325346693397 train_error 34.00% test_error 30.50%\n",
      "================================6251===================================\n",
      "6251/10000: train_loss: 3.592625469788909 train_error 34.00% test_error 30.50%\n",
      "================================6252===================================\n",
      "6252/10000: train_loss: 3.59251721393317 train_error 34.00% test_error 30.50%\n",
      "================================6253===================================\n",
      "6253/10000: train_loss: 3.592408802211285 train_error 34.00% test_error 30.50%\n",
      "================================6254===================================\n",
      "6254/10000: train_loss: 3.5923003820702433 train_error 34.00% test_error 30.50%\n",
      "================================6255===================================\n",
      "6255/10000: train_loss: 3.5921921572089195 train_error 33.88% test_error 30.50%\n",
      "================================6256===================================\n",
      "6256/10000: train_loss: 3.592081462368369 train_error 33.88% test_error 30.50%\n",
      "================================6257===================================\n",
      "6257/10000: train_loss: 3.5919681552052496 train_error 33.88% test_error 30.50%\n",
      "================================6258===================================\n",
      "6258/10000: train_loss: 3.591854224540293 train_error 33.88% test_error 30.50%\n",
      "================================6259===================================\n",
      "6259/10000: train_loss: 3.5917367820441726 train_error 33.88% test_error 30.50%\n",
      "================================6260===================================\n",
      "6260/10000: train_loss: 3.5916203171759844 train_error 33.88% test_error 30.50%\n",
      "================================6261===================================\n",
      "6261/10000: train_loss: 3.5915056008473036 train_error 33.88% test_error 30.50%\n",
      "================================6262===================================\n",
      "6262/10000: train_loss: 3.591391232386231 train_error 33.88% test_error 30.50%\n",
      "================================6263===================================\n",
      "6263/10000: train_loss: 3.591277992986143 train_error 33.88% test_error 30.50%\n",
      "================================6264===================================\n",
      "6264/10000: train_loss: 3.591164943985641 train_error 33.88% test_error 30.50%\n",
      "================================6265===================================\n",
      "6265/10000: train_loss: 3.591052248440683 train_error 33.88% test_error 30.50%\n",
      "================================6266===================================\n",
      "6266/10000: train_loss: 3.590940122567117 train_error 33.88% test_error 30.50%\n",
      "================================6267===================================\n",
      "6267/10000: train_loss: 3.5908290340378883 train_error 33.88% test_error 30.50%\n",
      "================================6268===================================\n",
      "6268/10000: train_loss: 3.5907176050543788 train_error 33.88% test_error 30.50%\n",
      "================================6269===================================\n",
      "6269/10000: train_loss: 3.590606168136001 train_error 33.88% test_error 30.50%\n",
      "================================6270===================================\n",
      "6270/10000: train_loss: 3.5904950824007393 train_error 33.88% test_error 30.50%\n",
      "================================6271===================================\n",
      "6271/10000: train_loss: 3.590388043187559 train_error 33.75% test_error 30.50%\n",
      "================================6272===================================\n",
      "6272/10000: train_loss: 3.5902817383036023 train_error 33.75% test_error 30.50%\n",
      "================================6273===================================\n",
      "6273/10000: train_loss: 3.590176056399941 train_error 33.75% test_error 30.50%\n",
      "================================6274===================================\n",
      "6274/10000: train_loss: 3.590069822482765 train_error 33.75% test_error 30.50%\n",
      "================================6275===================================\n",
      "6275/10000: train_loss: 3.5899643266946075 train_error 33.75% test_error 30.50%\n",
      "================================6276===================================\n",
      "6276/10000: train_loss: 3.5898597756400705 train_error 33.75% test_error 30.50%\n",
      "================================6277===================================\n",
      "6277/10000: train_loss: 3.5897554831579326 train_error 33.75% test_error 30.50%\n",
      "================================6278===================================\n",
      "6278/10000: train_loss: 3.589650902971625 train_error 33.75% test_error 30.50%\n",
      "================================6279===================================\n",
      "6279/10000: train_loss: 3.5895465355739002 train_error 33.75% test_error 30.50%\n",
      "================================6280===================================\n",
      "6280/10000: train_loss: 3.589442142993212 train_error 33.75% test_error 30.50%\n",
      "================================6281===================================\n",
      "6281/10000: train_loss: 3.5893381170183423 train_error 33.75% test_error 30.50%\n",
      "================================6282===================================\n",
      "6282/10000: train_loss: 3.5892331594228746 train_error 33.62% test_error 30.50%\n",
      "================================6283===================================\n",
      "6283/10000: train_loss: 3.58912876650691 train_error 33.62% test_error 30.50%\n",
      "================================6284===================================\n",
      "6284/10000: train_loss: 3.5890257107838988 train_error 33.62% test_error 30.50%\n",
      "================================6285===================================\n",
      "6285/10000: train_loss: 3.5889221565425395 train_error 33.62% test_error 30.50%\n",
      "================================6286===================================\n",
      "6286/10000: train_loss: 3.588818119317293 train_error 33.62% test_error 30.50%\n",
      "================================6287===================================\n",
      "6287/10000: train_loss: 3.588715163655579 train_error 33.62% test_error 30.50%\n",
      "================================6288===================================\n",
      "6288/10000: train_loss: 3.5886131291836496 train_error 33.75% test_error 30.50%\n",
      "================================6289===================================\n",
      "6289/10000: train_loss: 3.5885101230815053 train_error 33.75% test_error 30.50%\n",
      "================================6290===================================\n",
      "6290/10000: train_loss: 3.5884061368927362 train_error 33.75% test_error 30.50%\n",
      "================================6291===================================\n",
      "6291/10000: train_loss: 3.588304258547723 train_error 33.75% test_error 30.50%\n",
      "================================6292===================================\n",
      "6292/10000: train_loss: 3.5882054931670426 train_error 33.75% test_error 30.50%\n",
      "================================6293===================================\n",
      "6293/10000: train_loss: 3.5881081821396945 train_error 33.62% test_error 30.50%\n",
      "================================6294===================================\n",
      "6294/10000: train_loss: 3.5880137579515576 train_error 33.62% test_error 30.50%\n",
      "================================6295===================================\n",
      "6295/10000: train_loss: 3.5879200302436947 train_error 33.50% test_error 30.50%\n",
      "================================6296===================================\n",
      "6296/10000: train_loss: 3.587826423197985 train_error 33.50% test_error 30.50%\n",
      "================================6297===================================\n",
      "6297/10000: train_loss: 3.5877339170873164 train_error 33.50% test_error 30.50%\n",
      "================================6298===================================\n",
      "6298/10000: train_loss: 3.5876416323706506 train_error 33.50% test_error 30.50%\n",
      "================================6299===================================\n",
      "6299/10000: train_loss: 3.587549572065473 train_error 33.50% test_error 30.50%\n",
      "================================6300===================================\n",
      "6300/10000: train_loss: 3.5874584881588816 train_error 33.50% test_error 30.50%\n",
      "================================6301===================================\n",
      "6301/10000: train_loss: 3.5873693781346083 train_error 33.50% test_error 30.50%\n",
      "================================6302===================================\n",
      "6302/10000: train_loss: 3.587281310260296 train_error 33.50% test_error 30.50%\n",
      "================================6303===================================\n",
      "6303/10000: train_loss: 3.5871965890005226 train_error 33.50% test_error 30.50%\n",
      "================================6304===================================\n",
      "6304/10000: train_loss: 3.5871120207756757 train_error 33.50% test_error 30.00%\n",
      "================================6305===================================\n",
      "6305/10000: train_loss: 3.587028500176966 train_error 33.50% test_error 30.00%\n",
      "================================6306===================================\n",
      "6306/10000: train_loss: 3.5869459792599083 train_error 33.50% test_error 30.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6307===================================\n",
      "6307/10000: train_loss: 3.586864189915359 train_error 33.50% test_error 30.00%\n",
      "================================6308===================================\n",
      "6308/10000: train_loss: 3.58678283020854 train_error 33.50% test_error 30.00%\n",
      "================================6309===================================\n",
      "6309/10000: train_loss: 3.586703434623778 train_error 33.50% test_error 30.00%\n",
      "================================6310===================================\n",
      "6310/10000: train_loss: 3.586625970676541 train_error 33.50% test_error 30.00%\n",
      "================================6311===================================\n",
      "6311/10000: train_loss: 3.586548980176449 train_error 33.50% test_error 30.00%\n",
      "================================6312===================================\n",
      "6312/10000: train_loss: 3.58647144060582 train_error 33.50% test_error 30.00%\n",
      "================================6313===================================\n",
      "6313/10000: train_loss: 3.5863934776559474 train_error 33.50% test_error 30.00%\n",
      "================================6314===================================\n",
      "6314/10000: train_loss: 3.586315071024001 train_error 33.50% test_error 30.00%\n",
      "================================6315===================================\n",
      "6315/10000: train_loss: 3.5862374073266983 train_error 33.50% test_error 30.00%\n",
      "================================6316===================================\n",
      "6316/10000: train_loss: 3.5861595397070056 train_error 33.50% test_error 30.00%\n",
      "================================6317===================================\n",
      "6317/10000: train_loss: 3.5860817022249103 train_error 33.50% test_error 30.00%\n",
      "================================6318===================================\n",
      "6318/10000: train_loss: 3.5860045881941915 train_error 33.50% test_error 30.00%\n",
      "================================6319===================================\n",
      "6319/10000: train_loss: 3.585928817242384 train_error 33.50% test_error 30.00%\n",
      "================================6320===================================\n",
      "6320/10000: train_loss: 3.5858533440530302 train_error 33.50% test_error 30.00%\n",
      "================================6321===================================\n",
      "6321/10000: train_loss: 3.5857797244563696 train_error 33.50% test_error 30.00%\n",
      "================================6322===================================\n",
      "6322/10000: train_loss: 3.5857066740840673 train_error 33.50% test_error 30.00%\n",
      "================================6323===================================\n",
      "6323/10000: train_loss: 3.5856337865069507 train_error 33.50% test_error 30.00%\n",
      "================================6324===================================\n",
      "6324/10000: train_loss: 3.585560884140432 train_error 33.38% test_error 30.00%\n",
      "================================6325===================================\n",
      "6325/10000: train_loss: 3.58548942130059 train_error 33.38% test_error 30.00%\n",
      "================================6326===================================\n",
      "6326/10000: train_loss: 3.5854208131879566 train_error 33.38% test_error 30.00%\n",
      "================================6327===================================\n",
      "6327/10000: train_loss: 3.585351947024465 train_error 33.38% test_error 30.00%\n",
      "================================6328===================================\n",
      "6328/10000: train_loss: 3.585283099114895 train_error 33.38% test_error 30.00%\n",
      "================================6329===================================\n",
      "6329/10000: train_loss: 3.585214337334037 train_error 33.25% test_error 30.00%\n",
      "================================6330===================================\n",
      "6330/10000: train_loss: 3.585145038217306 train_error 33.25% test_error 30.00%\n",
      "================================6331===================================\n",
      "6331/10000: train_loss: 3.5850759119912983 train_error 33.25% test_error 30.00%\n",
      "================================6332===================================\n",
      "6332/10000: train_loss: 3.5850080752372744 train_error 33.25% test_error 30.00%\n",
      "================================6333===================================\n",
      "6333/10000: train_loss: 3.584940472878516 train_error 33.12% test_error 30.00%\n",
      "================================6334===================================\n",
      "6334/10000: train_loss: 3.5848735056445005 train_error 33.12% test_error 30.00%\n",
      "================================6335===================================\n",
      "6335/10000: train_loss: 3.58480850726366 train_error 33.12% test_error 30.00%\n",
      "================================6336===================================\n",
      "6336/10000: train_loss: 3.5847428226843476 train_error 33.12% test_error 29.50%\n",
      "================================6337===================================\n",
      "6337/10000: train_loss: 3.584677173867822 train_error 33.12% test_error 29.50%\n",
      "================================6338===================================\n",
      "6338/10000: train_loss: 3.5846117241308093 train_error 33.12% test_error 29.50%\n",
      "================================6339===================================\n",
      "6339/10000: train_loss: 3.584548995755613 train_error 33.12% test_error 29.00%\n",
      "================================6340===================================\n",
      "6340/10000: train_loss: 3.5844869475811723 train_error 33.12% test_error 29.00%\n",
      "================================6341===================================\n",
      "6341/10000: train_loss: 3.584424992837012 train_error 33.12% test_error 29.00%\n",
      "================================6342===================================\n",
      "6342/10000: train_loss: 3.584363654702902 train_error 33.12% test_error 29.00%\n",
      "================================6343===================================\n",
      "6343/10000: train_loss: 3.5843025099858643 train_error 33.12% test_error 29.00%\n",
      "================================6344===================================\n",
      "6344/10000: train_loss: 3.5842415208369496 train_error 33.12% test_error 29.00%\n",
      "================================6345===================================\n",
      "6345/10000: train_loss: 3.5841804471984506 train_error 33.12% test_error 29.00%\n",
      "================================6346===================================\n",
      "6346/10000: train_loss: 3.584118912369013 train_error 33.12% test_error 29.00%\n",
      "================================6347===================================\n",
      "6347/10000: train_loss: 3.5840568795055154 train_error 33.12% test_error 29.00%\n",
      "================================6348===================================\n",
      "6348/10000: train_loss: 3.58399522472173 train_error 33.12% test_error 29.00%\n",
      "================================6349===================================\n",
      "6349/10000: train_loss: 3.5839342228323225 train_error 33.12% test_error 29.00%\n",
      "================================6350===================================\n",
      "6350/10000: train_loss: 3.5838731744885446 train_error 33.12% test_error 29.00%\n",
      "================================6351===================================\n",
      "6351/10000: train_loss: 3.583812445476651 train_error 33.25% test_error 29.00%\n",
      "================================6352===================================\n",
      "6352/10000: train_loss: 3.5837507960945367 train_error 33.25% test_error 29.00%\n",
      "================================6353===================================\n",
      "6353/10000: train_loss: 3.583688554316759 train_error 33.25% test_error 29.00%\n",
      "================================6354===================================\n",
      "6354/10000: train_loss: 3.583626450523734 train_error 33.25% test_error 29.00%\n",
      "================================6355===================================\n",
      "6355/10000: train_loss: 3.5835644032061102 train_error 33.25% test_error 29.00%\n",
      "================================6356===================================\n",
      "6356/10000: train_loss: 3.583502872660756 train_error 32.88% test_error 29.00%\n",
      "================================6357===================================\n",
      "6357/10000: train_loss: 3.583441078998148 train_error 32.88% test_error 29.00%\n",
      "================================6358===================================\n",
      "6358/10000: train_loss: 3.5833793430402876 train_error 32.88% test_error 29.00%\n",
      "================================6359===================================\n",
      "6359/10000: train_loss: 3.583319536969066 train_error 32.88% test_error 29.00%\n",
      "================================6360===================================\n",
      "6360/10000: train_loss: 3.5832599659264086 train_error 32.88% test_error 29.00%\n",
      "================================6361===================================\n",
      "6361/10000: train_loss: 3.5832007555663585 train_error 32.75% test_error 29.00%\n",
      "================================6362===================================\n",
      "6362/10000: train_loss: 3.583141886591911 train_error 32.88% test_error 29.00%\n",
      "================================6363===================================\n",
      "6363/10000: train_loss: 3.583082446269691 train_error 32.88% test_error 29.00%\n",
      "================================6364===================================\n",
      "6364/10000: train_loss: 3.5830221834778784 train_error 32.88% test_error 29.00%\n",
      "================================6365===================================\n",
      "6365/10000: train_loss: 3.582962207980454 train_error 32.88% test_error 29.00%\n",
      "================================6366===================================\n",
      "6366/10000: train_loss: 3.5829029817134144 train_error 32.88% test_error 29.00%\n",
      "================================6367===================================\n",
      "6367/10000: train_loss: 3.5828439734131097 train_error 32.88% test_error 29.00%\n",
      "================================6368===================================\n",
      "6368/10000: train_loss: 3.582785371430218 train_error 32.88% test_error 29.00%\n",
      "================================6369===================================\n",
      "6369/10000: train_loss: 3.5827267811074854 train_error 32.88% test_error 28.50%\n",
      "================================6370===================================\n",
      "6370/10000: train_loss: 3.5826683262735606 train_error 32.88% test_error 28.50%\n",
      "================================6371===================================\n",
      "6371/10000: train_loss: 3.5826105223968625 train_error 32.88% test_error 28.50%\n",
      "================================6372===================================\n",
      "6372/10000: train_loss: 3.5825546156242494 train_error 32.88% test_error 28.50%\n",
      "================================6373===================================\n",
      "6373/10000: train_loss: 3.582498866915703 train_error 32.88% test_error 28.50%\n",
      "================================6374===================================\n",
      "6374/10000: train_loss: 3.582442892640829 train_error 32.88% test_error 28.50%\n",
      "================================6375===================================\n",
      "6375/10000: train_loss: 3.582386581301689 train_error 32.88% test_error 28.50%\n",
      "================================6376===================================\n",
      "6376/10000: train_loss: 3.582329303957522 train_error 32.88% test_error 28.50%\n",
      "================================6377===================================\n",
      "6377/10000: train_loss: 3.582270050905645 train_error 32.88% test_error 28.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6378===================================\n",
      "6378/10000: train_loss: 3.582212162576616 train_error 32.75% test_error 28.50%\n",
      "================================6379===================================\n",
      "6379/10000: train_loss: 3.5821543840318917 train_error 32.75% test_error 28.50%\n",
      "================================6380===================================\n",
      "6380/10000: train_loss: 3.582096869982779 train_error 32.75% test_error 28.50%\n",
      "================================6381===================================\n",
      "6381/10000: train_loss: 3.5820397230610252 train_error 32.75% test_error 28.50%\n",
      "================================6382===================================\n",
      "6382/10000: train_loss: 3.581982904188335 train_error 32.75% test_error 28.50%\n",
      "================================6383===================================\n",
      "6383/10000: train_loss: 3.581927468031645 train_error 32.75% test_error 28.50%\n",
      "================================6384===================================\n",
      "6384/10000: train_loss: 3.5818723082169894 train_error 32.75% test_error 28.50%\n",
      "================================6385===================================\n",
      "6385/10000: train_loss: 3.581816492266953 train_error 32.75% test_error 28.50%\n",
      "================================6386===================================\n",
      "6386/10000: train_loss: 3.5817621041461827 train_error 32.75% test_error 28.50%\n",
      "================================6387===================================\n",
      "6387/10000: train_loss: 3.58170606341213 train_error 32.75% test_error 28.50%\n",
      "================================6388===================================\n",
      "6388/10000: train_loss: 3.5816502827033405 train_error 32.75% test_error 28.50%\n",
      "================================6389===================================\n",
      "6389/10000: train_loss: 3.581593850553036 train_error 32.62% test_error 28.50%\n",
      "================================6390===================================\n",
      "6390/10000: train_loss: 3.5815373316034673 train_error 32.62% test_error 28.50%\n",
      "================================6391===================================\n",
      "6391/10000: train_loss: 3.581481232717633 train_error 32.62% test_error 28.50%\n",
      "================================6392===================================\n",
      "6392/10000: train_loss: 3.5814250341057776 train_error 32.62% test_error 28.50%\n",
      "================================6393===================================\n",
      "6393/10000: train_loss: 3.581366336494684 train_error 32.62% test_error 28.50%\n",
      "================================6394===================================\n",
      "6394/10000: train_loss: 3.581306415833533 train_error 32.62% test_error 28.50%\n",
      "================================6395===================================\n",
      "6395/10000: train_loss: 3.5812452853098513 train_error 32.62% test_error 28.50%\n",
      "================================6396===================================\n",
      "6396/10000: train_loss: 3.5811827318742875 train_error 32.62% test_error 28.50%\n",
      "================================6397===================================\n",
      "6397/10000: train_loss: 3.5811203207448123 train_error 32.62% test_error 28.50%\n",
      "================================6398===================================\n",
      "6398/10000: train_loss: 3.5810579694435 train_error 32.62% test_error 28.50%\n",
      "================================6399===================================\n",
      "6399/10000: train_loss: 3.580995897129178 train_error 32.62% test_error 28.50%\n",
      "================================6400===================================\n",
      "6400/10000: train_loss: 3.580932973958552 train_error 32.62% test_error 28.50%\n",
      "================================6401===================================\n",
      "6401/10000: train_loss: 3.580870235785842 train_error 32.50% test_error 28.50%\n",
      "================================6402===================================\n",
      "6402/10000: train_loss: 3.580807195343077 train_error 32.50% test_error 28.50%\n",
      "================================6403===================================\n",
      "6403/10000: train_loss: 3.5807444920390843 train_error 32.50% test_error 28.50%\n",
      "================================6404===================================\n",
      "6404/10000: train_loss: 3.580681658163667 train_error 32.50% test_error 28.50%\n",
      "================================6405===================================\n",
      "6405/10000: train_loss: 3.580616442486644 train_error 32.50% test_error 28.50%\n",
      "================================6406===================================\n",
      "6406/10000: train_loss: 3.5805503230169418 train_error 32.50% test_error 28.50%\n",
      "================================6407===================================\n",
      "6407/10000: train_loss: 3.580482680052519 train_error 32.50% test_error 28.50%\n",
      "================================6408===================================\n",
      "6408/10000: train_loss: 3.5804137266799807 train_error 32.50% test_error 28.50%\n",
      "================================6409===================================\n",
      "6409/10000: train_loss: 3.58034508086741 train_error 32.50% test_error 28.50%\n",
      "================================6410===================================\n",
      "6410/10000: train_loss: 3.5802756093442443 train_error 32.50% test_error 28.50%\n",
      "================================6411===================================\n",
      "6411/10000: train_loss: 3.5802062253281477 train_error 32.50% test_error 28.50%\n",
      "================================6412===================================\n",
      "6412/10000: train_loss: 3.5801376236602667 train_error 32.50% test_error 28.50%\n",
      "================================6413===================================\n",
      "6413/10000: train_loss: 3.5800691446661945 train_error 32.50% test_error 28.50%\n",
      "================================6414===================================\n",
      "6414/10000: train_loss: 3.580000569671393 train_error 32.50% test_error 28.50%\n",
      "================================6415===================================\n",
      "6415/10000: train_loss: 3.579931516163051 train_error 32.50% test_error 28.50%\n",
      "================================6416===================================\n",
      "6416/10000: train_loss: 3.579862820561975 train_error 32.50% test_error 28.50%\n",
      "================================6417===================================\n",
      "6417/10000: train_loss: 3.5797933730855584 train_error 32.50% test_error 28.50%\n",
      "================================6418===================================\n",
      "6418/10000: train_loss: 3.5797208955138924 train_error 32.38% test_error 28.50%\n",
      "================================6419===================================\n",
      "6419/10000: train_loss: 3.579648895934224 train_error 32.38% test_error 28.00%\n",
      "================================6420===================================\n",
      "6420/10000: train_loss: 3.5795775042288005 train_error 32.38% test_error 28.00%\n",
      "================================6421===================================\n",
      "6421/10000: train_loss: 3.5795054601691665 train_error 32.38% test_error 28.00%\n",
      "================================6422===================================\n",
      "6422/10000: train_loss: 3.579433902613819 train_error 32.38% test_error 28.00%\n",
      "================================6423===================================\n",
      "6423/10000: train_loss: 3.5793606500700115 train_error 32.38% test_error 28.00%\n",
      "================================6424===================================\n",
      "6424/10000: train_loss: 3.579286609832197 train_error 32.38% test_error 28.00%\n",
      "================================6425===================================\n",
      "6425/10000: train_loss: 3.5792121208459142 train_error 32.38% test_error 28.00%\n",
      "================================6426===================================\n",
      "6426/10000: train_loss: 3.5791378346830607 train_error 32.38% test_error 28.00%\n",
      "================================6427===================================\n",
      "6427/10000: train_loss: 3.5790634457021953 train_error 32.38% test_error 28.00%\n",
      "================================6428===================================\n",
      "6428/10000: train_loss: 3.5789875439740717 train_error 32.38% test_error 28.00%\n",
      "================================6429===================================\n",
      "6429/10000: train_loss: 3.5789114732109013 train_error 32.38% test_error 28.00%\n",
      "================================6430===================================\n",
      "6430/10000: train_loss: 3.578835528176278 train_error 32.38% test_error 28.00%\n",
      "================================6431===================================\n",
      "6431/10000: train_loss: 3.5787583687901496 train_error 32.38% test_error 28.00%\n",
      "================================6432===================================\n",
      "6432/10000: train_loss: 3.578680593315512 train_error 32.38% test_error 28.00%\n",
      "================================6433===================================\n",
      "6433/10000: train_loss: 3.578602134194225 train_error 32.38% test_error 28.00%\n",
      "================================6434===================================\n",
      "6434/10000: train_loss: 3.578520003110171 train_error 32.38% test_error 28.00%\n",
      "================================6435===================================\n",
      "6435/10000: train_loss: 3.578437670636922 train_error 32.38% test_error 28.00%\n",
      "================================6436===================================\n",
      "6436/10000: train_loss: 3.578354388363659 train_error 32.38% test_error 28.00%\n",
      "================================6437===================================\n",
      "6437/10000: train_loss: 3.5782705755531787 train_error 32.38% test_error 28.00%\n",
      "================================6438===================================\n",
      "6438/10000: train_loss: 3.578186750728637 train_error 32.38% test_error 28.00%\n",
      "================================6439===================================\n",
      "6439/10000: train_loss: 3.5781032283045353 train_error 32.38% test_error 28.00%\n",
      "================================6440===================================\n",
      "6440/10000: train_loss: 3.5780200969241562 train_error 32.25% test_error 28.00%\n",
      "================================6441===================================\n",
      "6441/10000: train_loss: 3.5779361112974586 train_error 32.25% test_error 28.00%\n",
      "================================6442===================================\n",
      "6442/10000: train_loss: 3.5778508385084566 train_error 32.25% test_error 28.00%\n",
      "================================6443===================================\n",
      "6443/10000: train_loss: 3.5777657786384225 train_error 32.25% test_error 28.00%\n",
      "================================6444===================================\n",
      "6444/10000: train_loss: 3.577679392322898 train_error 32.25% test_error 27.50%\n",
      "================================6445===================================\n",
      "6445/10000: train_loss: 3.5775934115238486 train_error 32.25% test_error 27.50%\n",
      "================================6446===================================\n",
      "6446/10000: train_loss: 3.577507677618414 train_error 32.25% test_error 27.50%\n",
      "================================6447===================================\n",
      "6447/10000: train_loss: 3.5774218512140212 train_error 32.25% test_error 27.50%\n",
      "================================6448===================================\n",
      "6448/10000: train_loss: 3.5773349264077843 train_error 32.12% test_error 27.50%\n",
      "================================6449===================================\n",
      "6449/10000: train_loss: 3.5772433293797077 train_error 32.12% test_error 27.50%\n",
      "================================6450===================================\n",
      "6450/10000: train_loss: 3.5771526931785047 train_error 32.12% test_error 27.50%\n",
      "================================6451===================================\n",
      "6451/10000: train_loss: 3.5770636619627476 train_error 32.12% test_error 27.50%\n",
      "================================6452===================================\n",
      "6452/10000: train_loss: 3.576974803395569 train_error 32.12% test_error 27.50%\n",
      "================================6453===================================\n",
      "6453/10000: train_loss: 3.5768857785500585 train_error 32.12% test_error 27.50%\n",
      "================================6454===================================\n",
      "6454/10000: train_loss: 3.5767970519326626 train_error 32.12% test_error 27.50%\n",
      "================================6455===================================\n",
      "6455/10000: train_loss: 3.576708210483193 train_error 32.12% test_error 27.50%\n",
      "================================6456===================================\n",
      "6456/10000: train_loss: 3.576618371978402 train_error 32.12% test_error 27.50%\n",
      "================================6457===================================\n",
      "6457/10000: train_loss: 3.5765259703435 train_error 32.12% test_error 27.50%\n",
      "================================6458===================================\n",
      "6458/10000: train_loss: 3.576432322114706 train_error 32.12% test_error 27.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6459===================================\n",
      "6459/10000: train_loss: 3.5763352690450847 train_error 32.12% test_error 27.00%\n",
      "================================6460===================================\n",
      "6460/10000: train_loss: 3.576237155534327 train_error 32.12% test_error 27.00%\n",
      "================================6461===================================\n",
      "6461/10000: train_loss: 3.5761389206908643 train_error 32.12% test_error 27.00%\n",
      "================================6462===================================\n",
      "6462/10000: train_loss: 3.5760403689183295 train_error 32.12% test_error 27.00%\n",
      "================================6463===================================\n",
      "6463/10000: train_loss: 3.575940093547106 train_error 32.12% test_error 27.00%\n",
      "================================6464===================================\n",
      "6464/10000: train_loss: 3.575841112155467 train_error 32.25% test_error 27.00%\n",
      "================================6465===================================\n",
      "6465/10000: train_loss: 3.5757428641989826 train_error 32.12% test_error 27.00%\n",
      "================================6466===================================\n",
      "6466/10000: train_loss: 3.575643366482109 train_error 32.12% test_error 27.00%\n",
      "================================6467===================================\n",
      "6467/10000: train_loss: 3.575541521217674 train_error 32.12% test_error 27.00%\n",
      "================================6468===================================\n",
      "6468/10000: train_loss: 3.5754400337673724 train_error 32.12% test_error 27.00%\n",
      "================================6469===================================\n",
      "6469/10000: train_loss: 3.575337582733482 train_error 32.25% test_error 27.00%\n",
      "================================6470===================================\n",
      "6470/10000: train_loss: 3.5752337497100233 train_error 32.25% test_error 27.00%\n",
      "================================6471===================================\n",
      "6471/10000: train_loss: 3.5751221831515427 train_error 32.25% test_error 27.00%\n",
      "================================6472===================================\n",
      "6472/10000: train_loss: 3.5750100975483656 train_error 32.25% test_error 27.00%\n",
      "================================6473===================================\n",
      "6473/10000: train_loss: 3.5748968943208457 train_error 32.25% test_error 27.00%\n",
      "================================6474===================================\n",
      "6474/10000: train_loss: 3.5747852699644866 train_error 32.25% test_error 27.00%\n",
      "================================6475===================================\n",
      "6475/10000: train_loss: 3.5746741655655203 train_error 32.25% test_error 27.00%\n",
      "================================6476===================================\n",
      "6476/10000: train_loss: 3.574562364704907 train_error 32.25% test_error 27.00%\n",
      "================================6477===================================\n",
      "6477/10000: train_loss: 3.5744500227086244 train_error 32.25% test_error 27.00%\n",
      "================================6478===================================\n",
      "6478/10000: train_loss: 3.574334567096084 train_error 32.25% test_error 27.00%\n",
      "================================6479===================================\n",
      "6479/10000: train_loss: 3.57421808520332 train_error 32.25% test_error 27.00%\n",
      "================================6480===================================\n",
      "6480/10000: train_loss: 3.574101527500898 train_error 32.25% test_error 27.00%\n",
      "================================6481===================================\n",
      "6481/10000: train_loss: 3.573984662629664 train_error 32.38% test_error 27.00%\n",
      "================================6482===================================\n",
      "6482/10000: train_loss: 3.573866282682866 train_error 32.38% test_error 27.00%\n",
      "================================6483===================================\n",
      "6483/10000: train_loss: 3.573747634459287 train_error 32.38% test_error 27.00%\n",
      "================================6484===================================\n",
      "6484/10000: train_loss: 3.5736281448043883 train_error 32.38% test_error 27.00%\n",
      "================================6485===================================\n",
      "6485/10000: train_loss: 3.5735069828853008 train_error 32.38% test_error 27.00%\n",
      "================================6486===================================\n",
      "6486/10000: train_loss: 3.573383029699326 train_error 32.38% test_error 27.00%\n",
      "================================6487===================================\n",
      "6487/10000: train_loss: 3.573253089468926 train_error 32.50% test_error 27.00%\n",
      "================================6488===================================\n",
      "6488/10000: train_loss: 3.5731217984855177 train_error 32.50% test_error 27.00%\n",
      "================================6489===================================\n",
      "6489/10000: train_loss: 3.572990455869585 train_error 32.50% test_error 27.00%\n",
      "================================6490===================================\n",
      "6490/10000: train_loss: 3.572857539374381 train_error 32.38% test_error 27.00%\n",
      "================================6491===================================\n",
      "6491/10000: train_loss: 3.572725719511509 train_error 32.38% test_error 27.00%\n",
      "================================6492===================================\n",
      "6492/10000: train_loss: 3.5725944345258176 train_error 32.38% test_error 27.00%\n",
      "================================6493===================================\n",
      "6493/10000: train_loss: 3.572462111953646 train_error 32.38% test_error 27.00%\n",
      "================================6494===================================\n",
      "6494/10000: train_loss: 3.5723279737867415 train_error 32.38% test_error 27.00%\n",
      "================================6495===================================\n",
      "6495/10000: train_loss: 3.5721929842047393 train_error 32.38% test_error 27.00%\n",
      "================================6496===================================\n",
      "6496/10000: train_loss: 3.5720572734251617 train_error 32.38% test_error 27.00%\n",
      "================================6497===================================\n",
      "6497/10000: train_loss: 3.571919139586389 train_error 32.38% test_error 27.00%\n",
      "================================6498===================================\n",
      "6498/10000: train_loss: 3.571780561823398 train_error 32.38% test_error 26.50%\n",
      "================================6499===================================\n",
      "6499/10000: train_loss: 3.571640362273902 train_error 32.38% test_error 26.50%\n",
      "================================6500===================================\n",
      "6500/10000: train_loss: 3.5714984741434455 train_error 32.38% test_error 26.50%\n",
      "================================6501===================================\n",
      "6501/10000: train_loss: 3.5713557821325956 train_error 32.38% test_error 26.50%\n",
      "================================6502===================================\n",
      "6502/10000: train_loss: 3.5712127131223674 train_error 32.38% test_error 26.50%\n",
      "================================6503===================================\n",
      "6503/10000: train_loss: 3.5710695499368015 train_error 32.25% test_error 26.00%\n",
      "================================6504===================================\n",
      "6504/10000: train_loss: 3.5709267737716437 train_error 32.25% test_error 26.00%\n",
      "================================6505===================================\n",
      "6505/10000: train_loss: 3.570784320589155 train_error 32.25% test_error 26.00%\n",
      "================================6506===================================\n",
      "6506/10000: train_loss: 3.5706441985070705 train_error 32.25% test_error 26.00%\n",
      "================================6507===================================\n",
      "6507/10000: train_loss: 3.5705019563436506 train_error 32.25% test_error 26.00%\n",
      "================================6508===================================\n",
      "6508/10000: train_loss: 3.570358227286488 train_error 32.25% test_error 26.00%\n",
      "================================6509===================================\n",
      "6509/10000: train_loss: 3.570211822390556 train_error 32.25% test_error 26.00%\n",
      "================================6510===================================\n",
      "6510/10000: train_loss: 3.5700638813152907 train_error 32.25% test_error 26.50%\n",
      "================================6511===================================\n",
      "6511/10000: train_loss: 3.569914689548314 train_error 32.25% test_error 26.50%\n",
      "================================6512===================================\n",
      "6512/10000: train_loss: 3.5697658477351073 train_error 32.12% test_error 26.50%\n",
      "================================6513===================================\n",
      "6513/10000: train_loss: 3.569616274368018 train_error 32.12% test_error 26.50%\n",
      "================================6514===================================\n",
      "6514/10000: train_loss: 3.569465509597212 train_error 32.12% test_error 26.50%\n",
      "================================6515===================================\n",
      "6515/10000: train_loss: 3.5693141782097517 train_error 32.12% test_error 26.50%\n",
      "================================6516===================================\n",
      "6516/10000: train_loss: 3.5691640601865946 train_error 32.12% test_error 26.50%\n",
      "================================6517===================================\n",
      "6517/10000: train_loss: 3.5690118221752343 train_error 32.12% test_error 26.50%\n",
      "================================6518===================================\n",
      "6518/10000: train_loss: 3.5688513488695026 train_error 32.12% test_error 26.00%\n",
      "================================6519===================================\n",
      "6519/10000: train_loss: 3.5686890377104286 train_error 32.25% test_error 25.50%\n",
      "================================6520===================================\n",
      "6520/10000: train_loss: 3.568524557966739 train_error 32.25% test_error 25.50%\n",
      "================================6521===================================\n",
      "6521/10000: train_loss: 3.5683585737273096 train_error 32.25% test_error 25.50%\n",
      "================================6522===================================\n",
      "6522/10000: train_loss: 3.5681907738372685 train_error 32.25% test_error 25.50%\n",
      "================================6523===================================\n",
      "6523/10000: train_loss: 3.568022320009768 train_error 32.25% test_error 25.50%\n",
      "================================6524===================================\n",
      "6524/10000: train_loss: 3.5678512675873937 train_error 32.25% test_error 25.50%\n",
      "================================6525===================================\n",
      "6525/10000: train_loss: 3.567677942868322 train_error 32.25% test_error 25.50%\n",
      "================================6526===================================\n",
      "6526/10000: train_loss: 3.5675021006539462 train_error 32.25% test_error 25.50%\n",
      "================================6527===================================\n",
      "6527/10000: train_loss: 3.567326584886759 train_error 32.25% test_error 25.50%\n",
      "================================6528===================================\n",
      "6528/10000: train_loss: 3.5671511828899387 train_error 32.25% test_error 25.50%\n",
      "================================6529===================================\n",
      "6529/10000: train_loss: 3.566974822934717 train_error 32.25% test_error 25.50%\n",
      "================================6530===================================\n",
      "6530/10000: train_loss: 3.5667978975363077 train_error 32.25% test_error 25.50%\n",
      "================================6531===================================\n",
      "6531/10000: train_loss: 3.5666209128312767 train_error 32.25% test_error 25.50%\n",
      "================================6532===================================\n",
      "6532/10000: train_loss: 3.566444005779922 train_error 32.25% test_error 25.50%\n",
      "================================6533===================================\n",
      "6533/10000: train_loss: 3.5662670808658 train_error 32.25% test_error 25.00%\n",
      "================================6534===================================\n",
      "6534/10000: train_loss: 3.5660882879421116 train_error 32.25% test_error 25.00%\n",
      "================================6535===================================\n",
      "6535/10000: train_loss: 3.565906875599176 train_error 32.25% test_error 25.00%\n",
      "================================6536===================================\n",
      "6536/10000: train_loss: 3.5657278746925294 train_error 32.25% test_error 25.00%\n",
      "================================6537===================================\n",
      "6537/10000: train_loss: 3.5655483553372327 train_error 32.25% test_error 25.00%\n",
      "================================6538===================================\n",
      "6538/10000: train_loss: 3.5653645174205306 train_error 32.00% test_error 25.00%\n",
      "================================6539===================================\n",
      "6539/10000: train_loss: 3.565176796093583 train_error 32.00% test_error 25.00%\n",
      "================================6540===================================\n",
      "6540/10000: train_loss: 3.5649848051555453 train_error 32.00% test_error 25.00%\n",
      "================================6541===================================\n",
      "6541/10000: train_loss: 3.5647920664027333 train_error 32.00% test_error 25.00%\n",
      "================================6542===================================\n",
      "6542/10000: train_loss: 3.564598854519427 train_error 32.00% test_error 25.00%\n",
      "================================6543===================================\n",
      "6543/10000: train_loss: 3.5644055519625546 train_error 32.00% test_error 25.50%\n",
      "================================6544===================================\n",
      "6544/10000: train_loss: 3.56420916615054 train_error 32.00% test_error 25.50%\n",
      "================================6545===================================\n",
      "6545/10000: train_loss: 3.564011140242219 train_error 32.00% test_error 25.50%\n",
      "================================6546===================================\n",
      "6546/10000: train_loss: 3.56381207453087 train_error 32.00% test_error 25.50%\n",
      "================================6547===================================\n",
      "6547/10000: train_loss: 3.5636081842146816 train_error 32.00% test_error 25.50%\n",
      "================================6548===================================\n",
      "6548/10000: train_loss: 3.5634042072109877 train_error 32.00% test_error 25.50%\n",
      "================================6549===================================\n",
      "6549/10000: train_loss: 3.5631983999535444 train_error 32.00% test_error 25.50%\n",
      "================================6550===================================\n",
      "6550/10000: train_loss: 3.562991295196116 train_error 32.00% test_error 25.50%\n",
      "================================6551===================================\n",
      "6551/10000: train_loss: 3.5627823799103497 train_error 32.00% test_error 25.50%\n",
      "================================6552===================================\n",
      "6552/10000: train_loss: 3.5625712121836837 train_error 32.00% test_error 25.50%\n",
      "================================6553===================================\n",
      "6553/10000: train_loss: 3.5623514793626967 train_error 32.00% test_error 25.50%\n",
      "================================6554===================================\n",
      "6554/10000: train_loss: 3.562130086924881 train_error 32.00% test_error 25.50%\n",
      "================================6555===================================\n",
      "6555/10000: train_loss: 3.561908083669841 train_error 32.00% test_error 25.50%\n",
      "================================6556===================================\n",
      "6556/10000: train_loss: 3.5616858176887036 train_error 32.00% test_error 25.50%\n",
      "================================6557===================================\n",
      "6557/10000: train_loss: 3.561462624426931 train_error 32.00% test_error 25.50%\n",
      "================================6558===================================\n",
      "6558/10000: train_loss: 3.561240391116589 train_error 32.00% test_error 25.50%\n",
      "================================6559===================================\n",
      "6559/10000: train_loss: 3.561019975524396 train_error 32.00% test_error 25.50%\n",
      "================================6560===================================\n",
      "6560/10000: train_loss: 3.5608013934083282 train_error 32.00% test_error 25.50%\n",
      "================================6561===================================\n",
      "6561/10000: train_loss: 3.560582307484001 train_error 32.00% test_error 25.50%\n",
      "================================6562===================================\n",
      "6562/10000: train_loss: 3.5603625224530697 train_error 32.00% test_error 25.50%\n",
      "================================6563===================================\n",
      "6563/10000: train_loss: 3.560142214503139 train_error 32.00% test_error 25.50%\n",
      "================================6564===================================\n",
      "6564/10000: train_loss: 3.5599212114699186 train_error 32.00% test_error 25.50%\n",
      "================================6565===================================\n",
      "6565/10000: train_loss: 3.559696694165468 train_error 32.00% test_error 25.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6566===================================\n",
      "6566/10000: train_loss: 3.5594708933494985 train_error 32.00% test_error 25.50%\n",
      "================================6567===================================\n",
      "6567/10000: train_loss: 3.559244649056345 train_error 32.00% test_error 25.50%\n",
      "================================6568===================================\n",
      "6568/10000: train_loss: 3.559017391633242 train_error 32.00% test_error 26.00%\n",
      "================================6569===================================\n",
      "6569/10000: train_loss: 3.5587865627370774 train_error 32.00% test_error 26.00%\n",
      "================================6570===================================\n",
      "6570/10000: train_loss: 3.5585550236701966 train_error 32.00% test_error 26.00%\n",
      "================================6571===================================\n",
      "6571/10000: train_loss: 3.5583226202800873 train_error 32.00% test_error 26.00%\n",
      "================================6572===================================\n",
      "6572/10000: train_loss: 3.558085394371301 train_error 32.00% test_error 26.00%\n",
      "================================6573===================================\n",
      "6573/10000: train_loss: 3.557847634740174 train_error 32.00% test_error 26.00%\n",
      "================================6574===================================\n",
      "6574/10000: train_loss: 3.557612163964659 train_error 32.00% test_error 26.00%\n",
      "================================6575===================================\n",
      "6575/10000: train_loss: 3.5573768332973126 train_error 32.00% test_error 26.00%\n",
      "================================6576===================================\n",
      "6576/10000: train_loss: 3.5571406227722764 train_error 32.00% test_error 26.00%\n",
      "================================6577===================================\n",
      "6577/10000: train_loss: 3.556906651873142 train_error 32.00% test_error 26.00%\n",
      "================================6578===================================\n",
      "6578/10000: train_loss: 3.5566709598153827 train_error 32.00% test_error 26.00%\n",
      "================================6579===================================\n",
      "6579/10000: train_loss: 3.556436736416072 train_error 32.00% test_error 26.00%\n",
      "================================6580===================================\n",
      "6580/10000: train_loss: 3.556203429717571 train_error 32.00% test_error 26.00%\n",
      "================================6581===================================\n",
      "6581/10000: train_loss: 3.5559695215150713 train_error 32.00% test_error 26.00%\n",
      "================================6582===================================\n",
      "6582/10000: train_loss: 3.555731799416244 train_error 32.00% test_error 26.00%\n",
      "================================6583===================================\n",
      "6583/10000: train_loss: 3.5554932036623357 train_error 32.00% test_error 26.00%\n",
      "================================6584===================================\n",
      "6584/10000: train_loss: 3.5552522711642087 train_error 32.00% test_error 26.00%\n",
      "================================6585===================================\n",
      "6585/10000: train_loss: 3.555004973821342 train_error 32.12% test_error 26.00%\n",
      "================================6586===================================\n",
      "6586/10000: train_loss: 3.554756666775793 train_error 32.12% test_error 26.00%\n",
      "================================6587===================================\n",
      "6587/10000: train_loss: 3.5545100277103483 train_error 32.12% test_error 26.00%\n",
      "================================6588===================================\n",
      "6588/10000: train_loss: 3.5542624988779425 train_error 32.12% test_error 26.00%\n",
      "================================6589===================================\n",
      "6589/10000: train_loss: 3.5540151314064863 train_error 32.25% test_error 26.00%\n",
      "================================6590===================================\n",
      "6590/10000: train_loss: 3.5537677852064373 train_error 32.38% test_error 26.00%\n",
      "================================6591===================================\n",
      "6591/10000: train_loss: 3.5535199590027333 train_error 32.38% test_error 26.00%\n",
      "================================6592===================================\n",
      "6592/10000: train_loss: 3.553272861763835 train_error 32.38% test_error 26.00%\n",
      "================================6593===================================\n",
      "6593/10000: train_loss: 3.5530259166657925 train_error 32.38% test_error 25.50%\n",
      "================================6594===================================\n",
      "6594/10000: train_loss: 3.552778801582754 train_error 32.38% test_error 25.50%\n",
      "================================6595===================================\n",
      "6595/10000: train_loss: 3.552531040813774 train_error 32.38% test_error 25.50%\n",
      "================================6596===================================\n",
      "6596/10000: train_loss: 3.552277324330062 train_error 32.38% test_error 25.50%\n",
      "================================6597===================================\n",
      "6597/10000: train_loss: 3.5520160050317644 train_error 32.38% test_error 25.50%\n",
      "================================6598===================================\n",
      "6598/10000: train_loss: 3.551751246489584 train_error 32.38% test_error 25.50%\n",
      "================================6599===================================\n",
      "6599/10000: train_loss: 3.551484054867178 train_error 32.38% test_error 25.50%\n",
      "================================6600===================================\n",
      "6600/10000: train_loss: 3.5512153733149168 train_error 32.38% test_error 25.50%\n",
      "================================6601===================================\n",
      "6601/10000: train_loss: 3.5509462608210742 train_error 32.38% test_error 25.50%\n",
      "================================6602===================================\n",
      "6602/10000: train_loss: 3.550676412433386 train_error 32.38% test_error 25.50%\n",
      "================================6603===================================\n",
      "6603/10000: train_loss: 3.5504079453274606 train_error 32.38% test_error 25.50%\n",
      "================================6604===================================\n",
      "6604/10000: train_loss: 3.550139270927757 train_error 32.38% test_error 25.50%\n",
      "================================6605===================================\n",
      "6605/10000: train_loss: 3.5498702536150812 train_error 32.38% test_error 25.50%\n",
      "================================6606===================================\n",
      "6606/10000: train_loss: 3.5496010231785475 train_error 32.25% test_error 25.50%\n",
      "================================6607===================================\n",
      "6607/10000: train_loss: 3.5493317824415858 train_error 32.12% test_error 25.50%\n",
      "================================6608===================================\n",
      "6608/10000: train_loss: 3.5490619788877664 train_error 32.00% test_error 25.50%\n",
      "================================6609===================================\n",
      "6609/10000: train_loss: 3.548792951330543 train_error 32.00% test_error 25.50%\n",
      "================================6610===================================\n",
      "6610/10000: train_loss: 3.548524476122111 train_error 32.00% test_error 25.50%\n",
      "================================6611===================================\n",
      "6611/10000: train_loss: 3.5482566785253584 train_error 31.87% test_error 25.50%\n",
      "================================6612===================================\n",
      "6612/10000: train_loss: 3.5479901876300572 train_error 31.87% test_error 25.50%\n",
      "================================6613===================================\n",
      "6613/10000: train_loss: 3.547724179662764 train_error 31.87% test_error 25.50%\n",
      "================================6614===================================\n",
      "6614/10000: train_loss: 3.5474606240727002 train_error 31.87% test_error 25.00%\n",
      "================================6615===================================\n",
      "6615/10000: train_loss: 3.547198142446578 train_error 31.87% test_error 25.00%\n",
      "================================6616===================================\n",
      "6616/10000: train_loss: 3.546935734469444 train_error 31.87% test_error 25.00%\n",
      "================================6617===================================\n",
      "6617/10000: train_loss: 3.546671912688762 train_error 31.75% test_error 25.00%\n",
      "================================6618===================================\n",
      "6618/10000: train_loss: 3.546407584603876 train_error 31.75% test_error 25.00%\n",
      "================================6619===================================\n",
      "6619/10000: train_loss: 3.5461426675133407 train_error 31.75% test_error 25.00%\n",
      "================================6620===================================\n",
      "6620/10000: train_loss: 3.5458785772882404 train_error 31.75% test_error 25.00%\n",
      "================================6621===================================\n",
      "6621/10000: train_loss: 3.545613958034665 train_error 31.75% test_error 25.00%\n",
      "================================6622===================================\n",
      "6622/10000: train_loss: 3.5453490467928352 train_error 31.75% test_error 25.00%\n",
      "================================6623===================================\n",
      "6623/10000: train_loss: 3.545083112455904 train_error 31.62% test_error 25.00%\n",
      "================================6624===================================\n",
      "6624/10000: train_loss: 3.544817136451602 train_error 31.50% test_error 25.00%\n",
      "================================6625===================================\n",
      "6625/10000: train_loss: 3.544549923669547 train_error 31.50% test_error 25.00%\n",
      "================================6626===================================\n",
      "6626/10000: train_loss: 3.5442807327583434 train_error 31.50% test_error 25.00%\n",
      "================================6627===================================\n",
      "6627/10000: train_loss: 3.544012657701969 train_error 31.50% test_error 25.00%\n",
      "================================6628===================================\n",
      "6628/10000: train_loss: 3.5437457821518183 train_error 31.50% test_error 25.00%\n",
      "================================6629===================================\n",
      "6629/10000: train_loss: 3.5434774956479673 train_error 31.50% test_error 25.00%\n",
      "================================6630===================================\n",
      "6630/10000: train_loss: 3.5432093610428272 train_error 31.50% test_error 25.00%\n",
      "================================6631===================================\n",
      "6631/10000: train_loss: 3.542940658386797 train_error 31.50% test_error 25.00%\n",
      "================================6632===================================\n",
      "6632/10000: train_loss: 3.542667709738016 train_error 31.50% test_error 25.00%\n",
      "================================6633===================================\n",
      "6633/10000: train_loss: 3.5423949570022524 train_error 31.50% test_error 25.00%\n",
      "================================6634===================================\n",
      "6634/10000: train_loss: 3.5421253928914664 train_error 31.50% test_error 25.00%\n",
      "================================6635===================================\n",
      "6635/10000: train_loss: 3.541854058913887 train_error 31.50% test_error 25.00%\n",
      "================================6636===================================\n",
      "6636/10000: train_loss: 3.541581580489874 train_error 31.50% test_error 25.00%\n",
      "================================6637===================================\n",
      "6637/10000: train_loss: 3.5413069975562395 train_error 31.50% test_error 25.00%\n",
      "================================6638===================================\n",
      "6638/10000: train_loss: 3.5410331206955017 train_error 31.62% test_error 25.00%\n",
      "================================6639===================================\n",
      "6639/10000: train_loss: 3.540758823826909 train_error 31.62% test_error 25.00%\n",
      "================================6640===================================\n",
      "6640/10000: train_loss: 3.540483277682215 train_error 31.62% test_error 25.00%\n",
      "================================6641===================================\n",
      "6641/10000: train_loss: 3.5402058540843426 train_error 31.62% test_error 25.00%\n",
      "================================6642===================================\n",
      "6642/10000: train_loss: 3.539928124751895 train_error 31.62% test_error 25.00%\n",
      "================================6643===================================\n",
      "6643/10000: train_loss: 3.5396507620625197 train_error 31.75% test_error 25.00%\n",
      "================================6644===================================\n",
      "6644/10000: train_loss: 3.5393736614100635 train_error 31.75% test_error 25.00%\n",
      "================================6645===================================\n",
      "6645/10000: train_loss: 3.5390962746925654 train_error 31.75% test_error 25.00%\n",
      "================================6646===================================\n",
      "6646/10000: train_loss: 3.538814951479435 train_error 31.75% test_error 25.00%\n",
      "================================6647===================================\n",
      "6647/10000: train_loss: 3.538531248122454 train_error 31.75% test_error 25.00%\n",
      "================================6648===================================\n",
      "6648/10000: train_loss: 3.5382415069825948 train_error 31.87% test_error 25.00%\n",
      "================================6649===================================\n",
      "6649/10000: train_loss: 3.537949818316847 train_error 32.00% test_error 25.00%\n",
      "================================6650===================================\n",
      "6650/10000: train_loss: 3.5376558077894154 train_error 31.87% test_error 25.00%\n",
      "================================6651===================================\n",
      "6651/10000: train_loss: 3.5373619272187353 train_error 31.87% test_error 25.00%\n",
      "================================6652===================================\n",
      "6652/10000: train_loss: 3.5370666092447935 train_error 31.87% test_error 25.00%\n",
      "================================6653===================================\n",
      "6653/10000: train_loss: 3.5367704385705294 train_error 31.87% test_error 25.00%\n",
      "================================6654===================================\n",
      "6654/10000: train_loss: 3.5364762985520066 train_error 31.87% test_error 25.00%\n",
      "================================6655===================================\n",
      "6655/10000: train_loss: 3.5361821161583067 train_error 31.87% test_error 25.00%\n",
      "================================6656===================================\n",
      "6656/10000: train_loss: 3.535889904070645 train_error 31.87% test_error 25.00%\n",
      "================================6657===================================\n",
      "6657/10000: train_loss: 3.5355969258770346 train_error 31.87% test_error 25.00%\n",
      "================================6658===================================\n",
      "6658/10000: train_loss: 3.5353039630874985 train_error 31.87% test_error 25.00%\n",
      "================================6659===================================\n",
      "6659/10000: train_loss: 3.5350113841891284 train_error 31.87% test_error 25.00%\n",
      "================================6660===================================\n",
      "6660/10000: train_loss: 3.5347188847512006 train_error 32.00% test_error 25.00%\n",
      "================================6661===================================\n",
      "6661/10000: train_loss: 3.5344267364591357 train_error 32.00% test_error 25.00%\n",
      "================================6662===================================\n",
      "6662/10000: train_loss: 3.534134055282921 train_error 31.87% test_error 25.00%\n",
      "================================6663===================================\n",
      "6663/10000: train_loss: 3.5338404429517682 train_error 31.87% test_error 25.00%\n",
      "================================6664===================================\n",
      "6664/10000: train_loss: 3.533544831741601 train_error 31.75% test_error 25.00%\n",
      "================================6665===================================\n",
      "6665/10000: train_loss: 3.5332490785792467 train_error 31.75% test_error 25.00%\n",
      "================================6666===================================\n",
      "6666/10000: train_loss: 3.5329522173665464 train_error 31.75% test_error 25.00%\n",
      "================================6667===================================\n",
      "6667/10000: train_loss: 3.532652573622763 train_error 31.75% test_error 25.00%\n",
      "================================6668===================================\n",
      "6668/10000: train_loss: 3.5323525385372343 train_error 31.75% test_error 25.00%\n",
      "================================6669===================================\n",
      "6669/10000: train_loss: 3.5320522009022532 train_error 31.75% test_error 25.00%\n",
      "================================6670===================================\n",
      "6670/10000: train_loss: 3.5317511429265145 train_error 31.75% test_error 25.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6671===================================\n",
      "6671/10000: train_loss: 3.5314494101703167 train_error 31.75% test_error 25.00%\n",
      "================================6672===================================\n",
      "6672/10000: train_loss: 3.5311460527032614 train_error 31.75% test_error 25.00%\n",
      "================================6673===================================\n",
      "6673/10000: train_loss: 3.53084253013134 train_error 31.75% test_error 25.00%\n",
      "================================6674===================================\n",
      "6674/10000: train_loss: 3.530539409127086 train_error 31.75% test_error 25.00%\n",
      "================================6675===================================\n",
      "6675/10000: train_loss: 3.5302372854948043 train_error 31.75% test_error 25.00%\n",
      "================================6676===================================\n",
      "6676/10000: train_loss: 3.52993728576228 train_error 31.75% test_error 24.50%\n",
      "================================6677===================================\n",
      "6677/10000: train_loss: 3.529638592042029 train_error 31.75% test_error 24.50%\n",
      "================================6678===================================\n",
      "6678/10000: train_loss: 3.5293381571210922 train_error 31.75% test_error 24.50%\n",
      "================================6679===================================\n",
      "6679/10000: train_loss: 3.5290345347672702 train_error 31.62% test_error 24.50%\n",
      "================================6680===================================\n",
      "6680/10000: train_loss: 3.5287312187999484 train_error 31.50% test_error 24.50%\n",
      "================================6681===================================\n",
      "6681/10000: train_loss: 3.528428709767759 train_error 31.50% test_error 24.50%\n",
      "================================6682===================================\n",
      "6682/10000: train_loss: 3.5281248032860457 train_error 31.50% test_error 24.50%\n",
      "================================6683===================================\n",
      "6683/10000: train_loss: 3.527824084516615 train_error 31.50% test_error 24.50%\n",
      "================================6684===================================\n",
      "6684/10000: train_loss: 3.5275226244702935 train_error 31.50% test_error 24.50%\n",
      "================================6685===================================\n",
      "6685/10000: train_loss: 3.527218497060239 train_error 31.50% test_error 24.50%\n",
      "================================6686===================================\n",
      "6686/10000: train_loss: 3.5269079284742473 train_error 31.62% test_error 24.00%\n",
      "================================6687===================================\n",
      "6687/10000: train_loss: 3.5265962150506676 train_error 31.62% test_error 24.00%\n",
      "================================6688===================================\n",
      "6688/10000: train_loss: 3.5262847236543893 train_error 31.62% test_error 24.50%\n",
      "================================6689===================================\n",
      "6689/10000: train_loss: 3.5259724724106487 train_error 31.62% test_error 24.00%\n",
      "================================6690===================================\n",
      "6690/10000: train_loss: 3.5256564382463695 train_error 31.62% test_error 24.00%\n",
      "================================6691===================================\n",
      "6691/10000: train_loss: 3.525341558177024 train_error 31.62% test_error 24.00%\n",
      "================================6692===================================\n",
      "6692/10000: train_loss: 3.5250272920727728 train_error 31.50% test_error 24.00%\n",
      "================================6693===================================\n",
      "6693/10000: train_loss: 3.5247087475471197 train_error 31.62% test_error 24.00%\n",
      "================================6694===================================\n",
      "6694/10000: train_loss: 3.524387201555073 train_error 31.62% test_error 24.00%\n",
      "================================6695===================================\n",
      "6695/10000: train_loss: 3.524067091513425 train_error 31.62% test_error 24.00%\n",
      "================================6696===================================\n",
      "6696/10000: train_loss: 3.5237402811087666 train_error 31.62% test_error 24.00%\n",
      "================================6697===================================\n",
      "6697/10000: train_loss: 3.5234063703566787 train_error 31.75% test_error 24.00%\n",
      "================================6698===================================\n",
      "6698/10000: train_loss: 3.5230709447525443 train_error 31.75% test_error 24.00%\n",
      "================================6699===================================\n",
      "6699/10000: train_loss: 3.522732031773776 train_error 31.75% test_error 24.00%\n",
      "================================6700===================================\n",
      "6700/10000: train_loss: 3.522389205209911 train_error 31.75% test_error 24.00%\n",
      "================================6701===================================\n",
      "6701/10000: train_loss: 3.522039320599288 train_error 31.75% test_error 24.00%\n",
      "================================6702===================================\n",
      "6702/10000: train_loss: 3.521688629500568 train_error 31.62% test_error 24.00%\n",
      "================================6703===================================\n",
      "6703/10000: train_loss: 3.5213353591039778 train_error 31.62% test_error 24.00%\n",
      "================================6704===================================\n",
      "6704/10000: train_loss: 3.5209781925193964 train_error 31.62% test_error 24.00%\n",
      "================================6705===================================\n",
      "6705/10000: train_loss: 3.5206207196228205 train_error 31.62% test_error 24.00%\n",
      "================================6706===================================\n",
      "6706/10000: train_loss: 3.520263706315309 train_error 31.62% test_error 24.00%\n",
      "================================6707===================================\n",
      "6707/10000: train_loss: 3.519906389657408 train_error 31.62% test_error 24.00%\n",
      "================================6708===================================\n",
      "6708/10000: train_loss: 3.519547719396651 train_error 31.62% test_error 24.00%\n",
      "================================6709===================================\n",
      "6709/10000: train_loss: 3.5191878874041143 train_error 31.62% test_error 24.00%\n",
      "================================6710===================================\n",
      "6710/10000: train_loss: 3.518827117085457 train_error 31.62% test_error 24.00%\n",
      "================================6711===================================\n",
      "6711/10000: train_loss: 3.5184669856540856 train_error 31.62% test_error 24.00%\n",
      "================================6712===================================\n",
      "6712/10000: train_loss: 3.5181076861731713 train_error 31.62% test_error 24.00%\n",
      "================================6713===================================\n",
      "6713/10000: train_loss: 3.5177476563118395 train_error 31.62% test_error 24.00%\n",
      "================================6714===================================\n",
      "6714/10000: train_loss: 3.517383958566934 train_error 31.62% test_error 24.00%\n",
      "================================6715===================================\n",
      "6715/10000: train_loss: 3.517020228691399 train_error 31.62% test_error 24.00%\n",
      "================================6716===================================\n",
      "6716/10000: train_loss: 3.516655525807291 train_error 31.62% test_error 24.00%\n",
      "================================6717===================================\n",
      "6717/10000: train_loss: 3.5162850242480634 train_error 31.62% test_error 24.00%\n",
      "================================6718===================================\n",
      "6718/10000: train_loss: 3.515911491215229 train_error 31.62% test_error 24.00%\n",
      "================================6719===================================\n",
      "6719/10000: train_loss: 3.515533939320594 train_error 31.62% test_error 24.00%\n",
      "================================6720===================================\n",
      "6720/10000: train_loss: 3.5151539135538044 train_error 31.62% test_error 24.00%\n",
      "================================6721===================================\n",
      "6721/10000: train_loss: 3.5147685317881403 train_error 31.75% test_error 24.00%\n",
      "================================6722===================================\n",
      "6722/10000: train_loss: 3.5143841630779207 train_error 31.75% test_error 24.00%\n",
      "================================6723===================================\n",
      "6723/10000: train_loss: 3.513999356776476 train_error 31.87% test_error 24.00%\n",
      "================================6724===================================\n",
      "6724/10000: train_loss: 3.513611600911245 train_error 31.87% test_error 24.00%\n",
      "================================6725===================================\n",
      "6725/10000: train_loss: 3.5132238306105137 train_error 31.87% test_error 24.00%\n",
      "================================6726===================================\n",
      "6726/10000: train_loss: 3.512834357311949 train_error 31.87% test_error 24.00%\n",
      "================================6727===================================\n",
      "6727/10000: train_loss: 3.5124433369468893 train_error 31.87% test_error 24.00%\n",
      "================================6728===================================\n",
      "6728/10000: train_loss: 3.512051721587777 train_error 31.87% test_error 24.00%\n",
      "================================6729===================================\n",
      "6729/10000: train_loss: 3.5116589098982516 train_error 31.75% test_error 24.00%\n",
      "================================6730===================================\n",
      "6730/10000: train_loss: 3.5112644042167815 train_error 31.75% test_error 24.00%\n",
      "================================6731===================================\n",
      "6731/10000: train_loss: 3.5108698685467243 train_error 31.75% test_error 24.00%\n",
      "================================6732===================================\n",
      "6732/10000: train_loss: 3.5104754375014453 train_error 31.75% test_error 24.00%\n",
      "================================6733===================================\n",
      "6733/10000: train_loss: 3.5100815096404405 train_error 31.62% test_error 24.00%\n",
      "================================6734===================================\n",
      "6734/10000: train_loss: 3.509687388772145 train_error 31.62% test_error 24.00%\n",
      "================================6735===================================\n",
      "6735/10000: train_loss: 3.5092934094741945 train_error 31.62% test_error 24.00%\n",
      "================================6736===================================\n",
      "6736/10000: train_loss: 3.50889332733117 train_error 31.62% test_error 24.00%\n",
      "================================6737===================================\n",
      "6737/10000: train_loss: 3.508493253812194 train_error 31.62% test_error 24.00%\n",
      "================================6738===================================\n",
      "6738/10000: train_loss: 3.5080930714681746 train_error 31.62% test_error 24.00%\n",
      "================================6739===================================\n",
      "6739/10000: train_loss: 3.5076904273312537 train_error 31.62% test_error 24.00%\n",
      "================================6740===================================\n",
      "6740/10000: train_loss: 3.507287648133934 train_error 31.50% test_error 24.00%\n",
      "================================6741===================================\n",
      "6741/10000: train_loss: 3.506885360190645 train_error 31.50% test_error 24.00%\n",
      "================================6742===================================\n",
      "6742/10000: train_loss: 3.5064837409742178 train_error 31.50% test_error 24.00%\n",
      "================================6743===================================\n",
      "6743/10000: train_loss: 3.5060810450278224 train_error 31.50% test_error 24.00%\n",
      "================================6744===================================\n",
      "6744/10000: train_loss: 3.505677362093702 train_error 31.50% test_error 24.00%\n",
      "================================6745===================================\n",
      "6745/10000: train_loss: 3.5052720208652315 train_error 31.50% test_error 24.00%\n",
      "================================6746===================================\n",
      "6746/10000: train_loss: 3.5048684259131555 train_error 31.50% test_error 24.00%\n",
      "================================6747===================================\n",
      "6747/10000: train_loss: 3.5044668367877603 train_error 31.50% test_error 24.00%\n",
      "================================6748===================================\n",
      "6748/10000: train_loss: 3.504061540933326 train_error 31.50% test_error 24.00%\n",
      "================================6749===================================\n",
      "6749/10000: train_loss: 3.5036572395078838 train_error 31.50% test_error 24.00%\n",
      "================================6750===================================\n",
      "6750/10000: train_loss: 3.5032534569781273 train_error 31.50% test_error 24.00%\n",
      "================================6751===================================\n",
      "6751/10000: train_loss: 3.502849713517353 train_error 31.50% test_error 24.00%\n",
      "================================6752===================================\n",
      "6752/10000: train_loss: 3.5024426862318068 train_error 31.50% test_error 24.00%\n",
      "================================6753===================================\n",
      "6753/10000: train_loss: 3.50203606964089 train_error 31.50% test_error 24.00%\n",
      "================================6754===================================\n",
      "6754/10000: train_loss: 3.5016294106375425 train_error 31.50% test_error 24.50%\n",
      "================================6755===================================\n",
      "6755/10000: train_loss: 3.5012214294075967 train_error 31.50% test_error 24.50%\n",
      "================================6756===================================\n",
      "6756/10000: train_loss: 3.500813298514113 train_error 31.50% test_error 24.50%\n",
      "================================6757===================================\n",
      "6757/10000: train_loss: 3.5004043340124187 train_error 31.50% test_error 24.50%\n",
      "================================6758===================================\n",
      "6758/10000: train_loss: 3.4999942774605004 train_error 31.50% test_error 24.50%\n",
      "================================6759===================================\n",
      "6759/10000: train_loss: 3.4995804899092766 train_error 31.50% test_error 24.50%\n",
      "================================6760===================================\n",
      "6760/10000: train_loss: 3.499166041975841 train_error 31.50% test_error 24.50%\n",
      "================================6761===================================\n",
      "6761/10000: train_loss: 3.498751450944692 train_error 31.50% test_error 24.50%\n",
      "================================6762===================================\n",
      "6762/10000: train_loss: 3.498338349899277 train_error 31.50% test_error 24.50%\n",
      "================================6763===================================\n",
      "6763/10000: train_loss: 3.497924295235425 train_error 31.50% test_error 24.50%\n",
      "================================6764===================================\n",
      "6764/10000: train_loss: 3.497510567670688 train_error 31.50% test_error 24.50%\n",
      "================================6765===================================\n",
      "6765/10000: train_loss: 3.497095807995647 train_error 31.50% test_error 24.50%\n",
      "================================6766===================================\n",
      "6766/10000: train_loss: 3.4966790928319096 train_error 31.37% test_error 24.50%\n",
      "================================6767===================================\n",
      "6767/10000: train_loss: 3.4962600830662995 train_error 31.37% test_error 24.50%\n",
      "================================6768===================================\n",
      "6768/10000: train_loss: 3.495841947356239 train_error 31.37% test_error 24.50%\n",
      "================================6769===================================\n",
      "6769/10000: train_loss: 3.495422679996118 train_error 31.37% test_error 24.50%\n",
      "================================6770===================================\n",
      "6770/10000: train_loss: 3.4950031697098165 train_error 31.37% test_error 24.50%\n",
      "================================6771===================================\n",
      "6771/10000: train_loss: 3.494590150117874 train_error 31.50% test_error 24.50%\n",
      "================================6772===================================\n",
      "6772/10000: train_loss: 3.494177490659058 train_error 31.50% test_error 24.50%\n",
      "================================6773===================================\n",
      "6773/10000: train_loss: 3.4937649407144638 train_error 31.50% test_error 24.50%\n",
      "================================6774===================================\n",
      "6774/10000: train_loss: 3.4933461588621144 train_error 31.50% test_error 24.50%\n",
      "================================6775===================================\n",
      "6775/10000: train_loss: 3.492924267901108 train_error 31.50% test_error 24.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6776===================================\n",
      "6776/10000: train_loss: 3.4925021408870816 train_error 31.50% test_error 24.50%\n",
      "================================6777===================================\n",
      "6777/10000: train_loss: 3.4920797299873083 train_error 31.50% test_error 24.50%\n",
      "================================6778===================================\n",
      "6778/10000: train_loss: 3.491658619390801 train_error 31.50% test_error 24.50%\n",
      "================================6779===================================\n",
      "6779/10000: train_loss: 3.491239549545571 train_error 31.50% test_error 24.50%\n",
      "================================6780===================================\n",
      "6780/10000: train_loss: 3.49082283353433 train_error 31.50% test_error 24.50%\n",
      "================================6781===================================\n",
      "6781/10000: train_loss: 3.490407584635541 train_error 31.25% test_error 24.50%\n",
      "================================6782===================================\n",
      "6782/10000: train_loss: 3.4899924099072814 train_error 31.25% test_error 24.50%\n",
      "================================6783===================================\n",
      "6783/10000: train_loss: 3.4895772786438464 train_error 31.25% test_error 24.50%\n",
      "================================6784===================================\n",
      "6784/10000: train_loss: 3.4891578416433187 train_error 31.25% test_error 24.50%\n",
      "================================6785===================================\n",
      "6785/10000: train_loss: 3.4887366958148776 train_error 31.25% test_error 24.50%\n",
      "================================6786===================================\n",
      "6786/10000: train_loss: 3.488314983220771 train_error 31.25% test_error 24.50%\n",
      "================================6787===================================\n",
      "6787/10000: train_loss: 3.4878912379872054 train_error 31.25% test_error 24.50%\n",
      "================================6788===================================\n",
      "6788/10000: train_loss: 3.487466025678441 train_error 31.37% test_error 24.50%\n",
      "================================6789===================================\n",
      "6789/10000: train_loss: 3.487040649773553 train_error 31.37% test_error 24.50%\n",
      "================================6790===================================\n",
      "6790/10000: train_loss: 3.486615574555471 train_error 31.37% test_error 24.50%\n",
      "================================6791===================================\n",
      "6791/10000: train_loss: 3.4861852929927406 train_error 31.25% test_error 24.50%\n",
      "================================6792===================================\n",
      "6792/10000: train_loss: 3.4857482131943107 train_error 31.25% test_error 24.50%\n",
      "================================6793===================================\n",
      "6793/10000: train_loss: 3.485310532441363 train_error 31.25% test_error 24.50%\n",
      "================================6794===================================\n",
      "6794/10000: train_loss: 3.4848696834780277 train_error 31.25% test_error 24.50%\n",
      "================================6795===================================\n",
      "6795/10000: train_loss: 3.484429343920201 train_error 31.25% test_error 24.50%\n",
      "================================6796===================================\n",
      "6796/10000: train_loss: 3.483987942589447 train_error 31.25% test_error 24.50%\n",
      "================================6797===================================\n",
      "6797/10000: train_loss: 3.4835469495784492 train_error 31.25% test_error 24.50%\n",
      "================================6798===================================\n",
      "6798/10000: train_loss: 3.4831074156519026 train_error 31.25% test_error 24.50%\n",
      "================================6799===================================\n",
      "6799/10000: train_loss: 3.4826692023687063 train_error 31.13% test_error 24.50%\n",
      "================================6800===================================\n",
      "6800/10000: train_loss: 3.482231697384268 train_error 31.13% test_error 24.50%\n",
      "================================6801===================================\n",
      "6801/10000: train_loss: 3.481790606379509 train_error 31.13% test_error 24.50%\n",
      "================================6802===================================\n",
      "6802/10000: train_loss: 3.4813447871897374 train_error 31.13% test_error 24.50%\n",
      "================================6803===================================\n",
      "6803/10000: train_loss: 3.480895321285352 train_error 31.13% test_error 24.50%\n",
      "================================6804===================================\n",
      "6804/10000: train_loss: 3.4804483720939605 train_error 31.13% test_error 24.50%\n",
      "================================6805===================================\n",
      "6805/10000: train_loss: 3.480001588948071 train_error 31.13% test_error 24.50%\n",
      "================================6806===================================\n",
      "6806/10000: train_loss: 3.4795542784594 train_error 31.13% test_error 24.50%\n",
      "================================6807===================================\n",
      "6807/10000: train_loss: 3.4791067192424086 train_error 31.13% test_error 24.50%\n",
      "================================6808===================================\n",
      "6808/10000: train_loss: 3.4786584016773854 train_error 31.13% test_error 24.50%\n",
      "================================6809===================================\n",
      "6809/10000: train_loss: 3.4782084632851182 train_error 31.13% test_error 24.50%\n",
      "================================6810===================================\n",
      "6810/10000: train_loss: 3.4777559716533872 train_error 31.13% test_error 24.50%\n",
      "================================6811===================================\n",
      "6811/10000: train_loss: 3.477304967828095 train_error 31.13% test_error 24.50%\n",
      "================================6812===================================\n",
      "6812/10000: train_loss: 3.4768542526382955 train_error 31.13% test_error 24.50%\n",
      "================================6813===================================\n",
      "6813/10000: train_loss: 3.4763966676127165 train_error 31.25% test_error 24.50%\n",
      "================================6814===================================\n",
      "6814/10000: train_loss: 3.4759389394242315 train_error 31.25% test_error 24.50%\n",
      "================================6815===================================\n",
      "6815/10000: train_loss: 3.4754809841047973 train_error 31.25% test_error 24.50%\n",
      "================================6816===================================\n",
      "6816/10000: train_loss: 3.4750227756798266 train_error 31.37% test_error 24.50%\n",
      "================================6817===================================\n",
      "6817/10000: train_loss: 3.474566176049411 train_error 31.37% test_error 24.50%\n",
      "================================6818===================================\n",
      "6818/10000: train_loss: 3.4741098380926996 train_error 31.37% test_error 24.50%\n",
      "================================6819===================================\n",
      "6819/10000: train_loss: 3.47365289863199 train_error 31.37% test_error 25.00%\n",
      "================================6820===================================\n",
      "6820/10000: train_loss: 3.4731958461087196 train_error 31.25% test_error 25.00%\n",
      "================================6821===================================\n",
      "6821/10000: train_loss: 3.472738140178844 train_error 31.25% test_error 25.00%\n",
      "================================6822===================================\n",
      "6822/10000: train_loss: 3.4722787704039364 train_error 31.25% test_error 24.50%\n",
      "================================6823===================================\n",
      "6823/10000: train_loss: 3.4718219131976364 train_error 31.25% test_error 24.50%\n",
      "================================6824===================================\n",
      "6824/10000: train_loss: 3.471365038212389 train_error 31.13% test_error 24.50%\n",
      "================================6825===================================\n",
      "6825/10000: train_loss: 3.470907050538808 train_error 31.13% test_error 24.50%\n",
      "================================6826===================================\n",
      "6826/10000: train_loss: 3.470449278336018 train_error 31.13% test_error 24.50%\n",
      "================================6827===================================\n",
      "6827/10000: train_loss: 3.4699916889704765 train_error 31.13% test_error 24.50%\n",
      "================================6828===================================\n",
      "6828/10000: train_loss: 3.4695354815013704 train_error 31.13% test_error 24.50%\n",
      "================================6829===================================\n",
      "6829/10000: train_loss: 3.4690812956914305 train_error 31.00% test_error 24.50%\n",
      "================================6830===================================\n",
      "6830/10000: train_loss: 3.4686283509805795 train_error 31.00% test_error 25.00%\n",
      "================================6831===================================\n",
      "6831/10000: train_loss: 3.4681722666602584 train_error 31.00% test_error 25.00%\n",
      "================================6832===================================\n",
      "6832/10000: train_loss: 3.467714304206893 train_error 30.88% test_error 25.00%\n",
      "================================6833===================================\n",
      "6833/10000: train_loss: 3.4672538414504377 train_error 31.00% test_error 25.00%\n",
      "================================6834===================================\n",
      "6834/10000: train_loss: 3.4667920190095898 train_error 31.00% test_error 25.00%\n",
      "================================6835===================================\n",
      "6835/10000: train_loss: 3.466327710710466 train_error 31.13% test_error 25.00%\n",
      "================================6836===================================\n",
      "6836/10000: train_loss: 3.4658636558707805 train_error 31.13% test_error 25.00%\n",
      "================================6837===================================\n",
      "6837/10000: train_loss: 3.4653989215288314 train_error 31.13% test_error 25.00%\n",
      "================================6838===================================\n",
      "6838/10000: train_loss: 3.464932608585805 train_error 31.13% test_error 25.00%\n",
      "================================6839===================================\n",
      "6839/10000: train_loss: 3.4644629175402226 train_error 31.25% test_error 25.00%\n",
      "================================6840===================================\n",
      "6840/10000: train_loss: 3.4639912664331494 train_error 31.25% test_error 25.00%\n",
      "================================6841===================================\n",
      "6841/10000: train_loss: 3.46351750260219 train_error 31.37% test_error 25.00%\n",
      "================================6842===================================\n",
      "6842/10000: train_loss: 3.463044524407014 train_error 31.37% test_error 25.00%\n",
      "================================6843===================================\n",
      "6843/10000: train_loss: 3.462571371663362 train_error 31.37% test_error 25.00%\n",
      "================================6844===================================\n",
      "6844/10000: train_loss: 3.4620960264839233 train_error 31.37% test_error 24.50%\n",
      "================================6845===================================\n",
      "6845/10000: train_loss: 3.461619478901848 train_error 31.37% test_error 24.50%\n",
      "================================6846===================================\n",
      "6846/10000: train_loss: 3.461141061913222 train_error 31.25% test_error 24.50%\n",
      "================================6847===================================\n",
      "6847/10000: train_loss: 3.4606606608629225 train_error 31.25% test_error 24.50%\n",
      "================================6848===================================\n",
      "6848/10000: train_loss: 3.460180054809898 train_error 31.25% test_error 24.50%\n",
      "================================6849===================================\n",
      "6849/10000: train_loss: 3.459697980955243 train_error 31.25% test_error 24.50%\n",
      "================================6850===================================\n",
      "6850/10000: train_loss: 3.459213998299092 train_error 31.25% test_error 24.50%\n",
      "================================6851===================================\n",
      "6851/10000: train_loss: 3.45873004081659 train_error 31.25% test_error 24.50%\n",
      "================================6852===================================\n",
      "6852/10000: train_loss: 3.4582458253763617 train_error 31.25% test_error 24.50%\n",
      "================================6853===================================\n",
      "6853/10000: train_loss: 3.457761410884559 train_error 31.37% test_error 24.50%\n",
      "================================6854===================================\n",
      "6854/10000: train_loss: 3.4572770050819965 train_error 31.25% test_error 24.50%\n",
      "================================6855===================================\n",
      "6855/10000: train_loss: 3.4567919539194554 train_error 31.25% test_error 24.50%\n",
      "================================6856===================================\n",
      "6856/10000: train_loss: 3.4563053420279175 train_error 31.25% test_error 25.00%\n",
      "================================6857===================================\n",
      "6857/10000: train_loss: 3.4558183313440534 train_error 31.25% test_error 25.00%\n",
      "================================6858===================================\n",
      "6858/10000: train_loss: 3.4553281891904772 train_error 31.13% test_error 25.00%\n",
      "================================6859===================================\n",
      "6859/10000: train_loss: 3.4548377971723676 train_error 31.13% test_error 25.00%\n",
      "================================6860===================================\n",
      "6860/10000: train_loss: 3.454346325667575 train_error 31.13% test_error 25.00%\n",
      "================================6861===================================\n",
      "6861/10000: train_loss: 3.4538560715690254 train_error 31.13% test_error 25.00%\n",
      "================================6862===================================\n",
      "6862/10000: train_loss: 3.453367395568639 train_error 31.13% test_error 25.00%\n",
      "================================6863===================================\n",
      "6863/10000: train_loss: 3.4528792478702957 train_error 31.13% test_error 25.00%\n",
      "================================6864===================================\n",
      "6864/10000: train_loss: 3.4523885842226445 train_error 31.13% test_error 25.00%\n",
      "================================6865===================================\n",
      "6865/10000: train_loss: 3.4518981167860328 train_error 31.13% test_error 25.00%\n",
      "================================6866===================================\n",
      "6866/10000: train_loss: 3.4514081493392585 train_error 31.00% test_error 25.00%\n",
      "================================6867===================================\n",
      "6867/10000: train_loss: 3.4509183312393725 train_error 31.13% test_error 25.00%\n",
      "================================6868===================================\n",
      "6868/10000: train_loss: 3.4504255968891084 train_error 31.13% test_error 24.50%\n",
      "================================6869===================================\n",
      "6869/10000: train_loss: 3.4499337321147325 train_error 31.13% test_error 24.50%\n",
      "================================6870===================================\n",
      "6870/10000: train_loss: 3.4494432250782845 train_error 31.13% test_error 24.50%\n",
      "================================6871===================================\n",
      "6871/10000: train_loss: 3.448951452998444 train_error 31.13% test_error 24.50%\n",
      "================================6872===================================\n",
      "6872/10000: train_loss: 3.44845634852536 train_error 31.00% test_error 24.50%\n",
      "================================6873===================================\n",
      "6873/10000: train_loss: 3.4479571409523486 train_error 31.00% test_error 24.50%\n",
      "================================6874===================================\n",
      "6874/10000: train_loss: 3.4474568534828722 train_error 30.75% test_error 24.50%\n",
      "================================6875===================================\n",
      "6875/10000: train_loss: 3.4469578007422386 train_error 30.75% test_error 24.50%\n",
      "================================6876===================================\n",
      "6876/10000: train_loss: 3.4464590599481015 train_error 30.75% test_error 24.50%\n",
      "================================6877===================================\n",
      "6877/10000: train_loss: 3.445960443476215 train_error 30.75% test_error 24.50%\n",
      "================================6878===================================\n",
      "6878/10000: train_loss: 3.44546255514957 train_error 30.75% test_error 24.50%\n",
      "================================6879===================================\n",
      "6879/10000: train_loss: 3.444964760215953 train_error 30.75% test_error 24.50%\n",
      "================================6880===================================\n",
      "6880/10000: train_loss: 3.444466868219897 train_error 30.75% test_error 24.50%\n",
      "================================6881===================================\n",
      "6881/10000: train_loss: 3.4439707959163934 train_error 30.75% test_error 24.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6882===================================\n",
      "6882/10000: train_loss: 3.4434751189593227 train_error 30.75% test_error 24.50%\n",
      "================================6883===================================\n",
      "6883/10000: train_loss: 3.442979077473283 train_error 30.75% test_error 24.50%\n",
      "================================6884===================================\n",
      "6884/10000: train_loss: 3.4424842010159047 train_error 30.75% test_error 24.50%\n",
      "================================6885===================================\n",
      "6885/10000: train_loss: 3.4419898687303068 train_error 30.75% test_error 24.50%\n",
      "================================6886===================================\n",
      "6886/10000: train_loss: 3.4414939169213175 train_error 30.75% test_error 24.00%\n",
      "================================6887===================================\n",
      "6887/10000: train_loss: 3.440998100088909 train_error 30.75% test_error 24.00%\n",
      "================================6888===================================\n",
      "6888/10000: train_loss: 3.440502753332257 train_error 30.75% test_error 24.00%\n",
      "================================6889===================================\n",
      "6889/10000: train_loss: 3.440005966266617 train_error 30.63% test_error 24.50%\n",
      "================================6890===================================\n",
      "6890/10000: train_loss: 3.439508672459051 train_error 30.63% test_error 24.50%\n",
      "================================6891===================================\n",
      "6891/10000: train_loss: 3.439010551692918 train_error 30.63% test_error 24.50%\n",
      "================================6892===================================\n",
      "6892/10000: train_loss: 3.4385130654834213 train_error 30.50% test_error 24.50%\n",
      "================================6893===================================\n",
      "6893/10000: train_loss: 3.4380137013457714 train_error 30.50% test_error 24.50%\n",
      "================================6894===================================\n",
      "6894/10000: train_loss: 3.4375127875618636 train_error 30.50% test_error 24.50%\n",
      "================================6895===================================\n",
      "6895/10000: train_loss: 3.437012652680278 train_error 30.38% test_error 24.50%\n",
      "================================6896===================================\n",
      "6896/10000: train_loss: 3.4365104474406687 train_error 30.38% test_error 24.50%\n",
      "================================6897===================================\n",
      "6897/10000: train_loss: 3.43600638596341 train_error 30.38% test_error 24.50%\n",
      "================================6898===================================\n",
      "6898/10000: train_loss: 3.43550420762971 train_error 30.38% test_error 24.50%\n",
      "================================6899===================================\n",
      "6899/10000: train_loss: 3.4349995175376535 train_error 30.38% test_error 24.50%\n",
      "================================6900===================================\n",
      "6900/10000: train_loss: 3.4344894079398363 train_error 30.38% test_error 24.50%\n",
      "================================6901===================================\n",
      "6901/10000: train_loss: 3.433979566851631 train_error 30.38% test_error 24.50%\n",
      "================================6902===================================\n",
      "6902/10000: train_loss: 3.4334682789724322 train_error 30.38% test_error 24.50%\n",
      "================================6903===================================\n",
      "6903/10000: train_loss: 3.432953643761575 train_error 30.50% test_error 24.50%\n",
      "================================6904===================================\n",
      "6904/10000: train_loss: 3.4324372976925224 train_error 30.50% test_error 24.50%\n",
      "================================6905===================================\n",
      "6905/10000: train_loss: 3.4319228073675188 train_error 30.50% test_error 24.50%\n",
      "================================6906===================================\n",
      "6906/10000: train_loss: 3.4314077579695734 train_error 30.50% test_error 24.50%\n",
      "================================6907===================================\n",
      "6907/10000: train_loss: 3.4308927702344953 train_error 30.38% test_error 24.50%\n",
      "================================6908===================================\n",
      "6908/10000: train_loss: 3.430377797093242 train_error 30.38% test_error 24.50%\n",
      "================================6909===================================\n",
      "6909/10000: train_loss: 3.429862575624138 train_error 30.38% test_error 24.50%\n",
      "================================6910===================================\n",
      "6910/10000: train_loss: 3.429347421322018 train_error 30.38% test_error 24.50%\n",
      "================================6911===================================\n",
      "6911/10000: train_loss: 3.4288343351054937 train_error 30.38% test_error 24.50%\n",
      "================================6912===================================\n",
      "6912/10000: train_loss: 3.4283222579490396 train_error 30.50% test_error 24.50%\n",
      "================================6913===================================\n",
      "6913/10000: train_loss: 3.4278087431378665 train_error 30.50% test_error 24.50%\n",
      "================================6914===================================\n",
      "6914/10000: train_loss: 3.4272930504754187 train_error 30.50% test_error 24.50%\n",
      "================================6915===================================\n",
      "6915/10000: train_loss: 3.4267779835872356 train_error 30.50% test_error 24.50%\n",
      "================================6916===================================\n",
      "6916/10000: train_loss: 3.4262613150011747 train_error 30.50% test_error 24.50%\n",
      "================================6917===================================\n",
      "6917/10000: train_loss: 3.425743753872812 train_error 30.50% test_error 24.50%\n",
      "================================6918===================================\n",
      "6918/10000: train_loss: 3.4252242895681415 train_error 30.50% test_error 24.50%\n",
      "================================6919===================================\n",
      "6919/10000: train_loss: 3.424704864462838 train_error 30.50% test_error 24.50%\n",
      "================================6920===================================\n",
      "6920/10000: train_loss: 3.424185973741114 train_error 30.50% test_error 24.50%\n",
      "================================6921===================================\n",
      "6921/10000: train_loss: 3.4236680825427177 train_error 30.50% test_error 24.50%\n",
      "================================6922===================================\n",
      "6922/10000: train_loss: 3.423150207903236 train_error 30.50% test_error 24.50%\n",
      "================================6923===================================\n",
      "6923/10000: train_loss: 3.4226353697478773 train_error 30.50% test_error 24.50%\n",
      "================================6924===================================\n",
      "6924/10000: train_loss: 3.4221213861647994 train_error 30.50% test_error 24.50%\n",
      "================================6925===================================\n",
      "6925/10000: train_loss: 3.4216054655332115 train_error 30.50% test_error 24.50%\n",
      "================================6926===================================\n",
      "6926/10000: train_loss: 3.421090309144929 train_error 30.50% test_error 24.50%\n",
      "================================6927===================================\n",
      "6927/10000: train_loss: 3.420577444760129 train_error 30.38% test_error 24.50%\n",
      "================================6928===================================\n",
      "6928/10000: train_loss: 3.4200667555630204 train_error 30.38% test_error 24.50%\n",
      "================================6929===================================\n",
      "6929/10000: train_loss: 3.419556438811123 train_error 30.38% test_error 24.50%\n",
      "================================6930===================================\n",
      "6930/10000: train_loss: 3.4190471058897676 train_error 30.38% test_error 24.50%\n",
      "================================6931===================================\n",
      "6931/10000: train_loss: 3.41854452656582 train_error 30.38% test_error 24.50%\n",
      "================================6932===================================\n",
      "6932/10000: train_loss: 3.4180453320406374 train_error 30.38% test_error 24.50%\n",
      "================================6933===================================\n",
      "6933/10000: train_loss: 3.4175460877828296 train_error 30.38% test_error 24.50%\n",
      "================================6934===================================\n",
      "6934/10000: train_loss: 3.417046442069113 train_error 30.38% test_error 24.50%\n",
      "================================6935===================================\n",
      "6935/10000: train_loss: 3.4165469484310593 train_error 30.38% test_error 24.50%\n",
      "================================6936===================================\n",
      "6936/10000: train_loss: 3.416045447681099 train_error 30.38% test_error 24.50%\n",
      "================================6937===================================\n",
      "6937/10000: train_loss: 3.4155430855136366 train_error 30.38% test_error 24.50%\n",
      "================================6938===================================\n",
      "6938/10000: train_loss: 3.4150422899238766 train_error 30.25% test_error 24.50%\n",
      "================================6939===================================\n",
      "6939/10000: train_loss: 3.4145406897645447 train_error 30.25% test_error 24.50%\n",
      "================================6940===================================\n",
      "6940/10000: train_loss: 3.414036882175133 train_error 30.12% test_error 24.50%\n",
      "================================6941===================================\n",
      "6941/10000: train_loss: 3.413533063232899 train_error 30.12% test_error 24.50%\n",
      "================================6942===================================\n",
      "6942/10000: train_loss: 3.413028674628585 train_error 30.12% test_error 24.50%\n",
      "================================6943===================================\n",
      "6943/10000: train_loss: 3.412521386053413 train_error 30.12% test_error 24.50%\n",
      "================================6944===================================\n",
      "6944/10000: train_loss: 3.412010956499725 train_error 30.12% test_error 24.50%\n",
      "================================6945===================================\n",
      "6945/10000: train_loss: 3.4114995648339392 train_error 30.12% test_error 24.50%\n",
      "================================6946===================================\n",
      "6946/10000: train_loss: 3.410986344702542 train_error 30.12% test_error 24.50%\n",
      "================================6947===================================\n",
      "6947/10000: train_loss: 3.410473059406504 train_error 30.12% test_error 24.50%\n",
      "================================6948===================================\n",
      "6948/10000: train_loss: 3.4099615192972124 train_error 30.12% test_error 24.50%\n",
      "================================6949===================================\n",
      "6949/10000: train_loss: 3.4094498545862733 train_error 30.12% test_error 24.50%\n",
      "================================6950===================================\n",
      "6950/10000: train_loss: 3.408935902453959 train_error 30.00% test_error 24.50%\n",
      "================================6951===================================\n",
      "6951/10000: train_loss: 3.408421863652766 train_error 30.00% test_error 24.50%\n",
      "================================6952===================================\n",
      "6952/10000: train_loss: 3.4079062285553667 train_error 30.00% test_error 24.50%\n",
      "================================6953===================================\n",
      "6953/10000: train_loss: 3.407386963032186 train_error 30.00% test_error 24.50%\n",
      "================================6954===================================\n",
      "6954/10000: train_loss: 3.4068663620296866 train_error 30.00% test_error 24.50%\n",
      "================================6955===================================\n",
      "6955/10000: train_loss: 3.4063485169876366 train_error 30.00% test_error 24.50%\n",
      "================================6956===================================\n",
      "6956/10000: train_loss: 3.405830153934658 train_error 30.00% test_error 24.50%\n",
      "================================6957===================================\n",
      "6957/10000: train_loss: 3.40531153654214 train_error 30.00% test_error 24.50%\n",
      "================================6958===================================\n",
      "6958/10000: train_loss: 3.404791677650064 train_error 30.00% test_error 24.50%\n",
      "================================6959===================================\n",
      "6959/10000: train_loss: 3.404271699665114 train_error 30.00% test_error 24.50%\n",
      "================================6960===================================\n",
      "6960/10000: train_loss: 3.403752322033979 train_error 30.00% test_error 24.50%\n",
      "================================6961===================================\n",
      "6961/10000: train_loss: 3.40323260565754 train_error 30.00% test_error 24.50%\n",
      "================================6962===================================\n",
      "6962/10000: train_loss: 3.402713593714871 train_error 29.88% test_error 24.50%\n",
      "================================6963===================================\n",
      "6963/10000: train_loss: 3.402195029486902 train_error 29.88% test_error 24.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================6964===================================\n",
      "6964/10000: train_loss: 3.4016788811096923 train_error 29.88% test_error 24.50%\n",
      "================================6965===================================\n",
      "6965/10000: train_loss: 3.401164260134101 train_error 29.88% test_error 24.50%\n",
      "================================6966===================================\n",
      "6966/10000: train_loss: 3.400648686848581 train_error 29.88% test_error 24.50%\n",
      "================================6967===================================\n",
      "6967/10000: train_loss: 3.4001332987425847 train_error 30.00% test_error 24.50%\n",
      "================================6968===================================\n",
      "6968/10000: train_loss: 3.399614820154384 train_error 30.00% test_error 24.50%\n",
      "================================6969===================================\n",
      "6969/10000: train_loss: 3.3990933232940734 train_error 30.00% test_error 24.50%\n",
      "================================6970===================================\n",
      "6970/10000: train_loss: 3.398571871458553 train_error 30.00% test_error 24.50%\n",
      "================================6971===================================\n",
      "6971/10000: train_loss: 3.398050375422463 train_error 30.00% test_error 24.50%\n",
      "================================6972===================================\n",
      "6972/10000: train_loss: 3.3975312255648897 train_error 30.00% test_error 24.50%\n",
      "================================6973===================================\n",
      "6973/10000: train_loss: 3.397012079157866 train_error 30.00% test_error 24.50%\n",
      "================================6974===================================\n",
      "6974/10000: train_loss: 3.396492272736505 train_error 30.00% test_error 24.50%\n",
      "================================6975===================================\n",
      "6975/10000: train_loss: 3.3959717961447318 train_error 30.12% test_error 24.50%\n",
      "================================6976===================================\n",
      "6976/10000: train_loss: 3.3954486404173077 train_error 30.12% test_error 24.50%\n",
      "================================6977===================================\n",
      "6977/10000: train_loss: 3.394926335271448 train_error 30.12% test_error 24.00%\n",
      "================================6978===================================\n",
      "6978/10000: train_loss: 3.3944038498820737 train_error 30.12% test_error 24.00%\n",
      "================================6979===================================\n",
      "6979/10000: train_loss: 3.393880323744379 train_error 30.12% test_error 24.00%\n",
      "================================6980===================================\n",
      "6980/10000: train_loss: 3.3933560586674143 train_error 30.12% test_error 24.00%\n",
      "================================6981===================================\n",
      "6981/10000: train_loss: 3.3928312904341147 train_error 30.12% test_error 24.00%\n",
      "================================6982===================================\n",
      "6982/10000: train_loss: 3.392306500785053 train_error 30.12% test_error 24.00%\n",
      "================================6983===================================\n",
      "6983/10000: train_loss: 3.391783442255109 train_error 30.00% test_error 24.00%\n",
      "================================6984===================================\n",
      "6984/10000: train_loss: 3.391261072582565 train_error 30.00% test_error 24.00%\n",
      "================================6985===================================\n",
      "6985/10000: train_loss: 3.3907384321931753 train_error 30.00% test_error 24.00%\n",
      "================================6986===================================\n",
      "6986/10000: train_loss: 3.390215185857378 train_error 30.00% test_error 24.00%\n",
      "================================6987===================================\n",
      "6987/10000: train_loss: 3.3896917210984974 train_error 30.00% test_error 24.00%\n",
      "================================6988===================================\n",
      "6988/10000: train_loss: 3.3891675517056137 train_error 30.00% test_error 24.00%\n",
      "================================6989===================================\n",
      "6989/10000: train_loss: 3.3886423855973407 train_error 30.00% test_error 24.00%\n",
      "================================6990===================================\n",
      "6990/10000: train_loss: 3.388118643164635 train_error 29.88% test_error 24.00%\n",
      "================================6991===================================\n",
      "6991/10000: train_loss: 3.3875916296103967 train_error 29.88% test_error 24.00%\n",
      "================================6992===================================\n",
      "6992/10000: train_loss: 3.3870613721013068 train_error 29.88% test_error 24.00%\n",
      "================================6993===================================\n",
      "6993/10000: train_loss: 3.3865329393092547 train_error 29.88% test_error 24.00%\n",
      "================================6994===================================\n",
      "6994/10000: train_loss: 3.386004274901934 train_error 29.88% test_error 24.00%\n",
      "================================6995===================================\n",
      "6995/10000: train_loss: 3.3854745653597638 train_error 30.00% test_error 24.00%\n",
      "================================6996===================================\n",
      "6996/10000: train_loss: 3.384946550163441 train_error 30.00% test_error 24.00%\n",
      "================================6997===================================\n",
      "6997/10000: train_loss: 3.3844187385262923 train_error 30.00% test_error 24.00%\n",
      "================================6998===================================\n",
      "6998/10000: train_loss: 3.3838917986536403 train_error 29.88% test_error 24.00%\n",
      "================================6999===================================\n",
      "6999/10000: train_loss: 3.3833653955953196 train_error 29.88% test_error 24.00%\n",
      "================================7000===================================\n",
      "7000/10000: train_loss: 3.382841255138628 train_error 29.88% test_error 23.50%\n",
      "================================7001===================================\n",
      "7001/10000: train_loss: 3.3823170369211586 train_error 29.88% test_error 23.50%\n",
      "================================7002===================================\n",
      "7002/10000: train_loss: 3.381792805120349 train_error 29.88% test_error 23.50%\n",
      "================================7003===================================\n",
      "7003/10000: train_loss: 3.381267460160889 train_error 29.75% test_error 23.50%\n",
      "================================7004===================================\n",
      "7004/10000: train_loss: 3.380741078099236 train_error 29.75% test_error 23.50%\n",
      "================================7005===================================\n",
      "7005/10000: train_loss: 3.380212072208524 train_error 29.75% test_error 23.50%\n",
      "================================7006===================================\n",
      "7006/10000: train_loss: 3.3796815420873463 train_error 29.75% test_error 23.50%\n",
      "================================7007===================================\n",
      "7007/10000: train_loss: 3.3791495679086077 train_error 29.75% test_error 23.50%\n",
      "================================7008===================================\n",
      "7008/10000: train_loss: 3.378617537934333 train_error 29.75% test_error 23.50%\n",
      "================================7009===================================\n",
      "7009/10000: train_loss: 3.3780853611091155 train_error 29.62% test_error 23.50%\n",
      "================================7010===================================\n",
      "7010/10000: train_loss: 3.3775537481252105 train_error 29.62% test_error 23.00%\n",
      "================================7011===================================\n",
      "7011/10000: train_loss: 3.377020207624882 train_error 29.62% test_error 23.00%\n",
      "================================7012===================================\n",
      "7012/10000: train_loss: 3.3764830934908243 train_error 29.62% test_error 23.00%\n",
      "================================7013===================================\n",
      "7013/10000: train_loss: 3.3759444772079585 train_error 29.62% test_error 23.00%\n",
      "================================7014===================================\n",
      "7014/10000: train_loss: 3.375405854093842 train_error 29.62% test_error 23.00%\n",
      "================================7015===================================\n",
      "7015/10000: train_loss: 3.3748671161336823 train_error 29.62% test_error 23.00%\n",
      "================================7016===================================\n",
      "7016/10000: train_loss: 3.3743286358285696 train_error 29.62% test_error 23.00%\n",
      "================================7017===================================\n",
      "7017/10000: train_loss: 3.3737910633394494 train_error 29.62% test_error 23.00%\n",
      "================================7018===================================\n",
      "7018/10000: train_loss: 3.3732533802697438 train_error 29.62% test_error 23.00%\n",
      "================================7019===================================\n",
      "7019/10000: train_loss: 3.3727154609328136 train_error 29.62% test_error 23.00%\n",
      "================================7020===================================\n",
      "7020/10000: train_loss: 3.3721778931934385 train_error 29.62% test_error 23.00%\n",
      "================================7021===================================\n",
      "7021/10000: train_loss: 3.371640660911799 train_error 29.62% test_error 23.00%\n",
      "================================7022===================================\n",
      "7022/10000: train_loss: 3.3711026907432826 train_error 29.62% test_error 23.00%\n",
      "================================7023===================================\n",
      "7023/10000: train_loss: 3.3705613916087893 train_error 29.62% test_error 23.00%\n",
      "================================7024===================================\n",
      "7024/10000: train_loss: 3.370019939974882 train_error 29.62% test_error 23.00%\n",
      "================================7025===================================\n",
      "7025/10000: train_loss: 3.3694781762035566 train_error 29.62% test_error 23.00%\n",
      "================================7026===================================\n",
      "7026/10000: train_loss: 3.3689345031417903 train_error 29.62% test_error 23.00%\n",
      "================================7027===================================\n",
      "7027/10000: train_loss: 3.3683837378257886 train_error 29.62% test_error 23.00%\n",
      "================================7028===================================\n",
      "7028/10000: train_loss: 3.3678293023305015 train_error 29.62% test_error 23.00%\n",
      "================================7029===================================\n",
      "7029/10000: train_loss: 3.367274139393121 train_error 29.62% test_error 23.00%\n",
      "================================7030===================================\n",
      "7030/10000: train_loss: 3.366718229665421 train_error 29.62% test_error 23.00%\n",
      "================================7031===================================\n",
      "7031/10000: train_loss: 3.3661676067393276 train_error 29.62% test_error 23.00%\n",
      "================================7032===================================\n",
      "7032/10000: train_loss: 3.3656174497073517 train_error 29.62% test_error 23.00%\n",
      "================================7033===================================\n",
      "7033/10000: train_loss: 3.3650681040016934 train_error 29.62% test_error 23.00%\n",
      "================================7034===================================\n",
      "7034/10000: train_loss: 3.364520614631474 train_error 29.75% test_error 23.00%\n",
      "================================7035===================================\n",
      "7035/10000: train_loss: 3.3639724854379893 train_error 29.75% test_error 23.00%\n",
      "================================7036===================================\n",
      "7036/10000: train_loss: 3.363422547467053 train_error 29.75% test_error 23.00%\n",
      "================================7037===================================\n",
      "7037/10000: train_loss: 3.362871800432913 train_error 29.75% test_error 23.00%\n",
      "================================7038===================================\n",
      "7038/10000: train_loss: 3.3623194308485838 train_error 29.75% test_error 23.00%\n",
      "================================7039===================================\n",
      "7039/10000: train_loss: 3.3617674945434555 train_error 29.75% test_error 23.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7040===================================\n",
      "7040/10000: train_loss: 3.3612181604467333 train_error 29.62% test_error 23.00%\n",
      "================================7041===================================\n",
      "7041/10000: train_loss: 3.3606654584174973 train_error 29.62% test_error 23.00%\n",
      "================================7042===================================\n",
      "7042/10000: train_loss: 3.3601110017020255 train_error 29.62% test_error 23.00%\n",
      "================================7043===================================\n",
      "7043/10000: train_loss: 3.359556347276084 train_error 29.62% test_error 23.00%\n",
      "================================7044===================================\n",
      "7044/10000: train_loss: 3.359001582670026 train_error 29.62% test_error 23.00%\n",
      "================================7045===================================\n",
      "7045/10000: train_loss: 3.3584464881848546 train_error 29.62% test_error 23.00%\n",
      "================================7046===================================\n",
      "7046/10000: train_loss: 3.3578906853077934 train_error 29.62% test_error 23.00%\n",
      "================================7047===================================\n",
      "7047/10000: train_loss: 3.3573337828507643 train_error 29.62% test_error 23.00%\n",
      "================================7048===================================\n",
      "7048/10000: train_loss: 3.3567746850522235 train_error 29.62% test_error 23.00%\n",
      "================================7049===================================\n",
      "7049/10000: train_loss: 3.3562157644191757 train_error 29.62% test_error 23.00%\n",
      "================================7050===================================\n",
      "7050/10000: train_loss: 3.355656150835566 train_error 29.62% test_error 23.00%\n",
      "================================7051===================================\n",
      "7051/10000: train_loss: 3.3550968297477812 train_error 29.62% test_error 23.00%\n",
      "================================7052===================================\n",
      "7052/10000: train_loss: 3.354537586644292 train_error 29.62% test_error 23.00%\n",
      "================================7053===================================\n",
      "7053/10000: train_loss: 3.3539792939601467 train_error 29.62% test_error 23.00%\n",
      "================================7054===================================\n",
      "7054/10000: train_loss: 3.3534192485688252 train_error 29.62% test_error 23.00%\n",
      "================================7055===================================\n",
      "7055/10000: train_loss: 3.352858491502702 train_error 29.62% test_error 23.00%\n",
      "================================7056===================================\n",
      "7056/10000: train_loss: 3.3522977348044516 train_error 29.62% test_error 23.00%\n",
      "================================7057===================================\n",
      "7057/10000: train_loss: 3.351739266538061 train_error 29.62% test_error 23.00%\n",
      "================================7058===================================\n",
      "7058/10000: train_loss: 3.3511832067510112 train_error 29.62% test_error 23.00%\n",
      "================================7059===================================\n",
      "7059/10000: train_loss: 3.3506264009187 train_error 29.62% test_error 23.00%\n",
      "================================7060===================================\n",
      "7060/10000: train_loss: 3.3500661259004847 train_error 29.62% test_error 23.00%\n",
      "================================7061===================================\n",
      "7061/10000: train_loss: 3.3495058234920725 train_error 29.62% test_error 23.00%\n",
      "================================7062===================================\n",
      "7062/10000: train_loss: 3.3489454179676255 train_error 29.62% test_error 23.00%\n",
      "================================7063===================================\n",
      "7063/10000: train_loss: 3.348382499208674 train_error 29.62% test_error 23.00%\n",
      "================================7064===================================\n",
      "7064/10000: train_loss: 3.347816709028557 train_error 29.62% test_error 23.00%\n",
      "================================7065===================================\n",
      "7065/10000: train_loss: 3.347249212213792 train_error 29.62% test_error 23.00%\n",
      "================================7066===================================\n",
      "7066/10000: train_loss: 3.346682817400433 train_error 29.62% test_error 23.00%\n",
      "================================7067===================================\n",
      "7067/10000: train_loss: 3.3461187167884785 train_error 29.62% test_error 23.00%\n",
      "================================7068===================================\n",
      "7068/10000: train_loss: 3.3455545417964463 train_error 29.62% test_error 23.00%\n",
      "================================7069===================================\n",
      "7069/10000: train_loss: 3.3449907791102307 train_error 29.62% test_error 23.00%\n",
      "================================7070===================================\n",
      "7070/10000: train_loss: 3.3444256306858735 train_error 29.62% test_error 23.00%\n",
      "================================7071===================================\n",
      "7071/10000: train_loss: 3.343861595694907 train_error 29.62% test_error 23.00%\n",
      "================================7072===================================\n",
      "7072/10000: train_loss: 3.3432982037449253 train_error 29.62% test_error 23.00%\n",
      "================================7073===================================\n",
      "7073/10000: train_loss: 3.3427351455390455 train_error 29.62% test_error 23.00%\n",
      "================================7074===================================\n",
      "7074/10000: train_loss: 3.342171353031881 train_error 29.62% test_error 23.00%\n",
      "================================7075===================================\n",
      "7075/10000: train_loss: 3.3416086125047877 train_error 29.62% test_error 23.00%\n",
      "================================7076===================================\n",
      "7076/10000: train_loss: 3.3410466911178083 train_error 29.62% test_error 23.00%\n",
      "================================7077===================================\n",
      "7077/10000: train_loss: 3.3404827528027816 train_error 29.62% test_error 23.00%\n",
      "================================7078===================================\n",
      "7078/10000: train_loss: 3.3399202245613564 train_error 29.62% test_error 23.00%\n",
      "================================7079===================================\n",
      "7079/10000: train_loss: 3.339359102533199 train_error 29.62% test_error 23.00%\n",
      "================================7080===================================\n",
      "7080/10000: train_loss: 3.338798854886554 train_error 29.62% test_error 22.50%\n",
      "================================7081===================================\n",
      "7081/10000: train_loss: 3.3382395400526006 train_error 29.62% test_error 22.50%\n",
      "================================7082===================================\n",
      "7082/10000: train_loss: 3.337678908421658 train_error 29.62% test_error 22.50%\n",
      "================================7083===================================\n",
      "7083/10000: train_loss: 3.3371139251021673 train_error 29.62% test_error 22.50%\n",
      "================================7084===================================\n",
      "7084/10000: train_loss: 3.336545431623235 train_error 29.62% test_error 22.00%\n",
      "================================7085===================================\n",
      "7085/10000: train_loss: 3.335976565168239 train_error 29.62% test_error 22.00%\n",
      "================================7086===================================\n",
      "7086/10000: train_loss: 3.3354104073951016 train_error 29.62% test_error 22.00%\n",
      "================================7087===================================\n",
      "7087/10000: train_loss: 3.3348440578719605 train_error 29.62% test_error 22.00%\n",
      "================================7088===================================\n",
      "7088/10000: train_loss: 3.3342771609686315 train_error 29.62% test_error 22.00%\n",
      "================================7089===================================\n",
      "7089/10000: train_loss: 3.333711476782337 train_error 29.62% test_error 22.00%\n",
      "================================7090===================================\n",
      "7090/10000: train_loss: 3.3331462024757634 train_error 29.62% test_error 22.00%\n",
      "================================7091===================================\n",
      "7091/10000: train_loss: 3.3325789513438937 train_error 29.62% test_error 22.00%\n",
      "================================7092===================================\n",
      "7092/10000: train_loss: 3.332012033010833 train_error 29.62% test_error 22.00%\n",
      "================================7093===================================\n",
      "7093/10000: train_loss: 3.33144625084009 train_error 29.62% test_error 22.00%\n",
      "================================7094===================================\n",
      "7094/10000: train_loss: 3.330881595709361 train_error 29.50% test_error 22.00%\n",
      "================================7095===================================\n",
      "7095/10000: train_loss: 3.3303202146478004 train_error 29.25% test_error 22.00%\n",
      "================================7096===================================\n",
      "7096/10000: train_loss: 3.3297630358254535 train_error 29.25% test_error 22.00%\n",
      "================================7097===================================\n",
      "7097/10000: train_loss: 3.3292068900261076 train_error 29.25% test_error 22.00%\n",
      "================================7098===================================\n",
      "7098/10000: train_loss: 3.3286530557926746 train_error 29.25% test_error 22.00%\n",
      "================================7099===================================\n",
      "7099/10000: train_loss: 3.3280984178418294 train_error 29.25% test_error 22.00%\n",
      "================================7100===================================\n",
      "7100/10000: train_loss: 3.3275454996293408 train_error 29.25% test_error 22.00%\n",
      "================================7101===================================\n",
      "7101/10000: train_loss: 3.326992722209543 train_error 29.25% test_error 22.00%\n",
      "================================7102===================================\n",
      "7102/10000: train_loss: 3.3264403334446255 train_error 29.25% test_error 22.00%\n",
      "================================7103===================================\n",
      "7103/10000: train_loss: 3.325889736204408 train_error 29.25% test_error 22.00%\n",
      "================================7104===================================\n",
      "7104/10000: train_loss: 3.325337486988865 train_error 29.25% test_error 22.00%\n",
      "================================7105===================================\n",
      "7105/10000: train_loss: 3.3247840330889447 train_error 29.25% test_error 22.00%\n",
      "================================7106===================================\n",
      "7106/10000: train_loss: 3.3242304156254976 train_error 29.25% test_error 22.00%\n",
      "================================7107===================================\n",
      "7107/10000: train_loss: 3.323681280752644 train_error 29.25% test_error 22.00%\n",
      "================================7108===================================\n",
      "7108/10000: train_loss: 3.32313366562128 train_error 29.25% test_error 22.00%\n",
      "================================7109===================================\n",
      "7109/10000: train_loss: 3.322585649006069 train_error 29.25% test_error 22.00%\n",
      "================================7110===================================\n",
      "7110/10000: train_loss: 3.3220390142966063 train_error 29.25% test_error 22.00%\n",
      "================================7111===================================\n",
      "7111/10000: train_loss: 3.321495022261515 train_error 29.25% test_error 22.00%\n",
      "================================7112===================================\n",
      "7112/10000: train_loss: 3.320952541520819 train_error 29.25% test_error 22.00%\n",
      "================================7113===================================\n",
      "7113/10000: train_loss: 3.3204103800375018 train_error 29.25% test_error 22.00%\n",
      "================================7114===================================\n",
      "7114/10000: train_loss: 3.3198688933812086 train_error 29.25% test_error 22.00%\n",
      "================================7115===================================\n",
      "7115/10000: train_loss: 3.319327566958964 train_error 29.25% test_error 22.00%\n",
      "================================7116===================================\n",
      "7116/10000: train_loss: 3.31878992785234 train_error 29.25% test_error 22.00%\n",
      "================================7117===================================\n",
      "7117/10000: train_loss: 3.3182535457937052 train_error 29.25% test_error 22.00%\n",
      "================================7118===================================\n",
      "7118/10000: train_loss: 3.317716451631859 train_error 29.25% test_error 22.00%\n",
      "================================7119===================================\n",
      "7119/10000: train_loss: 3.317178894658573 train_error 29.25% test_error 22.00%\n",
      "================================7120===================================\n",
      "7120/10000: train_loss: 3.3166412297775967 train_error 29.25% test_error 21.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7121===================================\n",
      "7121/10000: train_loss: 3.316102459281683 train_error 29.25% test_error 21.50%\n",
      "================================7122===================================\n",
      "7122/10000: train_loss: 3.3155638844519855 train_error 29.25% test_error 21.50%\n",
      "================================7123===================================\n",
      "7123/10000: train_loss: 3.3150232983520254 train_error 29.25% test_error 21.50%\n",
      "================================7124===================================\n",
      "7124/10000: train_loss: 3.3144812962412833 train_error 29.12% test_error 21.50%\n",
      "================================7125===================================\n",
      "7125/10000: train_loss: 3.3139356516161933 train_error 29.12% test_error 21.50%\n",
      "================================7126===================================\n",
      "7126/10000: train_loss: 3.3133902591839437 train_error 29.12% test_error 21.50%\n",
      "================================7127===================================\n",
      "7127/10000: train_loss: 3.312846169262193 train_error 29.12% test_error 21.50%\n",
      "================================7128===================================\n",
      "7128/10000: train_loss: 3.3123020581994203 train_error 29.12% test_error 21.50%\n",
      "================================7129===================================\n",
      "7129/10000: train_loss: 3.311757550612092 train_error 29.12% test_error 21.50%\n",
      "================================7130===================================\n",
      "7130/10000: train_loss: 3.311214931155555 train_error 29.00% test_error 21.50%\n",
      "================================7131===================================\n",
      "7131/10000: train_loss: 3.3106731453351674 train_error 29.00% test_error 21.50%\n",
      "================================7132===================================\n",
      "7132/10000: train_loss: 3.3101333023188637 train_error 29.00% test_error 21.50%\n",
      "================================7133===================================\n",
      "7133/10000: train_loss: 3.309594267196953 train_error 29.00% test_error 21.50%\n",
      "================================7134===================================\n",
      "7134/10000: train_loss: 3.309055288010277 train_error 29.00% test_error 21.50%\n",
      "================================7135===================================\n",
      "7135/10000: train_loss: 3.308516842485405 train_error 29.00% test_error 21.50%\n",
      "================================7136===================================\n",
      "7136/10000: train_loss: 3.3079820850212127 train_error 29.00% test_error 21.50%\n",
      "================================7137===================================\n",
      "7137/10000: train_loss: 3.3074475319869814 train_error 29.00% test_error 21.50%\n",
      "================================7138===================================\n",
      "7138/10000: train_loss: 3.3069142711674795 train_error 29.00% test_error 21.50%\n",
      "================================7139===================================\n",
      "7139/10000: train_loss: 3.3063810851518065 train_error 29.00% test_error 21.50%\n",
      "================================7140===================================\n",
      "7140/10000: train_loss: 3.3058462256239727 train_error 28.88% test_error 21.50%\n",
      "================================7141===================================\n",
      "7141/10000: train_loss: 3.305310816760175 train_error 28.88% test_error 21.50%\n",
      "================================7142===================================\n",
      "7142/10000: train_loss: 3.3047761979000647 train_error 28.88% test_error 21.50%\n",
      "================================7143===================================\n",
      "7143/10000: train_loss: 3.3042418762808667 train_error 28.88% test_error 21.50%\n",
      "================================7144===================================\n",
      "7144/10000: train_loss: 3.303708586855792 train_error 28.88% test_error 21.50%\n",
      "================================7145===================================\n",
      "7145/10000: train_loss: 3.3031741478899495 train_error 28.88% test_error 21.50%\n",
      "================================7146===================================\n",
      "7146/10000: train_loss: 3.3026375146396454 train_error 28.88% test_error 21.50%\n",
      "================================7147===================================\n",
      "7147/10000: train_loss: 3.3021008211886507 train_error 28.88% test_error 21.50%\n",
      "================================7148===================================\n",
      "7148/10000: train_loss: 3.3015635013580322 train_error 28.88% test_error 21.50%\n",
      "================================7149===================================\n",
      "7149/10000: train_loss: 3.3010261887451633 train_error 28.88% test_error 21.00%\n",
      "================================7150===================================\n",
      "7150/10000: train_loss: 3.3004892506543544 train_error 28.75% test_error 21.00%\n",
      "================================7151===================================\n",
      "7151/10000: train_loss: 3.2999531038152052 train_error 28.75% test_error 21.00%\n",
      "================================7152===================================\n",
      "7152/10000: train_loss: 3.2994178378349166 train_error 28.88% test_error 22.00%\n",
      "================================7153===================================\n",
      "7153/10000: train_loss: 3.298882235796191 train_error 28.88% test_error 22.00%\n",
      "================================7154===================================\n",
      "7154/10000: train_loss: 3.2983470107289032 train_error 28.88% test_error 22.00%\n",
      "================================7155===================================\n",
      "7155/10000: train_loss: 3.2978133895248174 train_error 29.00% test_error 22.00%\n",
      "================================7156===================================\n",
      "7156/10000: train_loss: 3.2972823462029917 train_error 29.12% test_error 22.00%\n",
      "================================7157===================================\n",
      "7157/10000: train_loss: 3.2967508691782133 train_error 29.12% test_error 22.00%\n",
      "================================7158===================================\n",
      "7158/10000: train_loss: 3.2962190945586185 train_error 29.12% test_error 22.00%\n",
      "================================7159===================================\n",
      "7159/10000: train_loss: 3.2956864271126687 train_error 29.12% test_error 22.00%\n",
      "================================7160===================================\n",
      "7160/10000: train_loss: 3.29515248789452 train_error 29.12% test_error 22.00%\n",
      "================================7161===================================\n",
      "7161/10000: train_loss: 3.294618278741837 train_error 29.12% test_error 22.00%\n",
      "================================7162===================================\n",
      "7162/10000: train_loss: 3.2940843297913673 train_error 29.12% test_error 22.50%\n",
      "================================7163===================================\n",
      "7163/10000: train_loss: 3.2935503088729456 train_error 29.12% test_error 22.50%\n",
      "================================7164===================================\n",
      "7164/10000: train_loss: 3.2930166115518658 train_error 29.12% test_error 22.50%\n",
      "================================7165===================================\n",
      "7165/10000: train_loss: 3.292483406323008 train_error 29.12% test_error 22.50%\n",
      "================================7166===================================\n",
      "7166/10000: train_loss: 3.29195029983297 train_error 29.00% test_error 22.50%\n",
      "================================7167===================================\n",
      "7167/10000: train_loss: 3.2914166208030657 train_error 29.00% test_error 22.50%\n",
      "================================7168===================================\n",
      "7168/10000: train_loss: 3.2908830080507325 train_error 29.00% test_error 22.50%\n",
      "================================7169===================================\n",
      "7169/10000: train_loss: 3.2903457789262758 train_error 29.00% test_error 22.50%\n",
      "================================7170===================================\n",
      "7170/10000: train_loss: 3.28980502196122 train_error 29.12% test_error 22.00%\n",
      "================================7171===================================\n",
      "7171/10000: train_loss: 3.2892633310332897 train_error 29.12% test_error 22.00%\n",
      "================================7172===================================\n",
      "7172/10000: train_loss: 3.288722548214719 train_error 29.12% test_error 22.50%\n",
      "================================7173===================================\n",
      "7173/10000: train_loss: 3.2881757744960485 train_error 29.12% test_error 22.50%\n",
      "================================7174===================================\n",
      "7174/10000: train_loss: 3.2876264410139995 train_error 29.12% test_error 22.50%\n",
      "================================7175===================================\n",
      "7175/10000: train_loss: 3.287076858121436 train_error 29.12% test_error 22.50%\n",
      "================================7176===================================\n",
      "7176/10000: train_loss: 3.2865266293869353 train_error 29.12% test_error 22.50%\n",
      "================================7177===================================\n",
      "7177/10000: train_loss: 3.2859781457181088 train_error 29.12% test_error 22.00%\n",
      "================================7178===================================\n",
      "7178/10000: train_loss: 3.285432794468943 train_error 29.12% test_error 22.00%\n",
      "================================7179===================================\n",
      "7179/10000: train_loss: 3.2848875928344206 train_error 29.12% test_error 22.00%\n",
      "================================7180===================================\n",
      "7180/10000: train_loss: 3.284343784863595 train_error 29.12% test_error 22.00%\n",
      "================================7181===================================\n",
      "7181/10000: train_loss: 3.283800181588158 train_error 29.12% test_error 22.00%\n",
      "================================7182===================================\n",
      "7182/10000: train_loss: 3.2832565513066947 train_error 29.12% test_error 22.00%\n",
      "================================7183===================================\n",
      "7183/10000: train_loss: 3.282713007947896 train_error 29.12% test_error 22.00%\n",
      "================================7184===================================\n",
      "7184/10000: train_loss: 3.2821694697579367 train_error 29.12% test_error 22.00%\n",
      "================================7185===================================\n",
      "7185/10000: train_loss: 3.281625894429162 train_error 29.12% test_error 22.00%\n",
      "================================7186===================================\n",
      "7186/10000: train_loss: 3.281082604001276 train_error 29.00% test_error 22.00%\n",
      "================================7187===================================\n",
      "7187/10000: train_loss: 3.2805389206903053 train_error 29.00% test_error 22.00%\n",
      "================================7188===================================\n",
      "7188/10000: train_loss: 3.279997514938004 train_error 28.88% test_error 22.00%\n",
      "================================7189===================================\n",
      "7189/10000: train_loss: 3.2794572508358395 train_error 28.88% test_error 22.00%\n",
      "================================7190===================================\n",
      "7190/10000: train_loss: 3.2789156406954865 train_error 28.88% test_error 22.00%\n",
      "================================7191===================================\n",
      "7191/10000: train_loss: 3.2783727059978993 train_error 28.88% test_error 22.00%\n",
      "================================7192===================================\n",
      "7192/10000: train_loss: 3.277832928714343 train_error 28.75% test_error 22.00%\n",
      "================================7193===================================\n",
      "7193/10000: train_loss: 3.2772970995632935 train_error 28.75% test_error 22.00%\n",
      "================================7194===================================\n",
      "7194/10000: train_loss: 3.276761604594067 train_error 28.75% test_error 22.50%\n",
      "================================7195===================================\n",
      "7195/10000: train_loss: 3.2762271949788553 train_error 28.75% test_error 22.50%\n",
      "================================7196===================================\n",
      "7196/10000: train_loss: 3.27569509513909 train_error 28.75% test_error 22.50%\n",
      "================================7197===================================\n",
      "7197/10000: train_loss: 3.275162422356661 train_error 28.88% test_error 22.50%\n",
      "================================7198===================================\n",
      "7198/10000: train_loss: 3.274629871547222 train_error 28.62% test_error 22.50%\n",
      "================================7199===================================\n",
      "7199/10000: train_loss: 3.274096588406246 train_error 28.62% test_error 22.50%\n",
      "================================7200===================================\n",
      "7200/10000: train_loss: 3.273561927406117 train_error 28.50% test_error 22.50%\n",
      "================================7201===================================\n",
      "7201/10000: train_loss: 3.2730269293347374 train_error 28.50% test_error 22.50%\n",
      "================================7202===================================\n",
      "7202/10000: train_loss: 3.272490960585419 train_error 28.50% test_error 22.50%\n",
      "================================7203===================================\n",
      "7203/10000: train_loss: 3.2719521726714444 train_error 28.38% test_error 22.50%\n",
      "================================7204===================================\n",
      "7204/10000: train_loss: 3.271409432000946 train_error 28.38% test_error 22.50%\n",
      "================================7205===================================\n",
      "7205/10000: train_loss: 3.2708681229990906 train_error 28.38% test_error 22.50%\n",
      "================================7206===================================\n",
      "7206/10000: train_loss: 3.270327050962951 train_error 28.38% test_error 22.50%\n",
      "================================7207===================================\n",
      "7207/10000: train_loss: 3.2697863094205966 train_error 28.38% test_error 22.50%\n",
      "================================7208===================================\n",
      "7208/10000: train_loss: 3.2692472853465007 train_error 28.38% test_error 22.50%\n",
      "================================7209===================================\n",
      "7209/10000: train_loss: 3.2687094394140876 train_error 28.38% test_error 22.50%\n",
      "================================7210===================================\n",
      "7210/10000: train_loss: 3.268171340893023 train_error 28.38% test_error 22.50%\n",
      "================================7211===================================\n",
      "7211/10000: train_loss: 3.2676337829604742 train_error 28.38% test_error 22.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7212===================================\n",
      "7212/10000: train_loss: 3.267093936884776 train_error 28.38% test_error 22.50%\n",
      "================================7213===================================\n",
      "7213/10000: train_loss: 3.2665559395053423 train_error 28.25% test_error 22.50%\n",
      "================================7214===================================\n",
      "7214/10000: train_loss: 3.2660180485527963 train_error 28.25% test_error 22.50%\n",
      "================================7215===================================\n",
      "7215/10000: train_loss: 3.265478607702535 train_error 28.25% test_error 22.50%\n",
      "================================7216===================================\n",
      "7216/10000: train_loss: 3.264938756907359 train_error 28.12% test_error 22.00%\n",
      "================================7217===================================\n",
      "7217/10000: train_loss: 3.2643994645262135 train_error 28.00% test_error 22.00%\n",
      "================================7218===================================\n",
      "7218/10000: train_loss: 3.2638603575737215 train_error 28.00% test_error 22.00%\n",
      "================================7219===================================\n",
      "7219/10000: train_loss: 3.2633200304745698 train_error 28.00% test_error 22.00%\n",
      "================================7220===================================\n",
      "7220/10000: train_loss: 3.2627799585857424 train_error 28.00% test_error 22.00%\n",
      "================================7221===================================\n",
      "7221/10000: train_loss: 3.2622408999223262 train_error 28.00% test_error 22.00%\n",
      "================================7222===================================\n",
      "7222/10000: train_loss: 3.2617035890277477 train_error 28.00% test_error 22.00%\n",
      "================================7223===================================\n",
      "7223/10000: train_loss: 3.261168194771744 train_error 27.75% test_error 22.00%\n",
      "================================7224===================================\n",
      "7224/10000: train_loss: 3.2606326758512294 train_error 27.75% test_error 22.00%\n",
      "================================7225===================================\n",
      "7225/10000: train_loss: 3.260096462322399 train_error 27.75% test_error 22.00%\n",
      "================================7226===================================\n",
      "7226/10000: train_loss: 3.2595602476364003 train_error 27.75% test_error 22.00%\n",
      "================================7227===================================\n",
      "7227/10000: train_loss: 3.2590253540244882 train_error 27.62% test_error 22.00%\n",
      "================================7228===================================\n",
      "7228/10000: train_loss: 3.2584895074763334 train_error 27.62% test_error 22.00%\n",
      "================================7229===================================\n",
      "7229/10000: train_loss: 3.2579540900117716 train_error 27.62% test_error 22.00%\n",
      "================================7230===================================\n",
      "7230/10000: train_loss: 3.257420872636139 train_error 27.62% test_error 22.00%\n",
      "================================7231===================================\n",
      "7231/10000: train_loss: 3.256884559278842 train_error 27.62% test_error 22.00%\n",
      "================================7232===================================\n",
      "7232/10000: train_loss: 3.2563461565319445 train_error 27.75% test_error 22.00%\n",
      "================================7233===================================\n",
      "7233/10000: train_loss: 3.2558086020033805 train_error 27.75% test_error 22.50%\n",
      "================================7234===================================\n",
      "7234/10000: train_loss: 3.2552715944568624 train_error 27.75% test_error 22.50%\n",
      "================================7235===================================\n",
      "7235/10000: train_loss: 3.254737005389761 train_error 27.62% test_error 22.50%\n",
      "================================7236===================================\n",
      "7236/10000: train_loss: 3.254202491035685 train_error 27.50% test_error 22.50%\n",
      "================================7237===================================\n",
      "7237/10000: train_loss: 3.2536675648088567 train_error 27.50% test_error 22.50%\n",
      "================================7238===================================\n",
      "7238/10000: train_loss: 3.2531334887258705 train_error 27.50% test_error 22.00%\n",
      "================================7239===================================\n",
      "7239/10000: train_loss: 3.252599374144338 train_error 27.50% test_error 22.00%\n",
      "================================7240===================================\n",
      "7240/10000: train_loss: 3.252063524029218 train_error 27.50% test_error 22.00%\n",
      "================================7241===================================\n",
      "7241/10000: train_loss: 3.251527349972166 train_error 27.50% test_error 22.00%\n",
      "================================7242===================================\n",
      "7242/10000: train_loss: 3.250991630894132 train_error 27.50% test_error 22.00%\n",
      "================================7243===================================\n",
      "7243/10000: train_loss: 3.250455789335538 train_error 27.50% test_error 22.00%\n",
      "================================7244===================================\n",
      "7244/10000: train_loss: 3.2499208054784683 train_error 27.50% test_error 22.00%\n",
      "================================7245===================================\n",
      "7245/10000: train_loss: 3.24938572968822 train_error 27.50% test_error 22.00%\n",
      "================================7246===================================\n",
      "7246/10000: train_loss: 3.2488488979637626 train_error 27.50% test_error 22.00%\n",
      "================================7247===================================\n",
      "7247/10000: train_loss: 3.2483073572278958 train_error 27.50% test_error 22.00%\n",
      "================================7248===================================\n",
      "7248/10000: train_loss: 3.247763820590917 train_error 27.50% test_error 22.00%\n",
      "================================7249===================================\n",
      "7249/10000: train_loss: 3.247220092318021 train_error 27.50% test_error 22.00%\n",
      "================================7250===================================\n",
      "7250/10000: train_loss: 3.2466787925153042 train_error 27.62% test_error 22.00%\n",
      "================================7251===================================\n",
      "7251/10000: train_loss: 3.246138964788988 train_error 27.50% test_error 22.50%\n",
      "================================7252===================================\n",
      "7252/10000: train_loss: 3.245599754715804 train_error 27.50% test_error 22.50%\n",
      "================================7253===================================\n",
      "7253/10000: train_loss: 3.2450612364779228 train_error 27.50% test_error 22.50%\n",
      "================================7254===================================\n",
      "7254/10000: train_loss: 3.244523190848995 train_error 27.50% test_error 22.50%\n",
      "================================7255===================================\n",
      "7255/10000: train_loss: 3.2439848479465585 train_error 27.50% test_error 22.50%\n",
      "================================7256===================================\n",
      "7256/10000: train_loss: 3.2434463189728557 train_error 27.50% test_error 22.50%\n",
      "================================7257===================================\n",
      "7257/10000: train_loss: 3.242907850504853 train_error 27.50% test_error 22.50%\n",
      "================================7258===================================\n",
      "7258/10000: train_loss: 3.242364425207488 train_error 27.38% test_error 22.50%\n",
      "================================7259===================================\n",
      "7259/10000: train_loss: 3.241817995691672 train_error 27.38% test_error 22.50%\n",
      "================================7260===================================\n",
      "7260/10000: train_loss: 3.2412737532285973 train_error 27.38% test_error 22.50%\n",
      "================================7261===================================\n",
      "7261/10000: train_loss: 3.2407316520856693 train_error 27.38% test_error 22.50%\n",
      "================================7262===================================\n",
      "7262/10000: train_loss: 3.240189699905459 train_error 27.38% test_error 22.50%\n",
      "================================7263===================================\n",
      "7263/10000: train_loss: 3.239647844270803 train_error 27.38% test_error 22.50%\n",
      "================================7264===================================\n",
      "7264/10000: train_loss: 3.2391039297683166 train_error 27.38% test_error 22.50%\n",
      "================================7265===================================\n",
      "7265/10000: train_loss: 3.2385596505226566 train_error 27.38% test_error 22.50%\n",
      "================================7266===================================\n",
      "7266/10000: train_loss: 3.2380171150295065 train_error 27.38% test_error 22.50%\n",
      "================================7267===================================\n",
      "7267/10000: train_loss: 3.2374741938896476 train_error 27.38% test_error 22.50%\n",
      "================================7268===================================\n",
      "7268/10000: train_loss: 3.236930509256199 train_error 27.38% test_error 22.50%\n",
      "================================7269===================================\n",
      "7269/10000: train_loss: 3.2363867845549246 train_error 27.38% test_error 22.50%\n",
      "================================7270===================================\n",
      "7270/10000: train_loss: 3.2358433112665077 train_error 27.38% test_error 22.50%\n",
      "================================7271===================================\n",
      "7271/10000: train_loss: 3.235299977168906 train_error 27.38% test_error 22.50%\n",
      "================================7272===================================\n",
      "7272/10000: train_loss: 3.234753028994892 train_error 27.38% test_error 22.50%\n",
      "================================7273===================================\n",
      "7273/10000: train_loss: 3.234203519979492 train_error 27.38% test_error 22.50%\n",
      "================================7274===================================\n",
      "7274/10000: train_loss: 3.2336482674232685 train_error 27.38% test_error 22.50%\n",
      "================================7275===================================\n",
      "7275/10000: train_loss: 3.233095788012724 train_error 27.38% test_error 22.50%\n",
      "================================7276===================================\n",
      "7276/10000: train_loss: 3.2325438444805332 train_error 27.38% test_error 22.50%\n",
      "================================7277===================================\n",
      "7277/10000: train_loss: 3.2319925113371575 train_error 27.38% test_error 22.50%\n",
      "================================7278===================================\n",
      "7278/10000: train_loss: 3.2314420386869456 train_error 27.38% test_error 22.50%\n",
      "================================7279===================================\n",
      "7279/10000: train_loss: 3.230896137361415 train_error 27.38% test_error 22.50%\n",
      "================================7280===================================\n",
      "7280/10000: train_loss: 3.2303522913903002 train_error 27.38% test_error 22.50%\n",
      "================================7281===================================\n",
      "7281/10000: train_loss: 3.2298087464366105 train_error 27.38% test_error 22.50%\n",
      "================================7282===================================\n",
      "7282/10000: train_loss: 3.229263870776631 train_error 27.12% test_error 22.50%\n",
      "================================7283===================================\n",
      "7283/10000: train_loss: 3.228715812752489 train_error 27.12% test_error 22.50%\n",
      "================================7284===================================\n",
      "7284/10000: train_loss: 3.228164752754383 train_error 27.12% test_error 22.50%\n",
      "================================7285===================================\n",
      "7285/10000: train_loss: 3.2276112818438563 train_error 27.12% test_error 22.50%\n",
      "================================7286===================================\n",
      "7286/10000: train_loss: 3.2270593979791737 train_error 27.12% test_error 22.50%\n",
      "================================7287===================================\n",
      "7287/10000: train_loss: 3.2265072895423508 train_error 27.25% test_error 22.50%\n",
      "================================7288===================================\n",
      "7288/10000: train_loss: 3.225958150413353 train_error 27.12% test_error 22.50%\n",
      "================================7289===================================\n",
      "7289/10000: train_loss: 3.2254101906949653 train_error 27.12% test_error 22.50%\n",
      "================================7290===================================\n",
      "7290/10000: train_loss: 3.2248654620838355 train_error 27.12% test_error 22.50%\n",
      "================================7291===================================\n",
      "7291/10000: train_loss: 3.224319416375365 train_error 27.12% test_error 22.50%\n",
      "================================7292===================================\n",
      "7292/10000: train_loss: 3.22377739550313 train_error 27.12% test_error 22.50%\n",
      "================================7293===================================\n",
      "7293/10000: train_loss: 3.2232372214319187 train_error 27.12% test_error 22.50%\n",
      "================================7294===================================\n",
      "7294/10000: train_loss: 3.2226976890116927 train_error 27.12% test_error 22.50%\n",
      "================================7295===================================\n",
      "7295/10000: train_loss: 3.222161515923217 train_error 27.12% test_error 22.50%\n",
      "================================7296===================================\n",
      "7296/10000: train_loss: 3.221624222304672 train_error 27.12% test_error 22.50%\n",
      "================================7297===================================\n",
      "7297/10000: train_loss: 3.2210851567774075 train_error 27.12% test_error 22.50%\n",
      "================================7298===================================\n",
      "7298/10000: train_loss: 3.2205458433693277 train_error 27.12% test_error 22.50%\n",
      "================================7299===================================\n",
      "7299/10000: train_loss: 3.220007412764244 train_error 27.12% test_error 22.50%\n",
      "================================7300===================================\n",
      "7300/10000: train_loss: 3.2194708325364627 train_error 27.12% test_error 22.50%\n",
      "================================7301===================================\n",
      "7301/10000: train_loss: 3.2189352461113594 train_error 27.12% test_error 22.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7302===================================\n",
      "7302/10000: train_loss: 3.2183990965248084 train_error 27.12% test_error 22.50%\n",
      "================================7303===================================\n",
      "7303/10000: train_loss: 3.217864521732554 train_error 27.00% test_error 22.50%\n",
      "================================7304===================================\n",
      "7304/10000: train_loss: 3.2173310565343125 train_error 27.00% test_error 22.50%\n",
      "================================7305===================================\n",
      "7305/10000: train_loss: 3.2167939700325947 train_error 26.88% test_error 22.50%\n",
      "================================7306===================================\n",
      "7306/10000: train_loss: 3.2162522612465545 train_error 26.88% test_error 22.50%\n",
      "================================7307===================================\n",
      "7307/10000: train_loss: 3.2157118794159034 train_error 26.88% test_error 22.50%\n",
      "================================7308===================================\n",
      "7308/10000: train_loss: 3.2151684616389686 train_error 26.88% test_error 22.50%\n",
      "================================7309===================================\n",
      "7309/10000: train_loss: 3.214624649942853 train_error 26.88% test_error 22.50%\n",
      "================================7310===================================\n",
      "7310/10000: train_loss: 3.2140832735272125 train_error 27.00% test_error 22.50%\n",
      "================================7311===================================\n",
      "7311/10000: train_loss: 3.2135424899240026 train_error 27.00% test_error 22.50%\n",
      "================================7312===================================\n",
      "7312/10000: train_loss: 3.213001803904772 train_error 27.00% test_error 22.50%\n",
      "================================7313===================================\n",
      "7313/10000: train_loss: 3.2124599783541634 train_error 27.00% test_error 22.50%\n",
      "================================7314===================================\n",
      "7314/10000: train_loss: 3.211919243214652 train_error 27.00% test_error 22.50%\n",
      "================================7315===================================\n",
      "7315/10000: train_loss: 3.2113846548786387 train_error 27.00% test_error 22.50%\n",
      "================================7316===================================\n",
      "7316/10000: train_loss: 3.210851236416493 train_error 27.00% test_error 22.50%\n",
      "================================7317===================================\n",
      "7317/10000: train_loss: 3.210318939925637 train_error 27.00% test_error 22.50%\n",
      "================================7318===================================\n",
      "7318/10000: train_loss: 3.2097871950874106 train_error 27.00% test_error 22.50%\n",
      "================================7319===================================\n",
      "7319/10000: train_loss: 3.2092591561796144 train_error 27.00% test_error 22.50%\n",
      "================================7320===================================\n",
      "7320/10000: train_loss: 3.208734978090506 train_error 27.00% test_error 22.50%\n",
      "================================7321===================================\n",
      "7321/10000: train_loss: 3.208215471946169 train_error 27.00% test_error 22.50%\n",
      "================================7322===================================\n",
      "7322/10000: train_loss: 3.2076970979524777 train_error 27.00% test_error 22.50%\n",
      "================================7323===================================\n",
      "7323/10000: train_loss: 3.2071802805084735 train_error 27.00% test_error 22.50%\n",
      "================================7324===================================\n",
      "7324/10000: train_loss: 3.2066634954232724 train_error 27.00% test_error 22.50%\n",
      "================================7325===================================\n",
      "7325/10000: train_loss: 3.206147633634973 train_error 27.00% test_error 22.50%\n",
      "================================7326===================================\n",
      "7326/10000: train_loss: 3.2056327648553995 train_error 27.00% test_error 22.50%\n",
      "================================7327===================================\n",
      "7327/10000: train_loss: 3.2051182706002144 train_error 27.00% test_error 22.50%\n",
      "================================7328===================================\n",
      "7328/10000: train_loss: 3.204604991131928 train_error 27.00% test_error 22.50%\n",
      "================================7329===================================\n",
      "7329/10000: train_loss: 3.2040925145428627 train_error 26.88% test_error 22.50%\n",
      "================================7330===================================\n",
      "7330/10000: train_loss: 3.2035814946144816 train_error 26.75% test_error 22.50%\n",
      "================================7331===================================\n",
      "7331/10000: train_loss: 3.203073755581863 train_error 26.75% test_error 22.50%\n",
      "================================7332===================================\n",
      "7332/10000: train_loss: 3.2025650778668933 train_error 26.75% test_error 22.50%\n",
      "================================7333===================================\n",
      "7333/10000: train_loss: 3.202053886873182 train_error 26.62% test_error 22.50%\n",
      "================================7334===================================\n",
      "7334/10000: train_loss: 3.201541006767657 train_error 26.62% test_error 22.50%\n",
      "================================7335===================================\n",
      "7335/10000: train_loss: 3.2010310652223417 train_error 26.62% test_error 22.50%\n",
      "================================7336===================================\n",
      "7336/10000: train_loss: 3.200525896162726 train_error 26.62% test_error 22.50%\n",
      "================================7337===================================\n",
      "7337/10000: train_loss: 3.2000210032379255 train_error 26.75% test_error 22.50%\n",
      "================================7338===================================\n",
      "7338/10000: train_loss: 3.1995167601155114 train_error 26.75% test_error 22.50%\n",
      "================================7339===================================\n",
      "7339/10000: train_loss: 3.19901227343129 train_error 26.75% test_error 22.50%\n",
      "================================7340===================================\n",
      "7340/10000: train_loss: 3.1985072772973218 train_error 26.75% test_error 22.50%\n",
      "================================7341===================================\n",
      "7341/10000: train_loss: 3.1980001531913875 train_error 26.75% test_error 22.50%\n",
      "================================7342===================================\n",
      "7342/10000: train_loss: 3.197494818097912 train_error 26.75% test_error 22.50%\n",
      "================================7343===================================\n",
      "7343/10000: train_loss: 3.196991523222532 train_error 26.88% test_error 22.50%\n",
      "================================7344===================================\n",
      "7344/10000: train_loss: 3.19649110376602 train_error 26.88% test_error 22.50%\n",
      "================================7345===================================\n",
      "7345/10000: train_loss: 3.19599085904425 train_error 26.88% test_error 22.50%\n",
      "================================7346===================================\n",
      "7346/10000: train_loss: 3.1954879054240886 train_error 26.88% test_error 22.50%\n",
      "================================7347===================================\n",
      "7347/10000: train_loss: 3.1949851929396393 train_error 26.88% test_error 22.50%\n",
      "================================7348===================================\n",
      "7348/10000: train_loss: 3.1944831831380727 train_error 26.88% test_error 22.50%\n",
      "================================7349===================================\n",
      "7349/10000: train_loss: 3.193982901852578 train_error 26.88% test_error 22.50%\n",
      "================================7350===================================\n",
      "7350/10000: train_loss: 3.1934819257399067 train_error 26.88% test_error 22.50%\n",
      "================================7351===================================\n",
      "7351/10000: train_loss: 3.1929786187852733 train_error 26.88% test_error 22.50%\n",
      "================================7352===================================\n",
      "7352/10000: train_loss: 3.192475890258793 train_error 27.00% test_error 22.50%\n",
      "================================7353===================================\n",
      "7353/10000: train_loss: 3.191970992626157 train_error 26.88% test_error 22.50%\n",
      "================================7354===================================\n",
      "7354/10000: train_loss: 3.191465438099112 train_error 26.88% test_error 22.50%\n",
      "================================7355===================================\n",
      "7355/10000: train_loss: 3.190961711867712 train_error 26.88% test_error 22.50%\n",
      "================================7356===================================\n",
      "7356/10000: train_loss: 3.1904577076807614 train_error 26.88% test_error 22.50%\n",
      "================================7357===================================\n",
      "7357/10000: train_loss: 3.1899538924964146 train_error 26.88% test_error 22.50%\n",
      "================================7358===================================\n",
      "7358/10000: train_loss: 3.1894488438684494 train_error 26.88% test_error 22.50%\n",
      "================================7359===================================\n",
      "7359/10000: train_loss: 3.188943170825951 train_error 26.88% test_error 22.50%\n",
      "================================7360===================================\n",
      "7360/10000: train_loss: 3.188438615736086 train_error 26.88% test_error 22.50%\n",
      "================================7361===================================\n",
      "7361/10000: train_loss: 3.187937071721535 train_error 26.75% test_error 22.50%\n",
      "================================7362===================================\n",
      "7362/10000: train_loss: 3.187437323539052 train_error 26.75% test_error 22.50%\n",
      "================================7363===================================\n",
      "7363/10000: train_loss: 3.1869430159358307 train_error 26.88% test_error 22.50%\n",
      "================================7364===================================\n",
      "7364/10000: train_loss: 3.186451379335485 train_error 26.88% test_error 22.50%\n",
      "================================7365===================================\n",
      "7365/10000: train_loss: 3.18596515793819 train_error 26.88% test_error 22.50%\n",
      "================================7366===================================\n",
      "7366/10000: train_loss: 3.1854797670501283 train_error 26.88% test_error 22.50%\n",
      "================================7367===================================\n",
      "7367/10000: train_loss: 3.1849944290402346 train_error 26.88% test_error 22.50%\n",
      "================================7368===================================\n",
      "7368/10000: train_loss: 3.1845085761789234 train_error 26.88% test_error 22.50%\n",
      "================================7369===================================\n",
      "7369/10000: train_loss: 3.18402002008399 train_error 26.88% test_error 22.50%\n",
      "================================7370===================================\n",
      "7370/10000: train_loss: 3.1835303202783685 train_error 26.88% test_error 22.50%\n",
      "================================7371===================================\n",
      "7371/10000: train_loss: 3.1830402283440344 train_error 26.88% test_error 22.50%\n",
      "================================7372===================================\n",
      "7372/10000: train_loss: 3.182548448340967 train_error 26.88% test_error 22.50%\n",
      "================================7373===================================\n",
      "7373/10000: train_loss: 3.182056059064344 train_error 26.88% test_error 22.50%\n",
      "================================7374===================================\n",
      "7374/10000: train_loss: 3.1815620099147783 train_error 26.88% test_error 22.50%\n",
      "================================7375===================================\n",
      "7375/10000: train_loss: 3.1810656992695296 train_error 26.88% test_error 22.50%\n",
      "================================7376===================================\n",
      "7376/10000: train_loss: 3.180565354877617 train_error 26.88% test_error 22.50%\n",
      "================================7377===================================\n",
      "7377/10000: train_loss: 3.1800656575011086 train_error 26.88% test_error 22.50%\n",
      "================================7378===================================\n",
      "7378/10000: train_loss: 3.179566496436019 train_error 26.88% test_error 22.50%\n",
      "================================7379===================================\n",
      "7379/10000: train_loss: 3.179068155419081 train_error 26.88% test_error 22.50%\n",
      "================================7380===================================\n",
      "7380/10000: train_loss: 3.178569769295864 train_error 26.88% test_error 22.50%\n",
      "================================7381===================================\n",
      "7381/10000: train_loss: 3.1780711864330806 train_error 26.88% test_error 22.50%\n",
      "================================7382===================================\n",
      "7382/10000: train_loss: 3.177572914923075 train_error 26.88% test_error 22.50%\n",
      "================================7383===================================\n",
      "7383/10000: train_loss: 3.177078576886561 train_error 26.88% test_error 22.50%\n",
      "================================7384===================================\n",
      "7384/10000: train_loss: 3.176583541786531 train_error 26.75% test_error 22.50%\n",
      "================================7385===================================\n",
      "7385/10000: train_loss: 3.1760877634875944 train_error 26.62% test_error 22.50%\n",
      "================================7386===================================\n",
      "7386/10000: train_loss: 3.17559378617676 train_error 26.62% test_error 22.50%\n",
      "================================7387===================================\n",
      "7387/10000: train_loss: 3.1751002447551584 train_error 26.62% test_error 22.50%\n",
      "================================7388===================================\n",
      "7388/10000: train_loss: 3.174605433713878 train_error 26.50% test_error 22.50%\n",
      "================================7389===================================\n",
      "7389/10000: train_loss: 3.1741109964670615 train_error 26.50% test_error 22.50%\n",
      "================================7390===================================\n",
      "7390/10000: train_loss: 3.1736170796141963 train_error 26.50% test_error 22.50%\n",
      "================================7391===================================\n",
      "7391/10000: train_loss: 3.1731256964372005 train_error 26.50% test_error 22.50%\n",
      "================================7392===================================\n",
      "7392/10000: train_loss: 3.1726347272144633 train_error 26.50% test_error 22.50%\n",
      "================================7393===================================\n",
      "7393/10000: train_loss: 3.1721465494541916 train_error 26.50% test_error 22.50%\n",
      "================================7394===================================\n",
      "7394/10000: train_loss: 3.1716587281133983 train_error 26.50% test_error 22.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7395===================================\n",
      "7395/10000: train_loss: 3.1711712857184464 train_error 26.50% test_error 22.50%\n",
      "================================7396===================================\n",
      "7396/10000: train_loss: 3.1706852058961523 train_error 26.50% test_error 22.50%\n",
      "================================7397===================================\n",
      "7397/10000: train_loss: 3.1701990947546435 train_error 26.50% test_error 22.50%\n",
      "================================7398===================================\n",
      "7398/10000: train_loss: 3.1697121002594937 train_error 26.50% test_error 22.50%\n",
      "================================7399===================================\n",
      "7399/10000: train_loss: 3.169226449179696 train_error 26.50% test_error 22.00%\n",
      "================================7400===================================\n",
      "7400/10000: train_loss: 3.1687414337205704 train_error 26.50% test_error 22.00%\n",
      "================================7401===================================\n",
      "7401/10000: train_loss: 3.1682578173885125 train_error 26.50% test_error 22.00%\n",
      "================================7402===================================\n",
      "7402/10000: train_loss: 3.1677758043108044 train_error 26.50% test_error 22.00%\n",
      "================================7403===================================\n",
      "7403/10000: train_loss: 3.1672961515397766 train_error 26.62% test_error 22.00%\n",
      "================================7404===================================\n",
      "7404/10000: train_loss: 3.166819006986916 train_error 26.62% test_error 22.00%\n",
      "================================7405===================================\n",
      "7405/10000: train_loss: 3.166342646538978 train_error 26.62% test_error 22.00%\n",
      "================================7406===================================\n",
      "7406/10000: train_loss: 3.165866387971909 train_error 26.62% test_error 22.00%\n",
      "================================7407===================================\n",
      "7407/10000: train_loss: 3.165389975149883 train_error 26.50% test_error 22.00%\n",
      "================================7408===================================\n",
      "7408/10000: train_loss: 3.1649180222454016 train_error 26.50% test_error 21.50%\n",
      "================================7409===================================\n",
      "7409/10000: train_loss: 3.164448846598389 train_error 26.50% test_error 21.50%\n",
      "================================7410===================================\n",
      "7410/10000: train_loss: 3.1639795060933102 train_error 26.50% test_error 21.50%\n",
      "================================7411===================================\n",
      "7411/10000: train_loss: 3.1635114604735284 train_error 26.50% test_error 21.50%\n",
      "================================7412===================================\n",
      "7412/10000: train_loss: 3.16304488067166 train_error 26.50% test_error 21.50%\n",
      "================================7413===================================\n",
      "7413/10000: train_loss: 3.162577235510107 train_error 26.50% test_error 21.50%\n",
      "================================7414===================================\n",
      "7414/10000: train_loss: 3.162110646071378 train_error 26.50% test_error 21.50%\n",
      "================================7415===================================\n",
      "7415/10000: train_loss: 3.1616449085786007 train_error 26.50% test_error 21.50%\n",
      "================================7416===================================\n",
      "7416/10000: train_loss: 3.1611777378234547 train_error 26.50% test_error 21.50%\n",
      "================================7417===================================\n",
      "7417/10000: train_loss: 3.1607113060273697 train_error 26.50% test_error 21.50%\n",
      "================================7418===================================\n",
      "7418/10000: train_loss: 3.1602426714613103 train_error 26.50% test_error 21.50%\n",
      "================================7419===================================\n",
      "7419/10000: train_loss: 3.159773991834372 train_error 26.50% test_error 21.50%\n",
      "================================7420===================================\n",
      "7420/10000: train_loss: 3.1593041655025447 train_error 26.50% test_error 21.50%\n",
      "================================7421===================================\n",
      "7421/10000: train_loss: 3.158834699225845 train_error 26.38% test_error 21.50%\n",
      "================================7422===================================\n",
      "7422/10000: train_loss: 3.1583632268058137 train_error 26.38% test_error 21.50%\n",
      "================================7423===================================\n",
      "7423/10000: train_loss: 3.1578928085940423 train_error 26.38% test_error 21.50%\n",
      "================================7424===================================\n",
      "7424/10000: train_loss: 3.1574224507587494 train_error 26.38% test_error 21.50%\n",
      "================================7425===================================\n",
      "7425/10000: train_loss: 3.156956006861292 train_error 26.38% test_error 21.50%\n",
      "================================7426===================================\n",
      "7426/10000: train_loss: 3.156491273741704 train_error 26.38% test_error 21.50%\n",
      "================================7427===================================\n",
      "7427/10000: train_loss: 3.1560264117072805 train_error 26.38% test_error 21.50%\n",
      "================================7428===================================\n",
      "7428/10000: train_loss: 3.1555595295305827 train_error 26.50% test_error 21.50%\n",
      "================================7429===================================\n",
      "7429/10000: train_loss: 3.1550949041545393 train_error 26.50% test_error 21.50%\n",
      "================================7430===================================\n",
      "7430/10000: train_loss: 3.154630644770805 train_error 26.50% test_error 21.50%\n",
      "================================7431===================================\n",
      "7431/10000: train_loss: 3.15416762460256 train_error 26.50% test_error 21.50%\n",
      "================================7432===================================\n",
      "7432/10000: train_loss: 3.153705717934063 train_error 26.50% test_error 21.50%\n",
      "================================7433===================================\n",
      "7433/10000: train_loss: 3.153240253728582 train_error 26.50% test_error 21.50%\n",
      "================================7434===================================\n",
      "7434/10000: train_loss: 3.152774828503607 train_error 26.50% test_error 21.50%\n",
      "================================7435===================================\n",
      "7435/10000: train_loss: 3.1523079450416844 train_error 26.38% test_error 21.50%\n",
      "================================7436===================================\n",
      "7436/10000: train_loss: 3.151839210324688 train_error 26.38% test_error 21.50%\n",
      "================================7437===================================\n",
      "7437/10000: train_loss: 3.1513701169611887 train_error 26.38% test_error 21.50%\n",
      "================================7438===================================\n",
      "7438/10000: train_loss: 3.1509022559283766 train_error 26.38% test_error 21.50%\n",
      "================================7439===================================\n",
      "7439/10000: train_loss: 3.1504339426930525 train_error 26.38% test_error 21.50%\n",
      "================================7440===================================\n",
      "7440/10000: train_loss: 3.14996656770003 train_error 26.38% test_error 21.50%\n",
      "================================7441===================================\n",
      "7441/10000: train_loss: 3.149500023326836 train_error 26.38% test_error 21.50%\n",
      "================================7442===================================\n",
      "7442/10000: train_loss: 3.1490359637117944 train_error 26.38% test_error 21.50%\n",
      "================================7443===================================\n",
      "7443/10000: train_loss: 3.1485725021024704 train_error 26.38% test_error 21.50%\n",
      "================================7444===================================\n",
      "7444/10000: train_loss: 3.148109207338421 train_error 26.38% test_error 21.50%\n",
      "================================7445===================================\n",
      "7445/10000: train_loss: 3.1476445401506497 train_error 26.38% test_error 21.50%\n",
      "================================7446===================================\n",
      "7446/10000: train_loss: 3.147180963242427 train_error 26.38% test_error 21.50%\n",
      "================================7447===================================\n",
      "7447/10000: train_loss: 3.146718071462819 train_error 26.38% test_error 21.50%\n",
      "================================7448===================================\n",
      "7448/10000: train_loss: 3.146257642740384 train_error 26.38% test_error 21.50%\n",
      "================================7449===================================\n",
      "7449/10000: train_loss: 3.145796140716411 train_error 26.38% test_error 21.50%\n",
      "================================7450===================================\n",
      "7450/10000: train_loss: 3.1453363878885288 train_error 26.38% test_error 21.50%\n",
      "================================7451===================================\n",
      "7451/10000: train_loss: 3.1448775225214196 train_error 26.38% test_error 21.50%\n",
      "================================7452===================================\n",
      "7452/10000: train_loss: 3.144419525238918 train_error 26.38% test_error 21.50%\n",
      "================================7453===================================\n",
      "7453/10000: train_loss: 3.1439679161901584 train_error 26.38% test_error 21.50%\n",
      "================================7454===================================\n",
      "7454/10000: train_loss: 3.1435154353897086 train_error 26.38% test_error 21.50%\n",
      "================================7455===================================\n",
      "7455/10000: train_loss: 3.143064601630904 train_error 26.38% test_error 21.50%\n",
      "================================7456===================================\n",
      "7456/10000: train_loss: 3.1426140708127055 train_error 26.38% test_error 21.50%\n",
      "================================7457===================================\n",
      "7457/10000: train_loss: 3.142163068030495 train_error 26.38% test_error 21.50%\n",
      "================================7458===================================\n",
      "7458/10000: train_loss: 3.1417134995991365 train_error 26.38% test_error 21.50%\n",
      "================================7459===================================\n",
      "7459/10000: train_loss: 3.1412593147787264 train_error 26.38% test_error 21.50%\n",
      "================================7460===================================\n",
      "7460/10000: train_loss: 3.1408082627377008 train_error 26.38% test_error 21.50%\n",
      "================================7461===================================\n",
      "7461/10000: train_loss: 3.1403594542341304 train_error 26.38% test_error 21.50%\n",
      "================================7462===================================\n",
      "7462/10000: train_loss: 3.139910588080529 train_error 26.38% test_error 21.50%\n",
      "================================7463===================================\n",
      "7463/10000: train_loss: 3.139462400970515 train_error 26.38% test_error 21.50%\n",
      "================================7464===================================\n",
      "7464/10000: train_loss: 3.1390133584756406 train_error 26.38% test_error 21.50%\n",
      "================================7465===================================\n",
      "7465/10000: train_loss: 3.138563023302704 train_error 26.38% test_error 21.50%\n",
      "================================7466===================================\n",
      "7466/10000: train_loss: 3.1381125681230335 train_error 26.38% test_error 21.50%\n",
      "================================7467===================================\n",
      "7467/10000: train_loss: 3.1376624126767276 train_error 26.38% test_error 21.50%\n",
      "================================7468===================================\n",
      "7468/10000: train_loss: 3.13721320789773 train_error 26.38% test_error 21.50%\n",
      "================================7469===================================\n",
      "7469/10000: train_loss: 3.1367672527825925 train_error 26.38% test_error 21.50%\n",
      "================================7470===================================\n",
      "7470/10000: train_loss: 3.1363206725893544 train_error 26.38% test_error 21.50%\n",
      "================================7471===================================\n",
      "7471/10000: train_loss: 3.1358722049661445 train_error 26.38% test_error 21.50%\n",
      "================================7472===================================\n",
      "7472/10000: train_loss: 3.1354241507838014 train_error 26.25% test_error 21.50%\n",
      "================================7473===================================\n",
      "7473/10000: train_loss: 3.1349776260124056 train_error 26.25% test_error 21.50%\n",
      "================================7474===================================\n",
      "7474/10000: train_loss: 3.1345301602303515 train_error 26.38% test_error 21.50%\n",
      "================================7475===================================\n",
      "7475/10000: train_loss: 3.1340830143191853 train_error 26.38% test_error 21.50%\n",
      "================================7476===================================\n",
      "7476/10000: train_loss: 3.1336360861710277 train_error 26.12% test_error 21.50%\n",
      "================================7477===================================\n",
      "7477/10000: train_loss: 3.133188403337263 train_error 26.12% test_error 21.50%\n",
      "================================7478===================================\n",
      "7478/10000: train_loss: 3.132734555552015 train_error 26.12% test_error 21.50%\n",
      "================================7479===================================\n",
      "7479/10000: train_loss: 3.132275370680727 train_error 26.12% test_error 21.50%\n",
      "================================7480===================================\n",
      "7480/10000: train_loss: 3.1318137576582377 train_error 26.12% test_error 21.50%\n",
      "================================7481===================================\n",
      "7481/10000: train_loss: 3.1313536608230788 train_error 26.12% test_error 21.50%\n",
      "================================7482===================================\n",
      "7482/10000: train_loss: 3.1308918322680985 train_error 26.12% test_error 21.50%\n",
      "================================7483===================================\n",
      "7483/10000: train_loss: 3.1304297771875285 train_error 26.12% test_error 21.50%\n",
      "================================7484===================================\n",
      "7484/10000: train_loss: 3.129970021714689 train_error 26.12% test_error 21.50%\n",
      "================================7485===================================\n",
      "7485/10000: train_loss: 3.129512794459006 train_error 26.12% test_error 21.50%\n",
      "================================7486===================================\n",
      "7486/10000: train_loss: 3.1290535775339228 train_error 26.12% test_error 21.50%\n",
      "================================7487===================================\n",
      "7487/10000: train_loss: 3.1285946531721853 train_error 26.12% test_error 21.50%\n",
      "================================7488===================================\n",
      "7488/10000: train_loss: 3.1281261616200204 train_error 26.12% test_error 21.50%\n",
      "================================7489===================================\n",
      "7489/10000: train_loss: 3.1276539626833983 train_error 26.12% test_error 22.00%\n",
      "================================7490===================================\n",
      "7490/10000: train_loss: 3.1271742619702128 train_error 26.12% test_error 22.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7491===================================\n",
      "7491/10000: train_loss: 3.126689233650686 train_error 26.12% test_error 22.00%\n",
      "================================7492===================================\n",
      "7492/10000: train_loss: 3.126203587579075 train_error 26.12% test_error 22.00%\n",
      "================================7493===================================\n",
      "7493/10000: train_loss: 3.1257181532017424 train_error 26.12% test_error 22.00%\n",
      "================================7494===================================\n",
      "7494/10000: train_loss: 3.1252329352661032 train_error 26.12% test_error 22.00%\n",
      "================================7495===================================\n",
      "7495/10000: train_loss: 3.1247485316824166 train_error 26.12% test_error 22.00%\n",
      "================================7496===================================\n",
      "7496/10000: train_loss: 3.124261904412415 train_error 26.12% test_error 22.00%\n",
      "================================7497===================================\n",
      "7497/10000: train_loss: 3.1237758777837734 train_error 26.12% test_error 22.00%\n",
      "================================7498===================================\n",
      "7498/10000: train_loss: 3.123292676843703 train_error 26.12% test_error 22.00%\n",
      "================================7499===================================\n",
      "7499/10000: train_loss: 3.1228075546829497 train_error 26.12% test_error 22.00%\n",
      "================================7500===================================\n",
      "7500/10000: train_loss: 3.122326898726169 train_error 26.12% test_error 22.00%\n",
      "================================7501===================================\n",
      "7501/10000: train_loss: 3.1218478430283723 train_error 26.12% test_error 22.00%\n",
      "================================7502===================================\n",
      "7502/10000: train_loss: 3.1213687798881438 train_error 26.12% test_error 22.00%\n",
      "================================7503===================================\n",
      "7503/10000: train_loss: 3.1208885646017737 train_error 26.12% test_error 22.00%\n",
      "================================7504===================================\n",
      "7504/10000: train_loss: 3.120407983257901 train_error 26.12% test_error 22.00%\n",
      "================================7505===================================\n",
      "7505/10000: train_loss: 3.1199282011273315 train_error 26.12% test_error 22.00%\n",
      "================================7506===================================\n",
      "7506/10000: train_loss: 3.1194520531082524 train_error 26.12% test_error 22.00%\n",
      "================================7507===================================\n",
      "7507/10000: train_loss: 3.1189792254695203 train_error 26.12% test_error 22.00%\n",
      "================================7508===================================\n",
      "7508/10000: train_loss: 3.1185082436120135 train_error 26.12% test_error 22.00%\n",
      "================================7509===================================\n",
      "7509/10000: train_loss: 3.1180399462673813 train_error 26.12% test_error 22.00%\n",
      "================================7510===================================\n",
      "7510/10000: train_loss: 3.1175722041213887 train_error 26.12% test_error 21.50%\n",
      "================================7511===================================\n",
      "7511/10000: train_loss: 3.117103902306408 train_error 26.12% test_error 21.50%\n",
      "================================7512===================================\n",
      "7512/10000: train_loss: 3.1166357046854682 train_error 26.12% test_error 21.50%\n",
      "================================7513===================================\n",
      "7513/10000: train_loss: 3.116167411037022 train_error 26.12% test_error 21.50%\n",
      "================================7514===================================\n",
      "7514/10000: train_loss: 3.1156981093960345 train_error 26.12% test_error 21.50%\n",
      "================================7515===================================\n",
      "7515/10000: train_loss: 3.1152310944022608 train_error 26.12% test_error 21.50%\n",
      "================================7516===================================\n",
      "7516/10000: train_loss: 3.114763477540109 train_error 26.12% test_error 21.50%\n",
      "================================7517===================================\n",
      "7517/10000: train_loss: 3.114296156330965 train_error 26.12% test_error 21.50%\n",
      "================================7518===================================\n",
      "7518/10000: train_loss: 3.113830792587251 train_error 26.12% test_error 21.50%\n",
      "================================7519===================================\n",
      "7519/10000: train_loss: 3.113370584025979 train_error 26.12% test_error 21.00%\n",
      "================================7520===================================\n",
      "7520/10000: train_loss: 3.1129119474638722 train_error 26.12% test_error 21.00%\n",
      "================================7521===================================\n",
      "7521/10000: train_loss: 3.112453269442776 train_error 26.12% test_error 21.00%\n",
      "================================7522===================================\n",
      "7522/10000: train_loss: 3.111994119954761 train_error 26.12% test_error 21.00%\n",
      "================================7523===================================\n",
      "7523/10000: train_loss: 3.1115354590443896 train_error 26.12% test_error 21.00%\n",
      "================================7524===================================\n",
      "7524/10000: train_loss: 3.1110766716662326 train_error 26.12% test_error 21.00%\n",
      "================================7525===================================\n",
      "7525/10000: train_loss: 3.110617805775255 train_error 26.12% test_error 21.00%\n",
      "================================7526===================================\n",
      "7526/10000: train_loss: 3.110157354953699 train_error 26.12% test_error 21.00%\n",
      "================================7527===================================\n",
      "7527/10000: train_loss: 3.109697502992349 train_error 26.12% test_error 21.00%\n",
      "================================7528===================================\n",
      "7528/10000: train_loss: 3.1092379041982348 train_error 26.12% test_error 21.00%\n",
      "================================7529===================================\n",
      "7529/10000: train_loss: 3.1087782950850666 train_error 26.12% test_error 21.00%\n",
      "================================7530===================================\n",
      "7530/10000: train_loss: 3.1083182929141913 train_error 26.12% test_error 21.00%\n",
      "================================7531===================================\n",
      "7531/10000: train_loss: 3.10785834511742 train_error 26.12% test_error 21.00%\n",
      "================================7532===================================\n",
      "7532/10000: train_loss: 3.1073984529427254 train_error 26.12% test_error 21.00%\n",
      "================================7533===================================\n",
      "7533/10000: train_loss: 3.1069376113126053 train_error 26.12% test_error 21.00%\n",
      "================================7534===================================\n",
      "7534/10000: train_loss: 3.106479146319907 train_error 26.00% test_error 21.00%\n",
      "================================7535===================================\n",
      "7535/10000: train_loss: 3.106023351454642 train_error 26.00% test_error 21.00%\n",
      "================================7536===================================\n",
      "7536/10000: train_loss: 3.1055704016727397 train_error 26.00% test_error 21.00%\n",
      "================================7537===================================\n",
      "7537/10000: train_loss: 3.105116704979446 train_error 26.00% test_error 21.00%\n",
      "================================7538===================================\n",
      "7538/10000: train_loss: 3.1046629458502863 train_error 26.00% test_error 21.00%\n",
      "================================7539===================================\n",
      "7539/10000: train_loss: 3.1042131404217796 train_error 26.00% test_error 21.00%\n",
      "================================7540===================================\n",
      "7540/10000: train_loss: 3.103764814203605 train_error 26.12% test_error 21.00%\n",
      "================================7541===================================\n",
      "7541/10000: train_loss: 3.103321599663468 train_error 26.12% test_error 21.00%\n",
      "================================7542===================================\n",
      "7542/10000: train_loss: 3.1028776106308213 train_error 26.12% test_error 21.00%\n",
      "================================7543===================================\n",
      "7543/10000: train_loss: 3.102437152962666 train_error 26.12% test_error 21.00%\n",
      "================================7544===================================\n",
      "7544/10000: train_loss: 3.101996435809415 train_error 26.12% test_error 21.00%\n",
      "================================7545===================================\n",
      "7545/10000: train_loss: 3.101557071749121 train_error 26.12% test_error 21.00%\n",
      "================================7546===================================\n",
      "7546/10000: train_loss: 3.101117501241388 train_error 26.12% test_error 21.00%\n",
      "================================7547===================================\n",
      "7547/10000: train_loss: 3.100677082163747 train_error 26.12% test_error 21.00%\n",
      "================================7548===================================\n",
      "7548/10000: train_loss: 3.100237324817572 train_error 26.12% test_error 21.00%\n",
      "================================7549===================================\n",
      "7549/10000: train_loss: 3.099798303093994 train_error 26.12% test_error 21.00%\n",
      "================================7550===================================\n",
      "7550/10000: train_loss: 3.099361194827361 train_error 26.12% test_error 21.00%\n",
      "================================7551===================================\n",
      "7551/10000: train_loss: 3.098925657432992 train_error 26.12% test_error 21.00%\n",
      "================================7552===================================\n",
      "7552/10000: train_loss: 3.0984911394841035 train_error 26.12% test_error 21.00%\n",
      "================================7553===================================\n",
      "7553/10000: train_loss: 3.0980568598769604 train_error 26.12% test_error 21.00%\n",
      "================================7554===================================\n",
      "7554/10000: train_loss: 3.0976235451409595 train_error 26.12% test_error 21.00%\n",
      "================================7555===================================\n",
      "7555/10000: train_loss: 3.097191718665417 train_error 26.12% test_error 21.00%\n",
      "================================7556===================================\n",
      "7556/10000: train_loss: 3.0967605296114926 train_error 26.12% test_error 21.00%\n",
      "================================7557===================================\n",
      "7557/10000: train_loss: 3.0963291474804286 train_error 26.12% test_error 21.00%\n",
      "================================7558===================================\n",
      "7558/10000: train_loss: 3.0958974655240303 train_error 26.12% test_error 21.00%\n",
      "================================7559===================================\n",
      "7559/10000: train_loss: 3.0954667746735502 train_error 26.12% test_error 21.00%\n",
      "================================7560===================================\n",
      "7560/10000: train_loss: 3.0950372215593234 train_error 26.25% test_error 21.00%\n",
      "================================7561===================================\n",
      "7561/10000: train_loss: 3.0946073335385877 train_error 26.25% test_error 21.00%\n",
      "================================7562===================================\n",
      "7562/10000: train_loss: 3.0941777095000726 train_error 26.25% test_error 21.00%\n",
      "================================7563===================================\n",
      "7563/10000: train_loss: 3.0937473545153624 train_error 26.25% test_error 21.00%\n",
      "================================7564===================================\n",
      "7564/10000: train_loss: 3.09331722623785 train_error 26.25% test_error 21.00%\n",
      "================================7565===================================\n",
      "7565/10000: train_loss: 3.0928883585776203 train_error 26.25% test_error 21.00%\n",
      "================================7566===================================\n",
      "7566/10000: train_loss: 3.0924574230256257 train_error 26.25% test_error 21.00%\n",
      "================================7567===================================\n",
      "7567/10000: train_loss: 3.0920256579056153 train_error 26.25% test_error 21.00%\n",
      "================================7568===================================\n",
      "7568/10000: train_loss: 3.0915941323578586 train_error 26.25% test_error 21.00%\n",
      "================================7569===================================\n",
      "7569/10000: train_loss: 3.091162961428636 train_error 26.25% test_error 21.00%\n",
      "================================7570===================================\n",
      "7570/10000: train_loss: 3.0907334011170313 train_error 26.25% test_error 20.50%\n",
      "================================7571===================================\n",
      "7571/10000: train_loss: 3.0903031939762875 train_error 26.25% test_error 20.50%\n",
      "================================7572===================================\n",
      "7572/10000: train_loss: 3.089873135231319 train_error 26.25% test_error 20.50%\n",
      "================================7573===================================\n",
      "7573/10000: train_loss: 3.089442900005961 train_error 26.25% test_error 20.50%\n",
      "================================7574===================================\n",
      "7574/10000: train_loss: 3.0890117643336996 train_error 26.25% test_error 20.50%\n",
      "================================7575===================================\n",
      "7575/10000: train_loss: 3.088580045255367 train_error 26.25% test_error 20.50%\n",
      "================================7576===================================\n",
      "7576/10000: train_loss: 3.0881457680294986 train_error 26.25% test_error 20.50%\n",
      "================================7577===================================\n",
      "7577/10000: train_loss: 3.087711928073549 train_error 26.25% test_error 20.50%\n",
      "================================7578===================================\n",
      "7578/10000: train_loss: 3.0872842087119348 train_error 26.25% test_error 20.50%\n",
      "================================7579===================================\n",
      "7579/10000: train_loss: 3.0868560749344764 train_error 26.12% test_error 20.50%\n",
      "================================7580===================================\n",
      "7580/10000: train_loss: 3.086426872300799 train_error 26.12% test_error 20.50%\n",
      "================================7581===================================\n",
      "7581/10000: train_loss: 3.0859969028475462 train_error 26.12% test_error 20.50%\n",
      "================================7582===================================\n",
      "7582/10000: train_loss: 3.085567557006143 train_error 26.12% test_error 20.50%\n",
      "================================7583===================================\n",
      "7583/10000: train_loss: 3.0851392225321614 train_error 26.12% test_error 20.50%\n",
      "================================7584===================================\n",
      "7584/10000: train_loss: 3.0847139408072692 train_error 26.12% test_error 20.50%\n",
      "================================7585===================================\n",
      "7585/10000: train_loss: 3.0842893241811544 train_error 26.12% test_error 20.50%\n",
      "================================7586===================================\n",
      "7586/10000: train_loss: 3.083866017366527 train_error 26.25% test_error 20.50%\n",
      "================================7587===================================\n",
      "7587/10000: train_loss: 3.083443418043898 train_error 26.25% test_error 20.50%\n",
      "================================7588===================================\n",
      "7588/10000: train_loss: 3.083023688526591 train_error 26.25% test_error 20.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7589===================================\n",
      "7589/10000: train_loss: 3.0826031633617825 train_error 26.25% test_error 20.50%\n",
      "================================7590===================================\n",
      "7590/10000: train_loss: 3.0821844020561544 train_error 26.25% test_error 20.50%\n",
      "================================7591===================================\n",
      "7591/10000: train_loss: 3.081767694122391 train_error 26.25% test_error 20.50%\n",
      "================================7592===================================\n",
      "7592/10000: train_loss: 3.0813511414494137 train_error 26.12% test_error 20.50%\n",
      "================================7593===================================\n",
      "7593/10000: train_loss: 3.080934625342488 train_error 26.12% test_error 20.50%\n",
      "================================7594===================================\n",
      "7594/10000: train_loss: 3.0805189057125246 train_error 26.12% test_error 20.50%\n",
      "================================7595===================================\n",
      "7595/10000: train_loss: 3.0801057273847983 train_error 26.12% test_error 20.50%\n",
      "================================7596===================================\n",
      "7596/10000: train_loss: 3.079694732144708 train_error 26.12% test_error 20.50%\n",
      "================================7597===================================\n",
      "7597/10000: train_loss: 3.079286311860778 train_error 26.12% test_error 20.50%\n",
      "================================7598===================================\n",
      "7598/10000: train_loss: 3.0788822113600327 train_error 26.12% test_error 20.50%\n",
      "================================7599===================================\n",
      "7599/10000: train_loss: 3.078476576253306 train_error 26.12% test_error 20.50%\n",
      "================================7600===================================\n",
      "7600/10000: train_loss: 3.078069275636226 train_error 26.12% test_error 20.50%\n",
      "================================7601===================================\n",
      "7601/10000: train_loss: 3.0776625287515342 train_error 26.12% test_error 20.50%\n",
      "================================7602===================================\n",
      "7602/10000: train_loss: 3.0772599300130965 train_error 26.12% test_error 20.50%\n",
      "================================7603===================================\n",
      "7603/10000: train_loss: 3.0768595307512445 train_error 26.12% test_error 20.50%\n",
      "================================7604===================================\n",
      "7604/10000: train_loss: 3.0764606464188544 train_error 26.12% test_error 20.50%\n",
      "================================7605===================================\n",
      "7605/10000: train_loss: 3.076061570990132 train_error 26.12% test_error 20.50%\n",
      "================================7606===================================\n",
      "7606/10000: train_loss: 3.075662327474565 train_error 26.12% test_error 20.50%\n",
      "================================7607===================================\n",
      "7607/10000: train_loss: 3.075263490990037 train_error 26.12% test_error 20.50%\n",
      "================================7608===================================\n",
      "7608/10000: train_loss: 3.0748645769472933 train_error 26.12% test_error 20.50%\n",
      "================================7609===================================\n",
      "7609/10000: train_loss: 3.0744665194430856 train_error 26.00% test_error 20.50%\n",
      "================================7610===================================\n",
      "7610/10000: train_loss: 3.074068930749199 train_error 26.00% test_error 20.50%\n",
      "================================7611===================================\n",
      "7611/10000: train_loss: 3.0736712242942303 train_error 26.00% test_error 20.50%\n",
      "================================7612===================================\n",
      "7612/10000: train_loss: 3.07327471630706 train_error 26.12% test_error 20.50%\n",
      "================================7613===================================\n",
      "7613/10000: train_loss: 3.072878345424542 train_error 26.12% test_error 20.50%\n",
      "================================7614===================================\n",
      "7614/10000: train_loss: 3.0724801492434923 train_error 26.12% test_error 20.50%\n",
      "================================7615===================================\n",
      "7615/10000: train_loss: 3.0720851640915496 train_error 26.12% test_error 20.50%\n",
      "================================7616===================================\n",
      "7616/10000: train_loss: 3.071693251035176 train_error 26.12% test_error 20.50%\n",
      "================================7617===================================\n",
      "7617/10000: train_loss: 3.071302962479531 train_error 26.12% test_error 20.50%\n",
      "================================7618===================================\n",
      "7618/10000: train_loss: 3.070912929511396 train_error 26.12% test_error 20.50%\n",
      "================================7619===================================\n",
      "7619/10000: train_loss: 3.07052305670979 train_error 26.12% test_error 20.50%\n",
      "================================7620===================================\n",
      "7620/10000: train_loss: 3.0701369192212584 train_error 26.12% test_error 20.50%\n",
      "================================7621===================================\n",
      "7621/10000: train_loss: 3.0697515767649746 train_error 26.00% test_error 20.50%\n",
      "================================7622===================================\n",
      "7622/10000: train_loss: 3.069368198229349 train_error 26.00% test_error 20.50%\n",
      "================================7623===================================\n",
      "7623/10000: train_loss: 3.0689836353517603 train_error 26.00% test_error 20.50%\n",
      "================================7624===================================\n",
      "7624/10000: train_loss: 3.0685985474375777 train_error 26.00% test_error 20.50%\n",
      "================================7625===================================\n",
      "7625/10000: train_loss: 3.0682130124606193 train_error 26.00% test_error 20.50%\n",
      "================================7626===================================\n",
      "7626/10000: train_loss: 3.06782775445492 train_error 26.00% test_error 20.50%\n",
      "================================7627===================================\n",
      "7627/10000: train_loss: 3.0674427376792304 train_error 26.00% test_error 20.50%\n",
      "================================7628===================================\n",
      "7628/10000: train_loss: 3.0670596641348675 train_error 25.87% test_error 20.50%\n",
      "================================7629===================================\n",
      "7629/10000: train_loss: 3.0666784123785327 train_error 25.87% test_error 20.50%\n",
      "================================7630===================================\n",
      "7630/10000: train_loss: 3.06629751143395 train_error 25.87% test_error 20.50%\n",
      "================================7631===================================\n",
      "7631/10000: train_loss: 3.06591643595777 train_error 25.87% test_error 20.50%\n",
      "================================7632===================================\n",
      "7632/10000: train_loss: 3.0655334688303992 train_error 25.87% test_error 20.50%\n",
      "================================7633===================================\n",
      "7633/10000: train_loss: 3.065149493152276 train_error 25.87% test_error 20.50%\n",
      "================================7634===================================\n",
      "7634/10000: train_loss: 3.0647669677628437 train_error 25.87% test_error 20.50%\n",
      "================================7635===================================\n",
      "7635/10000: train_loss: 3.06438887743745 train_error 25.87% test_error 20.50%\n",
      "================================7636===================================\n",
      "7636/10000: train_loss: 3.0640080637228677 train_error 25.87% test_error 20.50%\n",
      "================================7637===================================\n",
      "7637/10000: train_loss: 3.063625337811536 train_error 25.87% test_error 20.50%\n",
      "================================7638===================================\n",
      "7638/10000: train_loss: 3.0632422639918513 train_error 25.87% test_error 20.50%\n",
      "================================7639===================================\n",
      "7639/10000: train_loss: 3.062859643864795 train_error 25.87% test_error 20.50%\n",
      "================================7640===================================\n",
      "7640/10000: train_loss: 3.062480413588346 train_error 25.87% test_error 20.50%\n",
      "================================7641===================================\n",
      "7641/10000: train_loss: 3.0621020761417457 train_error 25.87% test_error 20.50%\n",
      "================================7642===================================\n",
      "7642/10000: train_loss: 3.0617252844752514 train_error 25.87% test_error 20.50%\n",
      "================================7643===================================\n",
      "7643/10000: train_loss: 3.061348629365093 train_error 25.87% test_error 20.50%\n",
      "================================7644===================================\n",
      "7644/10000: train_loss: 3.0609676371654495 train_error 25.87% test_error 20.50%\n",
      "================================7645===================================\n",
      "7645/10000: train_loss: 3.060583548241993 train_error 25.87% test_error 20.50%\n",
      "================================7646===================================\n",
      "7646/10000: train_loss: 3.060199775237124 train_error 25.87% test_error 20.50%\n",
      "================================7647===================================\n",
      "7647/10000: train_loss: 3.0598163469653805 train_error 26.00% test_error 20.50%\n",
      "================================7648===================================\n",
      "7648/10000: train_loss: 3.0594338960718597 train_error 26.00% test_error 20.50%\n",
      "================================7649===================================\n",
      "7649/10000: train_loss: 3.059052407415584 train_error 26.00% test_error 20.50%\n",
      "================================7650===================================\n",
      "7650/10000: train_loss: 3.0586685948987724 train_error 26.00% test_error 20.50%\n",
      "================================7651===================================\n",
      "7651/10000: train_loss: 3.058284088316723 train_error 26.00% test_error 20.50%\n",
      "================================7652===================================\n",
      "7652/10000: train_loss: 3.0578992939158347 train_error 26.00% test_error 20.50%\n",
      "================================7653===================================\n",
      "7653/10000: train_loss: 3.057514074264909 train_error 26.00% test_error 20.50%\n",
      "================================7654===================================\n",
      "7654/10000: train_loss: 3.0571286430652256 train_error 26.00% test_error 20.50%\n",
      "================================7655===================================\n",
      "7655/10000: train_loss: 3.05674702979275 train_error 26.00% test_error 20.50%\n",
      "================================7656===================================\n",
      "7656/10000: train_loss: 3.056365782545763 train_error 26.00% test_error 20.50%\n",
      "================================7657===================================\n",
      "7657/10000: train_loss: 3.055984466072405 train_error 26.00% test_error 20.50%\n",
      "================================7658===================================\n",
      "7658/10000: train_loss: 3.055601916455198 train_error 26.00% test_error 20.50%\n",
      "================================7659===================================\n",
      "7659/10000: train_loss: 3.0552191733237124 train_error 26.00% test_error 20.50%\n",
      "================================7660===================================\n",
      "7660/10000: train_loss: 3.054838804330211 train_error 26.00% test_error 20.50%\n",
      "================================7661===================================\n",
      "7661/10000: train_loss: 3.054463893752545 train_error 26.00% test_error 20.50%\n",
      "================================7662===================================\n",
      "7662/10000: train_loss: 3.0540896129072643 train_error 26.00% test_error 20.50%\n",
      "================================7663===================================\n",
      "7663/10000: train_loss: 3.0537137287465157 train_error 26.00% test_error 20.50%\n",
      "================================7664===================================\n",
      "7664/10000: train_loss: 3.0533345019747506 train_error 26.00% test_error 20.50%\n",
      "================================7665===================================\n",
      "7665/10000: train_loss: 3.0529566159163366 train_error 26.00% test_error 20.50%\n",
      "================================7666===================================\n",
      "7666/10000: train_loss: 3.0525789553846696 train_error 26.00% test_error 20.50%\n",
      "================================7667===================================\n",
      "7667/10000: train_loss: 3.0522023354278645 train_error 26.00% test_error 20.50%\n",
      "================================7668===================================\n",
      "7668/10000: train_loss: 3.0518265892146155 train_error 26.00% test_error 20.50%\n",
      "================================7669===================================\n",
      "7669/10000: train_loss: 3.0514513728482417 train_error 26.00% test_error 20.50%\n",
      "================================7670===================================\n",
      "7670/10000: train_loss: 3.0510772407043256 train_error 26.00% test_error 20.50%\n",
      "================================7671===================================\n",
      "7671/10000: train_loss: 3.0507022391387726 train_error 26.00% test_error 20.50%\n",
      "================================7672===================================\n",
      "7672/10000: train_loss: 3.050326714653638 train_error 26.00% test_error 20.50%\n",
      "================================7673===================================\n",
      "7673/10000: train_loss: 3.049951611132128 train_error 26.00% test_error 20.50%\n",
      "================================7674===================================\n",
      "7674/10000: train_loss: 3.049578244655277 train_error 25.87% test_error 20.50%\n",
      "================================7675===================================\n",
      "7675/10000: train_loss: 3.0492060765938365 train_error 25.87% test_error 20.50%\n",
      "================================7676===================================\n",
      "7676/10000: train_loss: 3.0488342467922487 train_error 25.87% test_error 20.50%\n",
      "================================7677===================================\n",
      "7677/10000: train_loss: 3.0484635569626697 train_error 25.87% test_error 20.50%\n",
      "================================7678===================================\n",
      "7678/10000: train_loss: 3.048093585054157 train_error 25.87% test_error 20.50%\n",
      "================================7679===================================\n",
      "7679/10000: train_loss: 3.0477232758380706 train_error 25.87% test_error 20.50%\n",
      "================================7680===================================\n",
      "7680/10000: train_loss: 3.047352831850294 train_error 25.87% test_error 20.50%\n",
      "================================7681===================================\n",
      "7681/10000: train_loss: 3.0469805109710433 train_error 25.87% test_error 20.50%\n",
      "================================7682===================================\n",
      "7682/10000: train_loss: 3.0466083348047683 train_error 25.87% test_error 20.50%\n",
      "================================7683===================================\n",
      "7683/10000: train_loss: 3.0462366676772943 train_error 25.87% test_error 20.50%\n",
      "================================7684===================================\n",
      "7684/10000: train_loss: 3.045866022168775 train_error 25.87% test_error 20.50%\n",
      "================================7685===================================\n",
      "7685/10000: train_loss: 3.0454962671094106 train_error 25.75% test_error 20.50%\n",
      "================================7686===================================\n",
      "7686/10000: train_loss: 3.045129104694934 train_error 25.75% test_error 20.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7687===================================\n",
      "7687/10000: train_loss: 3.044763583270251 train_error 25.75% test_error 20.50%\n",
      "================================7688===================================\n",
      "7688/10000: train_loss: 3.0444033878936896 train_error 25.62% test_error 20.50%\n",
      "================================7689===================================\n",
      "7689/10000: train_loss: 3.0440453258604974 train_error 25.62% test_error 20.50%\n",
      "================================7690===================================\n",
      "7690/10000: train_loss: 3.0436879103892713 train_error 25.62% test_error 20.50%\n",
      "================================7691===================================\n",
      "7691/10000: train_loss: 3.0433303233800686 train_error 25.62% test_error 20.50%\n",
      "================================7692===================================\n",
      "7692/10000: train_loss: 3.0429731017677115 train_error 25.62% test_error 20.50%\n",
      "================================7693===================================\n",
      "7693/10000: train_loss: 3.0426164830231572 train_error 25.62% test_error 20.50%\n",
      "================================7694===================================\n",
      "7694/10000: train_loss: 3.0422603379981594 train_error 25.62% test_error 20.50%\n",
      "================================7695===================================\n",
      "7695/10000: train_loss: 3.041901674428373 train_error 25.62% test_error 20.50%\n",
      "================================7696===================================\n",
      "7696/10000: train_loss: 3.041542943081586 train_error 25.50% test_error 20.50%\n",
      "================================7697===================================\n",
      "7697/10000: train_loss: 3.041185459541739 train_error 25.50% test_error 20.50%\n",
      "================================7698===================================\n",
      "7698/10000: train_loss: 3.0408324214577442 train_error 25.50% test_error 20.50%\n",
      "================================7699===================================\n",
      "7699/10000: train_loss: 3.040479932654416 train_error 25.50% test_error 20.50%\n",
      "================================7700===================================\n",
      "7700/10000: train_loss: 3.04012798014388 train_error 25.50% test_error 20.50%\n",
      "================================7701===================================\n",
      "7701/10000: train_loss: 3.0397760563885092 train_error 25.62% test_error 20.50%\n",
      "================================7702===================================\n",
      "7702/10000: train_loss: 3.0394246594031573 train_error 25.62% test_error 20.50%\n",
      "================================7703===================================\n",
      "7703/10000: train_loss: 3.0390739760751604 train_error 25.62% test_error 20.50%\n",
      "================================7704===================================\n",
      "7704/10000: train_loss: 3.038723933446454 train_error 25.62% test_error 20.50%\n",
      "================================7705===================================\n",
      "7705/10000: train_loss: 3.0383742584194993 train_error 25.62% test_error 20.50%\n",
      "================================7706===================================\n",
      "7706/10000: train_loss: 3.0380247369012796 train_error 25.75% test_error 20.50%\n",
      "================================7707===================================\n",
      "7707/10000: train_loss: 3.0376758721010995 train_error 25.62% test_error 20.50%\n",
      "================================7708===================================\n",
      "7708/10000: train_loss: 3.037327236524434 train_error 25.62% test_error 20.50%\n",
      "================================7709===================================\n",
      "7709/10000: train_loss: 3.0369803460541878 train_error 25.62% test_error 20.50%\n",
      "================================7710===================================\n",
      "7710/10000: train_loss: 3.036634796610451 train_error 25.62% test_error 20.50%\n",
      "================================7711===================================\n",
      "7711/10000: train_loss: 3.036290411208174 train_error 25.75% test_error 21.00%\n",
      "================================7712===================================\n",
      "7712/10000: train_loss: 3.0359470696095374 train_error 25.75% test_error 21.00%\n",
      "================================7713===================================\n",
      "7713/10000: train_loss: 3.035605932468898 train_error 25.75% test_error 21.00%\n",
      "================================7714===================================\n",
      "7714/10000: train_loss: 3.035264677585801 train_error 25.75% test_error 21.00%\n",
      "================================7715===================================\n",
      "7715/10000: train_loss: 3.034923613325809 train_error 25.75% test_error 21.00%\n",
      "================================7716===================================\n",
      "7716/10000: train_loss: 3.034583155782893 train_error 25.75% test_error 21.00%\n",
      "================================7717===================================\n",
      "7717/10000: train_loss: 3.034241764669423 train_error 25.75% test_error 21.00%\n",
      "================================7718===================================\n",
      "7718/10000: train_loss: 3.033899244284257 train_error 25.75% test_error 21.00%\n",
      "================================7719===================================\n",
      "7719/10000: train_loss: 3.0335549824370536 train_error 25.75% test_error 21.00%\n",
      "================================7720===================================\n",
      "7720/10000: train_loss: 3.0332084457983726 train_error 25.75% test_error 21.00%\n",
      "================================7721===================================\n",
      "7721/10000: train_loss: 3.0328602175810375 train_error 25.75% test_error 21.00%\n",
      "================================7722===================================\n",
      "7722/10000: train_loss: 3.032511831998127 train_error 25.75% test_error 21.00%\n",
      "================================7723===================================\n",
      "7723/10000: train_loss: 3.0321635011484616 train_error 25.75% test_error 21.00%\n",
      "================================7724===================================\n",
      "7724/10000: train_loss: 3.0318119920027677 train_error 25.75% test_error 21.00%\n",
      "================================7725===================================\n",
      "7725/10000: train_loss: 3.0314612192922503 train_error 25.75% test_error 21.00%\n",
      "================================7726===================================\n",
      "7726/10000: train_loss: 3.0311101751326355 train_error 25.75% test_error 21.00%\n",
      "================================7727===================================\n",
      "7727/10000: train_loss: 3.0307593334111154 train_error 25.75% test_error 21.00%\n",
      "================================7728===================================\n",
      "7728/10000: train_loss: 3.030411752669606 train_error 25.75% test_error 21.00%\n",
      "================================7729===================================\n",
      "7729/10000: train_loss: 3.030066480527166 train_error 25.62% test_error 21.00%\n",
      "================================7730===================================\n",
      "7730/10000: train_loss: 3.0297212417185078 train_error 25.62% test_error 21.00%\n",
      "================================7731===================================\n",
      "7731/10000: train_loss: 3.0293752438924275 train_error 25.62% test_error 21.00%\n",
      "================================7732===================================\n",
      "7732/10000: train_loss: 3.029028412326006 train_error 25.62% test_error 21.00%\n",
      "================================7733===================================\n",
      "7733/10000: train_loss: 3.0286845253943464 train_error 25.62% test_error 20.50%\n",
      "================================7734===================================\n",
      "7734/10000: train_loss: 3.028345472093206 train_error 25.62% test_error 20.00%\n",
      "================================7735===================================\n",
      "7735/10000: train_loss: 3.028007710237871 train_error 25.62% test_error 20.00%\n",
      "================================7736===================================\n",
      "7736/10000: train_loss: 3.027669730568305 train_error 25.62% test_error 20.00%\n",
      "================================7737===================================\n",
      "7737/10000: train_loss: 3.027332044236828 train_error 25.62% test_error 20.00%\n",
      "================================7738===================================\n",
      "7738/10000: train_loss: 3.0269954274152404 train_error 25.62% test_error 20.00%\n",
      "================================7739===================================\n",
      "7739/10000: train_loss: 3.0266602645721283 train_error 25.75% test_error 20.00%\n",
      "================================7740===================================\n",
      "7740/10000: train_loss: 3.026325175711536 train_error 25.75% test_error 20.00%\n",
      "================================7741===================================\n",
      "7741/10000: train_loss: 3.025986527932109 train_error 25.75% test_error 20.00%\n",
      "================================7742===================================\n",
      "7742/10000: train_loss: 3.02564626379055 train_error 25.75% test_error 20.00%\n",
      "================================7743===================================\n",
      "7743/10000: train_loss: 3.025309961697785 train_error 25.75% test_error 20.00%\n",
      "================================7744===================================\n",
      "7744/10000: train_loss: 3.0249690817733064 train_error 25.75% test_error 20.00%\n",
      "================================7745===================================\n",
      "7745/10000: train_loss: 3.0246177244733556 train_error 25.75% test_error 20.00%\n",
      "================================7746===================================\n",
      "7746/10000: train_loss: 3.024267517818953 train_error 25.75% test_error 20.00%\n",
      "================================7747===================================\n",
      "7747/10000: train_loss: 3.0239155127410777 train_error 25.75% test_error 20.00%\n",
      "================================7748===================================\n",
      "7748/10000: train_loss: 3.023565839444636 train_error 25.75% test_error 20.00%\n",
      "================================7749===================================\n",
      "7749/10000: train_loss: 3.023216335721663 train_error 25.75% test_error 20.00%\n",
      "================================7750===================================\n",
      "7750/10000: train_loss: 3.0228665056743194 train_error 25.75% test_error 20.00%\n",
      "================================7751===================================\n",
      "7751/10000: train_loss: 3.022515569089446 train_error 25.75% test_error 20.00%\n",
      "================================7752===================================\n",
      "7752/10000: train_loss: 3.0221646412755945 train_error 25.87% test_error 20.00%\n",
      "================================7753===================================\n",
      "7753/10000: train_loss: 3.0218170957508845 train_error 25.87% test_error 20.00%\n",
      "================================7754===================================\n",
      "7754/10000: train_loss: 3.0214714999659917 train_error 25.87% test_error 20.00%\n",
      "================================7755===================================\n",
      "7755/10000: train_loss: 3.0211256948724623 train_error 25.87% test_error 20.00%\n",
      "================================7756===================================\n",
      "7756/10000: train_loss: 3.020784636875324 train_error 25.87% test_error 20.00%\n",
      "================================7757===================================\n",
      "7757/10000: train_loss: 3.0204456674034006 train_error 25.87% test_error 20.00%\n",
      "================================7758===================================\n",
      "7758/10000: train_loss: 3.0201057182514344 train_error 25.87% test_error 20.00%\n",
      "================================7759===================================\n",
      "7759/10000: train_loss: 3.01976792971429 train_error 25.87% test_error 20.00%\n",
      "================================7760===================================\n",
      "7760/10000: train_loss: 3.0194293480191847 train_error 25.87% test_error 20.00%\n",
      "================================7761===================================\n",
      "7761/10000: train_loss: 3.0190866015240316 train_error 25.87% test_error 20.00%\n",
      "================================7762===================================\n",
      "7762/10000: train_loss: 3.0187430551581196 train_error 25.87% test_error 20.00%\n",
      "================================7763===================================\n",
      "7763/10000: train_loss: 3.018400094223034 train_error 25.87% test_error 20.00%\n",
      "================================7764===================================\n",
      "7764/10000: train_loss: 3.018054610290856 train_error 25.87% test_error 20.00%\n",
      "================================7765===================================\n",
      "7765/10000: train_loss: 3.017712934564333 train_error 25.87% test_error 20.00%\n",
      "================================7766===================================\n",
      "7766/10000: train_loss: 3.0173711018427274 train_error 25.87% test_error 20.00%\n",
      "================================7767===================================\n",
      "7767/10000: train_loss: 3.017030185479671 train_error 25.62% test_error 20.00%\n",
      "================================7768===================================\n",
      "7768/10000: train_loss: 3.016689009622496 train_error 25.62% test_error 20.00%\n",
      "================================7769===================================\n",
      "7769/10000: train_loss: 3.016348074042471 train_error 25.62% test_error 20.00%\n",
      "================================7770===================================\n",
      "7770/10000: train_loss: 3.016007576993434 train_error 25.62% test_error 20.00%\n",
      "================================7771===================================\n",
      "7771/10000: train_loss: 3.01566742727533 train_error 25.62% test_error 20.00%\n",
      "================================7772===================================\n",
      "7772/10000: train_loss: 3.0153269614087184 train_error 25.62% test_error 20.00%\n",
      "================================7773===================================\n",
      "7773/10000: train_loss: 3.0149869706598107 train_error 25.62% test_error 20.00%\n",
      "================================7774===================================\n",
      "7774/10000: train_loss: 3.014646064615226 train_error 25.75% test_error 20.00%\n",
      "================================7775===================================\n",
      "7775/10000: train_loss: 3.0143035926457373 train_error 25.75% test_error 20.00%\n",
      "================================7776===================================\n",
      "7776/10000: train_loss: 3.0139564536354735 train_error 25.75% test_error 20.00%\n",
      "================================7777===================================\n",
      "7777/10000: train_loss: 3.0136079074256124 train_error 25.75% test_error 20.00%\n",
      "================================7778===================================\n",
      "7778/10000: train_loss: 3.0132588736654724 train_error 25.75% test_error 20.00%\n",
      "================================7779===================================\n",
      "7779/10000: train_loss: 3.012913661286584 train_error 25.75% test_error 20.00%\n",
      "================================7780===================================\n",
      "7780/10000: train_loss: 3.012570205383527 train_error 25.75% test_error 20.00%\n",
      "================================7781===================================\n",
      "7781/10000: train_loss: 3.0122287418632183 train_error 25.75% test_error 20.00%\n",
      "================================7782===================================\n",
      "7782/10000: train_loss: 3.011890762686089 train_error 25.75% test_error 20.00%\n",
      "================================7783===================================\n",
      "7783/10000: train_loss: 3.0115499877528054 train_error 25.75% test_error 20.00%\n",
      "================================7784===================================\n",
      "7784/10000: train_loss: 3.0112098539335417 train_error 25.75% test_error 20.00%\n",
      "================================7785===================================\n",
      "7785/10000: train_loss: 3.010872065819858 train_error 25.75% test_error 20.00%\n",
      "================================7786===================================\n",
      "7786/10000: train_loss: 3.0105255457718156 train_error 25.75% test_error 20.00%\n",
      "================================7787===================================\n",
      "7787/10000: train_loss: 3.010176926995045 train_error 25.75% test_error 20.00%\n",
      "================================7788===================================\n",
      "7788/10000: train_loss: 3.0098282644702703 train_error 25.75% test_error 20.00%\n",
      "================================7789===================================\n",
      "7789/10000: train_loss: 3.0094797385341368 train_error 25.75% test_error 20.00%\n",
      "================================7790===================================\n",
      "7790/10000: train_loss: 3.009135857492219 train_error 25.75% test_error 20.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7791===================================\n",
      "7791/10000: train_loss: 3.008791690522921 train_error 25.62% test_error 20.00%\n",
      "================================7792===================================\n",
      "7792/10000: train_loss: 3.0084478786092954 train_error 25.62% test_error 20.00%\n",
      "================================7793===================================\n",
      "7793/10000: train_loss: 3.008103528515785 train_error 25.62% test_error 20.00%\n",
      "================================7794===================================\n",
      "7794/10000: train_loss: 3.0077596119986265 train_error 25.62% test_error 20.00%\n",
      "================================7795===================================\n",
      "7795/10000: train_loss: 3.007416714518622 train_error 25.62% test_error 20.00%\n",
      "================================7796===================================\n",
      "7796/10000: train_loss: 3.007072598557861 train_error 25.62% test_error 20.00%\n",
      "================================7797===================================\n",
      "7797/10000: train_loss: 3.0067307968856767 train_error 25.62% test_error 20.00%\n",
      "================================7798===================================\n",
      "7798/10000: train_loss: 3.006395277543634 train_error 25.62% test_error 20.00%\n",
      "================================7799===================================\n",
      "7799/10000: train_loss: 3.006063174714218 train_error 25.62% test_error 20.00%\n",
      "================================7800===================================\n",
      "7800/10000: train_loss: 3.005732179854531 train_error 25.62% test_error 20.00%\n",
      "================================7801===================================\n",
      "7801/10000: train_loss: 3.00540212898457 train_error 25.62% test_error 20.00%\n",
      "================================7802===================================\n",
      "7802/10000: train_loss: 3.0050729099771707 train_error 25.50% test_error 20.00%\n",
      "================================7803===================================\n",
      "7803/10000: train_loss: 3.004745378124062 train_error 25.50% test_error 20.00%\n",
      "================================7804===================================\n",
      "7804/10000: train_loss: 3.0044155337524714 train_error 25.50% test_error 20.00%\n",
      "================================7805===================================\n",
      "7805/10000: train_loss: 3.0040877850659307 train_error 25.50% test_error 20.00%\n",
      "================================7806===================================\n",
      "7806/10000: train_loss: 3.0037587243059534 train_error 25.50% test_error 20.00%\n",
      "================================7807===================================\n",
      "7807/10000: train_loss: 3.003431385983713 train_error 25.50% test_error 20.00%\n",
      "================================7808===================================\n",
      "7808/10000: train_loss: 3.0031046305567726 train_error 25.50% test_error 20.00%\n",
      "================================7809===================================\n",
      "7809/10000: train_loss: 3.002779404477333 train_error 25.50% test_error 20.00%\n",
      "================================7810===================================\n",
      "7810/10000: train_loss: 3.002453016226063 train_error 25.50% test_error 20.00%\n",
      "================================7811===================================\n",
      "7811/10000: train_loss: 3.002124516844633 train_error 25.50% test_error 20.00%\n",
      "================================7812===================================\n",
      "7812/10000: train_loss: 3.0017964458742057 train_error 25.50% test_error 20.00%\n",
      "================================7813===================================\n",
      "7813/10000: train_loss: 3.0014691103275983 train_error 25.50% test_error 20.00%\n",
      "================================7814===================================\n",
      "7814/10000: train_loss: 3.001144322875771 train_error 25.50% test_error 20.50%\n",
      "================================7815===================================\n",
      "7815/10000: train_loss: 3.0008187881222694 train_error 25.37% test_error 20.50%\n",
      "================================7816===================================\n",
      "7816/10000: train_loss: 3.000493075652921 train_error 25.37% test_error 20.50%\n",
      "================================7817===================================\n",
      "7817/10000: train_loss: 3.0001677422312785 train_error 25.37% test_error 20.50%\n",
      "================================7818===================================\n",
      "7818/10000: train_loss: 2.9998438834879195 train_error 25.37% test_error 20.50%\n",
      "================================7819===================================\n",
      "7819/10000: train_loss: 2.999517044530367 train_error 25.37% test_error 20.50%\n",
      "================================7820===================================\n",
      "7820/10000: train_loss: 2.999183106194541 train_error 25.37% test_error 20.50%\n",
      "================================7821===================================\n",
      "7821/10000: train_loss: 2.998846142520197 train_error 25.37% test_error 20.50%\n",
      "================================7822===================================\n",
      "7822/10000: train_loss: 2.998508929280506 train_error 25.37% test_error 20.50%\n",
      "================================7823===================================\n",
      "7823/10000: train_loss: 2.998171890027006 train_error 25.37% test_error 20.50%\n",
      "================================7824===================================\n",
      "7824/10000: train_loss: 2.9978320899739628 train_error 25.37% test_error 20.50%\n",
      "================================7825===================================\n",
      "7825/10000: train_loss: 2.9974884900214964 train_error 25.37% test_error 20.50%\n",
      "================================7826===================================\n",
      "7826/10000: train_loss: 2.9971507498636494 train_error 25.37% test_error 20.50%\n",
      "================================7827===================================\n",
      "7827/10000: train_loss: 2.996811198958021 train_error 25.37% test_error 20.50%\n",
      "================================7828===================================\n",
      "7828/10000: train_loss: 2.996470889448829 train_error 25.37% test_error 20.50%\n",
      "================================7829===================================\n",
      "7829/10000: train_loss: 2.9961310698342274 train_error 25.37% test_error 20.50%\n",
      "================================7830===================================\n",
      "7830/10000: train_loss: 2.995793041353754 train_error 25.37% test_error 20.50%\n",
      "================================7831===================================\n",
      "7831/10000: train_loss: 2.995454580017249 train_error 25.37% test_error 20.50%\n",
      "================================7832===================================\n",
      "7832/10000: train_loss: 2.995114330693032 train_error 25.37% test_error 20.50%\n",
      "================================7833===================================\n",
      "7833/10000: train_loss: 2.994775737693417 train_error 25.37% test_error 20.50%\n",
      "================================7834===================================\n",
      "7834/10000: train_loss: 2.99443952163856 train_error 25.37% test_error 20.50%\n",
      "================================7835===================================\n",
      "7835/10000: train_loss: 2.99410305338155 train_error 25.37% test_error 20.50%\n",
      "================================7836===================================\n",
      "7836/10000: train_loss: 2.993766888136161 train_error 25.37% test_error 20.50%\n",
      "================================7837===================================\n",
      "7837/10000: train_loss: 2.9934316496879907 train_error 25.37% test_error 20.50%\n",
      "================================7838===================================\n",
      "7838/10000: train_loss: 2.9930962688021827 train_error 25.37% test_error 20.50%\n",
      "================================7839===================================\n",
      "7839/10000: train_loss: 2.9927582392416663 train_error 25.25% test_error 20.50%\n",
      "================================7840===================================\n",
      "7840/10000: train_loss: 2.9924179342936257 train_error 25.25% test_error 20.50%\n",
      "================================7841===================================\n",
      "7841/10000: train_loss: 2.992078664457367 train_error 25.25% test_error 20.50%\n",
      "================================7842===================================\n",
      "7842/10000: train_loss: 2.9917412763350875 train_error 25.25% test_error 20.50%\n",
      "================================7843===================================\n",
      "7843/10000: train_loss: 2.9914071909981432 train_error 25.25% test_error 20.50%\n",
      "================================7844===================================\n",
      "7844/10000: train_loss: 2.9910737011412856 train_error 25.25% test_error 20.50%\n",
      "================================7845===================================\n",
      "7845/10000: train_loss: 2.9907346674471045 train_error 25.25% test_error 20.50%\n",
      "================================7846===================================\n",
      "7846/10000: train_loss: 2.9903948234333075 train_error 25.25% test_error 20.50%\n",
      "================================7847===================================\n",
      "7847/10000: train_loss: 2.9900559485098346 train_error 25.25% test_error 20.50%\n",
      "================================7848===================================\n",
      "7848/10000: train_loss: 2.989719328780193 train_error 25.25% test_error 20.50%\n",
      "================================7849===================================\n",
      "7849/10000: train_loss: 2.9893758790410354 train_error 25.25% test_error 20.50%\n",
      "================================7850===================================\n",
      "7850/10000: train_loss: 2.9890379526183826 train_error 25.25% test_error 20.50%\n",
      "================================7851===================================\n",
      "7851/10000: train_loss: 2.988706609064247 train_error 25.12% test_error 20.50%\n",
      "================================7852===================================\n",
      "7852/10000: train_loss: 2.9883763533306773 train_error 25.12% test_error 20.50%\n",
      "================================7853===================================\n",
      "7853/10000: train_loss: 2.9880448472464924 train_error 25.12% test_error 20.50%\n",
      "================================7854===================================\n",
      "7854/10000: train_loss: 2.9877113683708014 train_error 25.12% test_error 20.50%\n",
      "================================7855===================================\n",
      "7855/10000: train_loss: 2.9873808634575107 train_error 25.12% test_error 20.00%\n",
      "================================7856===================================\n",
      "7856/10000: train_loss: 2.9870567996331374 train_error 25.12% test_error 20.00%\n",
      "================================7857===================================\n",
      "7857/10000: train_loss: 2.9867249382787846 train_error 25.12% test_error 19.50%\n",
      "================================7858===================================\n",
      "7858/10000: train_loss: 2.986382331994828 train_error 25.12% test_error 19.50%\n",
      "================================7859===================================\n",
      "7859/10000: train_loss: 2.9860402268683535 train_error 25.12% test_error 19.50%\n",
      "================================7860===================================\n",
      "7860/10000: train_loss: 2.9857037589035462 train_error 25.12% test_error 19.50%\n",
      "================================7861===================================\n",
      "7861/10000: train_loss: 2.985371955394803 train_error 25.12% test_error 19.50%\n",
      "================================7862===================================\n",
      "7862/10000: train_loss: 2.985038475537731 train_error 25.12% test_error 19.50%\n",
      "================================7863===================================\n",
      "7863/10000: train_loss: 2.9847026027989343 train_error 25.12% test_error 19.50%\n",
      "================================7864===================================\n",
      "7864/10000: train_loss: 2.9843669717881127 train_error 25.25% test_error 19.50%\n",
      "================================7865===================================\n",
      "7865/10000: train_loss: 2.9840312213613656 train_error 25.25% test_error 19.50%\n",
      "================================7866===================================\n",
      "7866/10000: train_loss: 2.983696191987547 train_error 25.25% test_error 19.50%\n",
      "================================7867===================================\n",
      "7867/10000: train_loss: 2.9833617616121777 train_error 25.25% test_error 19.50%\n",
      "================================7868===================================\n",
      "7868/10000: train_loss: 2.9830284366881825 train_error 25.25% test_error 19.50%\n",
      "================================7869===================================\n",
      "7869/10000: train_loss: 2.982694436998572 train_error 25.25% test_error 19.50%\n",
      "================================7870===================================\n",
      "7870/10000: train_loss: 2.9823562995804243 train_error 25.25% test_error 19.50%\n",
      "================================7871===================================\n",
      "7871/10000: train_loss: 2.982017084211402 train_error 25.25% test_error 19.50%\n",
      "================================7872===================================\n",
      "7872/10000: train_loss: 2.9816805932525314 train_error 25.25% test_error 19.50%\n",
      "================================7873===================================\n",
      "7873/10000: train_loss: 2.9813451780946343 train_error 25.25% test_error 19.50%\n",
      "================================7874===================================\n",
      "7874/10000: train_loss: 2.98101178425306 train_error 25.25% test_error 19.50%\n",
      "================================7875===================================\n",
      "7875/10000: train_loss: 2.9806805128828273 train_error 25.25% test_error 19.50%\n",
      "================================7876===================================\n",
      "7876/10000: train_loss: 2.980356773826352 train_error 25.25% test_error 19.50%\n",
      "================================7877===================================\n",
      "7877/10000: train_loss: 2.980036677381431 train_error 25.25% test_error 19.50%\n",
      "================================7878===================================\n",
      "7878/10000: train_loss: 2.979716204791621 train_error 25.25% test_error 19.50%\n",
      "================================7879===================================\n",
      "7879/10000: train_loss: 2.9793955685922993 train_error 25.25% test_error 19.50%\n",
      "================================7880===================================\n",
      "7880/10000: train_loss: 2.97907531620207 train_error 25.12% test_error 19.50%\n",
      "================================7881===================================\n",
      "7881/10000: train_loss: 2.978757987265126 train_error 25.12% test_error 19.50%\n",
      "================================7882===================================\n",
      "7882/10000: train_loss: 2.9784442573360863 train_error 25.12% test_error 19.50%\n",
      "================================7883===================================\n",
      "7883/10000: train_loss: 2.978127217251167 train_error 25.12% test_error 19.50%\n",
      "================================7884===================================\n",
      "7884/10000: train_loss: 2.9778161584449117 train_error 25.12% test_error 19.50%\n",
      "================================7885===================================\n",
      "7885/10000: train_loss: 2.9775065321227885 train_error 25.12% test_error 19.50%\n",
      "================================7886===================================\n",
      "7886/10000: train_loss: 2.977197915335419 train_error 25.12% test_error 19.50%\n",
      "================================7887===================================\n",
      "7887/10000: train_loss: 2.9768901890530834 train_error 25.12% test_error 19.50%\n",
      "================================7888===================================\n",
      "7888/10000: train_loss: 2.9765827135127623 train_error 25.12% test_error 19.50%\n",
      "================================7889===================================\n",
      "7889/10000: train_loss: 2.9762755541605292 train_error 25.12% test_error 19.50%\n",
      "================================7890===================================\n",
      "7890/10000: train_loss: 2.9759670980938244 train_error 25.12% test_error 19.50%\n",
      "================================7891===================================\n",
      "7891/10000: train_loss: 2.9756569876568393 train_error 25.12% test_error 19.50%\n",
      "================================7892===================================\n",
      "7892/10000: train_loss: 2.9753444738590042 train_error 25.12% test_error 19.50%\n",
      "================================7893===================================\n",
      "7893/10000: train_loss: 2.975031209634617 train_error 25.12% test_error 19.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7894===================================\n",
      "7894/10000: train_loss: 2.9747179725967 train_error 25.12% test_error 19.50%\n",
      "================================7895===================================\n",
      "7895/10000: train_loss: 2.9744098871410825 train_error 25.12% test_error 19.00%\n",
      "================================7896===================================\n",
      "7896/10000: train_loss: 2.9741034663442405 train_error 25.12% test_error 19.00%\n",
      "================================7897===================================\n",
      "7897/10000: train_loss: 2.973796889593068 train_error 25.12% test_error 19.00%\n",
      "================================7898===================================\n",
      "7898/10000: train_loss: 2.9734892239631154 train_error 25.12% test_error 19.00%\n",
      "================================7899===================================\n",
      "7899/10000: train_loss: 2.9731798896274992 train_error 25.12% test_error 19.00%\n",
      "================================7900===================================\n",
      "7900/10000: train_loss: 2.97287162020104 train_error 25.12% test_error 19.00%\n",
      "================================7901===================================\n",
      "7901/10000: train_loss: 2.972560340775817 train_error 25.12% test_error 19.00%\n",
      "================================7902===================================\n",
      "7902/10000: train_loss: 2.9722475798675445 train_error 25.12% test_error 19.00%\n",
      "================================7903===================================\n",
      "7903/10000: train_loss: 2.9719332931641835 train_error 25.12% test_error 19.00%\n",
      "================================7904===================================\n",
      "7904/10000: train_loss: 2.971617634970171 train_error 25.12% test_error 19.00%\n",
      "================================7905===================================\n",
      "7905/10000: train_loss: 2.971300947380951 train_error 25.12% test_error 19.00%\n",
      "================================7906===================================\n",
      "7906/10000: train_loss: 2.9709838121099166 train_error 25.12% test_error 19.00%\n",
      "================================7907===================================\n",
      "7907/10000: train_loss: 2.9706668916167107 train_error 25.12% test_error 19.00%\n",
      "================================7908===================================\n",
      "7908/10000: train_loss: 2.970350732021034 train_error 25.12% test_error 19.00%\n",
      "================================7909===================================\n",
      "7909/10000: train_loss: 2.9700349149820977 train_error 25.12% test_error 19.00%\n",
      "================================7910===================================\n",
      "7910/10000: train_loss: 2.969718810315535 train_error 25.12% test_error 19.00%\n",
      "================================7911===================================\n",
      "7911/10000: train_loss: 2.969404906537093 train_error 25.12% test_error 19.00%\n",
      "================================7912===================================\n",
      "7912/10000: train_loss: 2.969091178609524 train_error 25.12% test_error 19.00%\n",
      "================================7913===================================\n",
      "7913/10000: train_loss: 2.968778270531039 train_error 25.12% test_error 19.00%\n",
      "================================7914===================================\n",
      "7914/10000: train_loss: 2.968461967889452 train_error 25.25% test_error 19.00%\n",
      "================================7915===================================\n",
      "7915/10000: train_loss: 2.9681422183991524 train_error 25.25% test_error 19.00%\n",
      "================================7916===================================\n",
      "7916/10000: train_loss: 2.967824148711224 train_error 25.25% test_error 19.00%\n",
      "================================7917===================================\n",
      "7917/10000: train_loss: 2.9675075327951346 train_error 25.25% test_error 18.50%\n",
      "================================7918===================================\n",
      "7918/10000: train_loss: 2.9671909471752587 train_error 25.25% test_error 18.50%\n",
      "================================7919===================================\n",
      "7919/10000: train_loss: 2.966875563695794 train_error 25.25% test_error 18.50%\n",
      "================================7920===================================\n",
      "7920/10000: train_loss: 2.966560401263414 train_error 25.25% test_error 18.00%\n",
      "================================7921===================================\n",
      "7921/10000: train_loss: 2.9662448476441208 train_error 25.25% test_error 18.00%\n",
      "================================7922===================================\n",
      "7922/10000: train_loss: 2.9659239313509898 train_error 25.25% test_error 18.00%\n",
      "================================7923===================================\n",
      "7923/10000: train_loss: 2.9656029573845446 train_error 25.25% test_error 18.00%\n",
      "================================7924===================================\n",
      "7924/10000: train_loss: 2.9652841681713467 train_error 25.25% test_error 18.00%\n",
      "================================7925===================================\n",
      "7925/10000: train_loss: 2.964965400560759 train_error 25.25% test_error 18.00%\n",
      "================================7926===================================\n",
      "7926/10000: train_loss: 2.96464673128241 train_error 25.25% test_error 18.00%\n",
      "================================7927===================================\n",
      "7927/10000: train_loss: 2.9643312308116583 train_error 25.25% test_error 18.00%\n",
      "================================7928===================================\n",
      "7928/10000: train_loss: 2.964017871939577 train_error 25.25% test_error 18.00%\n",
      "================================7929===================================\n",
      "7929/10000: train_loss: 2.9637041540580684 train_error 25.25% test_error 18.00%\n",
      "================================7930===================================\n",
      "7930/10000: train_loss: 2.9633910318824928 train_error 25.25% test_error 18.00%\n",
      "================================7931===================================\n",
      "7931/10000: train_loss: 2.9630749010566797 train_error 25.25% test_error 18.00%\n",
      "================================7932===================================\n",
      "7932/10000: train_loss: 2.962763408553292 train_error 25.25% test_error 18.00%\n",
      "================================7933===================================\n",
      "7933/10000: train_loss: 2.9624548065985437 train_error 25.25% test_error 18.00%\n",
      "================================7934===================================\n",
      "7934/10000: train_loss: 2.9621460830031716 train_error 25.25% test_error 18.00%\n",
      "================================7935===================================\n",
      "7935/10000: train_loss: 2.9618373855622484 train_error 25.25% test_error 18.00%\n",
      "================================7936===================================\n",
      "7936/10000: train_loss: 2.961528371844907 train_error 25.25% test_error 18.00%\n",
      "================================7937===================================\n",
      "7937/10000: train_loss: 2.9612193962307356 train_error 25.25% test_error 18.00%\n",
      "================================7938===================================\n",
      "7938/10000: train_loss: 2.9609101558443216 train_error 25.25% test_error 18.00%\n",
      "================================7939===================================\n",
      "7939/10000: train_loss: 2.9606015416793525 train_error 25.25% test_error 18.00%\n",
      "================================7940===================================\n",
      "7940/10000: train_loss: 2.960293082137068 train_error 25.12% test_error 18.00%\n",
      "================================7941===================================\n",
      "7941/10000: train_loss: 2.9599817314630488 train_error 25.12% test_error 18.00%\n",
      "================================7942===================================\n",
      "7942/10000: train_loss: 2.9596668141899865 train_error 25.12% test_error 18.00%\n",
      "================================7943===================================\n",
      "7943/10000: train_loss: 2.9593504757678604 train_error 25.12% test_error 18.00%\n",
      "================================7944===================================\n",
      "7944/10000: train_loss: 2.959028799099033 train_error 25.12% test_error 18.00%\n",
      "================================7945===================================\n",
      "7945/10000: train_loss: 2.9587071392820508 train_error 25.12% test_error 18.00%\n",
      "================================7946===================================\n",
      "7946/10000: train_loss: 2.9583862796842006 train_error 25.12% test_error 18.00%\n",
      "================================7947===================================\n",
      "7947/10000: train_loss: 2.9580670008491143 train_error 25.12% test_error 18.00%\n",
      "================================7948===================================\n",
      "7948/10000: train_loss: 2.957744771909202 train_error 25.12% test_error 18.00%\n",
      "================================7949===================================\n",
      "7949/10000: train_loss: 2.957419819674542 train_error 25.00% test_error 18.00%\n",
      "================================7950===================================\n",
      "7950/10000: train_loss: 2.9570972895402523 train_error 25.00% test_error 18.00%\n",
      "================================7951===================================\n",
      "7951/10000: train_loss: 2.9567774312665276 train_error 25.00% test_error 18.00%\n",
      "================================7952===================================\n",
      "7952/10000: train_loss: 2.9564607328853163 train_error 25.00% test_error 18.00%\n",
      "================================7953===================================\n",
      "7953/10000: train_loss: 2.956144705521001 train_error 25.00% test_error 18.00%\n",
      "================================7954===================================\n",
      "7954/10000: train_loss: 2.9558298998416284 train_error 25.00% test_error 18.00%\n",
      "================================7955===================================\n",
      "7955/10000: train_loss: 2.955516098475491 train_error 25.00% test_error 18.00%\n",
      "================================7956===================================\n",
      "7956/10000: train_loss: 2.9552023909114356 train_error 25.00% test_error 18.00%\n",
      "================================7957===================================\n",
      "7957/10000: train_loss: 2.954887807415507 train_error 25.00% test_error 18.00%\n",
      "================================7958===================================\n",
      "7958/10000: train_loss: 2.9545745612608156 train_error 25.00% test_error 18.00%\n",
      "================================7959===================================\n",
      "7959/10000: train_loss: 2.9542626072726854 train_error 25.00% test_error 18.00%\n",
      "================================7960===================================\n",
      "7960/10000: train_loss: 2.9539539304873323 train_error 25.00% test_error 18.00%\n",
      "================================7961===================================\n",
      "7961/10000: train_loss: 2.953644359777682 train_error 25.00% test_error 18.00%\n",
      "================================7962===================================\n",
      "7962/10000: train_loss: 2.953327728071308 train_error 25.00% test_error 18.00%\n",
      "================================7963===================================\n",
      "7963/10000: train_loss: 2.953012286669982 train_error 25.00% test_error 18.00%\n",
      "================================7964===================================\n",
      "7964/10000: train_loss: 2.9527022516065333 train_error 25.00% test_error 18.00%\n",
      "================================7965===================================\n",
      "7965/10000: train_loss: 2.952394164566649 train_error 25.00% test_error 18.00%\n",
      "================================7966===================================\n",
      "7966/10000: train_loss: 2.9520863605398335 train_error 25.00% test_error 18.00%\n",
      "================================7967===================================\n",
      "7967/10000: train_loss: 2.9517792382620973 train_error 25.00% test_error 18.00%\n",
      "================================7968===================================\n",
      "7968/10000: train_loss: 2.9514740071518464 train_error 25.00% test_error 18.00%\n",
      "================================7969===================================\n",
      "7969/10000: train_loss: 2.9511706210927513 train_error 25.00% test_error 18.00%\n",
      "================================7970===================================\n",
      "7970/10000: train_loss: 2.9508679464511807 train_error 25.00% test_error 18.00%\n",
      "================================7971===================================\n",
      "7971/10000: train_loss: 2.9505641504710365 train_error 25.00% test_error 18.00%\n",
      "================================7972===================================\n",
      "7972/10000: train_loss: 2.950260083793691 train_error 25.00% test_error 18.00%\n",
      "================================7973===================================\n",
      "7973/10000: train_loss: 2.9499564752141305 train_error 25.00% test_error 18.00%\n",
      "================================7974===================================\n",
      "7974/10000: train_loss: 2.949655705977784 train_error 25.00% test_error 18.00%\n",
      "================================7975===================================\n",
      "7975/10000: train_loss: 2.949354369595385 train_error 25.00% test_error 18.00%\n",
      "================================7976===================================\n",
      "7976/10000: train_loss: 2.949052072772611 train_error 25.00% test_error 18.00%\n",
      "================================7977===================================\n",
      "7977/10000: train_loss: 2.948749982649606 train_error 25.00% test_error 18.00%\n",
      "================================7978===================================\n",
      "7978/10000: train_loss: 2.948448203263106 train_error 25.00% test_error 18.00%\n",
      "================================7979===================================\n",
      "7979/10000: train_loss: 2.9481480164526146 train_error 25.00% test_error 18.00%\n",
      "================================7980===================================\n",
      "7980/10000: train_loss: 2.947850042042846 train_error 25.00% test_error 18.00%\n",
      "================================7981===================================\n",
      "7981/10000: train_loss: 2.9475529156859555 train_error 25.00% test_error 18.00%\n",
      "================================7982===================================\n",
      "7982/10000: train_loss: 2.947255828021589 train_error 25.00% test_error 18.00%\n",
      "================================7983===================================\n",
      "7983/10000: train_loss: 2.946959122515691 train_error 25.00% test_error 18.00%\n",
      "================================7984===================================\n",
      "7984/10000: train_loss: 2.946662859667558 train_error 25.00% test_error 18.00%\n",
      "================================7985===================================\n",
      "7985/10000: train_loss: 2.9463664518979202 train_error 25.00% test_error 18.00%\n",
      "================================7986===================================\n",
      "7986/10000: train_loss: 2.946070299876446 train_error 25.00% test_error 18.00%\n",
      "================================7987===================================\n",
      "7987/10000: train_loss: 2.945774121775612 train_error 25.00% test_error 18.00%\n",
      "================================7988===================================\n",
      "7988/10000: train_loss: 2.945475702001131 train_error 25.00% test_error 18.00%\n",
      "================================7989===================================\n",
      "7989/10000: train_loss: 2.945175657612708 train_error 25.00% test_error 18.00%\n",
      "================================7990===================================\n",
      "7990/10000: train_loss: 2.944870737366291 train_error 25.00% test_error 18.00%\n",
      "================================7991===================================\n",
      "7991/10000: train_loss: 2.9445665040293534 train_error 25.00% test_error 18.00%\n",
      "================================7992===================================\n",
      "7992/10000: train_loss: 2.9442654951738954 train_error 25.00% test_error 18.00%\n",
      "================================7993===================================\n",
      "7993/10000: train_loss: 2.943964399659599 train_error 25.00% test_error 18.00%\n",
      "================================7994===================================\n",
      "7994/10000: train_loss: 2.943663906996808 train_error 25.00% test_error 18.00%\n",
      "================================7995===================================\n",
      "7995/10000: train_loss: 2.943363333339657 train_error 25.00% test_error 18.00%\n",
      "================================7996===================================\n",
      "7996/10000: train_loss: 2.94306164100999 train_error 25.00% test_error 18.00%\n",
      "================================7997===================================\n",
      "7997/10000: train_loss: 2.9427596963495306 train_error 25.00% test_error 18.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================7998===================================\n",
      "7998/10000: train_loss: 2.942455988139991 train_error 25.00% test_error 18.00%\n",
      "================================7999===================================\n",
      "7999/10000: train_loss: 2.94215341502073 train_error 25.00% test_error 18.00%\n",
      "================================8000===================================\n",
      "8000/10000: train_loss: 2.94185489595955 train_error 25.00% test_error 18.00%\n",
      "================================8001===================================\n",
      "8001/10000: train_loss: 2.9415556725602072 train_error 25.00% test_error 18.00%\n",
      "================================8002===================================\n",
      "8002/10000: train_loss: 2.941257282295119 train_error 25.00% test_error 18.00%\n",
      "================================8003===================================\n",
      "8003/10000: train_loss: 2.940954432854196 train_error 25.00% test_error 18.00%\n",
      "================================8004===================================\n",
      "8004/10000: train_loss: 2.9406497302060597 train_error 25.00% test_error 18.00%\n",
      "================================8005===================================\n",
      "8005/10000: train_loss: 2.9403476320726623 train_error 25.00% test_error 18.00%\n",
      "================================8006===================================\n",
      "8006/10000: train_loss: 2.9400396738426933 train_error 25.00% test_error 18.00%\n",
      "================================8007===================================\n",
      "8007/10000: train_loss: 2.9397330471593888 train_error 25.00% test_error 18.00%\n",
      "================================8008===================================\n",
      "8008/10000: train_loss: 2.939425767294888 train_error 25.00% test_error 18.00%\n",
      "================================8009===================================\n",
      "8009/10000: train_loss: 2.939116396318423 train_error 25.00% test_error 18.00%\n",
      "================================8010===================================\n",
      "8010/10000: train_loss: 2.93880662675132 train_error 25.00% test_error 18.00%\n",
      "================================8011===================================\n",
      "8011/10000: train_loss: 2.938496045892243 train_error 25.00% test_error 18.00%\n",
      "================================8012===================================\n",
      "8012/10000: train_loss: 2.938181941826915 train_error 25.00% test_error 18.00%\n",
      "================================8013===================================\n",
      "8013/10000: train_loss: 2.937867954949761 train_error 25.00% test_error 18.00%\n",
      "================================8014===================================\n",
      "8014/10000: train_loss: 2.937557258075103 train_error 25.00% test_error 18.00%\n",
      "================================8015===================================\n",
      "8015/10000: train_loss: 2.9372467563158717 train_error 25.00% test_error 18.00%\n",
      "================================8016===================================\n",
      "8016/10000: train_loss: 2.93693738729562 train_error 25.00% test_error 18.00%\n",
      "================================8017===================================\n",
      "8017/10000: train_loss: 2.936633896377461 train_error 25.00% test_error 18.00%\n",
      "================================8018===================================\n",
      "8018/10000: train_loss: 2.9363359459783536 train_error 25.00% test_error 18.00%\n",
      "================================8019===================================\n",
      "8019/10000: train_loss: 2.9360388983109442 train_error 25.00% test_error 18.00%\n",
      "================================8020===================================\n",
      "8020/10000: train_loss: 2.935742877667508 train_error 25.00% test_error 18.00%\n",
      "================================8021===================================\n",
      "8021/10000: train_loss: 2.9354523584825802 train_error 25.00% test_error 18.00%\n",
      "================================8022===================================\n",
      "8022/10000: train_loss: 2.935170319044264 train_error 25.00% test_error 18.00%\n",
      "================================8023===================================\n",
      "8023/10000: train_loss: 2.9348890599998416 train_error 25.00% test_error 18.00%\n",
      "================================8024===================================\n",
      "8024/10000: train_loss: 2.934607776673511 train_error 25.00% test_error 18.00%\n",
      "================================8025===================================\n",
      "8025/10000: train_loss: 2.9343262899707767 train_error 25.00% test_error 18.00%\n",
      "================================8026===================================\n",
      "8026/10000: train_loss: 2.934045124469558 train_error 25.00% test_error 18.00%\n",
      "================================8027===================================\n",
      "8027/10000: train_loss: 2.9337693123427746 train_error 25.00% test_error 18.00%\n",
      "================================8028===================================\n",
      "8028/10000: train_loss: 2.933485741972545 train_error 25.00% test_error 18.00%\n",
      "================================8029===================================\n",
      "8029/10000: train_loss: 2.9332003595199785 train_error 25.00% test_error 18.00%\n",
      "================================8030===================================\n",
      "8030/10000: train_loss: 2.9329153077951924 train_error 25.00% test_error 18.00%\n",
      "================================8031===================================\n",
      "8031/10000: train_loss: 2.932629958897596 train_error 25.00% test_error 18.00%\n",
      "================================8032===================================\n",
      "8032/10000: train_loss: 2.9323443653741563 train_error 25.00% test_error 18.00%\n",
      "================================8033===================================\n",
      "8033/10000: train_loss: 2.9320586942011144 train_error 25.00% test_error 18.00%\n",
      "================================8034===================================\n",
      "8034/10000: train_loss: 2.9317722926773424 train_error 25.00% test_error 18.00%\n",
      "================================8035===================================\n",
      "8035/10000: train_loss: 2.931487385442888 train_error 25.00% test_error 18.00%\n",
      "================================8036===================================\n",
      "8036/10000: train_loss: 2.9312023737528943 train_error 25.00% test_error 18.00%\n",
      "================================8037===================================\n",
      "8037/10000: train_loss: 2.9309170686746078 train_error 25.00% test_error 18.00%\n",
      "================================8038===================================\n",
      "8038/10000: train_loss: 2.930636001532112 train_error 25.00% test_error 18.00%\n",
      "================================8039===================================\n",
      "8039/10000: train_loss: 2.9303577682896864 train_error 25.00% test_error 18.00%\n",
      "================================8040===================================\n",
      "8040/10000: train_loss: 2.9300827249609576 train_error 25.00% test_error 18.00%\n",
      "================================8041===================================\n",
      "8041/10000: train_loss: 2.9298083304293687 train_error 25.00% test_error 18.00%\n",
      "================================8042===================================\n",
      "8042/10000: train_loss: 2.929535774366086 train_error 25.00% test_error 18.00%\n",
      "================================8043===================================\n",
      "8043/10000: train_loss: 2.929263630360365 train_error 25.12% test_error 18.00%\n",
      "================================8044===================================\n",
      "8044/10000: train_loss: 2.9289907768688863 train_error 25.12% test_error 18.00%\n",
      "================================8045===================================\n",
      "8045/10000: train_loss: 2.928718547045719 train_error 25.12% test_error 18.00%\n",
      "================================8046===================================\n",
      "8046/10000: train_loss: 2.928446670602716 train_error 25.12% test_error 18.00%\n",
      "================================8047===================================\n",
      "8047/10000: train_loss: 2.9281773755766336 train_error 25.12% test_error 18.00%\n",
      "================================8048===================================\n",
      "8048/10000: train_loss: 2.92790840924863 train_error 25.12% test_error 18.00%\n",
      "================================8049===================================\n",
      "8049/10000: train_loss: 2.9276427988751674 train_error 25.12% test_error 18.00%\n",
      "================================8050===================================\n",
      "8050/10000: train_loss: 2.9273766754113604 train_error 25.12% test_error 18.00%\n",
      "================================8051===================================\n",
      "8051/10000: train_loss: 2.9271053206347277 train_error 25.12% test_error 18.00%\n",
      "================================8052===================================\n",
      "8052/10000: train_loss: 2.926830514994217 train_error 25.12% test_error 18.00%\n",
      "================================8053===================================\n",
      "8053/10000: train_loss: 2.9265536933606198 train_error 25.12% test_error 18.00%\n",
      "================================8054===================================\n",
      "8054/10000: train_loss: 2.926273196647962 train_error 25.12% test_error 18.00%\n",
      "================================8055===================================\n",
      "8055/10000: train_loss: 2.925991788334504 train_error 25.12% test_error 18.00%\n",
      "================================8056===================================\n",
      "8056/10000: train_loss: 2.925711483717023 train_error 25.12% test_error 18.00%\n",
      "================================8057===================================\n",
      "8057/10000: train_loss: 2.925431357242924 train_error 25.12% test_error 18.00%\n",
      "================================8058===================================\n",
      "8058/10000: train_loss: 2.9251501328180893 train_error 25.12% test_error 18.00%\n",
      "================================8059===================================\n",
      "8059/10000: train_loss: 2.9248703475260114 train_error 25.12% test_error 18.00%\n",
      "================================8060===================================\n",
      "8060/10000: train_loss: 2.924592376175278 train_error 25.12% test_error 18.00%\n",
      "================================8061===================================\n",
      "8061/10000: train_loss: 2.924312557616067 train_error 25.12% test_error 18.00%\n",
      "================================8062===================================\n",
      "8062/10000: train_loss: 2.9240271576373194 train_error 25.00% test_error 18.00%\n",
      "================================8063===================================\n",
      "8063/10000: train_loss: 2.923740179418383 train_error 25.00% test_error 18.00%\n",
      "================================8064===================================\n",
      "8064/10000: train_loss: 2.923452495541569 train_error 25.00% test_error 18.00%\n",
      "================================8065===================================\n",
      "8065/10000: train_loss: 2.9231647382539814 train_error 25.00% test_error 18.00%\n",
      "================================8066===================================\n",
      "8066/10000: train_loss: 2.9228762775500945 train_error 25.00% test_error 18.00%\n",
      "================================8067===================================\n",
      "8067/10000: train_loss: 2.922586234355985 train_error 25.00% test_error 18.00%\n",
      "================================8068===================================\n",
      "8068/10000: train_loss: 2.9222975252746255 train_error 25.00% test_error 18.00%\n",
      "================================8069===================================\n",
      "8069/10000: train_loss: 2.9220100013866612 train_error 24.88% test_error 18.00%\n",
      "================================8070===================================\n",
      "8070/10000: train_loss: 2.921722758724791 train_error 24.88% test_error 18.00%\n",
      "================================8071===================================\n",
      "8071/10000: train_loss: 2.9214348615276684 train_error 24.88% test_error 18.00%\n",
      "================================8072===================================\n",
      "8072/10000: train_loss: 2.9211455025782924 train_error 24.88% test_error 18.00%\n",
      "================================8073===================================\n",
      "8073/10000: train_loss: 2.920855915793072 train_error 24.88% test_error 18.00%\n",
      "================================8074===================================\n",
      "8074/10000: train_loss: 2.920567749756883 train_error 24.88% test_error 18.00%\n",
      "================================8075===================================\n",
      "8075/10000: train_loss: 2.9202823591785276 train_error 24.88% test_error 18.00%\n",
      "================================8076===================================\n",
      "8076/10000: train_loss: 2.9199974457484497 train_error 24.88% test_error 18.00%\n",
      "================================8077===================================\n",
      "8077/10000: train_loss: 2.9197175908804636 train_error 24.88% test_error 18.00%\n",
      "================================8078===================================\n",
      "8078/10000: train_loss: 2.9194429097666577 train_error 24.88% test_error 18.00%\n",
      "================================8079===================================\n",
      "8079/10000: train_loss: 2.9191701235005167 train_error 24.88% test_error 18.00%\n",
      "================================8080===================================\n",
      "8080/10000: train_loss: 2.918900235984766 train_error 24.88% test_error 18.00%\n",
      "================================8081===================================\n",
      "8081/10000: train_loss: 2.918630284987885 train_error 24.88% test_error 18.00%\n",
      "================================8082===================================\n",
      "8082/10000: train_loss: 2.918355015896668 train_error 24.88% test_error 18.00%\n",
      "================================8083===================================\n",
      "8083/10000: train_loss: 2.91807849751378 train_error 24.88% test_error 18.00%\n",
      "================================8084===================================\n",
      "8084/10000: train_loss: 2.917800739110098 train_error 24.88% test_error 18.00%\n",
      "================================8085===================================\n",
      "8085/10000: train_loss: 2.9175249439162143 train_error 24.88% test_error 18.00%\n",
      "================================8086===================================\n",
      "8086/10000: train_loss: 2.917251627811929 train_error 24.88% test_error 18.00%\n",
      "================================8087===================================\n",
      "8087/10000: train_loss: 2.9169790509855376 train_error 24.88% test_error 18.00%\n",
      "================================8088===================================\n",
      "8088/10000: train_loss: 2.9167098558173166 train_error 24.88% test_error 18.00%\n",
      "================================8089===================================\n",
      "8089/10000: train_loss: 2.9164420049468753 train_error 24.88% test_error 18.00%\n",
      "================================8090===================================\n",
      "8090/10000: train_loss: 2.9161752180675102 train_error 24.88% test_error 18.00%\n",
      "================================8091===================================\n",
      "8091/10000: train_loss: 2.915909130024375 train_error 24.88% test_error 18.00%\n",
      "================================8092===================================\n",
      "8092/10000: train_loss: 2.9156482228744425 train_error 24.88% test_error 18.00%\n",
      "================================8093===================================\n",
      "8093/10000: train_loss: 2.9153878551926757 train_error 24.88% test_error 18.00%\n",
      "================================8094===================================\n",
      "8094/10000: train_loss: 2.9151246190362143 train_error 24.88% test_error 18.00%\n",
      "================================8095===================================\n",
      "8095/10000: train_loss: 2.9148594810535724 train_error 24.88% test_error 18.00%\n",
      "================================8096===================================\n",
      "8096/10000: train_loss: 2.9145959098210734 train_error 24.88% test_error 18.00%\n",
      "================================8097===================================\n",
      "8097/10000: train_loss: 2.9143318756447116 train_error 24.88% test_error 18.00%\n",
      "================================8098===================================\n",
      "8098/10000: train_loss: 2.914067914488405 train_error 24.88% test_error 18.00%\n",
      "================================8099===================================\n",
      "8099/10000: train_loss: 2.9138003253166973 train_error 24.88% test_error 18.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8100===================================\n",
      "8100/10000: train_loss: 2.9135303868574556 train_error 24.88% test_error 18.00%\n",
      "================================8101===================================\n",
      "8101/10000: train_loss: 2.9132630668976343 train_error 24.88% test_error 18.00%\n",
      "================================8102===================================\n",
      "8102/10000: train_loss: 2.912998228321812 train_error 24.88% test_error 18.00%\n",
      "================================8103===================================\n",
      "8103/10000: train_loss: 2.9127344987889225 train_error 24.88% test_error 18.00%\n",
      "================================8104===================================\n",
      "8104/10000: train_loss: 2.912471739217872 train_error 24.88% test_error 18.00%\n",
      "================================8105===================================\n",
      "8105/10000: train_loss: 2.912209324651703 train_error 24.88% test_error 18.00%\n",
      "================================8106===================================\n",
      "8106/10000: train_loss: 2.9119475785303806 train_error 24.88% test_error 18.00%\n",
      "================================8107===================================\n",
      "8107/10000: train_loss: 2.9116848633166956 train_error 24.88% test_error 18.00%\n",
      "================================8108===================================\n",
      "8108/10000: train_loss: 2.9114223490425504 train_error 24.88% test_error 18.00%\n",
      "================================8109===================================\n",
      "8109/10000: train_loss: 2.911158531219844 train_error 24.88% test_error 18.00%\n",
      "================================8110===================================\n",
      "8110/10000: train_loss: 2.9108947362988693 train_error 24.88% test_error 18.00%\n",
      "================================8111===================================\n",
      "8111/10000: train_loss: 2.910630607975181 train_error 24.88% test_error 18.00%\n",
      "================================8112===================================\n",
      "8112/10000: train_loss: 2.9103631641110406 train_error 24.88% test_error 18.00%\n",
      "================================8113===================================\n",
      "8113/10000: train_loss: 2.910091170258602 train_error 24.88% test_error 18.00%\n",
      "================================8114===================================\n",
      "8114/10000: train_loss: 2.9098210783358804 train_error 24.88% test_error 18.00%\n",
      "================================8115===================================\n",
      "8115/10000: train_loss: 2.909554163008579 train_error 24.88% test_error 18.00%\n",
      "================================8116===================================\n",
      "8116/10000: train_loss: 2.90928931073533 train_error 24.88% test_error 18.00%\n",
      "================================8117===================================\n",
      "8117/10000: train_loss: 2.9090265320021715 train_error 24.88% test_error 18.00%\n",
      "================================8118===================================\n",
      "8118/10000: train_loss: 2.9087647169893174 train_error 24.88% test_error 18.00%\n",
      "================================8119===================================\n",
      "8119/10000: train_loss: 2.9085021729746954 train_error 24.88% test_error 18.00%\n",
      "================================8120===================================\n",
      "8120/10000: train_loss: 2.9082374670812716 train_error 24.88% test_error 18.00%\n",
      "================================8121===================================\n",
      "8121/10000: train_loss: 2.9079709832304794 train_error 24.88% test_error 18.00%\n",
      "================================8122===================================\n",
      "8122/10000: train_loss: 2.9077020728084606 train_error 24.88% test_error 18.00%\n",
      "================================8123===================================\n",
      "8123/10000: train_loss: 2.907434673794487 train_error 24.88% test_error 18.00%\n",
      "================================8124===================================\n",
      "8124/10000: train_loss: 2.9071691826689494 train_error 24.88% test_error 18.00%\n",
      "================================8125===================================\n",
      "8125/10000: train_loss: 2.9069081220237423 train_error 24.88% test_error 18.00%\n",
      "================================8126===================================\n",
      "8126/10000: train_loss: 2.9066470169927197 train_error 24.88% test_error 18.00%\n",
      "================================8127===================================\n",
      "8127/10000: train_loss: 2.906385479098535 train_error 24.88% test_error 18.00%\n",
      "================================8128===================================\n",
      "8128/10000: train_loss: 2.906123053451156 train_error 24.88% test_error 18.00%\n",
      "================================8129===================================\n",
      "8129/10000: train_loss: 2.905861169911586 train_error 24.88% test_error 18.00%\n",
      "================================8130===================================\n",
      "8130/10000: train_loss: 2.9056002797328255 train_error 24.88% test_error 18.00%\n",
      "================================8131===================================\n",
      "8131/10000: train_loss: 2.9053382739728115 train_error 24.88% test_error 18.00%\n",
      "================================8132===================================\n",
      "8132/10000: train_loss: 2.9050772067364594 train_error 24.88% test_error 18.00%\n",
      "================================8133===================================\n",
      "8133/10000: train_loss: 2.904817923820592 train_error 24.88% test_error 18.00%\n",
      "================================8134===================================\n",
      "8134/10000: train_loss: 2.9045571465061952 train_error 24.88% test_error 18.00%\n",
      "================================8135===================================\n",
      "8135/10000: train_loss: 2.9043030495420683 train_error 24.88% test_error 18.00%\n",
      "================================8136===================================\n",
      "8136/10000: train_loss: 2.9040485544518746 train_error 24.88% test_error 18.00%\n",
      "================================8137===================================\n",
      "8137/10000: train_loss: 2.9037936881651696 train_error 24.88% test_error 18.00%\n",
      "================================8138===================================\n",
      "8138/10000: train_loss: 2.903538647590831 train_error 24.88% test_error 18.00%\n",
      "================================8139===================================\n",
      "8139/10000: train_loss: 2.903283384969036 train_error 24.88% test_error 18.00%\n",
      "================================8140===================================\n",
      "8140/10000: train_loss: 2.9030274312130495 train_error 24.88% test_error 18.00%\n",
      "================================8141===================================\n",
      "8141/10000: train_loss: 2.902772668923135 train_error 24.88% test_error 18.00%\n",
      "================================8142===================================\n",
      "8142/10000: train_loss: 2.902520094536885 train_error 24.88% test_error 18.00%\n",
      "================================8143===================================\n",
      "8143/10000: train_loss: 2.90226590384038 train_error 24.88% test_error 18.00%\n",
      "================================8144===================================\n",
      "8144/10000: train_loss: 2.9020122677038307 train_error 24.88% test_error 18.00%\n",
      "================================8145===================================\n",
      "8145/10000: train_loss: 2.9017522428150553 train_error 24.88% test_error 18.00%\n",
      "================================8146===================================\n",
      "8146/10000: train_loss: 2.9014924544538374 train_error 24.88% test_error 18.00%\n",
      "================================8147===================================\n",
      "8147/10000: train_loss: 2.901232173708922 train_error 24.88% test_error 18.00%\n",
      "================================8148===================================\n",
      "8148/10000: train_loss: 2.9009702165346973 train_error 24.88% test_error 18.00%\n",
      "================================8149===================================\n",
      "8149/10000: train_loss: 2.900704516082987 train_error 24.88% test_error 18.00%\n",
      "================================8150===================================\n",
      "8150/10000: train_loss: 2.9004354457474983 train_error 24.88% test_error 18.00%\n",
      "================================8151===================================\n",
      "8151/10000: train_loss: 2.9001651338426018 train_error 24.88% test_error 18.00%\n",
      "================================8152===================================\n",
      "8152/10000: train_loss: 2.899894454298046 train_error 24.88% test_error 18.00%\n",
      "================================8153===================================\n",
      "8153/10000: train_loss: 2.8996232588723796 train_error 24.88% test_error 18.00%\n",
      "================================8154===================================\n",
      "8154/10000: train_loss: 2.8993515752477106 train_error 24.88% test_error 18.00%\n",
      "================================8155===================================\n",
      "8155/10000: train_loss: 2.8990821595576564 train_error 24.88% test_error 18.00%\n",
      "================================8156===================================\n",
      "8156/10000: train_loss: 2.8988129215392835 train_error 24.88% test_error 18.00%\n",
      "================================8157===================================\n",
      "8157/10000: train_loss: 2.8985414765845054 train_error 24.88% test_error 18.00%\n",
      "================================8158===================================\n",
      "8158/10000: train_loss: 2.8982632519515756 train_error 24.88% test_error 17.50%\n",
      "================================8159===================================\n",
      "8159/10000: train_loss: 2.8979837065634637 train_error 24.88% test_error 17.50%\n",
      "================================8160===================================\n",
      "8160/10000: train_loss: 2.8977044659313105 train_error 24.88% test_error 17.50%\n",
      "================================8161===================================\n",
      "8161/10000: train_loss: 2.8974250172252503 train_error 24.88% test_error 17.50%\n",
      "================================8162===================================\n",
      "8162/10000: train_loss: 2.8971433385768615 train_error 24.88% test_error 17.50%\n",
      "================================8163===================================\n",
      "8163/10000: train_loss: 2.896861802526546 train_error 24.88% test_error 17.50%\n",
      "================================8164===================================\n",
      "8164/10000: train_loss: 2.8965818765671427 train_error 24.88% test_error 17.50%\n",
      "================================8165===================================\n",
      "8165/10000: train_loss: 2.896302811613859 train_error 24.88% test_error 17.50%\n",
      "================================8166===================================\n",
      "8166/10000: train_loss: 2.896024326429324 train_error 24.88% test_error 17.50%\n",
      "================================8167===================================\n",
      "8167/10000: train_loss: 2.8957451955047144 train_error 24.88% test_error 17.50%\n",
      "================================8168===================================\n",
      "8168/10000: train_loss: 2.8954658587607995 train_error 24.88% test_error 17.50%\n",
      "================================8169===================================\n",
      "8169/10000: train_loss: 2.8951881031990343 train_error 24.88% test_error 17.50%\n",
      "================================8170===================================\n",
      "8170/10000: train_loss: 2.894910615947956 train_error 24.88% test_error 17.50%\n",
      "================================8171===================================\n",
      "8171/10000: train_loss: 2.8946336651073943 train_error 24.88% test_error 17.50%\n",
      "================================8172===================================\n",
      "8172/10000: train_loss: 2.8943565020535607 train_error 24.88% test_error 17.50%\n",
      "================================8173===================================\n",
      "8173/10000: train_loss: 2.8940777054135833 train_error 24.88% test_error 17.50%\n",
      "================================8174===================================\n",
      "8174/10000: train_loss: 2.8937972474141134 train_error 24.88% test_error 17.50%\n",
      "================================8175===================================\n",
      "8175/10000: train_loss: 2.893516242189216 train_error 24.88% test_error 17.50%\n",
      "================================8176===================================\n",
      "8176/10000: train_loss: 2.893235808305253 train_error 24.88% test_error 17.50%\n",
      "================================8177===================================\n",
      "8177/10000: train_loss: 2.892956494841128 train_error 24.88% test_error 17.50%\n",
      "================================8178===================================\n",
      "8178/10000: train_loss: 2.892677578393559 train_error 24.88% test_error 17.50%\n",
      "================================8179===================================\n",
      "8179/10000: train_loss: 2.892395353879838 train_error 24.88% test_error 17.50%\n",
      "================================8180===================================\n",
      "8180/10000: train_loss: 2.8921106057589347 train_error 24.88% test_error 17.50%\n",
      "================================8181===================================\n",
      "8181/10000: train_loss: 2.8918229327323934 train_error 24.88% test_error 17.50%\n",
      "================================8182===================================\n",
      "8182/10000: train_loss: 2.8915344460678893 train_error 24.88% test_error 17.50%\n",
      "================================8183===================================\n",
      "8183/10000: train_loss: 2.8912475600722973 train_error 24.88% test_error 17.50%\n",
      "================================8184===================================\n",
      "8184/10000: train_loss: 2.890962790501435 train_error 24.88% test_error 17.50%\n",
      "================================8185===================================\n",
      "8185/10000: train_loss: 2.890677933549014 train_error 25.00% test_error 17.50%\n",
      "================================8186===================================\n",
      "8186/10000: train_loss: 2.890392425979444 train_error 24.88% test_error 17.50%\n",
      "================================8187===================================\n",
      "8187/10000: train_loss: 2.890103222437974 train_error 24.88% test_error 17.50%\n",
      "================================8188===================================\n",
      "8188/10000: train_loss: 2.8898182537728276 train_error 24.88% test_error 17.50%\n",
      "================================8189===================================\n",
      "8189/10000: train_loss: 2.8895334726107107 train_error 24.88% test_error 17.50%\n",
      "================================8190===================================\n",
      "8190/10000: train_loss: 2.8892459180137666 train_error 24.88% test_error 17.50%\n",
      "================================8191===================================\n",
      "8191/10000: train_loss: 2.8889581842445478 train_error 24.88% test_error 17.50%\n",
      "================================8192===================================\n",
      "8192/10000: train_loss: 2.888670888971683 train_error 24.88% test_error 17.50%\n",
      "================================8193===================================\n",
      "8193/10000: train_loss: 2.888382659835115 train_error 24.88% test_error 17.50%\n",
      "================================8194===================================\n",
      "8194/10000: train_loss: 2.888093060273386 train_error 24.88% test_error 17.50%\n",
      "================================8195===================================\n",
      "8195/10000: train_loss: 2.8878029723958023 train_error 24.88% test_error 17.50%\n",
      "================================8196===================================\n",
      "8196/10000: train_loss: 2.887513324826141 train_error 24.88% test_error 17.50%\n",
      "================================8197===================================\n",
      "8197/10000: train_loss: 2.8872230463255257 train_error 24.88% test_error 17.50%\n",
      "================================8198===================================\n",
      "8198/10000: train_loss: 2.8869329624808597 train_error 24.88% test_error 17.50%\n",
      "================================8199===================================\n",
      "8199/10000: train_loss: 2.886642592099306 train_error 24.88% test_error 17.50%\n",
      "================================8200===================================\n",
      "8200/10000: train_loss: 2.886352233409562 train_error 24.88% test_error 17.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8201===================================\n",
      "8201/10000: train_loss: 2.886059431612157 train_error 24.88% test_error 17.50%\n",
      "================================8202===================================\n",
      "8202/10000: train_loss: 2.8857718602917157 train_error 24.88% test_error 17.50%\n",
      "================================8203===================================\n",
      "8203/10000: train_loss: 2.885489432432005 train_error 24.88% test_error 17.50%\n",
      "================================8204===================================\n",
      "8204/10000: train_loss: 2.885207608854689 train_error 24.88% test_error 17.50%\n",
      "================================8205===================================\n",
      "8205/10000: train_loss: 2.884925069072924 train_error 24.88% test_error 17.50%\n",
      "================================8206===================================\n",
      "8206/10000: train_loss: 2.884642441889664 train_error 24.88% test_error 17.50%\n",
      "================================8207===================================\n",
      "8207/10000: train_loss: 2.884359570534798 train_error 24.88% test_error 17.50%\n",
      "================================8208===================================\n",
      "8208/10000: train_loss: 2.884078195284528 train_error 24.88% test_error 17.50%\n",
      "================================8209===================================\n",
      "8209/10000: train_loss: 2.883799527527881 train_error 24.88% test_error 17.50%\n",
      "================================8210===================================\n",
      "8210/10000: train_loss: 2.8835205446449255 train_error 24.88% test_error 17.50%\n",
      "================================8211===================================\n",
      "8211/10000: train_loss: 2.88324046112386 train_error 24.88% test_error 17.50%\n",
      "================================8212===================================\n",
      "8212/10000: train_loss: 2.882955426010303 train_error 24.88% test_error 17.50%\n",
      "================================8213===================================\n",
      "8213/10000: train_loss: 2.8826668740445163 train_error 24.88% test_error 17.50%\n",
      "================================8214===================================\n",
      "8214/10000: train_loss: 2.8823774989069353 train_error 24.88% test_error 17.50%\n",
      "================================8215===================================\n",
      "8215/10000: train_loss: 2.8820905205495366 train_error 24.88% test_error 17.50%\n",
      "================================8216===================================\n",
      "8216/10000: train_loss: 2.8818035037417578 train_error 24.88% test_error 17.50%\n",
      "================================8217===================================\n",
      "8217/10000: train_loss: 2.881516573195404 train_error 24.88% test_error 17.50%\n",
      "================================8218===================================\n",
      "8218/10000: train_loss: 2.8812309332810404 train_error 25.00% test_error 17.50%\n",
      "================================8219===================================\n",
      "8219/10000: train_loss: 2.880946056236644 train_error 25.00% test_error 17.50%\n",
      "================================8220===================================\n",
      "8220/10000: train_loss: 2.8806618074329164 train_error 25.00% test_error 17.50%\n",
      "================================8221===================================\n",
      "8221/10000: train_loss: 2.880378124941635 train_error 25.00% test_error 17.50%\n",
      "================================8222===================================\n",
      "8222/10000: train_loss: 2.880094251906048 train_error 25.00% test_error 17.50%\n",
      "================================8223===================================\n",
      "8223/10000: train_loss: 2.8798108243544993 train_error 25.00% test_error 17.50%\n",
      "================================8224===================================\n",
      "8224/10000: train_loss: 2.879527857555368 train_error 25.00% test_error 17.50%\n",
      "================================8225===================================\n",
      "8225/10000: train_loss: 2.879243991267067 train_error 25.00% test_error 17.50%\n",
      "================================8226===================================\n",
      "8226/10000: train_loss: 2.878961076252745 train_error 25.00% test_error 17.50%\n",
      "================================8227===================================\n",
      "8227/10000: train_loss: 2.8786805952517898 train_error 25.00% test_error 17.50%\n",
      "================================8228===================================\n",
      "8228/10000: train_loss: 2.878401103497672 train_error 25.00% test_error 17.50%\n",
      "================================8229===================================\n",
      "8229/10000: train_loss: 2.8781218901678223 train_error 25.00% test_error 17.50%\n",
      "================================8230===================================\n",
      "8230/10000: train_loss: 2.8778444998578196 train_error 25.00% test_error 17.50%\n",
      "================================8231===================================\n",
      "8231/10000: train_loss: 2.877566533022691 train_error 25.00% test_error 17.50%\n",
      "================================8232===================================\n",
      "8232/10000: train_loss: 2.8772882296883475 train_error 25.00% test_error 17.50%\n",
      "================================8233===================================\n",
      "8233/10000: train_loss: 2.877008735096315 train_error 25.00% test_error 17.50%\n",
      "================================8234===================================\n",
      "8234/10000: train_loss: 2.8767266821909288 train_error 25.00% test_error 17.50%\n",
      "================================8235===================================\n",
      "8235/10000: train_loss: 2.876438286074918 train_error 25.00% test_error 17.50%\n",
      "================================8236===================================\n",
      "8236/10000: train_loss: 2.8761468971343858 train_error 25.00% test_error 17.50%\n",
      "================================8237===================================\n",
      "8237/10000: train_loss: 2.8758532062106683 train_error 25.00% test_error 17.50%\n",
      "================================8238===================================\n",
      "8238/10000: train_loss: 2.8755550135749948 train_error 25.00% test_error 17.50%\n",
      "================================8239===================================\n",
      "8239/10000: train_loss: 2.8752575433965104 train_error 25.00% test_error 17.50%\n",
      "================================8240===================================\n",
      "8240/10000: train_loss: 2.874960151518026 train_error 25.00% test_error 17.50%\n",
      "================================8241===================================\n",
      "8241/10000: train_loss: 2.874663778362592 train_error 25.00% test_error 17.50%\n",
      "================================8242===================================\n",
      "8242/10000: train_loss: 2.8743668108328713 train_error 25.00% test_error 17.50%\n",
      "================================8243===================================\n",
      "8243/10000: train_loss: 2.874067623190349 train_error 25.00% test_error 17.50%\n",
      "================================8244===================================\n",
      "8244/10000: train_loss: 2.873768811848786 train_error 25.00% test_error 17.50%\n",
      "================================8245===================================\n",
      "8245/10000: train_loss: 2.8734693063973102 train_error 25.00% test_error 17.50%\n",
      "================================8246===================================\n",
      "8246/10000: train_loss: 2.8731686049776908 train_error 25.12% test_error 17.50%\n",
      "================================8247===================================\n",
      "8247/10000: train_loss: 2.8728760371211686 train_error 25.12% test_error 17.50%\n",
      "================================8248===================================\n",
      "8248/10000: train_loss: 2.8725836209578848 train_error 25.12% test_error 17.50%\n",
      "================================8249===================================\n",
      "8249/10000: train_loss: 2.872297687123864 train_error 25.12% test_error 17.50%\n",
      "================================8250===================================\n",
      "8250/10000: train_loss: 2.872020625081495 train_error 25.12% test_error 17.50%\n",
      "================================8251===================================\n",
      "8251/10000: train_loss: 2.871745142378641 train_error 25.12% test_error 17.50%\n",
      "================================8252===================================\n",
      "8252/10000: train_loss: 2.8714727361805856 train_error 25.12% test_error 17.50%\n",
      "================================8253===================================\n",
      "8253/10000: train_loss: 2.8712013849109645 train_error 25.12% test_error 17.50%\n",
      "================================8254===================================\n",
      "8254/10000: train_loss: 2.8709323140035847 train_error 25.12% test_error 17.50%\n",
      "================================8255===================================\n",
      "8255/10000: train_loss: 2.8706661420963795 train_error 25.12% test_error 17.50%\n",
      "================================8256===================================\n",
      "8256/10000: train_loss: 2.8704003892573384 train_error 25.12% test_error 17.50%\n",
      "================================8257===================================\n",
      "8257/10000: train_loss: 2.87013441875155 train_error 25.12% test_error 17.50%\n",
      "================================8258===================================\n",
      "8258/10000: train_loss: 2.8698666881725514 train_error 25.12% test_error 17.50%\n",
      "================================8259===================================\n",
      "8259/10000: train_loss: 2.86959867512458 train_error 25.12% test_error 17.50%\n",
      "================================8260===================================\n",
      "8260/10000: train_loss: 2.869331725084849 train_error 25.12% test_error 17.50%\n",
      "================================8261===================================\n",
      "8261/10000: train_loss: 2.869065433555879 train_error 25.12% test_error 17.50%\n",
      "================================8262===================================\n",
      "8262/10000: train_loss: 2.8687941253924514 train_error 25.12% test_error 17.50%\n",
      "================================8263===================================\n",
      "8263/10000: train_loss: 2.868521204098215 train_error 25.12% test_error 17.50%\n",
      "================================8264===================================\n",
      "8264/10000: train_loss: 2.868248252449557 train_error 25.12% test_error 17.50%\n",
      "================================8265===================================\n",
      "8265/10000: train_loss: 2.867977851415417 train_error 25.12% test_error 17.50%\n",
      "================================8266===================================\n",
      "8266/10000: train_loss: 2.86770428037169 train_error 25.12% test_error 17.50%\n",
      "================================8267===================================\n",
      "8267/10000: train_loss: 2.867423168248497 train_error 25.00% test_error 17.50%\n",
      "================================8268===================================\n",
      "8268/10000: train_loss: 2.867143605715464 train_error 25.00% test_error 17.50%\n",
      "================================8269===================================\n",
      "8269/10000: train_loss: 2.8668654581064037 train_error 25.00% test_error 17.50%\n",
      "================================8270===================================\n",
      "8270/10000: train_loss: 2.8665849471482217 train_error 25.00% test_error 17.50%\n",
      "================================8271===================================\n",
      "8271/10000: train_loss: 2.8662992481119725 train_error 25.00% test_error 17.50%\n",
      "================================8272===================================\n",
      "8272/10000: train_loss: 2.8660158084405705 train_error 25.00% test_error 17.50%\n",
      "================================8273===================================\n",
      "8273/10000: train_loss: 2.8657319389614715 train_error 25.00% test_error 17.50%\n",
      "================================8274===================================\n",
      "8274/10000: train_loss: 2.8654484501238042 train_error 25.00% test_error 17.50%\n",
      "================================8275===================================\n",
      "8275/10000: train_loss: 2.8651636847616464 train_error 25.00% test_error 17.50%\n",
      "================================8276===================================\n",
      "8276/10000: train_loss: 2.864879397186596 train_error 25.00% test_error 17.50%\n",
      "================================8277===================================\n",
      "8277/10000: train_loss: 2.864592401229056 train_error 25.00% test_error 17.50%\n",
      "================================8278===================================\n",
      "8278/10000: train_loss: 2.864304127271243 train_error 25.00% test_error 17.50%\n",
      "================================8279===================================\n",
      "8279/10000: train_loss: 2.8640155029682863 train_error 25.00% test_error 17.50%\n",
      "================================8280===================================\n",
      "8280/10000: train_loss: 2.863726434457167 train_error 25.00% test_error 17.50%\n",
      "================================8281===================================\n",
      "8281/10000: train_loss: 2.8634378428154377 train_error 25.00% test_error 17.50%\n",
      "================================8282===================================\n",
      "8282/10000: train_loss: 2.863147825771957 train_error 25.00% test_error 17.50%\n",
      "================================8283===================================\n",
      "8283/10000: train_loss: 2.8628599039447726 train_error 25.00% test_error 17.50%\n",
      "================================8284===================================\n",
      "8284/10000: train_loss: 2.8625727904064844 train_error 25.00% test_error 17.50%\n",
      "================================8285===================================\n",
      "8285/10000: train_loss: 2.8622867628433233 train_error 25.00% test_error 17.50%\n",
      "================================8286===================================\n",
      "8286/10000: train_loss: 2.861998747908147 train_error 25.00% test_error 17.50%\n",
      "================================8287===================================\n",
      "8287/10000: train_loss: 2.8617078441601915 train_error 25.00% test_error 17.50%\n",
      "================================8288===================================\n",
      "8288/10000: train_loss: 2.8614174722670214 train_error 25.00% test_error 17.50%\n",
      "================================8289===================================\n",
      "8289/10000: train_loss: 2.861128385261654 train_error 25.00% test_error 17.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8290===================================\n",
      "8290/10000: train_loss: 2.8608380384756673 train_error 25.00% test_error 17.50%\n",
      "================================8291===================================\n",
      "8291/10000: train_loss: 2.860550255278613 train_error 25.00% test_error 17.50%\n",
      "================================8292===================================\n",
      "8292/10000: train_loss: 2.8602628227302924 train_error 25.00% test_error 17.50%\n",
      "================================8293===================================\n",
      "8293/10000: train_loss: 2.859975407450656 train_error 25.00% test_error 17.50%\n",
      "================================8294===================================\n",
      "8294/10000: train_loss: 2.8596893530253875 train_error 25.00% test_error 17.50%\n",
      "================================8295===================================\n",
      "8295/10000: train_loss: 2.859402240138734 train_error 25.00% test_error 17.50%\n",
      "================================8296===================================\n",
      "8296/10000: train_loss: 2.859114984105508 train_error 25.00% test_error 17.50%\n",
      "================================8297===================================\n",
      "8297/10000: train_loss: 2.858826996588214 train_error 25.00% test_error 17.50%\n",
      "================================8298===================================\n",
      "8298/10000: train_loss: 2.85853899646263 train_error 25.00% test_error 17.50%\n",
      "================================8299===================================\n",
      "8299/10000: train_loss: 2.858252436689072 train_error 25.00% test_error 17.50%\n",
      "================================8300===================================\n",
      "8300/10000: train_loss: 2.8579643158301042 train_error 25.00% test_error 17.50%\n",
      "================================8301===================================\n",
      "8301/10000: train_loss: 2.8576744552969466 train_error 25.00% test_error 17.50%\n",
      "================================8302===================================\n",
      "8302/10000: train_loss: 2.857386024733714 train_error 25.00% test_error 17.50%\n",
      "================================8303===================================\n",
      "8303/10000: train_loss: 2.857091125716179 train_error 25.00% test_error 17.50%\n",
      "================================8304===================================\n",
      "8304/10000: train_loss: 2.856798198169308 train_error 25.00% test_error 17.50%\n",
      "================================8305===================================\n",
      "8305/10000: train_loss: 2.8565060195335534 train_error 25.00% test_error 17.50%\n",
      "================================8306===================================\n",
      "8306/10000: train_loss: 2.8562183761379494 train_error 25.00% test_error 17.50%\n",
      "================================8307===================================\n",
      "8307/10000: train_loss: 2.8559396420589107 train_error 25.00% test_error 17.50%\n",
      "================================8308===================================\n",
      "8308/10000: train_loss: 2.8556606310192727 train_error 25.00% test_error 17.50%\n",
      "================================8309===================================\n",
      "8309/10000: train_loss: 2.8553824408108266 train_error 25.00% test_error 17.50%\n",
      "================================8310===================================\n",
      "8310/10000: train_loss: 2.85510484999515 train_error 25.00% test_error 17.50%\n",
      "================================8311===================================\n",
      "8311/10000: train_loss: 2.8548230445971057 train_error 25.00% test_error 17.50%\n",
      "================================8312===================================\n",
      "8312/10000: train_loss: 2.85453748555261 train_error 25.00% test_error 17.50%\n",
      "================================8313===================================\n",
      "8313/10000: train_loss: 2.8542513311813673 train_error 25.00% test_error 17.50%\n",
      "================================8314===================================\n",
      "8314/10000: train_loss: 2.853965070092345 train_error 25.00% test_error 17.50%\n",
      "================================8315===================================\n",
      "8315/10000: train_loss: 2.853678298032537 train_error 25.00% test_error 17.50%\n",
      "================================8316===================================\n",
      "8316/10000: train_loss: 2.8533948909883837 train_error 25.00% test_error 17.50%\n",
      "================================8317===================================\n",
      "8317/10000: train_loss: 2.853112772671011 train_error 25.00% test_error 17.50%\n",
      "================================8318===================================\n",
      "8318/10000: train_loss: 2.8528327446467663 train_error 25.00% test_error 17.50%\n",
      "================================8319===================================\n",
      "8319/10000: train_loss: 2.8525550662421297 train_error 25.00% test_error 17.50%\n",
      "================================8320===================================\n",
      "8320/10000: train_loss: 2.8522765767905 train_error 25.00% test_error 17.50%\n",
      "================================8321===================================\n",
      "8321/10000: train_loss: 2.85199818892339 train_error 25.00% test_error 17.50%\n",
      "================================8322===================================\n",
      "8322/10000: train_loss: 2.8517193179878086 train_error 25.00% test_error 17.50%\n",
      "================================8323===================================\n",
      "8323/10000: train_loss: 2.8514408950889627 train_error 25.00% test_error 17.50%\n",
      "================================8324===================================\n",
      "8324/10000: train_loss: 2.851164936409623 train_error 25.00% test_error 17.50%\n",
      "================================8325===================================\n",
      "8325/10000: train_loss: 2.85089088374345 train_error 25.00% test_error 17.50%\n",
      "================================8326===================================\n",
      "8326/10000: train_loss: 2.850617441410577 train_error 25.00% test_error 17.50%\n",
      "================================8327===================================\n",
      "8327/10000: train_loss: 2.850344782474858 train_error 25.00% test_error 17.50%\n",
      "================================8328===================================\n",
      "8328/10000: train_loss: 2.8500725600851733 train_error 25.00% test_error 17.50%\n",
      "================================8329===================================\n",
      "8329/10000: train_loss: 2.8498021528788744 train_error 24.75% test_error 17.50%\n",
      "================================8330===================================\n",
      "8330/10000: train_loss: 2.8495333715323796 train_error 24.62% test_error 17.50%\n",
      "================================8331===================================\n",
      "8331/10000: train_loss: 2.8492689459108442 train_error 24.62% test_error 17.50%\n",
      "================================8332===================================\n",
      "8332/10000: train_loss: 2.8490037532223504 train_error 24.62% test_error 17.50%\n",
      "================================8333===================================\n",
      "8333/10000: train_loss: 2.848737217168418 train_error 24.62% test_error 17.50%\n",
      "================================8334===================================\n",
      "8334/10000: train_loss: 2.8484663491078392 train_error 24.62% test_error 17.50%\n",
      "================================8335===================================\n",
      "8335/10000: train_loss: 2.848190595302585 train_error 24.62% test_error 17.50%\n",
      "================================8336===================================\n",
      "8336/10000: train_loss: 2.847914363015334 train_error 24.62% test_error 17.50%\n",
      "================================8337===================================\n",
      "8337/10000: train_loss: 2.8476393987151094 train_error 24.50% test_error 17.50%\n",
      "================================8338===================================\n",
      "8338/10000: train_loss: 2.8473647455947866 train_error 24.50% test_error 17.50%\n",
      "================================8339===================================\n",
      "8339/10000: train_loss: 2.8470899599013864 train_error 24.50% test_error 17.50%\n",
      "================================8340===================================\n",
      "8340/10000: train_loss: 2.8468132363200858 train_error 24.50% test_error 17.50%\n",
      "================================8341===================================\n",
      "8341/10000: train_loss: 2.8465375298974687 train_error 24.50% test_error 17.50%\n",
      "================================8342===================================\n",
      "8342/10000: train_loss: 2.8462632199423386 train_error 24.50% test_error 17.50%\n",
      "================================8343===================================\n",
      "8343/10000: train_loss: 2.8459898683096614 train_error 24.50% test_error 17.50%\n",
      "================================8344===================================\n",
      "8344/10000: train_loss: 2.8457172751415056 train_error 24.50% test_error 17.50%\n",
      "================================8345===================================\n",
      "8345/10000: train_loss: 2.8454476426589097 train_error 24.50% test_error 17.50%\n",
      "================================8346===================================\n",
      "8346/10000: train_loss: 2.8451792137075973 train_error 24.50% test_error 17.50%\n",
      "================================8347===================================\n",
      "8347/10000: train_loss: 2.844909910238603 train_error 24.50% test_error 17.50%\n",
      "================================8348===================================\n",
      "8348/10000: train_loss: 2.8446404378696752 train_error 24.50% test_error 17.50%\n",
      "================================8349===================================\n",
      "8349/10000: train_loss: 2.844372154085322 train_error 24.50% test_error 17.50%\n",
      "================================8350===================================\n",
      "8350/10000: train_loss: 2.84410378828612 train_error 24.50% test_error 17.50%\n",
      "================================8351===================================\n",
      "8351/10000: train_loss: 2.8438344276167116 train_error 24.50% test_error 17.50%\n",
      "================================8352===================================\n",
      "8352/10000: train_loss: 2.8435658677580067 train_error 24.50% test_error 17.50%\n",
      "================================8353===================================\n",
      "8353/10000: train_loss: 2.8432925732665537 train_error 24.50% test_error 17.50%\n",
      "================================8354===================================\n",
      "8354/10000: train_loss: 2.8430092045527635 train_error 24.50% test_error 17.50%\n",
      "================================8355===================================\n",
      "8355/10000: train_loss: 2.8427266231264365 train_error 24.50% test_error 17.50%\n",
      "================================8356===================================\n",
      "8356/10000: train_loss: 2.842442877622961 train_error 24.50% test_error 17.50%\n",
      "================================8357===================================\n",
      "8357/10000: train_loss: 2.8421528082852823 train_error 24.38% test_error 17.50%\n",
      "================================8358===================================\n",
      "8358/10000: train_loss: 2.841861126919757 train_error 24.38% test_error 17.50%\n",
      "================================8359===================================\n",
      "8359/10000: train_loss: 2.8415684513877206 train_error 24.38% test_error 17.50%\n",
      "================================8360===================================\n",
      "8360/10000: train_loss: 2.8412761700999543 train_error 24.25% test_error 17.50%\n",
      "================================8361===================================\n",
      "8361/10000: train_loss: 2.8409851212763533 train_error 24.25% test_error 17.50%\n",
      "================================8362===================================\n",
      "8362/10000: train_loss: 2.8406953444316607 train_error 24.25% test_error 17.50%\n",
      "================================8363===================================\n",
      "8363/10000: train_loss: 2.8404087516470824 train_error 24.25% test_error 17.50%\n",
      "================================8364===================================\n",
      "8364/10000: train_loss: 2.8401221228369105 train_error 24.25% test_error 17.50%\n",
      "================================8365===================================\n",
      "8365/10000: train_loss: 2.839835116443282 train_error 24.25% test_error 17.50%\n",
      "================================8366===================================\n",
      "8366/10000: train_loss: 2.8395479787919973 train_error 24.25% test_error 17.50%\n",
      "================================8367===================================\n",
      "8367/10000: train_loss: 2.8392584829480985 train_error 24.25% test_error 17.50%\n",
      "================================8368===================================\n",
      "8368/10000: train_loss: 2.8389684797452714 train_error 24.25% test_error 17.50%\n",
      "================================8369===================================\n",
      "8369/10000: train_loss: 2.83868135256791 train_error 24.25% test_error 17.50%\n",
      "================================8370===================================\n",
      "8370/10000: train_loss: 2.8383937119217446 train_error 24.25% test_error 17.50%\n",
      "================================8371===================================\n",
      "8371/10000: train_loss: 2.8381044163966 train_error 24.25% test_error 17.50%\n",
      "================================8372===================================\n",
      "8372/10000: train_loss: 2.837815365326824 train_error 24.25% test_error 17.50%\n",
      "================================8373===================================\n",
      "8373/10000: train_loss: 2.8375259972018467 train_error 24.25% test_error 17.50%\n",
      "================================8374===================================\n",
      "8374/10000: train_loss: 2.8372360122084133 train_error 24.25% test_error 17.50%\n",
      "================================8375===================================\n",
      "8375/10000: train_loss: 2.8369468505862097 train_error 24.25% test_error 17.50%\n",
      "================================8376===================================\n",
      "8376/10000: train_loss: 2.836660742317981 train_error 24.25% test_error 17.50%\n",
      "================================8377===================================\n",
      "8377/10000: train_loss: 2.836375673477451 train_error 24.25% test_error 17.50%\n",
      "================================8378===================================\n",
      "8378/10000: train_loss: 2.8360914861442144 train_error 24.25% test_error 17.50%\n",
      "================================8379===================================\n",
      "8379/10000: train_loss: 2.8358158490947245 train_error 24.25% test_error 17.50%\n",
      "================================8380===================================\n",
      "8380/10000: train_loss: 2.8355408032060585 train_error 24.25% test_error 17.50%\n",
      "================================8381===================================\n",
      "8381/10000: train_loss: 2.8352640679313117 train_error 24.25% test_error 17.50%\n",
      "================================8382===================================\n",
      "8382/10000: train_loss: 2.8349885448425627 train_error 24.25% test_error 17.50%\n",
      "================================8383===================================\n",
      "8383/10000: train_loss: 2.834717375892797 train_error 24.25% test_error 17.50%\n",
      "================================8384===================================\n",
      "8384/10000: train_loss: 2.834448600339456 train_error 24.25% test_error 17.50%\n",
      "================================8385===================================\n",
      "8385/10000: train_loss: 2.8341805273585488 train_error 24.25% test_error 17.50%\n",
      "================================8386===================================\n",
      "8386/10000: train_loss: 2.8339128690703728 train_error 24.25% test_error 17.50%\n",
      "================================8387===================================\n",
      "8387/10000: train_loss: 2.8336462654816934 train_error 24.25% test_error 17.50%\n",
      "================================8388===================================\n",
      "8388/10000: train_loss: 2.8333809057803956 train_error 24.25% test_error 17.50%\n",
      "================================8389===================================\n",
      "8389/10000: train_loss: 2.8331173151256737 train_error 24.25% test_error 17.50%\n",
      "================================8390===================================\n",
      "8390/10000: train_loss: 2.832855701492699 train_error 24.25% test_error 17.50%\n",
      "================================8391===================================\n",
      "8391/10000: train_loss: 2.8325921015537827 train_error 24.25% test_error 17.50%\n",
      "================================8392===================================\n",
      "8392/10000: train_loss: 2.8323260618242783 train_error 24.25% test_error 17.50%\n",
      "================================8393===================================\n",
      "8393/10000: train_loss: 2.832056076641238 train_error 24.25% test_error 17.50%\n",
      "================================8394===================================\n",
      "8394/10000: train_loss: 2.8317846642058795 train_error 24.25% test_error 17.50%\n",
      "================================8395===================================\n",
      "8395/10000: train_loss: 2.8315135302895578 train_error 24.25% test_error 17.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8396===================================\n",
      "8396/10000: train_loss: 2.831243150823793 train_error 24.25% test_error 17.50%\n",
      "================================8397===================================\n",
      "8397/10000: train_loss: 2.8309734544071397 train_error 24.25% test_error 17.50%\n",
      "================================8398===================================\n",
      "8398/10000: train_loss: 2.830703739951641 train_error 24.25% test_error 17.50%\n",
      "================================8399===================================\n",
      "8399/10000: train_loss: 2.830432259004192 train_error 24.25% test_error 17.50%\n",
      "================================8400===================================\n",
      "8400/10000: train_loss: 2.8301586889626194 train_error 24.25% test_error 17.50%\n",
      "================================8401===================================\n",
      "8401/10000: train_loss: 2.8298857845869496 train_error 24.25% test_error 17.50%\n",
      "================================8402===================================\n",
      "8402/10000: train_loss: 2.8296125952201687 train_error 24.38% test_error 17.50%\n",
      "================================8403===================================\n",
      "8403/10000: train_loss: 2.829339842960617 train_error 24.38% test_error 17.50%\n",
      "================================8404===================================\n",
      "8404/10000: train_loss: 2.8290678814647983 train_error 24.38% test_error 17.50%\n",
      "================================8405===================================\n",
      "8405/10000: train_loss: 2.8287983713332143 train_error 24.38% test_error 17.50%\n",
      "================================8406===================================\n",
      "8406/10000: train_loss: 2.8285293557431577 train_error 24.38% test_error 17.50%\n",
      "================================8407===================================\n",
      "8407/10000: train_loss: 2.8282583443531624 train_error 24.38% test_error 17.50%\n",
      "================================8408===================================\n",
      "8408/10000: train_loss: 2.827987076370518 train_error 24.38% test_error 17.50%\n",
      "================================8409===================================\n",
      "8409/10000: train_loss: 2.8277123518989535 train_error 24.38% test_error 17.50%\n",
      "================================8410===================================\n",
      "8410/10000: train_loss: 2.827437842457875 train_error 24.38% test_error 17.50%\n",
      "================================8411===================================\n",
      "8411/10000: train_loss: 2.8271674532151883 train_error 24.38% test_error 17.50%\n",
      "================================8412===================================\n",
      "8412/10000: train_loss: 2.8269000695135036 train_error 24.38% test_error 17.50%\n",
      "================================8413===================================\n",
      "8413/10000: train_loss: 2.826634456432621 train_error 24.38% test_error 17.50%\n",
      "================================8414===================================\n",
      "8414/10000: train_loss: 2.8263676465959726 train_error 24.38% test_error 17.50%\n",
      "================================8415===================================\n",
      "8415/10000: train_loss: 2.8260943022810534 train_error 24.38% test_error 17.50%\n",
      "================================8416===================================\n",
      "8416/10000: train_loss: 2.825818895020784 train_error 24.38% test_error 17.50%\n",
      "================================8417===================================\n",
      "8417/10000: train_loss: 2.8255427531545503 train_error 24.38% test_error 17.50%\n",
      "================================8418===================================\n",
      "8418/10000: train_loss: 2.825267714963993 train_error 24.50% test_error 17.50%\n",
      "================================8419===================================\n",
      "8419/10000: train_loss: 2.8249934485325503 train_error 24.50% test_error 17.50%\n",
      "================================8420===================================\n",
      "8420/10000: train_loss: 2.8247243810061264 train_error 24.50% test_error 17.50%\n",
      "================================8421===================================\n",
      "8421/10000: train_loss: 2.8244594368700198 train_error 24.50% test_error 17.50%\n",
      "================================8422===================================\n",
      "8422/10000: train_loss: 2.8241949517919784 train_error 24.50% test_error 17.50%\n",
      "================================8423===================================\n",
      "8423/10000: train_loss: 2.823928232853868 train_error 24.50% test_error 17.50%\n",
      "================================8424===================================\n",
      "8424/10000: train_loss: 2.8236567313101477 train_error 24.50% test_error 17.50%\n",
      "================================8425===================================\n",
      "8425/10000: train_loss: 2.823384571030656 train_error 24.50% test_error 17.50%\n",
      "================================8426===================================\n",
      "8426/10000: train_loss: 2.823112057942999 train_error 24.50% test_error 17.50%\n",
      "================================8427===================================\n",
      "8427/10000: train_loss: 2.822840839230266 train_error 24.50% test_error 17.50%\n",
      "================================8428===================================\n",
      "8428/10000: train_loss: 2.8225683033266975 train_error 24.50% test_error 17.50%\n",
      "================================8429===================================\n",
      "8429/10000: train_loss: 2.8222958115051373 train_error 24.50% test_error 17.50%\n",
      "================================8430===================================\n",
      "8430/10000: train_loss: 2.822021888849522 train_error 24.62% test_error 17.50%\n",
      "================================8431===================================\n",
      "8431/10000: train_loss: 2.821750986379775 train_error 24.62% test_error 17.00%\n",
      "================================8432===================================\n",
      "8432/10000: train_loss: 2.821477474867024 train_error 24.62% test_error 17.00%\n",
      "================================8433===================================\n",
      "8433/10000: train_loss: 2.8212000134135087 train_error 24.62% test_error 17.00%\n",
      "================================8434===================================\n",
      "8434/10000: train_loss: 2.820925856858139 train_error 24.62% test_error 17.00%\n",
      "================================8435===================================\n",
      "8435/10000: train_loss: 2.82065246318205 train_error 24.62% test_error 17.00%\n",
      "================================8436===================================\n",
      "8436/10000: train_loss: 2.8203784140288732 train_error 24.62% test_error 17.00%\n",
      "================================8437===================================\n",
      "8437/10000: train_loss: 2.820105086552139 train_error 24.62% test_error 17.00%\n",
      "================================8438===================================\n",
      "8438/10000: train_loss: 2.8198334413377233 train_error 24.62% test_error 17.00%\n",
      "================================8439===================================\n",
      "8439/10000: train_loss: 2.819560399482034 train_error 24.62% test_error 17.00%\n",
      "================================8440===================================\n",
      "8440/10000: train_loss: 2.8192851149206763 train_error 24.62% test_error 17.00%\n",
      "================================8441===================================\n",
      "8441/10000: train_loss: 2.8190042157380235 train_error 24.62% test_error 17.00%\n",
      "================================8442===================================\n",
      "8442/10000: train_loss: 2.8187240999867935 train_error 24.62% test_error 17.00%\n",
      "================================8443===================================\n",
      "8443/10000: train_loss: 2.818438774416954 train_error 24.62% test_error 17.00%\n",
      "================================8444===================================\n",
      "8444/10000: train_loss: 2.81815120105206 train_error 24.62% test_error 17.00%\n",
      "================================8445===================================\n",
      "8445/10000: train_loss: 2.8178660650440546 train_error 24.62% test_error 17.00%\n",
      "================================8446===================================\n",
      "8446/10000: train_loss: 2.817581672764154 train_error 24.62% test_error 17.00%\n",
      "================================8447===================================\n",
      "8447/10000: train_loss: 2.8172970872956284 train_error 24.62% test_error 17.00%\n",
      "================================8448===================================\n",
      "8448/10000: train_loss: 2.8170139301748716 train_error 24.62% test_error 17.00%\n",
      "================================8449===================================\n",
      "8449/10000: train_loss: 2.8167350516776057 train_error 24.62% test_error 17.00%\n",
      "================================8450===================================\n",
      "8450/10000: train_loss: 2.8164585543462817 train_error 24.62% test_error 17.00%\n",
      "================================8451===================================\n",
      "8451/10000: train_loss: 2.8161852965251275 train_error 24.75% test_error 17.00%\n",
      "================================8452===================================\n",
      "8452/10000: train_loss: 2.8159149149611036 train_error 24.75% test_error 17.00%\n",
      "================================8453===================================\n",
      "8453/10000: train_loss: 2.815644599094867 train_error 24.75% test_error 17.00%\n",
      "================================8454===================================\n",
      "8454/10000: train_loss: 2.8153690730112615 train_error 24.75% test_error 17.00%\n",
      "================================8455===================================\n",
      "8455/10000: train_loss: 2.815092281214547 train_error 24.75% test_error 17.00%\n",
      "================================8456===================================\n",
      "8456/10000: train_loss: 2.8148158661516938 train_error 24.75% test_error 17.00%\n",
      "================================8457===================================\n",
      "8457/10000: train_loss: 2.8145398265785664 train_error 24.75% test_error 17.00%\n",
      "================================8458===================================\n",
      "8458/10000: train_loss: 2.8142629783460507 train_error 24.75% test_error 17.00%\n",
      "================================8459===================================\n",
      "8459/10000: train_loss: 2.8139926637436297 train_error 24.75% test_error 17.00%\n",
      "================================8460===================================\n",
      "8460/10000: train_loss: 2.8137253637403044 train_error 24.50% test_error 17.00%\n",
      "================================8461===================================\n",
      "8461/10000: train_loss: 2.813460645642372 train_error 24.50% test_error 17.00%\n",
      "================================8462===================================\n",
      "8462/10000: train_loss: 2.8131975780298486 train_error 24.50% test_error 17.00%\n",
      "================================8463===================================\n",
      "8463/10000: train_loss: 2.812935637131377 train_error 24.50% test_error 17.00%\n",
      "================================8464===================================\n",
      "8464/10000: train_loss: 2.812668717430533 train_error 24.62% test_error 17.00%\n",
      "================================8465===================================\n",
      "8465/10000: train_loss: 2.812400992577586 train_error 24.62% test_error 17.00%\n",
      "================================8466===================================\n",
      "8466/10000: train_loss: 2.8121315385451817 train_error 24.62% test_error 17.00%\n",
      "================================8467===================================\n",
      "8467/10000: train_loss: 2.811866128676702 train_error 24.62% test_error 17.00%\n",
      "================================8468===================================\n",
      "8468/10000: train_loss: 2.811602343747454 train_error 24.62% test_error 17.00%\n",
      "================================8469===================================\n",
      "8469/10000: train_loss: 2.8113392314279917 train_error 24.62% test_error 17.00%\n",
      "================================8470===================================\n",
      "8470/10000: train_loss: 2.8110755306212196 train_error 24.62% test_error 17.00%\n",
      "================================8471===================================\n",
      "8471/10000: train_loss: 2.810811413625506 train_error 24.62% test_error 17.00%\n",
      "================================8472===================================\n",
      "8472/10000: train_loss: 2.8105510673520073 train_error 24.50% test_error 17.00%\n",
      "================================8473===================================\n",
      "8473/10000: train_loss: 2.81029199565859 train_error 24.50% test_error 17.00%\n",
      "================================8474===================================\n",
      "8474/10000: train_loss: 2.8100336206652723 train_error 24.50% test_error 17.00%\n",
      "================================8475===================================\n",
      "8475/10000: train_loss: 2.809777316985674 train_error 24.62% test_error 17.00%\n",
      "================================8476===================================\n",
      "8476/10000: train_loss: 2.80952668944612 train_error 24.62% test_error 16.50%\n",
      "================================8477===================================\n",
      "8477/10000: train_loss: 2.8092766495620527 train_error 24.62% test_error 16.50%\n",
      "================================8478===================================\n",
      "8478/10000: train_loss: 2.8090253512723393 train_error 24.62% test_error 16.50%\n",
      "================================8479===================================\n",
      "8479/10000: train_loss: 2.8087717560868075 train_error 24.62% test_error 16.50%\n",
      "================================8480===================================\n",
      "8480/10000: train_loss: 2.8085142646152232 train_error 24.50% test_error 16.50%\n",
      "================================8481===================================\n",
      "8481/10000: train_loss: 2.8082556849144202 train_error 24.50% test_error 16.50%\n",
      "================================8482===================================\n",
      "8482/10000: train_loss: 2.8079989918144204 train_error 24.50% test_error 16.00%\n",
      "================================8483===================================\n",
      "8483/10000: train_loss: 2.807744436388366 train_error 24.50% test_error 16.00%\n",
      "================================8484===================================\n",
      "8484/10000: train_loss: 2.8074956646186724 train_error 24.50% test_error 16.00%\n",
      "================================8485===================================\n",
      "8485/10000: train_loss: 2.807253752983561 train_error 24.50% test_error 16.00%\n",
      "================================8486===================================\n",
      "8486/10000: train_loss: 2.8070147470710616 train_error 24.50% test_error 16.00%\n",
      "================================8487===================================\n",
      "8487/10000: train_loss: 2.8067750078555767 train_error 24.50% test_error 16.00%\n",
      "================================8488===================================\n",
      "8488/10000: train_loss: 2.8065348962355525 train_error 24.50% test_error 16.00%\n",
      "================================8489===================================\n",
      "8489/10000: train_loss: 2.8062943316798736 train_error 24.50% test_error 16.00%\n",
      "================================8490===================================\n",
      "8490/10000: train_loss: 2.8060571183077814 train_error 24.50% test_error 16.00%\n",
      "================================8491===================================\n",
      "8491/10000: train_loss: 2.805817776137683 train_error 24.62% test_error 16.00%\n",
      "================================8492===================================\n",
      "8492/10000: train_loss: 2.8055783378435626 train_error 24.62% test_error 16.00%\n",
      "================================8493===================================\n",
      "8493/10000: train_loss: 2.8053439083767078 train_error 24.62% test_error 16.00%\n",
      "================================8494===================================\n",
      "8494/10000: train_loss: 2.8051102344270475 train_error 24.62% test_error 16.00%\n",
      "================================8495===================================\n",
      "8495/10000: train_loss: 2.8048751217862993 train_error 24.62% test_error 16.00%\n",
      "================================8496===================================\n",
      "8496/10000: train_loss: 2.8046364739282765 train_error 24.62% test_error 16.00%\n",
      "================================8497===================================\n",
      "8497/10000: train_loss: 2.8043982153920117 train_error 24.62% test_error 16.00%\n",
      "================================8498===================================\n",
      "8498/10000: train_loss: 2.804156115526075 train_error 24.62% test_error 16.00%\n",
      "================================8499===================================\n",
      "8499/10000: train_loss: 2.8039108161314292 train_error 24.50% test_error 16.00%\n",
      "================================8500===================================\n",
      "8500/10000: train_loss: 2.803665342939439 train_error 24.50% test_error 16.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8501===================================\n",
      "8501/10000: train_loss: 2.8034215925915125 train_error 24.50% test_error 16.00%\n",
      "================================8502===================================\n",
      "8502/10000: train_loss: 2.803176569599909 train_error 24.50% test_error 16.00%\n",
      "================================8503===================================\n",
      "8503/10000: train_loss: 2.802929968995668 train_error 24.50% test_error 16.00%\n",
      "================================8504===================================\n",
      "8504/10000: train_loss: 2.802687313045335 train_error 24.50% test_error 16.00%\n",
      "================================8505===================================\n",
      "8505/10000: train_loss: 2.8024435988813092 train_error 24.50% test_error 15.50%\n",
      "================================8506===================================\n",
      "8506/10000: train_loss: 2.8021988250665713 train_error 24.50% test_error 15.50%\n",
      "================================8507===================================\n",
      "8507/10000: train_loss: 2.8019523675178784 train_error 24.50% test_error 15.50%\n",
      "================================8508===================================\n",
      "8508/10000: train_loss: 2.8017046689939162 train_error 24.50% test_error 15.50%\n",
      "================================8509===================================\n",
      "8509/10000: train_loss: 2.8014547792251507 train_error 24.50% test_error 15.50%\n",
      "================================8510===================================\n",
      "8510/10000: train_loss: 2.8012015244474973 train_error 24.38% test_error 15.50%\n",
      "================================8511===================================\n",
      "8511/10000: train_loss: 2.800950986263542 train_error 24.25% test_error 15.50%\n",
      "================================8512===================================\n",
      "8512/10000: train_loss: 2.8006978356367838 train_error 24.25% test_error 15.50%\n",
      "================================8513===================================\n",
      "8513/10000: train_loss: 2.8004480561629683 train_error 24.12% test_error 15.50%\n",
      "================================8514===================================\n",
      "8514/10000: train_loss: 2.8001969541693144 train_error 24.12% test_error 15.50%\n",
      "================================8515===================================\n",
      "8515/10000: train_loss: 2.7999475704511316 train_error 24.12% test_error 15.50%\n",
      "================================8516===================================\n",
      "8516/10000: train_loss: 2.7997010941386726 train_error 24.00% test_error 15.50%\n",
      "================================8517===================================\n",
      "8517/10000: train_loss: 2.7994599219102017 train_error 24.00% test_error 15.50%\n",
      "================================8518===================================\n",
      "8518/10000: train_loss: 2.7992234685838233 train_error 24.00% test_error 15.50%\n",
      "================================8519===================================\n",
      "8519/10000: train_loss: 2.798984633739037 train_error 24.00% test_error 15.50%\n",
      "================================8520===================================\n",
      "8520/10000: train_loss: 2.7987447266443812 train_error 24.12% test_error 15.50%\n",
      "================================8521===================================\n",
      "8521/10000: train_loss: 2.79850132355612 train_error 24.12% test_error 15.50%\n",
      "================================8522===================================\n",
      "8522/10000: train_loss: 2.7982475425060147 train_error 24.12% test_error 15.50%\n",
      "================================8523===================================\n",
      "8523/10000: train_loss: 2.797994630113953 train_error 24.12% test_error 15.50%\n",
      "================================8524===================================\n",
      "8524/10000: train_loss: 2.7977405769517647 train_error 24.12% test_error 15.50%\n",
      "================================8525===================================\n",
      "8525/10000: train_loss: 2.79748427005854 train_error 24.00% test_error 15.50%\n",
      "================================8526===================================\n",
      "8526/10000: train_loss: 2.7972295915916767 train_error 24.00% test_error 15.50%\n",
      "================================8527===================================\n",
      "8527/10000: train_loss: 2.796983053503518 train_error 24.00% test_error 15.50%\n",
      "================================8528===================================\n",
      "8528/10000: train_loss: 2.7967396551567254 train_error 24.00% test_error 15.50%\n",
      "================================8529===================================\n",
      "8529/10000: train_loss: 2.7964958468997425 train_error 24.00% test_error 15.50%\n",
      "================================8530===================================\n",
      "8530/10000: train_loss: 2.7962527167840014 train_error 24.00% test_error 15.50%\n",
      "================================8531===================================\n",
      "8531/10000: train_loss: 2.796007902659567 train_error 24.00% test_error 15.50%\n",
      "================================8532===================================\n",
      "8532/10000: train_loss: 2.79576201324182 train_error 24.00% test_error 15.50%\n",
      "================================8533===================================\n",
      "8533/10000: train_loss: 2.7955158088341703 train_error 24.00% test_error 15.50%\n",
      "================================8534===================================\n",
      "8534/10000: train_loss: 2.7952632702248956 train_error 24.00% test_error 15.50%\n",
      "================================8535===================================\n",
      "8535/10000: train_loss: 2.7950093150357316 train_error 23.88% test_error 15.50%\n",
      "================================8536===================================\n",
      "8536/10000: train_loss: 2.79476208093889 train_error 23.88% test_error 15.50%\n",
      "================================8537===================================\n",
      "8537/10000: train_loss: 2.794514862562646 train_error 23.88% test_error 15.50%\n",
      "================================8538===================================\n",
      "8538/10000: train_loss: 2.7942634029585136 train_error 23.88% test_error 15.50%\n",
      "================================8539===================================\n",
      "8539/10000: train_loss: 2.7940121573573924 train_error 23.88% test_error 15.50%\n",
      "================================8540===================================\n",
      "8540/10000: train_loss: 2.793760479588636 train_error 23.88% test_error 15.50%\n",
      "================================8541===================================\n",
      "8541/10000: train_loss: 2.7935093119519845 train_error 23.88% test_error 15.50%\n",
      "================================8542===================================\n",
      "8542/10000: train_loss: 2.7932615827915837 train_error 23.88% test_error 15.50%\n",
      "================================8543===================================\n",
      "8543/10000: train_loss: 2.793019450037773 train_error 23.88% test_error 15.50%\n",
      "================================8544===================================\n",
      "8544/10000: train_loss: 2.7927858682625812 train_error 23.88% test_error 15.50%\n",
      "================================8545===================================\n",
      "8545/10000: train_loss: 2.792559216247628 train_error 23.88% test_error 15.50%\n",
      "================================8546===================================\n",
      "8546/10000: train_loss: 2.792337415470265 train_error 23.88% test_error 15.50%\n",
      "================================8547===================================\n",
      "8547/10000: train_loss: 2.7921203980768405 train_error 23.88% test_error 15.50%\n",
      "================================8548===================================\n",
      "8548/10000: train_loss: 2.7919029734905414 train_error 23.88% test_error 15.50%\n",
      "================================8549===================================\n",
      "8549/10000: train_loss: 2.791686993272051 train_error 23.88% test_error 15.50%\n",
      "================================8550===================================\n",
      "8550/10000: train_loss: 2.7914739997586366 train_error 23.88% test_error 15.50%\n",
      "================================8551===================================\n",
      "8551/10000: train_loss: 2.7912637254979016 train_error 23.88% test_error 15.50%\n",
      "================================8552===================================\n",
      "8552/10000: train_loss: 2.7910546236138547 train_error 23.88% test_error 15.50%\n",
      "================================8553===================================\n",
      "8553/10000: train_loss: 2.790848159096859 train_error 23.88% test_error 15.50%\n",
      "================================8554===================================\n",
      "8554/10000: train_loss: 2.7906436392662908 train_error 23.88% test_error 15.50%\n",
      "================================8555===================================\n",
      "8555/10000: train_loss: 2.7904394371782475 train_error 23.88% test_error 15.50%\n",
      "================================8556===================================\n",
      "8556/10000: train_loss: 2.7902364959276746 train_error 23.75% test_error 15.50%\n",
      "================================8557===================================\n",
      "8557/10000: train_loss: 2.790032060877693 train_error 23.75% test_error 15.50%\n",
      "================================8558===================================\n",
      "8558/10000: train_loss: 2.789824992920167 train_error 23.75% test_error 15.50%\n",
      "================================8559===================================\n",
      "8559/10000: train_loss: 2.789617768014359 train_error 23.75% test_error 15.50%\n",
      "================================8560===================================\n",
      "8560/10000: train_loss: 2.7894108664141273 train_error 23.75% test_error 15.50%\n",
      "================================8561===================================\n",
      "8561/10000: train_loss: 2.7892044408674885 train_error 23.75% test_error 15.50%\n",
      "================================8562===================================\n",
      "8562/10000: train_loss: 2.788999668456472 train_error 23.75% test_error 15.50%\n",
      "================================8563===================================\n",
      "8563/10000: train_loss: 2.78880751067647 train_error 23.75% test_error 15.50%\n",
      "================================8564===================================\n",
      "8564/10000: train_loss: 2.7886202730354674 train_error 23.75% test_error 15.50%\n",
      "================================8565===================================\n",
      "8565/10000: train_loss: 2.788429407659642 train_error 23.75% test_error 15.50%\n",
      "================================8566===================================\n",
      "8566/10000: train_loss: 2.7882362422100955 train_error 23.75% test_error 15.50%\n",
      "================================8567===================================\n",
      "8567/10000: train_loss: 2.7880468816309985 train_error 23.75% test_error 15.50%\n",
      "================================8568===================================\n",
      "8568/10000: train_loss: 2.7878588154346833 train_error 23.75% test_error 15.50%\n",
      "================================8569===================================\n",
      "8569/10000: train_loss: 2.7876673089861836 train_error 23.75% test_error 15.50%\n",
      "================================8570===================================\n",
      "8570/10000: train_loss: 2.78747687089839 train_error 23.88% test_error 15.50%\n",
      "================================8571===================================\n",
      "8571/10000: train_loss: 2.787290421696234 train_error 23.88% test_error 15.50%\n",
      "================================8572===================================\n",
      "8572/10000: train_loss: 2.787104079763831 train_error 23.88% test_error 15.50%\n",
      "================================8573===================================\n",
      "8573/10000: train_loss: 2.7869148674521056 train_error 23.88% test_error 15.50%\n",
      "================================8574===================================\n",
      "8574/10000: train_loss: 2.786722119564783 train_error 23.88% test_error 15.50%\n",
      "================================8575===================================\n",
      "8575/10000: train_loss: 2.786527919825894 train_error 23.88% test_error 15.50%\n",
      "================================8576===================================\n",
      "8576/10000: train_loss: 2.7863319333256187 train_error 23.88% test_error 15.50%\n",
      "================================8577===================================\n",
      "8577/10000: train_loss: 2.7861356741905183 train_error 23.75% test_error 15.50%\n",
      "================================8578===================================\n",
      "8578/10000: train_loss: 2.785939906719359 train_error 23.75% test_error 15.50%\n",
      "================================8579===================================\n",
      "8579/10000: train_loss: 2.785741412260222 train_error 23.75% test_error 15.50%\n",
      "================================8580===================================\n",
      "8580/10000: train_loss: 2.785542624305372 train_error 23.75% test_error 15.50%\n",
      "================================8581===================================\n",
      "8581/10000: train_loss: 2.7853463807565553 train_error 23.75% test_error 15.50%\n",
      "================================8582===================================\n",
      "8582/10000: train_loss: 2.7851476433980134 train_error 23.75% test_error 15.50%\n",
      "================================8583===================================\n",
      "8583/10000: train_loss: 2.78494584415962 train_error 23.75% test_error 15.50%\n",
      "================================8584===================================\n",
      "8584/10000: train_loss: 2.7847438100831186 train_error 23.50% test_error 15.00%\n",
      "================================8585===================================\n",
      "8585/10000: train_loss: 2.784545047871561 train_error 23.50% test_error 15.00%\n",
      "================================8586===================================\n",
      "8586/10000: train_loss: 2.78434525213037 train_error 23.50% test_error 15.00%\n",
      "================================8587===================================\n",
      "8587/10000: train_loss: 2.784146581679633 train_error 23.50% test_error 15.00%\n",
      "================================8588===================================\n",
      "8588/10000: train_loss: 2.7839470966326827 train_error 23.50% test_error 15.00%\n",
      "================================8589===================================\n",
      "8589/10000: train_loss: 2.7837445458171444 train_error 23.50% test_error 15.00%\n",
      "================================8590===================================\n",
      "8590/10000: train_loss: 2.783541376425201 train_error 23.50% test_error 15.00%\n",
      "================================8591===================================\n",
      "8591/10000: train_loss: 2.783338042681435 train_error 23.50% test_error 14.50%\n",
      "================================8592===================================\n",
      "8592/10000: train_loss: 2.7831333003163308 train_error 23.50% test_error 14.50%\n",
      "================================8593===================================\n",
      "8593/10000: train_loss: 2.7829289574448737 train_error 23.50% test_error 14.50%\n",
      "================================8594===================================\n",
      "8594/10000: train_loss: 2.782726364432201 train_error 23.50% test_error 14.50%\n",
      "================================8595===================================\n",
      "8595/10000: train_loss: 2.782524157215457 train_error 23.50% test_error 14.50%\n",
      "================================8596===================================\n",
      "8596/10000: train_loss: 2.782324958075005 train_error 23.38% test_error 14.50%\n",
      "================================8597===================================\n",
      "8597/10000: train_loss: 2.7821272605527883 train_error 23.38% test_error 14.50%\n",
      "================================8598===================================\n",
      "8598/10000: train_loss: 2.781933026050228 train_error 23.25% test_error 14.50%\n",
      "================================8599===================================\n",
      "8599/10000: train_loss: 2.7817383526425874 train_error 23.12% test_error 14.50%\n",
      "================================8600===================================\n",
      "8600/10000: train_loss: 2.7815409032782186 train_error 22.88% test_error 14.50%\n",
      "================================8601===================================\n",
      "8601/10000: train_loss: 2.7813477139567837 train_error 22.75% test_error 14.50%\n",
      "================================8602===================================\n",
      "8602/10000: train_loss: 2.781154467340393 train_error 22.75% test_error 14.50%\n",
      "================================8603===================================\n",
      "8603/10000: train_loss: 2.7809615770632443 train_error 22.62% test_error 14.50%\n",
      "================================8604===================================\n",
      "8604/10000: train_loss: 2.7807709234913633 train_error 22.62% test_error 14.50%\n",
      "================================8605===================================\n",
      "8605/10000: train_loss: 2.78058097572758 train_error 22.62% test_error 14.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8606===================================\n",
      "8606/10000: train_loss: 2.7803941132290397 train_error 22.50% test_error 14.50%\n",
      "================================8607===================================\n",
      "8607/10000: train_loss: 2.780213206155622 train_error 22.38% test_error 14.50%\n",
      "================================8608===================================\n",
      "8608/10000: train_loss: 2.7800388503055 train_error 22.38% test_error 14.50%\n",
      "================================8609===================================\n",
      "8609/10000: train_loss: 2.7798655905445138 train_error 22.38% test_error 14.50%\n",
      "================================8610===================================\n",
      "8610/10000: train_loss: 2.7796927248443897 train_error 22.38% test_error 14.50%\n",
      "================================8611===================================\n",
      "8611/10000: train_loss: 2.7795157175978966 train_error 22.12% test_error 14.50%\n",
      "================================8612===================================\n",
      "8612/10000: train_loss: 2.7793357978647695 train_error 22.12% test_error 14.50%\n",
      "================================8613===================================\n",
      "8613/10000: train_loss: 2.779152771191839 train_error 22.12% test_error 14.50%\n",
      "================================8614===================================\n",
      "8614/10000: train_loss: 2.7789636962969233 train_error 22.12% test_error 14.50%\n",
      "================================8615===================================\n",
      "8615/10000: train_loss: 2.7787728609644455 train_error 21.88% test_error 14.50%\n",
      "================================8616===================================\n",
      "8616/10000: train_loss: 2.7785803988162665 train_error 21.88% test_error 14.50%\n",
      "================================8617===================================\n",
      "8617/10000: train_loss: 2.7783917679853767 train_error 21.88% test_error 14.50%\n",
      "================================8618===================================\n",
      "8618/10000: train_loss: 2.7782010624305347 train_error 21.75% test_error 14.50%\n",
      "================================8619===================================\n",
      "8619/10000: train_loss: 2.778006411920833 train_error 21.75% test_error 14.50%\n",
      "================================8620===================================\n",
      "8620/10000: train_loss: 2.777805281771962 train_error 21.75% test_error 14.50%\n",
      "================================8621===================================\n",
      "8621/10000: train_loss: 2.7776023071829967 train_error 21.75% test_error 14.50%\n",
      "================================8622===================================\n",
      "8622/10000: train_loss: 2.777400569268111 train_error 21.75% test_error 14.50%\n",
      "================================8623===================================\n",
      "8623/10000: train_loss: 2.777199660022443 train_error 21.75% test_error 14.50%\n",
      "================================8624===================================\n",
      "8624/10000: train_loss: 2.7769987940786995 train_error 21.75% test_error 14.50%\n",
      "================================8625===================================\n",
      "8625/10000: train_loss: 2.7767996017740186 train_error 21.50% test_error 14.50%\n",
      "================================8626===================================\n",
      "8626/10000: train_loss: 2.776600701571388 train_error 21.50% test_error 14.50%\n",
      "================================8627===================================\n",
      "8627/10000: train_loss: 2.7764021874186438 train_error 21.12% test_error 14.50%\n",
      "================================8628===================================\n",
      "8628/10000: train_loss: 2.7762016510926335 train_error 21.25% test_error 14.50%\n",
      "================================8629===================================\n",
      "8629/10000: train_loss: 2.775994593218802 train_error 21.25% test_error 14.00%\n",
      "================================8630===================================\n",
      "8630/10000: train_loss: 2.775784295303274 train_error 21.00% test_error 14.00%\n",
      "================================8631===================================\n",
      "8631/10000: train_loss: 2.7755685601067945 train_error 21.00% test_error 14.00%\n",
      "================================8632===================================\n",
      "8632/10000: train_loss: 2.775349381092192 train_error 20.88% test_error 13.50%\n",
      "================================8633===================================\n",
      "8633/10000: train_loss: 2.77513102750474 train_error 20.88% test_error 13.50%\n",
      "================================8634===================================\n",
      "8634/10000: train_loss: 2.7749110468774596 train_error 20.88% test_error 13.50%\n",
      "================================8635===================================\n",
      "8635/10000: train_loss: 2.774689395998221 train_error 20.88% test_error 13.50%\n",
      "================================8636===================================\n",
      "8636/10000: train_loss: 2.774468616020731 train_error 20.88% test_error 13.50%\n",
      "================================8637===================================\n",
      "8637/10000: train_loss: 2.774248897118378 train_error 20.88% test_error 13.50%\n",
      "================================8638===================================\n",
      "8638/10000: train_loss: 2.7740301934374294 train_error 20.88% test_error 13.50%\n",
      "================================8639===================================\n",
      "8639/10000: train_loss: 2.7738136679228136 train_error 20.88% test_error 13.50%\n",
      "================================8640===================================\n",
      "8640/10000: train_loss: 2.7735978339121536 train_error 20.88% test_error 13.50%\n",
      "================================8641===================================\n",
      "8641/10000: train_loss: 2.773381731037589 train_error 20.88% test_error 13.50%\n",
      "================================8642===================================\n",
      "8642/10000: train_loss: 2.7731628691309744 train_error 20.88% test_error 13.50%\n",
      "================================8643===================================\n",
      "8643/10000: train_loss: 2.772937222403225 train_error 20.88% test_error 13.50%\n",
      "================================8644===================================\n",
      "8644/10000: train_loss: 2.772712273110928 train_error 20.75% test_error 13.50%\n",
      "================================8645===================================\n",
      "8645/10000: train_loss: 2.772487783210199 train_error 20.62% test_error 13.50%\n",
      "================================8646===================================\n",
      "8646/10000: train_loss: 2.7722636189968672 train_error 20.62% test_error 13.50%\n",
      "================================8647===================================\n",
      "8647/10000: train_loss: 2.7720416733084856 train_error 20.62% test_error 13.50%\n",
      "================================8648===================================\n",
      "8648/10000: train_loss: 2.771822620401681 train_error 20.50% test_error 13.50%\n",
      "================================8649===================================\n",
      "8649/10000: train_loss: 2.771606438938334 train_error 20.38% test_error 13.50%\n",
      "================================8650===================================\n",
      "8650/10000: train_loss: 2.7713928370108625 train_error 20.38% test_error 13.50%\n",
      "================================8651===================================\n",
      "8651/10000: train_loss: 2.771179696917852 train_error 20.38% test_error 13.50%\n",
      "================================8652===================================\n",
      "8652/10000: train_loss: 2.7709619892366484 train_error 20.38% test_error 13.50%\n",
      "================================8653===================================\n",
      "8653/10000: train_loss: 2.7707471421272567 train_error 20.25% test_error 13.00%\n",
      "================================8654===================================\n",
      "8654/10000: train_loss: 2.770531232535013 train_error 20.12% test_error 13.00%\n",
      "================================8655===================================\n",
      "8655/10000: train_loss: 2.7703159126448553 train_error 20.00% test_error 13.00%\n",
      "================================8656===================================\n",
      "8656/10000: train_loss: 2.7700980846023135 train_error 19.88% test_error 13.00%\n",
      "================================8657===================================\n",
      "8657/10000: train_loss: 2.769878850661771 train_error 19.88% test_error 12.50%\n",
      "================================8658===================================\n",
      "8658/10000: train_loss: 2.769665241891389 train_error 19.75% test_error 12.50%\n",
      "================================8659===================================\n",
      "8659/10000: train_loss: 2.7694528466912103 train_error 19.75% test_error 12.50%\n",
      "================================8660===================================\n",
      "8660/10000: train_loss: 2.76924233419596 train_error 19.75% test_error 12.50%\n",
      "================================8661===================================\n",
      "8661/10000: train_loss: 2.7690313565536506 train_error 19.75% test_error 12.50%\n",
      "================================8662===================================\n",
      "8662/10000: train_loss: 2.768820084368581 train_error 19.75% test_error 12.00%\n",
      "================================8663===================================\n",
      "8663/10000: train_loss: 2.768606998477517 train_error 19.75% test_error 12.00%\n",
      "================================8664===================================\n",
      "8664/10000: train_loss: 2.768394344557064 train_error 19.75% test_error 12.00%\n",
      "================================8665===================================\n",
      "8665/10000: train_loss: 2.7681841969926335 train_error 19.75% test_error 12.00%\n",
      "================================8666===================================\n",
      "8666/10000: train_loss: 2.767975177140197 train_error 19.75% test_error 12.00%\n",
      "================================8667===================================\n",
      "8667/10000: train_loss: 2.7677692443931026 train_error 19.75% test_error 12.00%\n",
      "================================8668===================================\n",
      "8668/10000: train_loss: 2.767563194636914 train_error 19.62% test_error 12.00%\n",
      "================================8669===================================\n",
      "8669/10000: train_loss: 2.7673559922583446 train_error 19.62% test_error 12.00%\n",
      "================================8670===================================\n",
      "8670/10000: train_loss: 2.7671489255658615 train_error 19.62% test_error 12.00%\n",
      "================================8671===================================\n",
      "8671/10000: train_loss: 2.766942534176651 train_error 19.38% test_error 12.00%\n",
      "================================8672===================================\n",
      "8672/10000: train_loss: 2.7667367508296232 train_error 19.38% test_error 12.00%\n",
      "================================8673===================================\n",
      "8673/10000: train_loss: 2.7665318597945405 train_error 19.25% test_error 12.00%\n",
      "================================8674===================================\n",
      "8674/10000: train_loss: 2.766329051754874 train_error 19.12% test_error 12.00%\n",
      "================================8675===================================\n",
      "8675/10000: train_loss: 2.766127333991208 train_error 19.12% test_error 12.00%\n",
      "================================8676===================================\n",
      "8676/10000: train_loss: 2.7659258388724175 train_error 19.00% test_error 12.00%\n",
      "================================8677===================================\n",
      "8677/10000: train_loss: 2.7657246714053416 train_error 19.00% test_error 12.00%\n",
      "================================8678===================================\n",
      "8678/10000: train_loss: 2.7655234986100368 train_error 19.00% test_error 12.00%\n",
      "================================8679===================================\n",
      "8679/10000: train_loss: 2.7653218349153215 train_error 18.88% test_error 12.00%\n",
      "================================8680===================================\n",
      "8680/10000: train_loss: 2.765121181812738 train_error 18.88% test_error 12.00%\n",
      "================================8681===================================\n",
      "8681/10000: train_loss: 2.7649170020017935 train_error 18.75% test_error 12.00%\n",
      "================================8682===================================\n",
      "8682/10000: train_loss: 2.76470979435735 train_error 18.62% test_error 12.00%\n",
      "================================8683===================================\n",
      "8683/10000: train_loss: 2.764501918936994 train_error 18.62% test_error 12.00%\n",
      "================================8684===================================\n",
      "8684/10000: train_loss: 2.7642942455766475 train_error 18.62% test_error 12.00%\n",
      "================================8685===================================\n",
      "8685/10000: train_loss: 2.7640888850744245 train_error 18.62% test_error 12.00%\n",
      "================================8686===================================\n",
      "8686/10000: train_loss: 2.7638777017007214 train_error 18.75% test_error 12.00%\n",
      "================================8687===================================\n",
      "8687/10000: train_loss: 2.7636678992544055 train_error 18.62% test_error 12.00%\n",
      "================================8688===================================\n",
      "8688/10000: train_loss: 2.7634595656733287 train_error 18.62% test_error 12.00%\n",
      "================================8689===================================\n",
      "8689/10000: train_loss: 2.7632528866127903 train_error 18.62% test_error 12.00%\n",
      "================================8690===================================\n",
      "8690/10000: train_loss: 2.763045166683105 train_error 18.62% test_error 12.00%\n",
      "================================8691===================================\n",
      "8691/10000: train_loss: 2.7628339710868843 train_error 18.62% test_error 12.00%\n",
      "================================8692===================================\n",
      "8692/10000: train_loss: 2.7626226767097797 train_error 18.50% test_error 12.00%\n",
      "================================8693===================================\n",
      "8693/10000: train_loss: 2.76241380903909 train_error 18.50% test_error 12.00%\n",
      "================================8694===================================\n",
      "8694/10000: train_loss: 2.7622088042527317 train_error 18.50% test_error 12.00%\n",
      "================================8695===================================\n",
      "8695/10000: train_loss: 2.762009397772008 train_error 18.50% test_error 12.00%\n",
      "================================8696===================================\n",
      "8696/10000: train_loss: 2.761812431017788 train_error 18.50% test_error 12.00%\n",
      "================================8697===================================\n",
      "8697/10000: train_loss: 2.7616171708457475 train_error 18.50% test_error 12.00%\n",
      "================================8698===================================\n",
      "8698/10000: train_loss: 2.761424968552174 train_error 18.38% test_error 12.00%\n",
      "================================8699===================================\n",
      "8699/10000: train_loss: 2.761226203766746 train_error 18.38% test_error 12.00%\n",
      "================================8700===================================\n",
      "8700/10000: train_loss: 2.761026410533168 train_error 18.38% test_error 12.00%\n",
      "================================8701===================================\n",
      "8701/10000: train_loss: 2.76082280928219 train_error 18.38% test_error 12.00%\n",
      "================================8702===================================\n",
      "8702/10000: train_loss: 2.7606197167528537 train_error 18.38% test_error 12.00%\n",
      "================================8703===================================\n",
      "8703/10000: train_loss: 2.760418332344889 train_error 18.25% test_error 12.00%\n",
      "================================8704===================================\n",
      "8704/10000: train_loss: 2.76021547768687 train_error 18.12% test_error 12.00%\n",
      "================================8705===================================\n",
      "8705/10000: train_loss: 2.760012242806233 train_error 18.12% test_error 12.00%\n",
      "================================8706===================================\n",
      "8706/10000: train_loss: 2.7598100325645647 train_error 18.12% test_error 12.00%\n",
      "================================8707===================================\n",
      "8707/10000: train_loss: 2.759611398208226 train_error 18.00% test_error 12.00%\n",
      "================================8708===================================\n",
      "8708/10000: train_loss: 2.7594132572249146 train_error 17.88% test_error 12.00%\n",
      "================================8709===================================\n",
      "8709/10000: train_loss: 2.7592180598573304 train_error 17.88% test_error 12.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8710===================================\n",
      "8710/10000: train_loss: 2.7590259904238614 train_error 17.88% test_error 12.00%\n",
      "================================8711===================================\n",
      "8711/10000: train_loss: 2.7588374528466737 train_error 17.88% test_error 12.00%\n",
      "================================8712===================================\n",
      "8712/10000: train_loss: 2.758650015337721 train_error 17.88% test_error 12.00%\n",
      "================================8713===================================\n",
      "8713/10000: train_loss: 2.7584632173278396 train_error 17.75% test_error 12.00%\n",
      "================================8714===================================\n",
      "8714/10000: train_loss: 2.758277298909038 train_error 17.75% test_error 12.00%\n",
      "================================8715===================================\n",
      "8715/10000: train_loss: 2.758092146087656 train_error 17.75% test_error 12.00%\n",
      "================================8716===================================\n",
      "8716/10000: train_loss: 2.757907402103524 train_error 17.62% test_error 12.00%\n",
      "================================8717===================================\n",
      "8717/10000: train_loss: 2.7577239993060174 train_error 17.62% test_error 12.00%\n",
      "================================8718===================================\n",
      "8718/10000: train_loss: 2.7575387323185123 train_error 17.50% test_error 12.00%\n",
      "================================8719===================================\n",
      "8719/10000: train_loss: 2.757355125410227 train_error 17.50% test_error 12.00%\n",
      "================================8720===================================\n",
      "8720/10000: train_loss: 2.7571703039533304 train_error 17.38% test_error 12.00%\n",
      "================================8721===================================\n",
      "8721/10000: train_loss: 2.7569900996011256 train_error 17.25% test_error 12.00%\n",
      "================================8722===================================\n",
      "8722/10000: train_loss: 2.756810099620866 train_error 17.25% test_error 12.00%\n",
      "================================8723===================================\n",
      "8723/10000: train_loss: 2.7566296258405965 train_error 17.25% test_error 12.00%\n",
      "================================8724===================================\n",
      "8724/10000: train_loss: 2.7564495643515237 train_error 17.25% test_error 12.00%\n",
      "================================8725===================================\n",
      "8725/10000: train_loss: 2.7562698504919627 train_error 17.25% test_error 12.50%\n",
      "================================8726===================================\n",
      "8726/10000: train_loss: 2.756085850388045 train_error 17.25% test_error 12.50%\n",
      "================================8727===================================\n",
      "8727/10000: train_loss: 2.755893137397834 train_error 17.25% test_error 12.50%\n",
      "================================8728===================================\n",
      "8728/10000: train_loss: 2.7557008105153367 train_error 17.25% test_error 12.00%\n",
      "================================8729===================================\n",
      "8729/10000: train_loss: 2.7555077305973645 train_error 17.25% test_error 12.00%\n",
      "================================8730===================================\n",
      "8730/10000: train_loss: 2.755316016995444 train_error 17.12% test_error 12.00%\n",
      "================================8731===================================\n",
      "8731/10000: train_loss: 2.7551266057925203 train_error 17.12% test_error 12.00%\n",
      "================================8732===================================\n",
      "8732/10000: train_loss: 2.7549384314039163 train_error 17.12% test_error 11.50%\n",
      "================================8733===================================\n",
      "8733/10000: train_loss: 2.7547533507163324 train_error 17.12% test_error 11.50%\n",
      "================================8734===================================\n",
      "8734/10000: train_loss: 2.754570139910838 train_error 17.12% test_error 11.50%\n",
      "================================8735===================================\n",
      "8735/10000: train_loss: 2.7543907779267647 train_error 17.12% test_error 11.50%\n",
      "================================8736===================================\n",
      "8736/10000: train_loss: 2.7542102207326753 train_error 17.00% test_error 11.50%\n",
      "================================8737===================================\n",
      "8737/10000: train_loss: 2.7540230575619216 train_error 16.88% test_error 11.50%\n",
      "================================8738===================================\n",
      "8738/10000: train_loss: 2.7538319913255873 train_error 16.88% test_error 11.50%\n",
      "================================8739===================================\n",
      "8739/10000: train_loss: 2.7536415307293285 train_error 16.88% test_error 11.00%\n",
      "================================8740===================================\n",
      "8740/10000: train_loss: 2.753457637052966 train_error 16.88% test_error 11.00%\n",
      "================================8741===================================\n",
      "8741/10000: train_loss: 2.7532794433463055 train_error 16.88% test_error 11.00%\n",
      "================================8742===================================\n",
      "8742/10000: train_loss: 2.753102488839631 train_error 16.88% test_error 11.00%\n",
      "================================8743===================================\n",
      "8743/10000: train_loss: 2.752926884137646 train_error 16.88% test_error 11.00%\n",
      "================================8744===================================\n",
      "8744/10000: train_loss: 2.752750762175069 train_error 16.88% test_error 11.00%\n",
      "================================8745===================================\n",
      "8745/10000: train_loss: 2.7525778165065957 train_error 16.88% test_error 11.00%\n",
      "================================8746===================================\n",
      "8746/10000: train_loss: 2.752404396621278 train_error 16.75% test_error 11.00%\n",
      "================================8747===================================\n",
      "8747/10000: train_loss: 2.7522317278986703 train_error 16.88% test_error 11.00%\n",
      "================================8748===================================\n",
      "8748/10000: train_loss: 2.752059132130339 train_error 16.75% test_error 11.00%\n",
      "================================8749===================================\n",
      "8749/10000: train_loss: 2.75188822736448 train_error 16.50% test_error 11.00%\n",
      "================================8750===================================\n",
      "8750/10000: train_loss: 2.751716745782742 train_error 16.50% test_error 11.00%\n",
      "================================8751===================================\n",
      "8751/10000: train_loss: 2.751545434566715 train_error 16.50% test_error 11.00%\n",
      "================================8752===================================\n",
      "8752/10000: train_loss: 2.751374379463673 train_error 16.50% test_error 11.00%\n",
      "================================8753===================================\n",
      "8753/10000: train_loss: 2.7512042062150113 train_error 16.50% test_error 11.00%\n",
      "================================8754===================================\n",
      "8754/10000: train_loss: 2.7510347075038406 train_error 16.50% test_error 10.50%\n",
      "================================8755===================================\n",
      "8755/10000: train_loss: 2.7508673926489067 train_error 16.50% test_error 10.50%\n",
      "================================8756===================================\n",
      "8756/10000: train_loss: 2.7507019634582504 train_error 16.50% test_error 10.50%\n",
      "================================8757===================================\n",
      "8757/10000: train_loss: 2.7505354279381615 train_error 16.50% test_error 11.00%\n",
      "================================8758===================================\n",
      "8758/10000: train_loss: 2.7503680288074746 train_error 16.50% test_error 11.00%\n",
      "================================8759===================================\n",
      "8759/10000: train_loss: 2.7502017062184496 train_error 16.50% test_error 11.00%\n",
      "================================8760===================================\n",
      "8760/10000: train_loss: 2.7500388706323795 train_error 16.50% test_error 11.00%\n",
      "================================8761===================================\n",
      "8761/10000: train_loss: 2.7498777484122914 train_error 16.50% test_error 11.00%\n",
      "================================8762===================================\n",
      "8762/10000: train_loss: 2.749718063404857 train_error 16.50% test_error 11.00%\n",
      "================================8763===================================\n",
      "8763/10000: train_loss: 2.7495581936387223 train_error 16.50% test_error 11.00%\n",
      "================================8764===================================\n",
      "8764/10000: train_loss: 2.7494011284095627 train_error 16.38% test_error 11.00%\n",
      "================================8765===================================\n",
      "8765/10000: train_loss: 2.749247251648812 train_error 16.12% test_error 11.00%\n",
      "================================8766===================================\n",
      "8766/10000: train_loss: 2.749094900073474 train_error 16.12% test_error 11.00%\n",
      "================================8767===================================\n",
      "8767/10000: train_loss: 2.748942283908427 train_error 16.12% test_error 11.00%\n",
      "================================8768===================================\n",
      "8768/10000: train_loss: 2.7487878164428095 train_error 16.12% test_error 11.00%\n",
      "================================8769===================================\n",
      "8769/10000: train_loss: 2.748634881455182 train_error 16.12% test_error 11.00%\n",
      "================================8770===================================\n",
      "8770/10000: train_loss: 2.7484821262101424 train_error 16.00% test_error 11.00%\n",
      "================================8771===================================\n",
      "8771/10000: train_loss: 2.7483331975579675 train_error 16.00% test_error 11.00%\n",
      "================================8772===================================\n",
      "8772/10000: train_loss: 2.748181364304273 train_error 15.75% test_error 11.00%\n",
      "================================8773===================================\n",
      "8773/10000: train_loss: 2.7480251846550985 train_error 15.75% test_error 11.00%\n",
      "================================8774===================================\n",
      "8774/10000: train_loss: 2.747870297478653 train_error 15.75% test_error 11.00%\n",
      "================================8775===================================\n",
      "8775/10000: train_loss: 2.7477144067840893 train_error 15.75% test_error 11.00%\n",
      "================================8776===================================\n",
      "8776/10000: train_loss: 2.747556708534726 train_error 15.75% test_error 11.00%\n",
      "================================8777===================================\n",
      "8777/10000: train_loss: 2.747397681235948 train_error 15.62% test_error 11.00%\n",
      "================================8778===================================\n",
      "8778/10000: train_loss: 2.747239340811175 train_error 15.62% test_error 11.00%\n",
      "================================8779===================================\n",
      "8779/10000: train_loss: 2.747082107257147 train_error 15.62% test_error 11.00%\n",
      "================================8780===================================\n",
      "8780/10000: train_loss: 2.7469253147973767 train_error 15.62% test_error 11.00%\n",
      "================================8781===================================\n",
      "8781/10000: train_loss: 2.746763969900544 train_error 15.62% test_error 11.00%\n",
      "================================8782===================================\n",
      "8782/10000: train_loss: 2.7466016081826505 train_error 15.62% test_error 10.50%\n",
      "================================8783===================================\n",
      "8783/10000: train_loss: 2.7464401349546277 train_error 15.50% test_error 10.50%\n",
      "================================8784===================================\n",
      "8784/10000: train_loss: 2.7462807525625745 train_error 15.50% test_error 10.50%\n",
      "================================8785===================================\n",
      "8785/10000: train_loss: 2.74612175136378 train_error 15.50% test_error 10.50%\n",
      "================================8786===================================\n",
      "8786/10000: train_loss: 2.745966231736047 train_error 15.50% test_error 10.50%\n",
      "================================8787===================================\n",
      "8787/10000: train_loss: 2.7458175311520376 train_error 15.50% test_error 10.50%\n",
      "================================8788===================================\n",
      "8788/10000: train_loss: 2.7456734247738313 train_error 15.50% test_error 10.50%\n",
      "================================8789===================================\n",
      "8789/10000: train_loss: 2.7455285355064643 train_error 15.50% test_error 10.50%\n",
      "================================8790===================================\n",
      "8790/10000: train_loss: 2.745383789688085 train_error 15.50% test_error 10.50%\n",
      "================================8791===================================\n",
      "8791/10000: train_loss: 2.745238687640995 train_error 15.50% test_error 10.50%\n",
      "================================8792===================================\n",
      "8792/10000: train_loss: 2.745094014925353 train_error 15.50% test_error 10.50%\n",
      "================================8793===================================\n",
      "8793/10000: train_loss: 2.7449490342388208 train_error 15.62% test_error 10.50%\n",
      "================================8794===================================\n",
      "8794/10000: train_loss: 2.744801543646076 train_error 15.75% test_error 10.00%\n",
      "================================8795===================================\n",
      "8795/10000: train_loss: 2.744652285491188 train_error 15.75% test_error 10.00%\n",
      "================================8796===================================\n",
      "8796/10000: train_loss: 2.744498120364615 train_error 15.75% test_error 10.00%\n",
      "================================8797===================================\n",
      "8797/10000: train_loss: 2.7443383314401353 train_error 15.75% test_error 10.00%\n",
      "================================8798===================================\n",
      "8798/10000: train_loss: 2.7441784935026767 train_error 15.50% test_error 10.00%\n",
      "================================8799===================================\n",
      "8799/10000: train_loss: 2.7440191398790374 train_error 15.50% test_error 10.00%\n",
      "================================8800===================================\n",
      "8800/10000: train_loss: 2.7438608890985323 train_error 15.50% test_error 10.00%\n",
      "================================8801===================================\n",
      "8801/10000: train_loss: 2.7437023812152983 train_error 15.38% test_error 10.00%\n",
      "================================8802===================================\n",
      "8802/10000: train_loss: 2.7435391882150677 train_error 15.38% test_error 10.00%\n",
      "================================8803===================================\n",
      "8803/10000: train_loss: 2.743375131051707 train_error 15.38% test_error 10.00%\n",
      "================================8804===================================\n",
      "8804/10000: train_loss: 2.7432120430426674 train_error 15.38% test_error 10.00%\n",
      "================================8805===================================\n",
      "8805/10000: train_loss: 2.7430480584540873 train_error 15.38% test_error 10.00%\n",
      "================================8806===================================\n",
      "8806/10000: train_loss: 2.7428855735972957 train_error 15.38% test_error 10.00%\n",
      "================================8807===================================\n",
      "8807/10000: train_loss: 2.742724737172603 train_error 15.38% test_error 10.00%\n",
      "================================8808===================================\n",
      "8808/10000: train_loss: 2.742564229961035 train_error 15.38% test_error 10.00%\n",
      "================================8809===================================\n",
      "8809/10000: train_loss: 2.7424026436666415 train_error 15.38% test_error 10.00%\n",
      "================================8810===================================\n",
      "8810/10000: train_loss: 2.742239885259569 train_error 15.25% test_error 10.00%\n",
      "================================8811===================================\n",
      "8811/10000: train_loss: 2.742077822360798 train_error 15.25% test_error 10.00%\n",
      "================================8812===================================\n",
      "8812/10000: train_loss: 2.741912963646741 train_error 15.12% test_error 10.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8813===================================\n",
      "8813/10000: train_loss: 2.741742493296597 train_error 15.12% test_error 10.00%\n",
      "================================8814===================================\n",
      "8814/10000: train_loss: 2.741573086411168 train_error 15.12% test_error 10.00%\n",
      "================================8815===================================\n",
      "8815/10000: train_loss: 2.7414045133893206 train_error 15.12% test_error 10.00%\n",
      "================================8816===================================\n",
      "8816/10000: train_loss: 2.741240889314968 train_error 15.12% test_error 10.00%\n",
      "================================8817===================================\n",
      "8817/10000: train_loss: 2.741078507956181 train_error 15.12% test_error 10.00%\n",
      "================================8818===================================\n",
      "8818/10000: train_loss: 2.7409191741049383 train_error 15.12% test_error 10.00%\n",
      "================================8819===================================\n",
      "8819/10000: train_loss: 2.7407581004669606 train_error 15.12% test_error 10.00%\n",
      "================================8820===================================\n",
      "8820/10000: train_loss: 2.7405977086203936 train_error 15.12% test_error 10.00%\n",
      "================================8821===================================\n",
      "8821/10000: train_loss: 2.7404398694459453 train_error 15.12% test_error 10.00%\n",
      "================================8822===================================\n",
      "8822/10000: train_loss: 2.740284657183174 train_error 15.12% test_error 10.00%\n",
      "================================8823===================================\n",
      "8823/10000: train_loss: 2.7401300509928115 train_error 15.12% test_error 10.00%\n",
      "================================8824===================================\n",
      "8824/10000: train_loss: 2.7399769159756717 train_error 15.00% test_error 10.00%\n",
      "================================8825===================================\n",
      "8825/10000: train_loss: 2.739820001768007 train_error 14.88% test_error 10.00%\n",
      "================================8826===================================\n",
      "8826/10000: train_loss: 2.7396600457071556 train_error 15.00% test_error 10.00%\n",
      "================================8827===================================\n",
      "8827/10000: train_loss: 2.739502120748343 train_error 15.12% test_error 10.00%\n",
      "================================8828===================================\n",
      "8828/10000: train_loss: 2.739344431040599 train_error 15.00% test_error 9.50%\n",
      "================================8829===================================\n",
      "8829/10000: train_loss: 2.739185855760507 train_error 15.00% test_error 9.50%\n",
      "================================8830===================================\n",
      "8830/10000: train_loss: 2.7390265238146636 train_error 15.00% test_error 9.50%\n",
      "================================8831===================================\n",
      "8831/10000: train_loss: 2.7388684299054105 train_error 14.88% test_error 9.50%\n",
      "================================8832===================================\n",
      "8832/10000: train_loss: 2.738709333860129 train_error 14.75% test_error 9.50%\n",
      "================================8833===================================\n",
      "8833/10000: train_loss: 2.7385504586103524 train_error 14.75% test_error 9.50%\n",
      "================================8834===================================\n",
      "8834/10000: train_loss: 2.7383882229535494 train_error 14.75% test_error 9.50%\n",
      "================================8835===================================\n",
      "8835/10000: train_loss: 2.7382236046790602 train_error 14.88% test_error 9.50%\n",
      "================================8836===================================\n",
      "8836/10000: train_loss: 2.7380599467710685 train_error 14.88% test_error 9.50%\n",
      "================================8837===================================\n",
      "8837/10000: train_loss: 2.7379021876412573 train_error 14.75% test_error 9.50%\n",
      "================================8838===================================\n",
      "8838/10000: train_loss: 2.73774189216555 train_error 14.75% test_error 9.50%\n",
      "================================8839===================================\n",
      "8839/10000: train_loss: 2.737577476555366 train_error 14.75% test_error 10.00%\n",
      "================================8840===================================\n",
      "8840/10000: train_loss: 2.7374147053391695 train_error 14.75% test_error 10.00%\n",
      "================================8841===================================\n",
      "8841/10000: train_loss: 2.7372558343981135 train_error 14.75% test_error 10.00%\n",
      "================================8842===================================\n",
      "8842/10000: train_loss: 2.7370978815666964 train_error 14.75% test_error 10.00%\n",
      "================================8843===================================\n",
      "8843/10000: train_loss: 2.736941396173031 train_error 14.75% test_error 10.00%\n",
      "================================8844===================================\n",
      "8844/10000: train_loss: 2.736787873339158 train_error 14.75% test_error 10.00%\n",
      "================================8845===================================\n",
      "8845/10000: train_loss: 2.7366396629294742 train_error 14.75% test_error 10.00%\n",
      "================================8846===================================\n",
      "8846/10000: train_loss: 2.736494302077069 train_error 14.75% test_error 10.00%\n",
      "================================8847===================================\n",
      "8847/10000: train_loss: 2.736345372918281 train_error 14.75% test_error 10.00%\n",
      "================================8848===================================\n",
      "8848/10000: train_loss: 2.736194174308525 train_error 14.88% test_error 10.00%\n",
      "================================8849===================================\n",
      "8849/10000: train_loss: 2.736041724798697 train_error 15.00% test_error 10.00%\n",
      "================================8850===================================\n",
      "8850/10000: train_loss: 2.7358924582570037 train_error 15.00% test_error 10.00%\n",
      "================================8851===================================\n",
      "8851/10000: train_loss: 2.735745710592671 train_error 15.12% test_error 9.50%\n",
      "================================8852===================================\n",
      "8852/10000: train_loss: 2.7356045960328945 train_error 15.25% test_error 9.50%\n",
      "================================8853===================================\n",
      "8853/10000: train_loss: 2.7354655502652645 train_error 15.38% test_error 9.50%\n",
      "================================8854===================================\n",
      "8854/10000: train_loss: 2.735322467551971 train_error 15.38% test_error 9.50%\n",
      "================================8855===================================\n",
      "8855/10000: train_loss: 2.7351756689032936 train_error 15.38% test_error 9.50%\n",
      "================================8856===================================\n",
      "8856/10000: train_loss: 2.7350289100311533 train_error 15.38% test_error 9.50%\n",
      "================================8857===================================\n",
      "8857/10000: train_loss: 2.734882004502076 train_error 15.38% test_error 9.50%\n",
      "================================8858===================================\n",
      "8858/10000: train_loss: 2.734735721667598 train_error 15.38% test_error 9.50%\n",
      "================================8859===================================\n",
      "8859/10000: train_loss: 2.734592997661375 train_error 15.25% test_error 9.50%\n",
      "================================8860===================================\n",
      "8860/10000: train_loss: 2.734450946029963 train_error 15.25% test_error 9.50%\n",
      "================================8861===================================\n",
      "8861/10000: train_loss: 2.7343021038319377 train_error 15.25% test_error 9.50%\n",
      "================================8862===================================\n",
      "8862/10000: train_loss: 2.73415122280393 train_error 15.25% test_error 9.50%\n",
      "================================8863===================================\n",
      "8863/10000: train_loss: 2.7340019473434927 train_error 15.25% test_error 9.50%\n",
      "================================8864===================================\n",
      "8864/10000: train_loss: 2.733851478205006 train_error 15.25% test_error 9.50%\n",
      "================================8865===================================\n",
      "8865/10000: train_loss: 2.7337007943081173 train_error 15.25% test_error 9.50%\n",
      "================================8866===================================\n",
      "8866/10000: train_loss: 2.7335485362652503 train_error 15.12% test_error 9.50%\n",
      "================================8867===================================\n",
      "8867/10000: train_loss: 2.733390075979885 train_error 15.12% test_error 9.50%\n",
      "================================8868===================================\n",
      "8868/10000: train_loss: 2.7332306316138717 train_error 15.12% test_error 9.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8869===================================\n",
      "8869/10000: train_loss: 2.733070730396223 train_error 15.12% test_error 9.50%\n",
      "================================8870===================================\n",
      "8870/10000: train_loss: 2.7329085510862727 train_error 15.12% test_error 9.50%\n",
      "================================8871===================================\n",
      "8871/10000: train_loss: 2.7327474093787236 train_error 15.12% test_error 9.50%\n",
      "================================8872===================================\n",
      "8872/10000: train_loss: 2.732587005482128 train_error 15.12% test_error 9.00%\n",
      "================================8873===================================\n",
      "8873/10000: train_loss: 2.732429446854715 train_error 15.12% test_error 9.00%\n",
      "================================8874===================================\n",
      "8874/10000: train_loss: 2.7322725890688138 train_error 15.12% test_error 9.00%\n",
      "================================8875===================================\n",
      "8875/10000: train_loss: 2.7321140089858567 train_error 15.12% test_error 9.00%\n",
      "================================8876===================================\n",
      "8876/10000: train_loss: 2.7319561433890067 train_error 15.12% test_error 9.00%\n",
      "================================8877===================================\n",
      "8877/10000: train_loss: 2.7317948915222536 train_error 15.12% test_error 9.00%\n",
      "================================8878===================================\n",
      "8878/10000: train_loss: 2.731633806705868 train_error 15.12% test_error 9.00%\n",
      "================================8879===================================\n",
      "8879/10000: train_loss: 2.7314771722930393 train_error 15.00% test_error 9.00%\n",
      "================================8880===================================\n",
      "8880/10000: train_loss: 2.731313553690061 train_error 15.00% test_error 9.00%\n",
      "================================8881===================================\n",
      "8881/10000: train_loss: 2.7311485962540405 train_error 15.00% test_error 9.00%\n",
      "================================8882===================================\n",
      "8882/10000: train_loss: 2.7309852608863325 train_error 15.00% test_error 9.00%\n",
      "================================8883===================================\n",
      "8883/10000: train_loss: 2.730821804201796 train_error 15.00% test_error 9.00%\n",
      "================================8884===================================\n",
      "8884/10000: train_loss: 2.7306598217008107 train_error 15.00% test_error 9.00%\n",
      "================================8885===================================\n",
      "8885/10000: train_loss: 2.730500104884425 train_error 15.00% test_error 9.00%\n",
      "================================8886===================================\n",
      "8886/10000: train_loss: 2.7303424071460154 train_error 15.00% test_error 9.00%\n",
      "================================8887===================================\n",
      "8887/10000: train_loss: 2.7301870010272884 train_error 14.88% test_error 9.00%\n",
      "================================8888===================================\n",
      "8888/10000: train_loss: 2.7300362760532266 train_error 14.88% test_error 9.00%\n",
      "================================8889===================================\n",
      "8889/10000: train_loss: 2.7298908272203564 train_error 14.88% test_error 9.50%\n",
      "================================8890===================================\n",
      "8890/10000: train_loss: 2.729743856287935 train_error 14.75% test_error 9.50%\n",
      "================================8891===================================\n",
      "8891/10000: train_loss: 2.7295968209602823 train_error 14.75% test_error 9.50%\n",
      "================================8892===================================\n",
      "8892/10000: train_loss: 2.7294527155050243 train_error 14.75% test_error 9.50%\n",
      "================================8893===================================\n",
      "8893/10000: train_loss: 2.729313464026543 train_error 14.75% test_error 9.50%\n",
      "================================8894===================================\n",
      "8894/10000: train_loss: 2.729178207370394 train_error 14.75% test_error 9.50%\n",
      "================================8895===================================\n",
      "8895/10000: train_loss: 2.7290455800054425 train_error 14.75% test_error 9.50%\n",
      "================================8896===================================\n",
      "8896/10000: train_loss: 2.728911125503223 train_error 14.75% test_error 9.50%\n",
      "================================8897===================================\n",
      "8897/10000: train_loss: 2.7287730155205305 train_error 14.75% test_error 9.50%\n",
      "================================8898===================================\n",
      "8898/10000: train_loss: 2.7286354325283035 train_error 14.75% test_error 9.50%\n",
      "================================8899===================================\n",
      "8899/10000: train_loss: 2.7285026227591134 train_error 14.75% test_error 9.50%\n",
      "================================8900===================================\n",
      "8900/10000: train_loss: 2.7283710273248905 train_error 14.75% test_error 9.50%\n",
      "================================8901===================================\n",
      "8901/10000: train_loss: 2.728237858500502 train_error 14.75% test_error 9.50%\n",
      "================================8902===================================\n",
      "8902/10000: train_loss: 2.7281096869268344 train_error 14.75% test_error 9.50%\n",
      "================================8903===================================\n",
      "8903/10000: train_loss: 2.7279819258313185 train_error 14.75% test_error 9.50%\n",
      "================================8904===================================\n",
      "8904/10000: train_loss: 2.7278531221881965 train_error 14.75% test_error 9.50%\n",
      "================================8905===================================\n",
      "8905/10000: train_loss: 2.7277286410543953 train_error 14.75% test_error 9.50%\n",
      "================================8906===================================\n",
      "8906/10000: train_loss: 2.727604605414202 train_error 14.75% test_error 9.50%\n",
      "================================8907===================================\n",
      "8907/10000: train_loss: 2.72748306040884 train_error 14.75% test_error 9.50%\n",
      "================================8908===================================\n",
      "8908/10000: train_loss: 2.727360244452475 train_error 14.75% test_error 9.50%\n",
      "================================8909===================================\n",
      "8909/10000: train_loss: 2.7272355376045105 train_error 14.75% test_error 9.50%\n",
      "================================8910===================================\n",
      "8910/10000: train_loss: 2.727109364838582 train_error 14.75% test_error 9.50%\n",
      "================================8911===================================\n",
      "8911/10000: train_loss: 2.726983052828664 train_error 14.50% test_error 9.50%\n",
      "================================8912===================================\n",
      "8912/10000: train_loss: 2.726858624165077 train_error 14.50% test_error 9.50%\n",
      "================================8913===================================\n",
      "8913/10000: train_loss: 2.726734474524087 train_error 14.50% test_error 9.50%\n",
      "================================8914===================================\n",
      "8914/10000: train_loss: 2.7266110650414292 train_error 14.50% test_error 9.50%\n",
      "================================8915===================================\n",
      "8915/10000: train_loss: 2.726489187467448 train_error 14.37% test_error 9.50%\n",
      "================================8916===================================\n",
      "8916/10000: train_loss: 2.7263692749330968 train_error 14.37% test_error 9.50%\n",
      "================================8917===================================\n",
      "8917/10000: train_loss: 2.726249928711436 train_error 14.37% test_error 9.50%\n",
      "================================8918===================================\n",
      "8918/10000: train_loss: 2.7261258984252574 train_error 14.25% test_error 9.50%\n",
      "================================8919===================================\n",
      "8919/10000: train_loss: 2.7259939549971364 train_error 14.12% test_error 9.50%\n",
      "================================8920===================================\n",
      "8920/10000: train_loss: 2.725864378901931 train_error 14.12% test_error 9.50%\n",
      "================================8921===================================\n",
      "8921/10000: train_loss: 2.725732079538993 train_error 14.12% test_error 9.50%\n",
      "================================8922===================================\n",
      "8922/10000: train_loss: 2.7255946480708375 train_error 14.12% test_error 9.50%\n",
      "================================8923===================================\n",
      "8923/10000: train_loss: 2.7254577372621815 train_error 14.12% test_error 9.50%\n",
      "================================8924===================================\n",
      "8924/10000: train_loss: 2.725324742535497 train_error 14.25% test_error 9.50%\n",
      "================================8925===================================\n",
      "8925/10000: train_loss: 2.7251931477086533 train_error 14.25% test_error 9.50%\n",
      "================================8926===================================\n",
      "8926/10000: train_loss: 2.72506144329805 train_error 14.25% test_error 9.50%\n",
      "================================8927===================================\n",
      "8927/10000: train_loss: 2.7249264512867737 train_error 14.25% test_error 9.50%\n",
      "================================8928===================================\n",
      "8928/10000: train_loss: 2.7247881751510414 train_error 14.25% test_error 9.50%\n",
      "================================8929===================================\n",
      "8929/10000: train_loss: 2.7246506161005346 train_error 14.37% test_error 9.50%\n",
      "================================8930===================================\n",
      "8930/10000: train_loss: 2.7245187482546793 train_error 14.37% test_error 9.50%\n",
      "================================8931===================================\n",
      "8931/10000: train_loss: 2.7243906588967826 train_error 14.37% test_error 9.50%\n",
      "================================8932===================================\n",
      "8932/10000: train_loss: 2.7242632261388917 train_error 14.37% test_error 9.50%\n",
      "================================8933===================================\n",
      "8933/10000: train_loss: 2.724136497423342 train_error 14.37% test_error 9.50%\n",
      "================================8934===================================\n",
      "8934/10000: train_loss: 2.724011166536195 train_error 14.25% test_error 9.50%\n",
      "================================8935===================================\n",
      "8935/10000: train_loss: 2.7238860847266344 train_error 14.25% test_error 9.50%\n",
      "================================8936===================================\n",
      "8936/10000: train_loss: 2.7237634459383777 train_error 14.37% test_error 9.50%\n",
      "================================8937===================================\n",
      "8937/10000: train_loss: 2.723641653700404 train_error 14.37% test_error 9.50%\n",
      "================================8938===================================\n",
      "8938/10000: train_loss: 2.7235196935406316 train_error 14.37% test_error 9.50%\n",
      "================================8939===================================\n",
      "8939/10000: train_loss: 2.723399123071408 train_error 14.25% test_error 9.50%\n",
      "================================8940===================================\n",
      "8940/10000: train_loss: 2.723280242330297 train_error 14.25% test_error 9.50%\n",
      "================================8941===================================\n",
      "8941/10000: train_loss: 2.7231619782439225 train_error 14.12% test_error 9.50%\n",
      "================================8942===================================\n",
      "8942/10000: train_loss: 2.7230452528951874 train_error 14.12% test_error 9.00%\n",
      "================================8943===================================\n",
      "8943/10000: train_loss: 2.722925222687011 train_error 14.12% test_error 9.00%\n",
      "================================8944===================================\n",
      "8944/10000: train_loss: 2.722802897374102 train_error 14.12% test_error 9.00%\n",
      "================================8945===================================\n",
      "8945/10000: train_loss: 2.7226796033532263 train_error 14.12% test_error 9.00%\n",
      "================================8946===================================\n",
      "8946/10000: train_loss: 2.72255583363069 train_error 14.12% test_error 9.00%\n",
      "================================8947===================================\n",
      "8947/10000: train_loss: 2.7224338676435607 train_error 14.12% test_error 9.00%\n",
      "================================8948===================================\n",
      "8948/10000: train_loss: 2.7223124573338278 train_error 14.12% test_error 9.00%\n",
      "================================8949===================================\n",
      "8949/10000: train_loss: 2.7221944007506433 train_error 14.12% test_error 9.00%\n",
      "================================8950===================================\n",
      "8950/10000: train_loss: 2.722073768673795 train_error 14.12% test_error 9.00%\n",
      "================================8951===================================\n",
      "8951/10000: train_loss: 2.7219562098507026 train_error 14.00% test_error 9.00%\n",
      "================================8952===================================\n",
      "8952/10000: train_loss: 2.721844242460238 train_error 14.00% test_error 9.00%\n",
      "================================8953===================================\n",
      "8953/10000: train_loss: 2.721728359588976 train_error 14.00% test_error 9.00%\n",
      "================================8954===================================\n",
      "8954/10000: train_loss: 2.7216087094015893 train_error 14.00% test_error 9.00%\n",
      "================================8955===================================\n",
      "8955/10000: train_loss: 2.721489338285749 train_error 14.00% test_error 9.00%\n",
      "================================8956===================================\n",
      "8956/10000: train_loss: 2.721369760565601 train_error 14.00% test_error 9.00%\n",
      "================================8957===================================\n",
      "8957/10000: train_loss: 2.721252680183759 train_error 14.00% test_error 9.00%\n",
      "================================8958===================================\n",
      "8958/10000: train_loss: 2.7211389495088 train_error 14.00% test_error 9.00%\n",
      "================================8959===================================\n",
      "8959/10000: train_loss: 2.721025286326681 train_error 14.00% test_error 9.00%\n",
      "================================8960===================================\n",
      "8960/10000: train_loss: 2.720911487280005 train_error 13.88% test_error 9.00%\n",
      "================================8961===================================\n",
      "8961/10000: train_loss: 2.7207982272183013 train_error 13.88% test_error 9.00%\n",
      "================================8962===================================\n",
      "8962/10000: train_loss: 2.7206834810687908 train_error 13.88% test_error 9.00%\n",
      "================================8963===================================\n",
      "8963/10000: train_loss: 2.720567876051822 train_error 13.88% test_error 9.00%\n",
      "================================8964===================================\n",
      "8964/10000: train_loss: 2.720450329013006 train_error 13.88% test_error 9.00%\n",
      "================================8965===================================\n",
      "8965/10000: train_loss: 2.7203284692153593 train_error 13.88% test_error 9.00%\n",
      "================================8966===================================\n",
      "8966/10000: train_loss: 2.720204420630221 train_error 13.88% test_error 9.00%\n",
      "================================8967===================================\n",
      "8967/10000: train_loss: 2.720079117454717 train_error 13.88% test_error 9.00%\n",
      "================================8968===================================\n",
      "8968/10000: train_loss: 2.7199536628073493 train_error 14.00% test_error 9.00%\n",
      "================================8969===================================\n",
      "8969/10000: train_loss: 2.719830040982819 train_error 14.00% test_error 9.00%\n",
      "================================8970===================================\n",
      "8970/10000: train_loss: 2.7197067307557026 train_error 13.88% test_error 9.00%\n",
      "================================8971===================================\n",
      "8971/10000: train_loss: 2.71958277236831 train_error 13.88% test_error 9.00%\n",
      "================================8972===================================\n",
      "8972/10000: train_loss: 2.71945828505703 train_error 13.88% test_error 9.00%\n",
      "================================8973===================================\n",
      "8973/10000: train_loss: 2.7193346950698754 train_error 13.88% test_error 9.00%\n",
      "================================8974===================================\n",
      "8974/10000: train_loss: 2.719212647767597 train_error 13.88% test_error 9.00%\n",
      "================================8975===================================\n",
      "8975/10000: train_loss: 2.71909180497374 train_error 13.88% test_error 9.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================8976===================================\n",
      "8976/10000: train_loss: 2.718972245874884 train_error 13.88% test_error 9.00%\n",
      "================================8977===================================\n",
      "8977/10000: train_loss: 2.718853422566358 train_error 13.75% test_error 9.00%\n",
      "================================8978===================================\n",
      "8978/10000: train_loss: 2.718733553331446 train_error 13.88% test_error 9.00%\n",
      "================================8979===================================\n",
      "8979/10000: train_loss: 2.718614501244547 train_error 13.88% test_error 9.00%\n",
      "================================8980===================================\n",
      "8980/10000: train_loss: 2.7184941316164615 train_error 14.00% test_error 9.00%\n",
      "================================8981===================================\n",
      "8981/10000: train_loss: 2.7183771429460033 train_error 14.00% test_error 9.00%\n",
      "================================8982===================================\n",
      "8982/10000: train_loss: 2.718264151400242 train_error 14.00% test_error 9.00%\n",
      "================================8983===================================\n",
      "8983/10000: train_loss: 2.7181556188962963 train_error 14.00% test_error 9.00%\n",
      "================================8984===================================\n",
      "8984/10000: train_loss: 2.718048915948156 train_error 14.12% test_error 9.00%\n",
      "================================8985===================================\n",
      "8985/10000: train_loss: 2.717943709610637 train_error 14.12% test_error 9.00%\n",
      "================================8986===================================\n",
      "8986/10000: train_loss: 2.7178401322436265 train_error 14.12% test_error 9.00%\n",
      "================================8987===================================\n",
      "8987/10000: train_loss: 2.717737382799075 train_error 14.12% test_error 9.00%\n",
      "================================8988===================================\n",
      "8988/10000: train_loss: 2.717639435523497 train_error 14.12% test_error 9.00%\n",
      "================================8989===================================\n",
      "8989/10000: train_loss: 2.7175443450499963 train_error 14.12% test_error 9.00%\n",
      "================================8990===================================\n",
      "8990/10000: train_loss: 2.7174496425950623 train_error 14.12% test_error 9.00%\n",
      "================================8991===================================\n",
      "8991/10000: train_loss: 2.7173540168249235 train_error 14.12% test_error 9.00%\n",
      "================================8992===================================\n",
      "8992/10000: train_loss: 2.7172557483714432 train_error 14.12% test_error 9.00%\n",
      "================================8993===================================\n",
      "8993/10000: train_loss: 2.7171544724906864 train_error 14.12% test_error 9.00%\n",
      "================================8994===================================\n",
      "8994/10000: train_loss: 2.7170515921895104 train_error 14.12% test_error 9.00%\n",
      "================================8995===================================\n",
      "8995/10000: train_loss: 2.716948155675121 train_error 14.12% test_error 9.00%\n",
      "================================8996===================================\n",
      "8996/10000: train_loss: 2.7168453171948177 train_error 14.12% test_error 9.00%\n",
      "================================8997===================================\n",
      "8997/10000: train_loss: 2.7167431415031786 train_error 14.00% test_error 9.00%\n",
      "================================8998===================================\n",
      "8998/10000: train_loss: 2.716646118175311 train_error 14.00% test_error 9.00%\n",
      "================================8999===================================\n",
      "8999/10000: train_loss: 2.716549753935816 train_error 14.00% test_error 9.00%\n",
      "================================9000===================================\n",
      "9000/10000: train_loss: 2.716453870598962 train_error 13.88% test_error 9.00%\n",
      "================================9001===================================\n",
      "9001/10000: train_loss: 2.7163593658447773 train_error 13.88% test_error 9.00%\n",
      "================================9002===================================\n",
      "9002/10000: train_loss: 2.716266667788533 train_error 13.88% test_error 9.00%\n",
      "================================9003===================================\n",
      "9003/10000: train_loss: 2.71617669980198 train_error 13.88% test_error 9.00%\n",
      "================================9004===================================\n",
      "9004/10000: train_loss: 2.7160896036295035 train_error 14.00% test_error 9.00%\n",
      "================================9005===================================\n",
      "9005/10000: train_loss: 2.7160020363216546 train_error 14.00% test_error 9.00%\n",
      "================================9006===================================\n",
      "9006/10000: train_loss: 2.7159153214208707 train_error 14.00% test_error 9.00%\n",
      "================================9007===================================\n",
      "9007/10000: train_loss: 2.715826955662069 train_error 14.00% test_error 9.00%\n",
      "================================9008===================================\n",
      "9008/10000: train_loss: 2.7157379420065344 train_error 14.00% test_error 9.00%\n",
      "================================9009===================================\n",
      "9009/10000: train_loss: 2.7156494294621467 train_error 14.00% test_error 9.00%\n",
      "================================9010===================================\n",
      "9010/10000: train_loss: 2.715561577740714 train_error 14.00% test_error 9.00%\n",
      "================================9011===================================\n",
      "9011/10000: train_loss: 2.7154786231187424 train_error 14.00% test_error 9.00%\n",
      "================================9012===================================\n",
      "9012/10000: train_loss: 2.715396457855473 train_error 14.00% test_error 9.00%\n",
      "================================9013===================================\n",
      "9013/10000: train_loss: 2.7153148907528983 train_error 14.00% test_error 9.00%\n",
      "================================9014===================================\n",
      "9014/10000: train_loss: 2.7152331446151368 train_error 14.00% test_error 9.00%\n",
      "================================9015===================================\n",
      "9015/10000: train_loss: 2.715152819856394 train_error 14.00% test_error 9.00%\n",
      "================================9016===================================\n",
      "9016/10000: train_loss: 2.7150712204537015 train_error 14.00% test_error 9.00%\n",
      "================================9017===================================\n",
      "9017/10000: train_loss: 2.7149883433110746 train_error 14.00% test_error 9.00%\n",
      "================================9018===================================\n",
      "9018/10000: train_loss: 2.7149060783132635 train_error 14.00% test_error 9.00%\n",
      "================================9019===================================\n",
      "9019/10000: train_loss: 2.7148255546541384 train_error 14.00% test_error 9.00%\n",
      "================================9020===================================\n",
      "9020/10000: train_loss: 2.714744078634972 train_error 14.00% test_error 9.00%\n",
      "================================9021===================================\n",
      "9021/10000: train_loss: 2.7146626308820507 train_error 14.00% test_error 9.00%\n",
      "================================9022===================================\n",
      "9022/10000: train_loss: 2.7145804527918256 train_error 14.00% test_error 9.00%\n",
      "================================9023===================================\n",
      "9023/10000: train_loss: 2.714496593146441 train_error 14.00% test_error 9.00%\n",
      "================================9024===================================\n",
      "9024/10000: train_loss: 2.714413177287753 train_error 14.00% test_error 9.00%\n",
      "================================9025===================================\n",
      "9025/10000: train_loss: 2.7143326735384337 train_error 14.00% test_error 9.00%\n",
      "================================9026===================================\n",
      "9026/10000: train_loss: 2.7142520839669886 train_error 14.12% test_error 9.00%\n",
      "================================9027===================================\n",
      "9027/10000: train_loss: 2.7141659958185165 train_error 14.12% test_error 9.00%\n",
      "================================9028===================================\n",
      "9028/10000: train_loss: 2.7140753718774806 train_error 14.12% test_error 9.00%\n",
      "================================9029===================================\n",
      "9029/10000: train_loss: 2.7139869162247225 train_error 14.12% test_error 9.00%\n",
      "================================9030===================================\n",
      "9030/10000: train_loss: 2.7138987622707953 train_error 14.12% test_error 9.00%\n",
      "================================9031===================================\n",
      "9031/10000: train_loss: 2.713812113683624 train_error 14.12% test_error 9.00%\n",
      "================================9032===================================\n",
      "9032/10000: train_loss: 2.713719208338685 train_error 14.12% test_error 9.00%\n",
      "================================9033===================================\n",
      "9033/10000: train_loss: 2.7136254922374965 train_error 14.12% test_error 9.00%\n",
      "================================9034===================================\n",
      "9034/10000: train_loss: 2.713537824552136 train_error 14.12% test_error 9.00%\n",
      "================================9035===================================\n",
      "9035/10000: train_loss: 2.713452952939465 train_error 14.12% test_error 9.00%\n",
      "================================9036===================================\n",
      "9036/10000: train_loss: 2.713365534366476 train_error 14.12% test_error 9.00%\n",
      "================================9037===================================\n",
      "9037/10000: train_loss: 2.7132803543589104 train_error 14.12% test_error 9.00%\n",
      "================================9038===================================\n",
      "9038/10000: train_loss: 2.713197223609178 train_error 14.12% test_error 9.00%\n",
      "================================9039===================================\n",
      "9039/10000: train_loss: 2.7131164405199524 train_error 14.12% test_error 9.00%\n",
      "================================9040===================================\n",
      "9040/10000: train_loss: 2.7130376584042013 train_error 14.12% test_error 9.00%\n",
      "================================9041===================================\n",
      "9041/10000: train_loss: 2.71295921816238 train_error 14.12% test_error 9.00%\n",
      "================================9042===================================\n",
      "9042/10000: train_loss: 2.712879679167929 train_error 14.12% test_error 9.00%\n",
      "================================9043===================================\n",
      "9043/10000: train_loss: 2.7128018701935854 train_error 14.12% test_error 9.00%\n",
      "================================9044===================================\n",
      "9044/10000: train_loss: 2.7127275315723782 train_error 14.12% test_error 9.00%\n",
      "================================9045===================================\n",
      "9045/10000: train_loss: 2.7126541362435317 train_error 14.12% test_error 9.00%\n",
      "================================9046===================================\n",
      "9046/10000: train_loss: 2.712583057821572 train_error 14.12% test_error 9.00%\n",
      "================================9047===================================\n",
      "9047/10000: train_loss: 2.7125183159351094 train_error 14.12% test_error 9.00%\n",
      "================================9048===================================\n",
      "9048/10000: train_loss: 2.7124565731364796 train_error 14.12% test_error 9.00%\n",
      "================================9049===================================\n",
      "9049/10000: train_loss: 2.7123934199979605 train_error 14.12% test_error 9.00%\n",
      "================================9050===================================\n",
      "9050/10000: train_loss: 2.712328466395734 train_error 14.12% test_error 9.00%\n",
      "================================9051===================================\n",
      "9051/10000: train_loss: 2.712261955796535 train_error 14.12% test_error 9.00%\n",
      "================================9052===================================\n",
      "9052/10000: train_loss: 2.712195208752389 train_error 14.12% test_error 9.00%\n",
      "================================9053===================================\n",
      "9053/10000: train_loss: 2.7121270177565724 train_error 14.12% test_error 9.00%\n",
      "================================9054===================================\n",
      "9054/10000: train_loss: 2.712061477233701 train_error 14.12% test_error 9.00%\n",
      "================================9055===================================\n",
      "9055/10000: train_loss: 2.7119969928902345 train_error 14.12% test_error 9.00%\n",
      "================================9056===================================\n",
      "9056/10000: train_loss: 2.7119308923355683 train_error 14.12% test_error 9.00%\n",
      "================================9057===================================\n",
      "9057/10000: train_loss: 2.7118659985881073 train_error 14.12% test_error 9.00%\n",
      "================================9058===================================\n",
      "9058/10000: train_loss: 2.7118026908827666 train_error 14.12% test_error 9.00%\n",
      "================================9059===================================\n",
      "9059/10000: train_loss: 2.711741991056505 train_error 14.12% test_error 9.00%\n",
      "================================9060===================================\n",
      "9060/10000: train_loss: 2.7116888473812946 train_error 14.12% test_error 8.50%\n",
      "================================9061===================================\n",
      "9061/10000: train_loss: 2.711636068698499 train_error 14.12% test_error 8.50%\n",
      "================================9062===================================\n",
      "9062/10000: train_loss: 2.7115834234783494 train_error 14.25% test_error 8.50%\n",
      "================================9063===================================\n",
      "9063/10000: train_loss: 2.711533024447049 train_error 14.25% test_error 8.50%\n",
      "================================9064===================================\n",
      "9064/10000: train_loss: 2.711484711386969 train_error 14.25% test_error 8.50%\n",
      "================================9065===================================\n",
      "9065/10000: train_loss: 2.711440076140012 train_error 14.25% test_error 8.50%\n",
      "================================9066===================================\n",
      "9066/10000: train_loss: 2.7113988244281098 train_error 14.25% test_error 8.50%\n",
      "================================9067===================================\n",
      "9067/10000: train_loss: 2.711362922484825 train_error 14.25% test_error 8.50%\n",
      "================================9068===================================\n",
      "9068/10000: train_loss: 2.711328139275656 train_error 14.25% test_error 8.50%\n",
      "================================9069===================================\n",
      "9069/10000: train_loss: 2.7112949941026074 train_error 14.25% test_error 8.50%\n",
      "================================9070===================================\n",
      "9070/10000: train_loss: 2.711261975445367 train_error 14.25% test_error 8.50%\n",
      "================================9071===================================\n",
      "9071/10000: train_loss: 2.7112276587819895 train_error 14.25% test_error 8.50%\n",
      "================================9072===================================\n",
      "9072/10000: train_loss: 2.7111933572995444 train_error 14.25% test_error 8.50%\n",
      "================================9073===================================\n",
      "9073/10000: train_loss: 2.7111570820413546 train_error 14.25% test_error 8.50%\n",
      "================================9074===================================\n",
      "9074/10000: train_loss: 2.7111202954961136 train_error 14.25% test_error 8.50%\n",
      "================================9075===================================\n",
      "9075/10000: train_loss: 2.711081913480333 train_error 14.25% test_error 8.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================9076===================================\n",
      "9076/10000: train_loss: 2.711041439199464 train_error 14.25% test_error 8.50%\n",
      "================================9077===================================\n",
      "9077/10000: train_loss: 2.7109989293590697 train_error 14.25% test_error 8.50%\n",
      "================================9078===================================\n",
      "9078/10000: train_loss: 2.7109536500490474 train_error 14.25% test_error 8.50%\n",
      "================================9079===================================\n",
      "9079/10000: train_loss: 2.710910036194337 train_error 14.25% test_error 8.50%\n",
      "================================9080===================================\n",
      "9080/10000: train_loss: 2.710866899472575 train_error 14.25% test_error 8.50%\n",
      "================================9081===================================\n",
      "9081/10000: train_loss: 2.710824136645418 train_error 14.25% test_error 8.50%\n",
      "================================9082===================================\n",
      "9082/10000: train_loss: 2.7107788608358097 train_error 14.25% test_error 8.50%\n",
      "================================9083===================================\n",
      "9083/10000: train_loss: 2.7107308921150834 train_error 14.25% test_error 8.50%\n",
      "================================9084===================================\n",
      "9084/10000: train_loss: 2.710683454190744 train_error 14.25% test_error 8.50%\n",
      "================================9085===================================\n",
      "9085/10000: train_loss: 2.710635846510231 train_error 14.12% test_error 8.50%\n",
      "================================9086===================================\n",
      "9086/10000: train_loss: 2.7105902929814314 train_error 14.12% test_error 8.50%\n",
      "================================9087===================================\n",
      "9087/10000: train_loss: 2.7105454834762726 train_error 14.12% test_error 8.50%\n",
      "================================9088===================================\n",
      "9088/10000: train_loss: 2.710500804007332 train_error 14.12% test_error 8.50%\n",
      "================================9089===================================\n",
      "9089/10000: train_loss: 2.7104563873715906 train_error 14.12% test_error 8.50%\n",
      "================================9090===================================\n",
      "9090/10000: train_loss: 2.71041269036417 train_error 14.12% test_error 8.50%\n",
      "================================9091===================================\n",
      "9091/10000: train_loss: 2.7103693498179084 train_error 14.12% test_error 8.50%\n",
      "================================9092===================================\n",
      "9092/10000: train_loss: 2.710323519828453 train_error 14.12% test_error 8.50%\n",
      "================================9093===================================\n",
      "9093/10000: train_loss: 2.7102752606210516 train_error 14.12% test_error 8.50%\n",
      "================================9094===================================\n",
      "9094/10000: train_loss: 2.710228110522992 train_error 14.12% test_error 8.50%\n",
      "================================9095===================================\n",
      "9095/10000: train_loss: 2.710182108179227 train_error 14.12% test_error 8.50%\n",
      "================================9096===================================\n",
      "9096/10000: train_loss: 2.7101372612491135 train_error 14.12% test_error 8.50%\n",
      "================================9097===================================\n",
      "9097/10000: train_loss: 2.7100919681379843 train_error 14.12% test_error 8.50%\n",
      "================================9098===================================\n",
      "9098/10000: train_loss: 2.7100470423196867 train_error 14.12% test_error 8.50%\n",
      "================================9099===================================\n",
      "9099/10000: train_loss: 2.710002283381001 train_error 14.12% test_error 8.50%\n",
      "================================9100===================================\n",
      "9100/10000: train_loss: 2.7099566923382294 train_error 14.12% test_error 8.50%\n",
      "================================9101===================================\n",
      "9101/10000: train_loss: 2.7099076873882115 train_error 14.12% test_error 8.50%\n",
      "================================9102===================================\n",
      "9102/10000: train_loss: 2.70985815857423 train_error 14.12% test_error 8.50%\n",
      "================================9103===================================\n",
      "9103/10000: train_loss: 2.709811896085464 train_error 14.12% test_error 8.50%\n",
      "================================9104===================================\n",
      "9104/10000: train_loss: 2.7097608368724058 train_error 14.12% test_error 8.50%\n",
      "================================9105===================================\n",
      "9105/10000: train_loss: 2.7097079290984802 train_error 14.12% test_error 8.50%\n",
      "================================9106===================================\n",
      "9106/10000: train_loss: 2.7096550373575576 train_error 14.00% test_error 8.50%\n",
      "================================9107===================================\n",
      "9107/10000: train_loss: 2.7096046981075017 train_error 14.00% test_error 8.50%\n",
      "================================9108===================================\n",
      "9108/10000: train_loss: 2.7095559840362897 train_error 14.00% test_error 8.50%\n",
      "================================9109===================================\n",
      "9109/10000: train_loss: 2.709510797748786 train_error 14.00% test_error 8.50%\n",
      "================================9110===================================\n",
      "9110/10000: train_loss: 2.709466957114657 train_error 14.00% test_error 8.50%\n",
      "================================9111===================================\n",
      "9111/10000: train_loss: 2.709424948557161 train_error 14.00% test_error 8.50%\n",
      "================================9112===================================\n",
      "9112/10000: train_loss: 2.709386638160318 train_error 14.00% test_error 8.50%\n",
      "================================9113===================================\n",
      "9113/10000: train_loss: 2.7093525549410846 train_error 14.00% test_error 8.50%\n",
      "================================9114===================================\n",
      "9114/10000: train_loss: 2.7093185069240278 train_error 14.00% test_error 8.50%\n",
      "================================9115===================================\n",
      "9115/10000: train_loss: 2.709284975234846 train_error 14.00% test_error 8.50%\n",
      "================================9116===================================\n",
      "9116/10000: train_loss: 2.7092534234483105 train_error 14.00% test_error 8.50%\n",
      "================================9117===================================\n",
      "9117/10000: train_loss: 2.7092260771495336 train_error 14.00% test_error 8.50%\n",
      "================================9118===================================\n",
      "9118/10000: train_loss: 2.709199511217314 train_error 14.00% test_error 8.50%\n",
      "================================9119===================================\n",
      "9119/10000: train_loss: 2.7091739914774697 train_error 14.00% test_error 8.50%\n",
      "================================9120===================================\n",
      "9120/10000: train_loss: 2.709147215780523 train_error 14.00% test_error 8.50%\n",
      "================================9121===================================\n",
      "9121/10000: train_loss: 2.709122990940151 train_error 14.00% test_error 8.50%\n",
      "================================9122===================================\n",
      "9122/10000: train_loss: 2.7090980842482195 train_error 14.00% test_error 8.50%\n",
      "================================9123===================================\n",
      "9123/10000: train_loss: 2.7090746144946802 train_error 14.00% test_error 8.50%\n",
      "================================9124===================================\n",
      "9124/10000: train_loss: 2.7090548459155803 train_error 14.00% test_error 8.50%\n",
      "================================9125===================================\n",
      "9125/10000: train_loss: 2.709037981892371 train_error 14.00% test_error 8.50%\n",
      "================================9126===================================\n",
      "9126/10000: train_loss: 2.7090237983840035 train_error 14.00% test_error 8.50%\n",
      "================================9127===================================\n",
      "9127/10000: train_loss: 2.7090100132557704 train_error 14.00% test_error 8.50%\n",
      "================================9128===================================\n",
      "9128/10000: train_loss: 2.7089977038249224 train_error 14.00% test_error 8.50%\n",
      "================================9129===================================\n",
      "9129/10000: train_loss: 2.7089861756231826 train_error 14.00% test_error 8.50%\n",
      "================================9130===================================\n",
      "9130/10000: train_loss: 2.7089778534722058 train_error 14.00% test_error 8.50%\n",
      "================================9131===================================\n",
      "9131/10000: train_loss: 2.7089713150673855 train_error 14.00% test_error 8.50%\n",
      "================================9132===================================\n",
      "9132/10000: train_loss: 2.7089655112366935 train_error 14.00% test_error 8.50%\n",
      "================================9133===================================\n",
      "9133/10000: train_loss: 2.708960780919239 train_error 14.00% test_error 8.50%\n",
      "================================9134===================================\n",
      "9134/10000: train_loss: 2.708954959570486 train_error 14.00% test_error 8.50%\n",
      "================================9135===================================\n",
      "9135/10000: train_loss: 2.708949211632667 train_error 14.00% test_error 8.50%\n",
      "================================9136===================================\n",
      "9136/10000: train_loss: 2.7089314787853636 train_error 14.00% test_error 8.50%\n",
      "================================9137===================================\n",
      "9137/10000: train_loss: 2.708913179279292 train_error 14.00% test_error 8.50%\n",
      "================================9138===================================\n",
      "9138/10000: train_loss: 2.7088932851418575 train_error 14.00% test_error 8.50%\n",
      "================================9139===================================\n",
      "9139/10000: train_loss: 2.7088735165466575 train_error 14.00% test_error 8.50%\n",
      "================================9140===================================\n",
      "9140/10000: train_loss: 2.7088552431879744 train_error 14.00% test_error 8.50%\n",
      "================================9141===================================\n",
      "9141/10000: train_loss: 2.7088398563606138 train_error 14.00% test_error 8.50%\n",
      "================================9142===================================\n",
      "9142/10000: train_loss: 2.708824746701051 train_error 14.00% test_error 8.50%\n",
      "================================9143===================================\n",
      "9143/10000: train_loss: 2.708808770216284 train_error 14.00% test_error 8.50%\n",
      "================================9144===================================\n",
      "9144/10000: train_loss: 2.708793377449383 train_error 13.88% test_error 8.50%\n",
      "================================9145===================================\n",
      "9145/10000: train_loss: 2.708775240659488 train_error 13.88% test_error 8.50%\n",
      "================================9146===================================\n",
      "9146/10000: train_loss: 2.708756389236613 train_error 13.88% test_error 8.50%\n",
      "================================9147===================================\n",
      "9147/10000: train_loss: 2.7087347547284777 train_error 13.88% test_error 8.50%\n",
      "================================9148===================================\n",
      "9148/10000: train_loss: 2.708718408452302 train_error 13.88% test_error 8.50%\n",
      "================================9149===================================\n",
      "9149/10000: train_loss: 2.708708613447192 train_error 13.88% test_error 8.50%\n",
      "================================9150===================================\n",
      "9150/10000: train_loss: 2.70870213697519 train_error 13.88% test_error 8.50%\n",
      "================================9151===================================\n",
      "9151/10000: train_loss: 2.708692780183789 train_error 13.88% test_error 8.50%\n",
      "================================9152===================================\n",
      "9152/10000: train_loss: 2.7086861052774363 train_error 13.88% test_error 8.50%\n",
      "================================9153===================================\n",
      "9153/10000: train_loss: 2.7086815728178264 train_error 13.88% test_error 8.50%\n",
      "================================9154===================================\n",
      "9154/10000: train_loss: 2.7086786549976987 train_error 13.88% test_error 8.50%\n",
      "================================9155===================================\n",
      "9155/10000: train_loss: 2.7086789024669002 train_error 13.88% test_error 8.50%\n",
      "================================9156===================================\n",
      "9156/10000: train_loss: 2.7086823912177125 train_error 13.88% test_error 8.50%\n",
      "================================9157===================================\n",
      "9157/10000: train_loss: 2.7086875824169763 train_error 13.88% test_error 8.50%\n",
      "================================9158===================================\n",
      "9158/10000: train_loss: 2.708690511266763 train_error 13.88% test_error 8.50%\n",
      "================================9159===================================\n",
      "9159/10000: train_loss: 2.7086936512380753 train_error 13.88% test_error 8.50%\n",
      "================================9160===================================\n",
      "9160/10000: train_loss: 2.7087028443491956 train_error 13.88% test_error 8.50%\n",
      "================================9161===================================\n",
      "9161/10000: train_loss: 2.7087152831428374 train_error 13.88% test_error 8.50%\n",
      "================================9162===================================\n",
      "9162/10000: train_loss: 2.7087281728598693 train_error 14.00% test_error 8.50%\n",
      "================================9163===================================\n",
      "9163/10000: train_loss: 2.7087417990810554 train_error 14.00% test_error 8.50%\n",
      "================================9164===================================\n",
      "9164/10000: train_loss: 2.7087556976427605 train_error 14.00% test_error 8.50%\n",
      "================================9165===================================\n",
      "9165/10000: train_loss: 2.708771277559804 train_error 14.00% test_error 8.50%\n",
      "================================9166===================================\n",
      "9166/10000: train_loss: 2.70879026114185 train_error 14.00% test_error 8.50%\n",
      "================================9167===================================\n",
      "9167/10000: train_loss: 2.7088098826452036 train_error 14.00% test_error 8.50%\n",
      "================================9168===================================\n",
      "9168/10000: train_loss: 2.708828491844142 train_error 14.00% test_error 8.50%\n",
      "================================9169===================================\n",
      "9169/10000: train_loss: 2.7088456347914986 train_error 13.88% test_error 8.50%\n",
      "================================9170===================================\n",
      "9170/10000: train_loss: 2.7088631302468995 train_error 13.88% test_error 8.50%\n",
      "================================9171===================================\n",
      "9171/10000: train_loss: 2.7088799229792384 train_error 13.88% test_error 8.50%\n",
      "================================9172===================================\n",
      "9172/10000: train_loss: 2.708897003245223 train_error 13.88% test_error 8.50%\n",
      "================================9173===================================\n",
      "9173/10000: train_loss: 2.708917599110103 train_error 13.88% test_error 8.50%\n",
      "================================9174===================================\n",
      "9174/10000: train_loss: 2.7089384352668073 train_error 13.88% test_error 8.50%\n",
      "================================9175===================================\n",
      "9175/10000: train_loss: 2.708960782211917 train_error 13.88% test_error 8.50%\n",
      "================================9176===================================\n",
      "9176/10000: train_loss: 2.7089829804796564 train_error 13.88% test_error 8.50%\n",
      "================================9177===================================\n",
      "9177/10000: train_loss: 2.7090032732555773 train_error 13.88% test_error 8.50%\n",
      "================================9178===================================\n",
      "9178/10000: train_loss: 2.709024008328967 train_error 13.88% test_error 8.50%\n",
      "================================9179===================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9179/10000: train_loss: 2.7090469970365443 train_error 13.88% test_error 8.50%\n",
      "================================9180===================================\n",
      "9180/10000: train_loss: 2.7090663598399574 train_error 13.88% test_error 8.50%\n",
      "================================9181===================================\n",
      "9181/10000: train_loss: 2.7090874623053955 train_error 13.88% test_error 8.50%\n",
      "================================9182===================================\n",
      "9182/10000: train_loss: 2.7091081687107494 train_error 13.88% test_error 8.00%\n",
      "================================9183===================================\n",
      "9183/10000: train_loss: 2.709128839565238 train_error 13.88% test_error 8.00%\n",
      "================================9184===================================\n",
      "9184/10000: train_loss: 2.7091502364597737 train_error 13.88% test_error 8.00%\n",
      "================================9185===================================\n",
      "9185/10000: train_loss: 2.7091725921155936 train_error 13.88% test_error 8.00%\n",
      "================================9186===================================\n",
      "9186/10000: train_loss: 2.7091957947516336 train_error 13.88% test_error 8.00%\n",
      "================================9187===================================\n",
      "9187/10000: train_loss: 2.7092199434429975 train_error 13.88% test_error 8.00%\n",
      "================================9188===================================\n",
      "9188/10000: train_loss: 2.7092417805363755 train_error 13.88% test_error 8.00%\n",
      "================================9189===================================\n",
      "9189/10000: train_loss: 2.709266788640652 train_error 13.88% test_error 8.00%\n",
      "================================9190===================================\n",
      "9190/10000: train_loss: 2.7092930830316426 train_error 13.88% test_error 8.00%\n",
      "================================9191===================================\n",
      "9191/10000: train_loss: 2.7093207573381863 train_error 13.88% test_error 8.00%\n",
      "================================9192===================================\n",
      "9192/10000: train_loss: 2.7093486216052476 train_error 13.88% test_error 8.00%\n",
      "================================9193===================================\n",
      "9193/10000: train_loss: 2.7093797642141673 train_error 13.88% test_error 8.00%\n",
      "================================9194===================================\n",
      "9194/10000: train_loss: 2.7094103115088375 train_error 13.88% test_error 8.00%\n",
      "================================9195===================================\n",
      "9195/10000: train_loss: 2.7094410121155414 train_error 13.88% test_error 8.00%\n",
      "================================9196===================================\n",
      "9196/10000: train_loss: 2.7094709156448147 train_error 13.88% test_error 8.00%\n",
      "================================9197===================================\n",
      "9197/10000: train_loss: 2.709501197020598 train_error 14.00% test_error 8.00%\n",
      "================================9198===================================\n",
      "9198/10000: train_loss: 2.709532423151078 train_error 14.00% test_error 8.00%\n",
      "================================9199===================================\n",
      "9199/10000: train_loss: 2.709563179842306 train_error 14.00% test_error 8.00%\n",
      "================================9200===================================\n",
      "9200/10000: train_loss: 2.709596215381418 train_error 14.00% test_error 8.00%\n",
      "================================9201===================================\n",
      "9201/10000: train_loss: 2.709631183177035 train_error 14.00% test_error 8.00%\n",
      "================================9202===================================\n",
      "9202/10000: train_loss: 2.7096713493707805 train_error 14.00% test_error 8.00%\n",
      "================================9203===================================\n",
      "9203/10000: train_loss: 2.709713055466218 train_error 14.00% test_error 8.00%\n",
      "================================9204===================================\n",
      "9204/10000: train_loss: 2.7097539710744605 train_error 14.00% test_error 8.00%\n",
      "================================9205===================================\n",
      "9205/10000: train_loss: 2.709792131056988 train_error 14.00% test_error 8.00%\n",
      "================================9206===================================\n",
      "9206/10000: train_loss: 2.709826239949069 train_error 14.00% test_error 8.00%\n",
      "================================9207===================================\n",
      "9207/10000: train_loss: 2.7098580417136806 train_error 14.12% test_error 8.00%\n",
      "================================9208===================================\n",
      "9208/10000: train_loss: 2.709889376861261 train_error 14.12% test_error 8.00%\n",
      "================================9209===================================\n",
      "9209/10000: train_loss: 2.7099226440195854 train_error 14.12% test_error 8.00%\n",
      "================================9210===================================\n",
      "9210/10000: train_loss: 2.709960744826638 train_error 14.12% test_error 8.00%\n",
      "================================9211===================================\n",
      "9211/10000: train_loss: 2.709999038404484 train_error 14.12% test_error 8.00%\n",
      "================================9212===================================\n",
      "9212/10000: train_loss: 2.710033880316358 train_error 14.12% test_error 8.00%\n",
      "================================9213===================================\n",
      "9213/10000: train_loss: 2.7100679237596683 train_error 14.12% test_error 8.00%\n",
      "================================9214===================================\n",
      "9214/10000: train_loss: 2.7100995627385913 train_error 14.12% test_error 8.00%\n",
      "================================9215===================================\n",
      "9215/10000: train_loss: 2.710135098269327 train_error 14.12% test_error 8.00%\n",
      "================================9216===================================\n",
      "9216/10000: train_loss: 2.710172235869295 train_error 14.12% test_error 8.00%\n",
      "================================9217===================================\n",
      "9217/10000: train_loss: 2.7102089491011756 train_error 14.12% test_error 8.00%\n",
      "================================9218===================================\n",
      "9218/10000: train_loss: 2.71024845591203 train_error 14.12% test_error 8.00%\n",
      "================================9219===================================\n",
      "9219/10000: train_loss: 2.7102903349679677 train_error 14.12% test_error 8.00%\n",
      "================================9220===================================\n",
      "9220/10000: train_loss: 2.710337370673809 train_error 14.12% test_error 8.00%\n",
      "================================9221===================================\n",
      "9221/10000: train_loss: 2.710385653356628 train_error 14.12% test_error 8.00%\n",
      "================================9222===================================\n",
      "9222/10000: train_loss: 2.71043774047133 train_error 14.12% test_error 8.00%\n",
      "================================9223===================================\n",
      "9223/10000: train_loss: 2.7104937887114415 train_error 14.12% test_error 8.00%\n",
      "================================9224===================================\n",
      "9224/10000: train_loss: 2.7105507183415094 train_error 14.12% test_error 8.00%\n",
      "================================9225===================================\n",
      "9225/10000: train_loss: 2.710607875953391 train_error 14.12% test_error 8.00%\n",
      "================================9226===================================\n",
      "9226/10000: train_loss: 2.7106673939260375 train_error 14.12% test_error 8.00%\n",
      "================================9227===================================\n",
      "9227/10000: train_loss: 2.710729844173469 train_error 14.12% test_error 8.00%\n",
      "================================9228===================================\n",
      "9228/10000: train_loss: 2.710792049286736 train_error 14.12% test_error 8.00%\n",
      "================================9229===================================\n",
      "9229/10000: train_loss: 2.7108547585439475 train_error 14.12% test_error 8.00%\n",
      "================================9230===================================\n",
      "9230/10000: train_loss: 2.710916254354348 train_error 14.12% test_error 8.50%\n",
      "================================9231===================================\n",
      "9231/10000: train_loss: 2.7109771336440636 train_error 14.12% test_error 8.50%\n",
      "================================9232===================================\n",
      "9232/10000: train_loss: 2.711039141614338 train_error 14.25% test_error 8.50%\n",
      "================================9233===================================\n",
      "9233/10000: train_loss: 2.7111024279742915 train_error 14.25% test_error 8.50%\n",
      "================================9234===================================\n",
      "9234/10000: train_loss: 2.711164859284855 train_error 14.25% test_error 8.50%\n",
      "================================9235===================================\n",
      "9235/10000: train_loss: 2.7112273792528914 train_error 14.25% test_error 8.50%\n",
      "================================9236===================================\n",
      "9236/10000: train_loss: 2.711291435105176 train_error 14.25% test_error 8.50%\n",
      "================================9237===================================\n",
      "9237/10000: train_loss: 2.711357696280656 train_error 14.25% test_error 8.50%\n",
      "================================9238===================================\n",
      "9238/10000: train_loss: 2.7114266288430393 train_error 14.37% test_error 8.50%\n",
      "================================9239===================================\n",
      "9239/10000: train_loss: 2.7114957067172267 train_error 14.37% test_error 8.50%\n",
      "================================9240===================================\n",
      "9240/10000: train_loss: 2.7115654451438527 train_error 14.37% test_error 8.50%\n",
      "================================9241===================================\n",
      "9241/10000: train_loss: 2.7116348571816786 train_error 14.37% test_error 8.50%\n",
      "================================9242===================================\n",
      "9242/10000: train_loss: 2.7117045520876655 train_error 14.37% test_error 8.50%\n",
      "================================9243===================================\n",
      "9243/10000: train_loss: 2.7117743046936362 train_error 14.37% test_error 8.50%\n",
      "================================9244===================================\n",
      "9244/10000: train_loss: 2.71184461537885 train_error 14.37% test_error 8.50%\n",
      "================================9245===================================\n",
      "9245/10000: train_loss: 2.7119153194929804 train_error 14.37% test_error 8.50%\n",
      "================================9246===================================\n",
      "9246/10000: train_loss: 2.711988355093905 train_error 14.37% test_error 8.50%\n",
      "================================9247===================================\n",
      "9247/10000: train_loss: 2.7120637817234075 train_error 14.37% test_error 8.50%\n",
      "================================9248===================================\n",
      "9248/10000: train_loss: 2.7121392582446027 train_error 14.37% test_error 8.50%\n",
      "================================9249===================================\n",
      "9249/10000: train_loss: 2.712217505457096 train_error 14.37% test_error 8.50%\n",
      "================================9250===================================\n",
      "9250/10000: train_loss: 2.7122947398984096 train_error 14.37% test_error 8.50%\n",
      "================================9251===================================\n",
      "9251/10000: train_loss: 2.712372196210308 train_error 14.37% test_error 8.50%\n",
      "================================9252===================================\n",
      "9252/10000: train_loss: 2.712448580779719 train_error 14.37% test_error 8.50%\n",
      "================================9253===================================\n",
      "9253/10000: train_loss: 2.712526586882245 train_error 14.37% test_error 8.50%\n",
      "================================9254===================================\n",
      "9254/10000: train_loss: 2.7126063224137815 train_error 14.37% test_error 8.50%\n",
      "================================9255===================================\n",
      "9255/10000: train_loss: 2.7126875794190384 train_error 14.37% test_error 8.50%\n",
      "================================9256===================================\n",
      "9256/10000: train_loss: 2.71277113010244 train_error 14.37% test_error 8.50%\n",
      "================================9257===================================\n",
      "9257/10000: train_loss: 2.7128562815164114 train_error 14.37% test_error 8.50%\n",
      "================================9258===================================\n",
      "9258/10000: train_loss: 2.7129419318890986 train_error 14.62% test_error 8.50%\n",
      "================================9259===================================\n",
      "9259/10000: train_loss: 2.713027552013701 train_error 14.62% test_error 8.50%\n",
      "================================9260===================================\n",
      "9260/10000: train_loss: 2.7131130538278105 train_error 14.62% test_error 8.50%\n",
      "================================9261===================================\n",
      "9261/10000: train_loss: 2.7132008877912597 train_error 14.62% test_error 8.50%\n",
      "================================9262===================================\n",
      "9262/10000: train_loss: 2.713289357706271 train_error 14.62% test_error 8.50%\n",
      "================================9263===================================\n",
      "9263/10000: train_loss: 2.71337578436913 train_error 14.62% test_error 8.50%\n",
      "================================9264===================================\n",
      "9264/10000: train_loss: 2.7134622602453335 train_error 14.62% test_error 8.50%\n",
      "================================9265===================================\n",
      "9265/10000: train_loss: 2.713551306732531 train_error 14.62% test_error 8.50%\n",
      "================================9266===================================\n",
      "9266/10000: train_loss: 2.7136423900770827 train_error 14.62% test_error 8.50%\n",
      "================================9267===================================\n",
      "9267/10000: train_loss: 2.7137349678729947 train_error 14.62% test_error 8.50%\n",
      "================================9268===================================\n",
      "9268/10000: train_loss: 2.713831118542689 train_error 14.62% test_error 8.50%\n",
      "================================9269===================================\n",
      "9269/10000: train_loss: 2.713927200948093 train_error 14.62% test_error 8.50%\n",
      "================================9270===================================\n",
      "9270/10000: train_loss: 2.714025964533446 train_error 14.62% test_error 8.50%\n",
      "================================9271===================================\n",
      "9271/10000: train_loss: 2.7141271009880157 train_error 14.75% test_error 8.50%\n",
      "================================9272===================================\n",
      "9272/10000: train_loss: 2.714225418645312 train_error 14.75% test_error 8.50%\n",
      "================================9273===================================\n",
      "9273/10000: train_loss: 2.7143241602379 train_error 14.75% test_error 8.50%\n",
      "================================9274===================================\n",
      "9274/10000: train_loss: 2.7144233344860265 train_error 14.75% test_error 8.50%\n",
      "================================9275===================================\n",
      "9275/10000: train_loss: 2.7145212956761733 train_error 14.75% test_error 8.50%\n",
      "================================9276===================================\n",
      "9276/10000: train_loss: 2.7146175956546994 train_error 14.75% test_error 8.50%\n",
      "================================9277===================================\n",
      "9277/10000: train_loss: 2.7147152935930183 train_error 14.75% test_error 8.50%\n",
      "================================9278===================================\n",
      "9278/10000: train_loss: 2.714813776708762 train_error 14.75% test_error 8.50%\n",
      "================================9279===================================\n",
      "9279/10000: train_loss: 2.7149125550075213 train_error 14.75% test_error 8.50%\n",
      "================================9280===================================\n",
      "9280/10000: train_loss: 2.715011583061749 train_error 14.88% test_error 8.50%\n",
      "================================9281===================================\n",
      "9281/10000: train_loss: 2.7151064727240617 train_error 15.00% test_error 8.50%\n",
      "================================9282===================================\n",
      "9282/10000: train_loss: 2.7152008574920488 train_error 15.00% test_error 8.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================9283===================================\n",
      "9283/10000: train_loss: 2.7152930615034743 train_error 15.00% test_error 8.50%\n",
      "================================9284===================================\n",
      "9284/10000: train_loss: 2.7153847044839203 train_error 15.00% test_error 8.50%\n",
      "================================9285===================================\n",
      "9285/10000: train_loss: 2.7154768439355985 train_error 15.00% test_error 8.50%\n",
      "================================9286===================================\n",
      "9286/10000: train_loss: 2.715569668453343 train_error 15.00% test_error 8.50%\n",
      "================================9287===================================\n",
      "9287/10000: train_loss: 2.7156624377305487 train_error 15.12% test_error 8.50%\n",
      "================================9288===================================\n",
      "9288/10000: train_loss: 2.7157556243770267 train_error 15.12% test_error 8.50%\n",
      "================================9289===================================\n",
      "9289/10000: train_loss: 2.715849184227808 train_error 15.12% test_error 8.50%\n",
      "================================9290===================================\n",
      "9290/10000: train_loss: 2.7159428796464806 train_error 15.12% test_error 8.50%\n",
      "================================9291===================================\n",
      "9291/10000: train_loss: 2.716036773049562 train_error 15.12% test_error 8.50%\n",
      "================================9292===================================\n",
      "9292/10000: train_loss: 2.716130470136132 train_error 15.12% test_error 8.50%\n",
      "================================9293===================================\n",
      "9293/10000: train_loss: 2.7162227394793232 train_error 15.12% test_error 8.50%\n",
      "================================9294===================================\n",
      "9294/10000: train_loss: 2.7163156285930588 train_error 15.12% test_error 8.50%\n",
      "================================9295===================================\n",
      "9295/10000: train_loss: 2.7164087064158062 train_error 15.25% test_error 8.50%\n",
      "================================9296===================================\n",
      "9296/10000: train_loss: 2.716502084080407 train_error 15.25% test_error 8.50%\n",
      "================================9297===================================\n",
      "9297/10000: train_loss: 2.7165956997210916 train_error 15.25% test_error 8.50%\n",
      "================================9298===================================\n",
      "9298/10000: train_loss: 2.716690189674825 train_error 15.25% test_error 8.50%\n",
      "================================9299===================================\n",
      "9299/10000: train_loss: 2.716785826042978 train_error 15.25% test_error 8.50%\n",
      "================================9300===================================\n",
      "9300/10000: train_loss: 2.716882274436724 train_error 15.25% test_error 8.50%\n",
      "================================9301===================================\n",
      "9301/10000: train_loss: 2.716975995470399 train_error 15.25% test_error 8.50%\n",
      "================================9302===================================\n",
      "9302/10000: train_loss: 2.717069386009859 train_error 15.25% test_error 8.50%\n",
      "================================9303===================================\n",
      "9303/10000: train_loss: 2.717159054382284 train_error 15.25% test_error 8.50%\n",
      "================================9304===================================\n",
      "9304/10000: train_loss: 2.717245159008004 train_error 15.25% test_error 8.50%\n",
      "================================9305===================================\n",
      "9305/10000: train_loss: 2.717331622539361 train_error 15.25% test_error 8.50%\n",
      "================================9306===================================\n",
      "9306/10000: train_loss: 2.7174197021805115 train_error 15.25% test_error 8.50%\n",
      "================================9307===================================\n",
      "9307/10000: train_loss: 2.7175075638175077 train_error 15.25% test_error 8.50%\n",
      "================================9308===================================\n",
      "9308/10000: train_loss: 2.7175967156635177 train_error 15.25% test_error 8.50%\n",
      "================================9309===================================\n",
      "9309/10000: train_loss: 2.717686389395716 train_error 15.25% test_error 8.50%\n",
      "================================9310===================================\n",
      "9310/10000: train_loss: 2.7177767927514793 train_error 15.25% test_error 8.50%\n",
      "================================9311===================================\n",
      "9311/10000: train_loss: 2.717867742961906 train_error 15.25% test_error 8.50%\n",
      "================================9312===================================\n",
      "9312/10000: train_loss: 2.7179589904296364 train_error 15.25% test_error 8.50%\n",
      "================================9313===================================\n",
      "9313/10000: train_loss: 2.718051814940903 train_error 15.25% test_error 9.00%\n",
      "================================9314===================================\n",
      "9314/10000: train_loss: 2.7181490490644564 train_error 15.25% test_error 9.00%\n",
      "================================9315===================================\n",
      "9315/10000: train_loss: 2.7182493108483996 train_error 15.25% test_error 9.00%\n",
      "================================9316===================================\n",
      "9316/10000: train_loss: 2.718355220317712 train_error 15.25% test_error 9.00%\n",
      "================================9317===================================\n",
      "9317/10000: train_loss: 2.7184603808766417 train_error 15.25% test_error 9.00%\n",
      "================================9318===================================\n",
      "9318/10000: train_loss: 2.7185647052564033 train_error 15.25% test_error 9.50%\n",
      "================================9319===================================\n",
      "9319/10000: train_loss: 2.7186672494112125 train_error 15.50% test_error 9.50%\n",
      "================================9320===================================\n",
      "9320/10000: train_loss: 2.7187685326697677 train_error 15.50% test_error 9.50%\n",
      "================================9321===================================\n",
      "9321/10000: train_loss: 2.718866730204706 train_error 15.50% test_error 9.50%\n",
      "================================9322===================================\n",
      "9322/10000: train_loss: 2.7189626263354087 train_error 15.50% test_error 9.50%\n",
      "================================9323===================================\n",
      "9323/10000: train_loss: 2.7190555531947793 train_error 15.50% test_error 9.50%\n",
      "================================9324===================================\n",
      "9324/10000: train_loss: 2.719147455724712 train_error 15.50% test_error 9.50%\n",
      "================================9325===================================\n",
      "9325/10000: train_loss: 2.719239246136728 train_error 15.62% test_error 9.50%\n",
      "================================9326===================================\n",
      "9326/10000: train_loss: 2.7193315009500525 train_error 15.62% test_error 9.50%\n",
      "================================9327===================================\n",
      "9327/10000: train_loss: 2.7194258244080034 train_error 15.62% test_error 9.50%\n",
      "================================9328===================================\n",
      "9328/10000: train_loss: 2.7195202973696855 train_error 15.62% test_error 9.50%\n",
      "================================9329===================================\n",
      "9329/10000: train_loss: 2.7196101592522464 train_error 15.62% test_error 9.50%\n",
      "================================9330===================================\n",
      "9330/10000: train_loss: 2.719690627608607 train_error 15.62% test_error 9.50%\n",
      "================================9331===================================\n",
      "9331/10000: train_loss: 2.7197694294705856 train_error 15.75% test_error 9.50%\n",
      "================================9332===================================\n",
      "9332/10000: train_loss: 2.7198461379225187 train_error 15.75% test_error 9.50%\n",
      "================================9333===================================\n",
      "9333/10000: train_loss: 2.719923323370356 train_error 15.75% test_error 9.50%\n",
      "================================9334===================================\n",
      "9334/10000: train_loss: 2.7199993253673633 train_error 15.75% test_error 9.50%\n",
      "================================9335===================================\n",
      "9335/10000: train_loss: 2.7200738998869913 train_error 15.75% test_error 9.50%\n",
      "================================9336===================================\n",
      "9336/10000: train_loss: 2.720149466757784 train_error 15.75% test_error 9.50%\n",
      "================================9337===================================\n",
      "9337/10000: train_loss: 2.7202249154875786 train_error 15.75% test_error 9.50%\n",
      "================================9338===================================\n",
      "9338/10000: train_loss: 2.7203018995591783 train_error 15.75% test_error 9.50%\n",
      "================================9339===================================\n",
      "9339/10000: train_loss: 2.720378889530987 train_error 15.75% test_error 9.50%\n",
      "================================9340===================================\n",
      "9340/10000: train_loss: 2.720456611749556 train_error 15.75% test_error 9.50%\n",
      "================================9341===================================\n",
      "9341/10000: train_loss: 2.720534076546911 train_error 15.75% test_error 9.50%\n",
      "================================9342===================================\n",
      "9342/10000: train_loss: 2.7206140564595147 train_error 15.75% test_error 9.50%\n",
      "================================9343===================================\n",
      "9343/10000: train_loss: 2.720689034435774 train_error 15.88% test_error 9.50%\n",
      "================================9344===================================\n",
      "9344/10000: train_loss: 2.7207625788196825 train_error 15.88% test_error 9.50%\n",
      "================================9345===================================\n",
      "9345/10000: train_loss: 2.7208326936734943 train_error 15.88% test_error 9.50%\n",
      "================================9346===================================\n",
      "9346/10000: train_loss: 2.7209000996865753 train_error 15.88% test_error 9.50%\n",
      "================================9347===================================\n",
      "9347/10000: train_loss: 2.720970156106199 train_error 15.88% test_error 9.50%\n",
      "================================9348===================================\n",
      "9348/10000: train_loss: 2.7210456517830934 train_error 15.88% test_error 9.50%\n",
      "================================9349===================================\n",
      "9349/10000: train_loss: 2.721117382654244 train_error 15.88% test_error 9.50%\n",
      "================================9350===================================\n",
      "9350/10000: train_loss: 2.7211881827786506 train_error 15.88% test_error 9.50%\n",
      "================================9351===================================\n",
      "9351/10000: train_loss: 2.7212599663973136 train_error 15.88% test_error 9.50%\n",
      "================================9352===================================\n",
      "9352/10000: train_loss: 2.721329756482766 train_error 15.88% test_error 9.50%\n",
      "================================9353===================================\n",
      "9353/10000: train_loss: 2.7214000709930724 train_error 15.88% test_error 9.50%\n",
      "================================9354===================================\n",
      "9354/10000: train_loss: 2.7214732098380776 train_error 15.88% test_error 9.50%\n",
      "================================9355===================================\n",
      "9355/10000: train_loss: 2.721549066935454 train_error 15.88% test_error 9.50%\n",
      "================================9356===================================\n",
      "9356/10000: train_loss: 2.7216257337463254 train_error 15.88% test_error 9.50%\n",
      "================================9357===================================\n",
      "9357/10000: train_loss: 2.7217034604486905 train_error 15.88% test_error 9.50%\n",
      "================================9358===================================\n",
      "9358/10000: train_loss: 2.721782276074184 train_error 15.88% test_error 9.50%\n",
      "================================9359===================================\n",
      "9359/10000: train_loss: 2.7218628264576963 train_error 15.88% test_error 10.00%\n",
      "================================9360===================================\n",
      "9360/10000: train_loss: 2.7219451706963693 train_error 15.88% test_error 10.00%\n",
      "================================9361===================================\n",
      "9361/10000: train_loss: 2.7220277545805995 train_error 15.88% test_error 10.00%\n",
      "================================9362===================================\n",
      "9362/10000: train_loss: 2.722111773424783 train_error 15.88% test_error 10.00%\n",
      "================================9363===================================\n",
      "9363/10000: train_loss: 2.7221999749504437 train_error 15.88% test_error 10.00%\n",
      "================================9364===================================\n",
      "9364/10000: train_loss: 2.722288983775938 train_error 15.88% test_error 10.00%\n",
      "================================9365===================================\n",
      "9365/10000: train_loss: 2.722376620041985 train_error 15.88% test_error 10.00%\n",
      "================================9366===================================\n",
      "9366/10000: train_loss: 2.7224647738445054 train_error 15.88% test_error 10.00%\n",
      "================================9367===================================\n",
      "9367/10000: train_loss: 2.7225545359581997 train_error 15.88% test_error 10.00%\n",
      "================================9368===================================\n",
      "9368/10000: train_loss: 2.7226447033332963 train_error 15.88% test_error 10.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================9369===================================\n",
      "9369/10000: train_loss: 2.7227355001907805 train_error 15.88% test_error 10.00%\n",
      "================================9370===================================\n",
      "9370/10000: train_loss: 2.7228266889451898 train_error 15.88% test_error 10.00%\n",
      "================================9371===================================\n",
      "9371/10000: train_loss: 2.7229182275178956 train_error 15.88% test_error 10.00%\n",
      "================================9372===================================\n",
      "9372/10000: train_loss: 2.7230095450584093 train_error 15.88% test_error 10.00%\n",
      "================================9373===================================\n",
      "9373/10000: train_loss: 2.723098339274419 train_error 15.88% test_error 10.00%\n",
      "================================9374===================================\n",
      "9374/10000: train_loss: 2.7231849973071753 train_error 15.88% test_error 10.00%\n",
      "================================9375===================================\n",
      "9375/10000: train_loss: 2.7232742051961507 train_error 15.88% test_error 10.00%\n",
      "================================9376===================================\n",
      "9376/10000: train_loss: 2.7233652996554096 train_error 15.88% test_error 10.00%\n",
      "================================9377===================================\n",
      "9377/10000: train_loss: 2.7234569570160896 train_error 16.00% test_error 10.00%\n",
      "================================9378===================================\n",
      "9378/10000: train_loss: 2.723550745007701 train_error 16.00% test_error 10.00%\n",
      "================================9379===================================\n",
      "9379/10000: train_loss: 2.723644134708974 train_error 16.00% test_error 10.00%\n",
      "================================9380===================================\n",
      "9380/10000: train_loss: 2.723737692757357 train_error 16.00% test_error 10.00%\n",
      "================================9381===================================\n",
      "9381/10000: train_loss: 2.7238326161315016 train_error 16.00% test_error 10.00%\n",
      "================================9382===================================\n",
      "9382/10000: train_loss: 2.7239272558137095 train_error 16.00% test_error 10.00%\n",
      "================================9383===================================\n",
      "9383/10000: train_loss: 2.7240251308313734 train_error 16.00% test_error 10.00%\n",
      "================================9384===================================\n",
      "9384/10000: train_loss: 2.7241245581460913 train_error 16.00% test_error 10.00%\n",
      "================================9385===================================\n",
      "9385/10000: train_loss: 2.7242250090335487 train_error 16.00% test_error 10.00%\n",
      "================================9386===================================\n",
      "9386/10000: train_loss: 2.7243261320197742 train_error 16.00% test_error 10.00%\n",
      "================================9387===================================\n",
      "9387/10000: train_loss: 2.724429396142555 train_error 16.00% test_error 10.00%\n",
      "================================9388===================================\n",
      "9388/10000: train_loss: 2.7245359655022123 train_error 16.12% test_error 10.00%\n",
      "================================9389===================================\n",
      "9389/10000: train_loss: 2.724644136539257 train_error 16.12% test_error 10.00%\n",
      "================================9390===================================\n",
      "9390/10000: train_loss: 2.724752721675994 train_error 16.12% test_error 10.00%\n",
      "================================9391===================================\n",
      "9391/10000: train_loss: 2.724856277284149 train_error 16.12% test_error 10.00%\n",
      "================================9392===================================\n",
      "9392/10000: train_loss: 2.72495865763153 train_error 16.12% test_error 10.00%\n",
      "================================9393===================================\n",
      "9393/10000: train_loss: 2.7250629609349653 train_error 16.12% test_error 10.00%\n",
      "================================9394===================================\n",
      "9394/10000: train_loss: 2.725163386233376 train_error 16.12% test_error 10.00%\n",
      "================================9395===================================\n",
      "9395/10000: train_loss: 2.7252613975039917 train_error 16.12% test_error 10.00%\n",
      "================================9396===================================\n",
      "9396/10000: train_loss: 2.725359417923381 train_error 16.12% test_error 10.00%\n",
      "================================9397===================================\n",
      "9397/10000: train_loss: 2.725459250420397 train_error 16.12% test_error 10.00%\n",
      "================================9398===================================\n",
      "9398/10000: train_loss: 2.72556000848337 train_error 16.12% test_error 10.00%\n",
      "================================9399===================================\n",
      "9399/10000: train_loss: 2.7256608037159014 train_error 16.12% test_error 10.00%\n",
      "================================9400===================================\n",
      "9400/10000: train_loss: 2.7257620732493306 train_error 16.12% test_error 10.00%\n",
      "================================9401===================================\n",
      "9401/10000: train_loss: 2.725865958469972 train_error 16.12% test_error 10.00%\n",
      "================================9402===================================\n",
      "9402/10000: train_loss: 2.725970807735663 train_error 16.12% test_error 10.00%\n",
      "================================9403===================================\n",
      "9403/10000: train_loss: 2.726075945057211 train_error 16.12% test_error 10.00%\n",
      "================================9404===================================\n",
      "9404/10000: train_loss: 2.7261847041650977 train_error 16.12% test_error 10.00%\n",
      "================================9405===================================\n",
      "9405/10000: train_loss: 2.726295000398404 train_error 16.12% test_error 10.00%\n",
      "================================9406===================================\n",
      "9406/10000: train_loss: 2.726404419645541 train_error 16.12% test_error 10.50%\n",
      "================================9407===================================\n",
      "9407/10000: train_loss: 2.7265144425988668 train_error 16.12% test_error 10.50%\n",
      "================================9408===================================\n",
      "9408/10000: train_loss: 2.7266262692513763 train_error 16.12% test_error 10.50%\n",
      "================================9409===================================\n",
      "9409/10000: train_loss: 2.726736338141404 train_error 16.12% test_error 10.50%\n",
      "================================9410===================================\n",
      "9410/10000: train_loss: 2.726847210964174 train_error 16.12% test_error 10.50%\n",
      "================================9411===================================\n",
      "9411/10000: train_loss: 2.7269568667619524 train_error 16.12% test_error 10.50%\n",
      "================================9412===================================\n",
      "9412/10000: train_loss: 2.72706765488663 train_error 16.12% test_error 10.50%\n",
      "================================9413===================================\n",
      "9413/10000: train_loss: 2.727178929214606 train_error 16.12% test_error 10.50%\n",
      "================================9414===================================\n",
      "9414/10000: train_loss: 2.7272908437863146 train_error 16.12% test_error 10.50%\n",
      "================================9415===================================\n",
      "9415/10000: train_loss: 2.727404563555459 train_error 16.12% test_error 10.50%\n",
      "================================9416===================================\n",
      "9416/10000: train_loss: 2.727517108260046 train_error 16.12% test_error 10.50%\n",
      "================================9417===================================\n",
      "9417/10000: train_loss: 2.727629091026759 train_error 16.12% test_error 10.50%\n",
      "================================9418===================================\n",
      "9418/10000: train_loss: 2.7277411825902944 train_error 16.25% test_error 10.50%\n",
      "================================9419===================================\n",
      "9419/10000: train_loss: 2.7278537410352457 train_error 16.25% test_error 10.50%\n",
      "================================9420===================================\n",
      "9420/10000: train_loss: 2.727969324751176 train_error 16.25% test_error 10.50%\n",
      "================================9421===================================\n",
      "9421/10000: train_loss: 2.7280776142792726 train_error 16.25% test_error 10.50%\n",
      "================================9422===================================\n",
      "9422/10000: train_loss: 2.7281826622512115 train_error 16.25% test_error 10.50%\n",
      "================================9423===================================\n",
      "9423/10000: train_loss: 2.728288654250056 train_error 16.25% test_error 10.50%\n",
      "================================9424===================================\n",
      "9424/10000: train_loss: 2.7283945818252477 train_error 16.25% test_error 10.50%\n",
      "================================9425===================================\n",
      "9425/10000: train_loss: 2.7284990786111125 train_error 16.38% test_error 10.50%\n",
      "================================9426===================================\n",
      "9426/10000: train_loss: 2.7286035081412465 train_error 16.38% test_error 10.50%\n",
      "================================9427===================================\n",
      "9427/10000: train_loss: 2.728708962712451 train_error 16.38% test_error 10.50%\n",
      "================================9428===================================\n",
      "9428/10000: train_loss: 2.728814978708407 train_error 16.38% test_error 10.50%\n",
      "================================9429===================================\n",
      "9429/10000: train_loss: 2.728921029069153 train_error 16.38% test_error 10.50%\n",
      "================================9430===================================\n",
      "9430/10000: train_loss: 2.729027771294986 train_error 16.38% test_error 10.50%\n",
      "================================9431===================================\n",
      "9431/10000: train_loss: 2.729132877200249 train_error 16.50% test_error 10.50%\n",
      "================================9432===================================\n",
      "9432/10000: train_loss: 2.7292384758413837 train_error 16.50% test_error 10.50%\n",
      "================================9433===================================\n",
      "9433/10000: train_loss: 2.729344361197488 train_error 16.50% test_error 10.50%\n",
      "================================9434===================================\n",
      "9434/10000: train_loss: 2.7294498588443306 train_error 16.50% test_error 10.50%\n",
      "================================9435===================================\n",
      "9435/10000: train_loss: 2.7295532254992385 train_error 16.50% test_error 10.50%\n",
      "================================9436===================================\n",
      "9436/10000: train_loss: 2.7296567646310317 train_error 16.50% test_error 10.50%\n",
      "================================9437===================================\n",
      "9437/10000: train_loss: 2.7297596695806643 train_error 16.50% test_error 10.50%\n",
      "================================9438===================================\n",
      "9438/10000: train_loss: 2.7298663020133365 train_error 16.50% test_error 10.50%\n",
      "================================9439===================================\n",
      "9439/10000: train_loss: 2.7299728512421053 train_error 16.50% test_error 10.50%\n",
      "================================9440===================================\n",
      "9440/10000: train_loss: 2.7300787247302907 train_error 16.50% test_error 10.50%\n",
      "================================9441===================================\n",
      "9441/10000: train_loss: 2.7301850076038963 train_error 16.50% test_error 10.50%\n",
      "================================9442===================================\n",
      "9442/10000: train_loss: 2.7302901393501555 train_error 16.50% test_error 10.50%\n",
      "================================9443===================================\n",
      "9443/10000: train_loss: 2.730395017128604 train_error 16.50% test_error 10.50%\n",
      "================================9444===================================\n",
      "9444/10000: train_loss: 2.7304988672726402 train_error 16.50% test_error 10.50%\n",
      "================================9445===================================\n",
      "9445/10000: train_loss: 2.7306020055939495 train_error 16.50% test_error 11.00%\n",
      "================================9446===================================\n",
      "9446/10000: train_loss: 2.7307059703658387 train_error 16.50% test_error 11.00%\n",
      "================================9447===================================\n",
      "9447/10000: train_loss: 2.730811439926571 train_error 16.50% test_error 11.00%\n",
      "================================9448===================================\n",
      "9448/10000: train_loss: 2.730917551058674 train_error 16.50% test_error 11.00%\n",
      "================================9449===================================\n",
      "9449/10000: train_loss: 2.7310246538013496 train_error 16.50% test_error 11.00%\n",
      "================================9450===================================\n",
      "9450/10000: train_loss: 2.731129980966335 train_error 16.50% test_error 11.00%\n",
      "================================9451===================================\n",
      "9451/10000: train_loss: 2.7312350534323393 train_error 16.50% test_error 11.00%\n",
      "================================9452===================================\n",
      "9452/10000: train_loss: 2.7313378094934406 train_error 16.50% test_error 11.00%\n",
      "================================9453===================================\n",
      "9453/10000: train_loss: 2.7314399868202286 train_error 16.50% test_error 11.00%\n",
      "================================9454===================================\n",
      "9454/10000: train_loss: 2.731542273701084 train_error 16.50% test_error 11.00%\n",
      "================================9455===================================\n",
      "9455/10000: train_loss: 2.7316451659644203 train_error 16.50% test_error 11.00%\n",
      "================================9456===================================\n",
      "9456/10000: train_loss: 2.731749308224517 train_error 16.50% test_error 11.50%\n",
      "================================9457===================================\n",
      "9457/10000: train_loss: 2.7318501619476323 train_error 16.50% test_error 11.50%\n",
      "================================9458===================================\n",
      "9458/10000: train_loss: 2.7319462711281024 train_error 16.50% test_error 11.50%\n",
      "================================9459===================================\n",
      "9459/10000: train_loss: 2.7320424661420213 train_error 16.50% test_error 11.50%\n",
      "================================9460===================================\n",
      "9460/10000: train_loss: 2.7321373268650797 train_error 16.50% test_error 11.50%\n",
      "================================9461===================================\n",
      "9461/10000: train_loss: 2.7322297532967177 train_error 16.50% test_error 11.50%\n",
      "================================9462===================================\n",
      "9462/10000: train_loss: 2.7323233463833825 train_error 16.50% test_error 11.50%\n",
      "================================9463===================================\n",
      "9463/10000: train_loss: 2.732415877185083 train_error 16.50% test_error 11.50%\n",
      "================================9464===================================\n",
      "9464/10000: train_loss: 2.732508572446939 train_error 16.50% test_error 11.50%\n",
      "================================9465===================================\n",
      "9465/10000: train_loss: 2.732601340260515 train_error 16.50% test_error 12.00%\n",
      "================================9466===================================\n",
      "9466/10000: train_loss: 2.7326925710696015 train_error 16.50% test_error 12.00%\n",
      "================================9467===================================\n",
      "9467/10000: train_loss: 2.732783703666269 train_error 16.50% test_error 12.00%\n",
      "================================9468===================================\n",
      "9468/10000: train_loss: 2.7328748156759746 train_error 16.50% test_error 12.00%\n",
      "================================9469===================================\n",
      "9469/10000: train_loss: 2.7329638576980493 train_error 16.50% test_error 12.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================9470===================================\n",
      "9470/10000: train_loss: 2.733052648948263 train_error 16.50% test_error 12.00%\n",
      "================================9471===================================\n",
      "9471/10000: train_loss: 2.73314080466679 train_error 16.50% test_error 12.00%\n",
      "================================9472===================================\n",
      "9472/10000: train_loss: 2.733227234790833 train_error 16.50% test_error 12.00%\n",
      "================================9473===================================\n",
      "9473/10000: train_loss: 2.7333166379528464 train_error 16.50% test_error 12.00%\n",
      "================================9474===================================\n",
      "9474/10000: train_loss: 2.733401231800947 train_error 16.50% test_error 12.00%\n",
      "================================9475===================================\n",
      "9475/10000: train_loss: 2.7334874642914384 train_error 16.50% test_error 12.00%\n",
      "================================9476===================================\n",
      "9476/10000: train_loss: 2.7335744953688796 train_error 16.50% test_error 12.00%\n",
      "================================9477===================================\n",
      "9477/10000: train_loss: 2.7336621149979434 train_error 16.50% test_error 12.00%\n",
      "================================9478===================================\n",
      "9478/10000: train_loss: 2.733746824349335 train_error 16.50% test_error 12.00%\n",
      "================================9479===================================\n",
      "9479/10000: train_loss: 2.7338252632551345 train_error 16.50% test_error 12.00%\n",
      "================================9480===================================\n",
      "9480/10000: train_loss: 2.73390136645847 train_error 16.50% test_error 12.00%\n",
      "================================9481===================================\n",
      "9481/10000: train_loss: 2.73397482696182 train_error 16.62% test_error 12.00%\n",
      "================================9482===================================\n",
      "9482/10000: train_loss: 2.734051277604035 train_error 16.62% test_error 12.00%\n",
      "================================9483===================================\n",
      "9483/10000: train_loss: 2.7341277049225594 train_error 16.62% test_error 12.00%\n",
      "================================9484===================================\n",
      "9484/10000: train_loss: 2.7342013106653127 train_error 16.62% test_error 12.00%\n",
      "================================9485===================================\n",
      "9485/10000: train_loss: 2.7342735293866878 train_error 16.62% test_error 12.00%\n",
      "================================9486===================================\n",
      "9486/10000: train_loss: 2.734346363299557 train_error 16.62% test_error 12.00%\n",
      "================================9487===================================\n",
      "9487/10000: train_loss: 2.734420285328327 train_error 16.62% test_error 12.00%\n",
      "================================9488===================================\n",
      "9488/10000: train_loss: 2.73449757003902 train_error 16.62% test_error 12.00%\n",
      "================================9489===================================\n",
      "9489/10000: train_loss: 2.7345759701526884 train_error 16.62% test_error 12.00%\n",
      "================================9490===================================\n",
      "9490/10000: train_loss: 2.734653587894079 train_error 16.62% test_error 12.00%\n",
      "================================9491===================================\n",
      "9491/10000: train_loss: 2.7347283081272074 train_error 16.62% test_error 12.00%\n",
      "================================9492===================================\n",
      "9492/10000: train_loss: 2.7348041913682377 train_error 16.62% test_error 12.00%\n",
      "================================9493===================================\n",
      "9493/10000: train_loss: 2.734880719017943 train_error 16.62% test_error 12.00%\n",
      "================================9494===================================\n",
      "9494/10000: train_loss: 2.734956674728055 train_error 16.62% test_error 12.00%\n",
      "================================9495===================================\n",
      "9495/10000: train_loss: 2.73503638404539 train_error 16.62% test_error 12.00%\n",
      "================================9496===================================\n",
      "9496/10000: train_loss: 2.7351182789426933 train_error 16.62% test_error 12.00%\n",
      "================================9497===================================\n",
      "9497/10000: train_loss: 2.735200344830517 train_error 16.62% test_error 12.00%\n",
      "================================9498===================================\n",
      "9498/10000: train_loss: 2.73528273782052 train_error 16.62% test_error 12.00%\n",
      "================================9499===================================\n",
      "9499/10000: train_loss: 2.7353633659497802 train_error 16.62% test_error 12.00%\n",
      "================================9500===================================\n",
      "9500/10000: train_loss: 2.73544534720837 train_error 16.75% test_error 12.00%\n",
      "================================9501===================================\n",
      "9501/10000: train_loss: 2.735528220880277 train_error 16.75% test_error 12.00%\n",
      "================================9502===================================\n",
      "9502/10000: train_loss: 2.735611382497173 train_error 16.75% test_error 12.00%\n",
      "================================9503===================================\n",
      "9503/10000: train_loss: 2.7356946697535567 train_error 16.75% test_error 12.00%\n",
      "================================9504===================================\n",
      "9504/10000: train_loss: 2.7357769690458946 train_error 16.75% test_error 12.00%\n",
      "================================9505===================================\n",
      "9505/10000: train_loss: 2.735857692049083 train_error 16.75% test_error 12.00%\n",
      "================================9506===================================\n",
      "9506/10000: train_loss: 2.7359392069841513 train_error 16.75% test_error 12.00%\n",
      "================================9507===================================\n",
      "9507/10000: train_loss: 2.7360205380430753 train_error 16.75% test_error 12.00%\n",
      "================================9508===================================\n",
      "9508/10000: train_loss: 2.7361045734800955 train_error 16.75% test_error 12.00%\n",
      "================================9509===================================\n",
      "9509/10000: train_loss: 2.736188164737575 train_error 16.75% test_error 12.00%\n",
      "================================9510===================================\n",
      "9510/10000: train_loss: 2.736270973288203 train_error 16.75% test_error 12.00%\n",
      "================================9511===================================\n",
      "9511/10000: train_loss: 2.7363543325219704 train_error 16.75% test_error 12.00%\n",
      "================================9512===================================\n",
      "9512/10000: train_loss: 2.736438724613729 train_error 16.75% test_error 12.00%\n",
      "================================9513===================================\n",
      "9513/10000: train_loss: 2.7365245280896953 train_error 16.75% test_error 12.00%\n",
      "================================9514===================================\n",
      "9514/10000: train_loss: 2.7366091316182457 train_error 16.75% test_error 12.00%\n",
      "================================9515===================================\n",
      "9515/10000: train_loss: 2.7366942878366376 train_error 16.75% test_error 12.00%\n",
      "================================9516===================================\n",
      "9516/10000: train_loss: 2.736780707278595 train_error 16.75% test_error 12.00%\n",
      "================================9517===================================\n",
      "9517/10000: train_loss: 2.736863201694961 train_error 16.75% test_error 12.00%\n",
      "================================9518===================================\n",
      "9518/10000: train_loss: 2.7369419538865745 train_error 16.75% test_error 12.00%\n",
      "================================9519===================================\n",
      "9519/10000: train_loss: 2.7370197491259427 train_error 16.75% test_error 12.00%\n",
      "================================9520===================================\n",
      "9520/10000: train_loss: 2.737093495863125 train_error 16.75% test_error 12.00%\n",
      "================================9521===================================\n",
      "9521/10000: train_loss: 2.737167342322668 train_error 16.75% test_error 12.00%\n",
      "================================9522===================================\n",
      "9522/10000: train_loss: 2.737240428747672 train_error 16.75% test_error 12.00%\n",
      "================================9523===================================\n",
      "9523/10000: train_loss: 2.7373141138002213 train_error 16.75% test_error 12.00%\n",
      "================================9524===================================\n",
      "9524/10000: train_loss: 2.737389983084295 train_error 16.75% test_error 12.00%\n",
      "================================9525===================================\n",
      "9525/10000: train_loss: 2.7374674585111705 train_error 16.75% test_error 12.00%\n",
      "================================9526===================================\n",
      "9526/10000: train_loss: 2.73754516409599 train_error 16.75% test_error 12.00%\n",
      "================================9527===================================\n",
      "9527/10000: train_loss: 2.7376223839979446 train_error 16.88% test_error 12.00%\n",
      "================================9528===================================\n",
      "9528/10000: train_loss: 2.7376984083120006 train_error 16.88% test_error 12.00%\n",
      "================================9529===================================\n",
      "9529/10000: train_loss: 2.7377727708490984 train_error 16.88% test_error 12.00%\n",
      "================================9530===================================\n",
      "9530/10000: train_loss: 2.7378456779224694 train_error 16.88% test_error 12.00%\n",
      "================================9531===================================\n",
      "9531/10000: train_loss: 2.7379183263281095 train_error 16.88% test_error 12.00%\n",
      "================================9532===================================\n",
      "9532/10000: train_loss: 2.7379910334948367 train_error 16.88% test_error 12.00%\n",
      "================================9533===================================\n",
      "9533/10000: train_loss: 2.7380638208699706 train_error 16.88% test_error 12.00%\n",
      "================================9534===================================\n",
      "9534/10000: train_loss: 2.73813687717489 train_error 16.88% test_error 12.00%\n",
      "================================9535===================================\n",
      "9535/10000: train_loss: 2.7382102702493003 train_error 16.88% test_error 12.00%\n",
      "================================9536===================================\n",
      "9536/10000: train_loss: 2.7382824515430695 train_error 16.88% test_error 12.00%\n",
      "================================9537===================================\n",
      "9537/10000: train_loss: 2.738355995520533 train_error 16.88% test_error 12.00%\n",
      "================================9538===================================\n",
      "9538/10000: train_loss: 2.738431532704265 train_error 16.88% test_error 11.50%\n",
      "================================9539===================================\n",
      "9539/10000: train_loss: 2.738502259612217 train_error 16.88% test_error 11.50%\n",
      "================================9540===================================\n",
      "9540/10000: train_loss: 2.7385749829134056 train_error 16.88% test_error 11.50%\n",
      "================================9541===================================\n",
      "9541/10000: train_loss: 2.738648692371551 train_error 16.88% test_error 11.50%\n",
      "================================9542===================================\n",
      "9542/10000: train_loss: 2.738722020494435 train_error 16.88% test_error 11.50%\n",
      "================================9543===================================\n",
      "9543/10000: train_loss: 2.7387921799319077 train_error 16.88% test_error 11.50%\n",
      "================================9544===================================\n",
      "9544/10000: train_loss: 2.738862062377522 train_error 16.88% test_error 11.50%\n",
      "================================9545===================================\n",
      "9545/10000: train_loss: 2.738931191212107 train_error 16.88% test_error 11.50%\n",
      "================================9546===================================\n",
      "9546/10000: train_loss: 2.739000471389833 train_error 16.88% test_error 11.50%\n",
      "================================9547===================================\n",
      "9547/10000: train_loss: 2.7390701627747105 train_error 16.88% test_error 11.50%\n",
      "================================9548===================================\n",
      "9548/10000: train_loss: 2.7391401395388604 train_error 16.88% test_error 11.50%\n",
      "================================9549===================================\n",
      "9549/10000: train_loss: 2.7392092389679052 train_error 16.88% test_error 11.50%\n",
      "================================9550===================================\n",
      "9550/10000: train_loss: 2.739278718827472 train_error 16.88% test_error 11.50%\n",
      "================================9551===================================\n",
      "9551/10000: train_loss: 2.739348531787391 train_error 16.88% test_error 11.50%\n",
      "================================9552===================================\n",
      "9552/10000: train_loss: 2.739418429093015 train_error 16.88% test_error 11.50%\n",
      "================================9553===================================\n",
      "9553/10000: train_loss: 2.7394874620576175 train_error 16.88% test_error 11.50%\n",
      "================================9554===================================\n",
      "9554/10000: train_loss: 2.7395564540505104 train_error 16.88% test_error 11.50%\n",
      "================================9555===================================\n",
      "9555/10000: train_loss: 2.739626455638774 train_error 16.88% test_error 11.50%\n",
      "================================9556===================================\n",
      "9556/10000: train_loss: 2.7396974037284756 train_error 16.88% test_error 11.50%\n",
      "================================9557===================================\n",
      "9557/10000: train_loss: 2.7397678013476554 train_error 16.88% test_error 11.50%\n",
      "================================9558===================================\n",
      "9558/10000: train_loss: 2.7398342778270166 train_error 16.88% test_error 11.50%\n",
      "================================9559===================================\n",
      "9559/10000: train_loss: 2.7398964439328926 train_error 16.88% test_error 11.50%\n",
      "================================9560===================================\n",
      "9560/10000: train_loss: 2.7399578416605297 train_error 16.88% test_error 11.50%\n",
      "================================9561===================================\n",
      "9561/10000: train_loss: 2.7400200207433763 train_error 16.88% test_error 11.50%\n",
      "================================9562===================================\n",
      "9562/10000: train_loss: 2.740079523343389 train_error 16.88% test_error 11.50%\n",
      "================================9563===================================\n",
      "9563/10000: train_loss: 2.7401389896893114 train_error 16.88% test_error 11.50%\n",
      "================================9564===================================\n",
      "9564/10000: train_loss: 2.7401987789190114 train_error 16.88% test_error 11.50%\n",
      "================================9565===================================\n",
      "9565/10000: train_loss: 2.7402601719695157 train_error 16.88% test_error 11.50%\n",
      "================================9566===================================\n",
      "9566/10000: train_loss: 2.740324078665952 train_error 16.88% test_error 11.50%\n",
      "================================9567===================================\n",
      "9567/10000: train_loss: 2.7403889134574726 train_error 16.88% test_error 11.50%\n",
      "================================9568===================================\n",
      "9568/10000: train_loss: 2.7404542819196487 train_error 16.88% test_error 11.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================9569===================================\n",
      "9569/10000: train_loss: 2.740519979651579 train_error 16.88% test_error 11.50%\n",
      "================================9570===================================\n",
      "9570/10000: train_loss: 2.7405865269538228 train_error 16.88% test_error 11.50%\n",
      "================================9571===================================\n",
      "9571/10000: train_loss: 2.7406533700870663 train_error 16.88% test_error 11.50%\n",
      "================================9572===================================\n",
      "9572/10000: train_loss: 2.7407203584503295 train_error 16.88% test_error 11.50%\n",
      "================================9573===================================\n",
      "9573/10000: train_loss: 2.7407879801868393 train_error 16.88% test_error 11.50%\n",
      "================================9574===================================\n",
      "9574/10000: train_loss: 2.740855666781729 train_error 17.00% test_error 11.50%\n",
      "================================9575===================================\n",
      "9575/10000: train_loss: 2.7409233066528276 train_error 17.00% test_error 11.50%\n",
      "================================9576===================================\n",
      "9576/10000: train_loss: 2.740991361610595 train_error 17.00% test_error 11.50%\n",
      "================================9577===================================\n",
      "9577/10000: train_loss: 2.741060597743697 train_error 17.00% test_error 11.50%\n",
      "================================9578===================================\n",
      "9578/10000: train_loss: 2.741130913227154 train_error 17.00% test_error 11.50%\n",
      "================================9579===================================\n",
      "9579/10000: train_loss: 2.7412020101632235 train_error 17.00% test_error 11.50%\n",
      "================================9580===================================\n",
      "9580/10000: train_loss: 2.741273333772016 train_error 17.00% test_error 11.50%\n",
      "================================9581===================================\n",
      "9581/10000: train_loss: 2.7413438295092933 train_error 17.00% test_error 11.50%\n",
      "================================9582===================================\n",
      "9582/10000: train_loss: 2.7414142717537517 train_error 17.00% test_error 11.50%\n",
      "================================9583===================================\n",
      "9583/10000: train_loss: 2.7414857983188785 train_error 17.00% test_error 11.50%\n",
      "================================9584===================================\n",
      "9584/10000: train_loss: 2.74155925998311 train_error 17.00% test_error 11.50%\n",
      "================================9585===================================\n",
      "9585/10000: train_loss: 2.741632007804163 train_error 17.00% test_error 11.50%\n",
      "================================9586===================================\n",
      "9586/10000: train_loss: 2.7417045537998623 train_error 17.00% test_error 11.50%\n",
      "================================9587===================================\n",
      "9587/10000: train_loss: 2.741777919159656 train_error 17.00% test_error 11.50%\n",
      "================================9588===================================\n",
      "9588/10000: train_loss: 2.7418517693251623 train_error 17.00% test_error 11.50%\n",
      "================================9589===================================\n",
      "9589/10000: train_loss: 2.741928223718577 train_error 17.00% test_error 11.50%\n",
      "================================9590===================================\n",
      "9590/10000: train_loss: 2.742006199874746 train_error 17.12% test_error 11.50%\n",
      "================================9591===================================\n",
      "9591/10000: train_loss: 2.742084953592757 train_error 17.12% test_error 11.50%\n",
      "================================9592===================================\n",
      "9592/10000: train_loss: 2.7421635490499727 train_error 17.12% test_error 11.50%\n",
      "================================9593===================================\n",
      "9593/10000: train_loss: 2.7422397394555365 train_error 17.12% test_error 11.50%\n",
      "================================9594===================================\n",
      "9594/10000: train_loss: 2.742316315735712 train_error 17.12% test_error 11.50%\n",
      "================================9595===================================\n",
      "9595/10000: train_loss: 2.742395119241446 train_error 17.12% test_error 11.50%\n",
      "================================9596===================================\n",
      "9596/10000: train_loss: 2.7424721749954335 train_error 17.12% test_error 11.50%\n",
      "================================9597===================================\n",
      "9597/10000: train_loss: 2.7425471547138804 train_error 17.12% test_error 11.50%\n",
      "================================9598===================================\n",
      "9598/10000: train_loss: 2.7426195838936938 train_error 17.25% test_error 11.50%\n",
      "================================9599===================================\n",
      "9599/10000: train_loss: 2.7426920663766934 train_error 17.25% test_error 11.50%\n",
      "================================9600===================================\n",
      "9600/10000: train_loss: 2.742764012351733 train_error 17.25% test_error 11.50%\n",
      "================================9601===================================\n",
      "9601/10000: train_loss: 2.742833982729624 train_error 17.25% test_error 11.50%\n",
      "================================9602===================================\n",
      "9602/10000: train_loss: 2.742896115153398 train_error 17.25% test_error 11.50%\n",
      "================================9603===================================\n",
      "9603/10000: train_loss: 2.742957746790275 train_error 17.25% test_error 11.50%\n",
      "================================9604===================================\n",
      "9604/10000: train_loss: 2.7430158011998222 train_error 17.25% test_error 11.50%\n",
      "================================9605===================================\n",
      "9605/10000: train_loss: 2.743068884941034 train_error 17.25% test_error 11.50%\n",
      "================================9606===================================\n",
      "9606/10000: train_loss: 2.7431209711860696 train_error 17.25% test_error 11.50%\n",
      "================================9607===================================\n",
      "9607/10000: train_loss: 2.7431760629552846 train_error 17.25% test_error 11.50%\n",
      "================================9608===================================\n",
      "9608/10000: train_loss: 2.7432342007580974 train_error 17.12% test_error 12.00%\n",
      "================================9609===================================\n",
      "9609/10000: train_loss: 2.7432904772076028 train_error 17.12% test_error 12.00%\n",
      "================================9610===================================\n",
      "9610/10000: train_loss: 2.7433463803949865 train_error 17.12% test_error 12.00%\n",
      "================================9611===================================\n",
      "9611/10000: train_loss: 2.743401071985749 train_error 17.12% test_error 12.00%\n",
      "================================9612===================================\n",
      "9612/10000: train_loss: 2.7434548312430374 train_error 17.12% test_error 12.00%\n",
      "================================9613===================================\n",
      "9613/10000: train_loss: 2.7435114820148367 train_error 17.12% test_error 12.00%\n",
      "================================9614===================================\n",
      "9614/10000: train_loss: 2.7435691295658065 train_error 17.12% test_error 12.00%\n",
      "================================9615===================================\n",
      "9615/10000: train_loss: 2.7436260094318863 train_error 17.12% test_error 12.00%\n",
      "================================9616===================================\n",
      "9616/10000: train_loss: 2.743683137428617 train_error 17.12% test_error 12.00%\n",
      "================================9617===================================\n",
      "9617/10000: train_loss: 2.743741083082195 train_error 17.12% test_error 12.00%\n",
      "================================9618===================================\n",
      "9618/10000: train_loss: 2.743799424777732 train_error 17.12% test_error 12.00%\n",
      "================================9619===================================\n",
      "9619/10000: train_loss: 2.743854854538962 train_error 17.12% test_error 12.00%\n",
      "================================9620===================================\n",
      "9620/10000: train_loss: 2.743910216034542 train_error 17.12% test_error 12.00%\n",
      "================================9621===================================\n",
      "9621/10000: train_loss: 2.7439662462980765 train_error 17.12% test_error 12.00%\n",
      "================================9622===================================\n",
      "9622/10000: train_loss: 2.744021384353609 train_error 17.12% test_error 12.00%\n",
      "================================9623===================================\n",
      "9623/10000: train_loss: 2.7440791350517504 train_error 17.12% test_error 12.00%\n",
      "================================9624===================================\n",
      "9624/10000: train_loss: 2.7441370684981563 train_error 17.12% test_error 12.00%\n",
      "================================9625===================================\n",
      "9625/10000: train_loss: 2.7441948732253056 train_error 17.12% test_error 12.00%\n",
      "================================9626===================================\n",
      "9626/10000: train_loss: 2.744253265337413 train_error 17.25% test_error 12.00%\n",
      "================================9627===================================\n",
      "9627/10000: train_loss: 2.744312064734608 train_error 17.25% test_error 12.00%\n",
      "================================9628===================================\n",
      "9628/10000: train_loss: 2.744371229516046 train_error 17.25% test_error 12.00%\n",
      "================================9629===================================\n",
      "9629/10000: train_loss: 2.7444316561336954 train_error 17.25% test_error 12.00%\n",
      "================================9630===================================\n",
      "9630/10000: train_loss: 2.7444923461955466 train_error 17.25% test_error 12.00%\n",
      "================================9631===================================\n",
      "9631/10000: train_loss: 2.744552776741243 train_error 17.25% test_error 12.00%\n",
      "================================9632===================================\n",
      "9632/10000: train_loss: 2.7446130812028167 train_error 17.25% test_error 12.00%\n",
      "================================9633===================================\n",
      "9633/10000: train_loss: 2.744672886404161 train_error 17.38% test_error 12.00%\n",
      "================================9634===================================\n",
      "9634/10000: train_loss: 2.744732788522686 train_error 17.38% test_error 12.00%\n",
      "================================9635===================================\n",
      "9635/10000: train_loss: 2.7447935780250816 train_error 17.38% test_error 12.00%\n",
      "================================9636===================================\n",
      "9636/10000: train_loss: 2.7448551212092362 train_error 17.38% test_error 12.00%\n",
      "================================9637===================================\n",
      "9637/10000: train_loss: 2.7449164981864116 train_error 17.38% test_error 12.00%\n",
      "================================9638===================================\n",
      "9638/10000: train_loss: 2.7449774693418174 train_error 17.38% test_error 12.00%\n",
      "================================9639===================================\n",
      "9639/10000: train_loss: 2.7450387039007373 train_error 17.38% test_error 12.00%\n",
      "================================9640===================================\n",
      "9640/10000: train_loss: 2.745099705808369 train_error 17.38% test_error 12.00%\n",
      "================================9641===================================\n",
      "9641/10000: train_loss: 2.7451616915059986 train_error 17.38% test_error 12.00%\n",
      "================================9642===================================\n",
      "9642/10000: train_loss: 2.745224020246683 train_error 17.38% test_error 12.00%\n",
      "================================9643===================================\n",
      "9643/10000: train_loss: 2.745288114317053 train_error 17.38% test_error 12.00%\n",
      "================================9644===================================\n",
      "9644/10000: train_loss: 2.7453526295104114 train_error 17.38% test_error 12.00%\n",
      "================================9645===================================\n",
      "9645/10000: train_loss: 2.7454151406730753 train_error 17.38% test_error 12.00%\n",
      "================================9646===================================\n",
      "9646/10000: train_loss: 2.74547870343045 train_error 17.38% test_error 12.00%\n",
      "================================9647===================================\n",
      "9647/10000: train_loss: 2.7455406162492935 train_error 17.38% test_error 12.00%\n",
      "================================9648===================================\n",
      "9648/10000: train_loss: 2.7456028595794577 train_error 17.38% test_error 12.00%\n",
      "================================9649===================================\n",
      "9649/10000: train_loss: 2.7456655404040036 train_error 17.38% test_error 12.00%\n",
      "================================9650===================================\n",
      "9650/10000: train_loss: 2.745722330667041 train_error 17.38% test_error 12.00%\n",
      "================================9651===================================\n",
      "9651/10000: train_loss: 2.74577679188115 train_error 17.38% test_error 12.00%\n",
      "================================9652===================================\n",
      "9652/10000: train_loss: 2.745830220532912 train_error 17.38% test_error 12.00%\n",
      "================================9653===================================\n",
      "9653/10000: train_loss: 2.745887787877684 train_error 17.38% test_error 12.00%\n",
      "================================9654===================================\n",
      "9654/10000: train_loss: 2.745941754388139 train_error 17.38% test_error 12.00%\n",
      "================================9655===================================\n",
      "9655/10000: train_loss: 2.7459896869012645 train_error 17.38% test_error 12.00%\n",
      "================================9656===================================\n",
      "9656/10000: train_loss: 2.746034358924198 train_error 17.38% test_error 12.00%\n",
      "================================9657===================================\n",
      "9657/10000: train_loss: 2.7460741621406317 train_error 17.38% test_error 12.00%\n",
      "================================9658===================================\n",
      "9658/10000: train_loss: 2.7461160319332536 train_error 17.38% test_error 12.00%\n",
      "================================9659===================================\n",
      "9659/10000: train_loss: 2.746158804474329 train_error 17.38% test_error 12.00%\n",
      "================================9660===================================\n",
      "9660/10000: train_loss: 2.7461992144689527 train_error 17.38% test_error 12.00%\n",
      "================================9661===================================\n",
      "9661/10000: train_loss: 2.746236289768131 train_error 17.38% test_error 12.00%\n",
      "================================9662===================================\n",
      "9662/10000: train_loss: 2.7462740858054033 train_error 17.50% test_error 12.00%\n",
      "================================9663===================================\n",
      "9663/10000: train_loss: 2.746311663959675 train_error 17.50% test_error 12.00%\n",
      "================================9664===================================\n",
      "9664/10000: train_loss: 2.7463517270843556 train_error 17.50% test_error 12.00%\n",
      "================================9665===================================\n",
      "9665/10000: train_loss: 2.746395600126644 train_error 17.50% test_error 12.00%\n",
      "================================9666===================================\n",
      "9666/10000: train_loss: 2.746439285188991 train_error 17.62% test_error 12.00%\n",
      "================================9667===================================\n",
      "9667/10000: train_loss: 2.7464787310648084 train_error 17.62% test_error 12.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================9668===================================\n",
      "9668/10000: train_loss: 2.746517732655639 train_error 17.62% test_error 12.00%\n",
      "================================9669===================================\n",
      "9669/10000: train_loss: 2.746557150000449 train_error 17.62% test_error 12.00%\n",
      "================================9670===================================\n",
      "9670/10000: train_loss: 2.746596816503443 train_error 17.62% test_error 12.00%\n",
      "================================9671===================================\n",
      "9671/10000: train_loss: 2.746628715356399 train_error 17.62% test_error 12.00%\n",
      "================================9672===================================\n",
      "9672/10000: train_loss: 2.746660756761326 train_error 17.62% test_error 12.00%\n",
      "================================9673===================================\n",
      "9673/10000: train_loss: 2.7466931382721222 train_error 17.62% test_error 12.00%\n",
      "================================9674===================================\n",
      "9674/10000: train_loss: 2.7467257688213222 train_error 17.62% test_error 12.00%\n",
      "================================9675===================================\n",
      "9675/10000: train_loss: 2.74676112365344 train_error 17.62% test_error 12.00%\n",
      "================================9676===================================\n",
      "9676/10000: train_loss: 2.746799405186756 train_error 17.62% test_error 12.00%\n",
      "================================9677===================================\n",
      "9677/10000: train_loss: 2.7468383005444155 train_error 17.62% test_error 12.00%\n",
      "================================9678===================================\n",
      "9678/10000: train_loss: 2.746877044719019 train_error 17.62% test_error 12.00%\n",
      "================================9679===================================\n",
      "9679/10000: train_loss: 2.746917998818919 train_error 17.62% test_error 12.00%\n",
      "================================9680===================================\n",
      "9680/10000: train_loss: 2.7469599620096 train_error 17.62% test_error 12.00%\n",
      "================================9681===================================\n",
      "9681/10000: train_loss: 2.7470031640926917 train_error 17.62% test_error 12.00%\n",
      "================================9682===================================\n",
      "9682/10000: train_loss: 2.7470474796642446 train_error 17.62% test_error 12.00%\n",
      "================================9683===================================\n",
      "9683/10000: train_loss: 2.7470900438552084 train_error 17.62% test_error 12.00%\n",
      "================================9684===================================\n",
      "9684/10000: train_loss: 2.7471310573100447 train_error 17.62% test_error 12.00%\n",
      "================================9685===================================\n",
      "9685/10000: train_loss: 2.7471721457898655 train_error 17.62% test_error 12.00%\n",
      "================================9686===================================\n",
      "9686/10000: train_loss: 2.7472190514300405 train_error 17.62% test_error 12.00%\n",
      "================================9687===================================\n",
      "9687/10000: train_loss: 2.7472674569298596 train_error 17.62% test_error 12.00%\n",
      "================================9688===================================\n",
      "9688/10000: train_loss: 2.747318203086092 train_error 17.62% test_error 12.00%\n",
      "================================9689===================================\n",
      "9689/10000: train_loss: 2.747369901005703 train_error 17.62% test_error 12.00%\n",
      "================================9690===================================\n",
      "9690/10000: train_loss: 2.7474235177363684 train_error 17.62% test_error 12.00%\n",
      "================================9691===================================\n",
      "9691/10000: train_loss: 2.7474771742078197 train_error 17.62% test_error 12.00%\n",
      "================================9692===================================\n",
      "9692/10000: train_loss: 2.7475323645088414 train_error 17.62% test_error 12.00%\n",
      "================================9693===================================\n",
      "9693/10000: train_loss: 2.747589192428529 train_error 17.62% test_error 12.00%\n",
      "================================9694===================================\n",
      "9694/10000: train_loss: 2.7476487807631793 train_error 17.62% test_error 12.00%\n",
      "================================9695===================================\n",
      "9695/10000: train_loss: 2.747710906894393 train_error 17.75% test_error 12.00%\n",
      "================================9696===================================\n",
      "9696/10000: train_loss: 2.7477725048261727 train_error 17.75% test_error 12.00%\n",
      "================================9697===================================\n",
      "9697/10000: train_loss: 2.7478352927219896 train_error 17.75% test_error 12.00%\n",
      "================================9698===================================\n",
      "9698/10000: train_loss: 2.747899245455814 train_error 17.75% test_error 12.00%\n",
      "================================9699===================================\n",
      "9699/10000: train_loss: 2.747963186320441 train_error 17.75% test_error 12.00%\n",
      "================================9700===================================\n",
      "9700/10000: train_loss: 2.748026638318192 train_error 17.75% test_error 12.00%\n",
      "================================9701===================================\n",
      "9701/10000: train_loss: 2.7480904916777913 train_error 17.75% test_error 12.00%\n",
      "================================9702===================================\n",
      "9702/10000: train_loss: 2.7481556068861335 train_error 17.75% test_error 12.00%\n",
      "================================9703===================================\n",
      "9703/10000: train_loss: 2.7482217435745953 train_error 17.75% test_error 12.00%\n",
      "================================9704===================================\n",
      "9704/10000: train_loss: 2.748289817143986 train_error 17.75% test_error 12.00%\n",
      "================================9705===================================\n",
      "9705/10000: train_loss: 2.7483579067544652 train_error 17.75% test_error 12.00%\n",
      "================================9706===================================\n",
      "9706/10000: train_loss: 2.74842614535973 train_error 17.75% test_error 12.00%\n",
      "================================9707===================================\n",
      "9707/10000: train_loss: 2.7484966604357366 train_error 17.75% test_error 12.00%\n",
      "================================9708===================================\n",
      "9708/10000: train_loss: 2.7485704644628552 train_error 17.75% test_error 12.00%\n",
      "================================9709===================================\n",
      "9709/10000: train_loss: 2.748643550272245 train_error 17.75% test_error 12.00%\n",
      "================================9710===================================\n",
      "9710/10000: train_loss: 2.748717418135195 train_error 17.75% test_error 12.00%\n",
      "================================9711===================================\n",
      "9711/10000: train_loss: 2.748791716194261 train_error 17.75% test_error 12.00%\n",
      "================================9712===================================\n",
      "9712/10000: train_loss: 2.7488657219856236 train_error 17.75% test_error 12.00%\n",
      "================================9713===================================\n",
      "9713/10000: train_loss: 2.748940074498136 train_error 17.75% test_error 12.00%\n",
      "================================9714===================================\n",
      "9714/10000: train_loss: 2.7490150784421106 train_error 17.75% test_error 12.00%\n",
      "================================9715===================================\n",
      "9715/10000: train_loss: 2.7490916454614354 train_error 17.75% test_error 12.00%\n",
      "================================9716===================================\n",
      "9716/10000: train_loss: 2.7491674452992925 train_error 17.75% test_error 12.00%\n",
      "================================9717===================================\n",
      "9717/10000: train_loss: 2.749244465564339 train_error 17.75% test_error 12.00%\n",
      "================================9718===================================\n",
      "9718/10000: train_loss: 2.7493230629154324 train_error 17.75% test_error 12.00%\n",
      "================================9719===================================\n",
      "9719/10000: train_loss: 2.7494014527971107 train_error 17.88% test_error 12.00%\n",
      "================================9720===================================\n",
      "9720/10000: train_loss: 2.749481293552026 train_error 17.88% test_error 12.00%\n",
      "================================9721===================================\n",
      "9721/10000: train_loss: 2.7495619179539768 train_error 17.88% test_error 12.00%\n",
      "================================9722===================================\n",
      "9722/10000: train_loss: 2.7496422553516395 train_error 17.88% test_error 12.00%\n",
      "================================9723===================================\n",
      "9723/10000: train_loss: 2.749722765669171 train_error 17.88% test_error 12.00%\n",
      "================================9724===================================\n",
      "9724/10000: train_loss: 2.7498067301451807 train_error 17.88% test_error 12.00%\n",
      "================================9725===================================\n",
      "9725/10000: train_loss: 2.74989231811863 train_error 18.00% test_error 12.00%\n",
      "================================9726===================================\n",
      "9726/10000: train_loss: 2.7499801471286958 train_error 18.00% test_error 12.00%\n",
      "================================9727===================================\n",
      "9727/10000: train_loss: 2.7500653094211 train_error 18.00% test_error 12.00%\n",
      "================================9728===================================\n",
      "9728/10000: train_loss: 2.750148174856168 train_error 18.00% test_error 12.00%\n",
      "================================9729===================================\n",
      "9729/10000: train_loss: 2.750227036386921 train_error 18.00% test_error 12.00%\n",
      "================================9730===================================\n",
      "9730/10000: train_loss: 2.750300060221089 train_error 18.00% test_error 12.00%\n",
      "================================9731===================================\n",
      "9731/10000: train_loss: 2.750371296762064 train_error 18.00% test_error 12.00%\n",
      "================================9732===================================\n",
      "9732/10000: train_loss: 2.7504411966882936 train_error 18.12% test_error 12.00%\n",
      "================================9733===================================\n",
      "9733/10000: train_loss: 2.7505101842533373 train_error 18.12% test_error 12.00%\n",
      "================================9734===================================\n",
      "9734/10000: train_loss: 2.750578127172658 train_error 18.12% test_error 12.00%\n",
      "================================9735===================================\n",
      "9735/10000: train_loss: 2.750642082695747 train_error 18.12% test_error 12.00%\n",
      "================================9736===================================\n",
      "9736/10000: train_loss: 2.750705276239399 train_error 18.12% test_error 12.00%\n",
      "================================9737===================================\n",
      "9737/10000: train_loss: 2.7507688172925637 train_error 18.12% test_error 12.00%\n",
      "================================9738===================================\n",
      "9738/10000: train_loss: 2.7508311378693646 train_error 18.12% test_error 12.00%\n",
      "================================9739===================================\n",
      "9739/10000: train_loss: 2.7508893760277657 train_error 18.12% test_error 12.00%\n",
      "================================9740===================================\n",
      "9740/10000: train_loss: 2.7509452697253574 train_error 18.12% test_error 12.00%\n",
      "================================9741===================================\n",
      "9741/10000: train_loss: 2.7510015144770956 train_error 18.12% test_error 12.00%\n",
      "================================9742===================================\n",
      "9742/10000: train_loss: 2.7510593656927385 train_error 18.25% test_error 12.00%\n",
      "================================9743===================================\n",
      "9743/10000: train_loss: 2.7511174163671512 train_error 18.25% test_error 12.00%\n",
      "================================9744===================================\n",
      "9744/10000: train_loss: 2.751173122905584 train_error 18.25% test_error 12.00%\n",
      "================================9745===================================\n",
      "9745/10000: train_loss: 2.751229227782821 train_error 18.25% test_error 12.00%\n",
      "================================9746===================================\n",
      "9746/10000: train_loss: 2.7512847395342397 train_error 18.25% test_error 12.50%\n",
      "================================9747===================================\n",
      "9747/10000: train_loss: 2.7513388230107454 train_error 18.25% test_error 12.50%\n",
      "================================9748===================================\n",
      "9748/10000: train_loss: 2.7513930462631513 train_error 18.25% test_error 12.50%\n",
      "================================9749===================================\n",
      "9749/10000: train_loss: 2.7514453041793443 train_error 18.25% test_error 12.50%\n",
      "================================9750===================================\n",
      "9750/10000: train_loss: 2.7514999518200853 train_error 18.25% test_error 12.50%\n",
      "================================9751===================================\n",
      "9751/10000: train_loss: 2.7515562161103677 train_error 18.25% test_error 12.50%\n",
      "================================9752===================================\n",
      "9752/10000: train_loss: 2.751612787036497 train_error 18.25% test_error 12.50%\n",
      "================================9753===================================\n",
      "9753/10000: train_loss: 2.7516678511072215 train_error 18.25% test_error 12.50%\n",
      "================================9754===================================\n",
      "9754/10000: train_loss: 2.751722527400457 train_error 18.12% test_error 12.50%\n",
      "================================9755===================================\n",
      "9755/10000: train_loss: 2.751779304001288 train_error 18.25% test_error 12.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================9756===================================\n",
      "9756/10000: train_loss: 2.751840406766317 train_error 18.25% test_error 12.00%\n",
      "================================9757===================================\n",
      "9757/10000: train_loss: 2.751902129244409 train_error 18.25% test_error 12.00%\n",
      "================================9758===================================\n",
      "9758/10000: train_loss: 2.7519649829090365 train_error 18.25% test_error 12.00%\n",
      "================================9759===================================\n",
      "9759/10000: train_loss: 2.752030400032414 train_error 18.25% test_error 12.00%\n",
      "================================9760===================================\n",
      "9760/10000: train_loss: 2.7520949076485897 train_error 18.25% test_error 12.00%\n",
      "================================9761===================================\n",
      "9761/10000: train_loss: 2.752159184148959 train_error 18.25% test_error 12.00%\n",
      "================================9762===================================\n",
      "9762/10000: train_loss: 2.7522203960813654 train_error 18.25% test_error 12.00%\n",
      "================================9763===================================\n",
      "9763/10000: train_loss: 2.7522797149716465 train_error 18.25% test_error 12.00%\n",
      "================================9764===================================\n",
      "9764/10000: train_loss: 2.7523393732103516 train_error 18.25% test_error 12.00%\n",
      "================================9765===================================\n",
      "9765/10000: train_loss: 2.752400621376638 train_error 18.25% test_error 12.00%\n",
      "================================9766===================================\n",
      "9766/10000: train_loss: 2.7524639199505305 train_error 18.25% test_error 12.00%\n",
      "================================9767===================================\n",
      "9767/10000: train_loss: 2.7525256029658642 train_error 18.25% test_error 12.00%\n",
      "================================9768===================================\n",
      "9768/10000: train_loss: 2.7525876228694792 train_error 18.25% test_error 12.00%\n",
      "================================9769===================================\n",
      "9769/10000: train_loss: 2.75264743475412 train_error 18.25% test_error 12.00%\n",
      "================================9770===================================\n",
      "9770/10000: train_loss: 2.75269999934576 train_error 18.25% test_error 12.00%\n",
      "================================9771===================================\n",
      "9771/10000: train_loss: 2.752751634552759 train_error 18.25% test_error 12.00%\n",
      "================================9772===================================\n",
      "9772/10000: train_loss: 2.7528039611237585 train_error 18.25% test_error 12.00%\n",
      "================================9773===================================\n",
      "9773/10000: train_loss: 2.7528561982623225 train_error 18.25% test_error 12.00%\n",
      "================================9774===================================\n",
      "9774/10000: train_loss: 2.752906629791676 train_error 18.25% test_error 12.00%\n",
      "================================9775===================================\n",
      "9775/10000: train_loss: 2.7529571118486182 train_error 18.25% test_error 12.00%\n",
      "================================9776===================================\n",
      "9776/10000: train_loss: 2.7530063063478125 train_error 18.25% test_error 12.00%\n",
      "================================9777===================================\n",
      "9777/10000: train_loss: 2.753056196665775 train_error 18.38% test_error 12.00%\n",
      "================================9778===================================\n",
      "9778/10000: train_loss: 2.753106240683764 train_error 18.38% test_error 12.00%\n",
      "================================9779===================================\n",
      "9779/10000: train_loss: 2.753156596118864 train_error 18.38% test_error 12.00%\n",
      "================================9780===================================\n",
      "9780/10000: train_loss: 2.7532066510370847 train_error 18.38% test_error 12.00%\n",
      "================================9781===================================\n",
      "9781/10000: train_loss: 2.753256836979575 train_error 18.38% test_error 12.00%\n",
      "================================9782===================================\n",
      "9782/10000: train_loss: 2.7533078142903227 train_error 18.38% test_error 12.00%\n",
      "================================9783===================================\n",
      "9783/10000: train_loss: 2.7533575527815755 train_error 18.38% test_error 12.00%\n",
      "================================9784===================================\n",
      "9784/10000: train_loss: 2.753400808730528 train_error 18.38% test_error 12.00%\n",
      "================================9785===================================\n",
      "9785/10000: train_loss: 2.753444525071369 train_error 18.38% test_error 12.00%\n",
      "================================9786===================================\n",
      "9786/10000: train_loss: 2.7534880926819216 train_error 18.38% test_error 12.00%\n",
      "================================9787===================================\n",
      "9787/10000: train_loss: 2.7535357900168247 train_error 18.38% test_error 12.00%\n",
      "================================9788===================================\n",
      "9788/10000: train_loss: 2.7535875492905606 train_error 18.38% test_error 12.00%\n",
      "================================9789===================================\n",
      "9789/10000: train_loss: 2.7536394541287113 train_error 18.38% test_error 12.50%\n",
      "================================9790===================================\n",
      "9790/10000: train_loss: 2.7536916908595845 train_error 18.38% test_error 12.50%\n",
      "================================9791===================================\n",
      "9791/10000: train_loss: 2.753744348720827 train_error 18.38% test_error 12.50%\n",
      "================================9792===================================\n",
      "9792/10000: train_loss: 2.7537973767451 train_error 18.38% test_error 12.50%\n",
      "================================9793===================================\n",
      "9793/10000: train_loss: 2.7538446301576336 train_error 18.38% test_error 12.50%\n",
      "================================9794===================================\n",
      "9794/10000: train_loss: 2.753890646755415 train_error 18.38% test_error 12.50%\n",
      "================================9795===================================\n",
      "9795/10000: train_loss: 2.7539359672472683 train_error 18.38% test_error 12.50%\n",
      "================================9796===================================\n",
      "9796/10000: train_loss: 2.7539788818316935 train_error 18.38% test_error 12.50%\n",
      "================================9797===================================\n",
      "9797/10000: train_loss: 2.7540219562945514 train_error 18.38% test_error 12.50%\n",
      "================================9798===================================\n",
      "9798/10000: train_loss: 2.754065193550975 train_error 18.38% test_error 12.50%\n",
      "================================9799===================================\n",
      "9799/10000: train_loss: 2.7541078914441943 train_error 18.38% test_error 12.50%\n",
      "================================9800===================================\n",
      "9800/10000: train_loss: 2.7541494097867774 train_error 18.38% test_error 12.50%\n",
      "================================9801===================================\n",
      "9801/10000: train_loss: 2.754189196325239 train_error 18.38% test_error 12.50%\n",
      "================================9802===================================\n",
      "9802/10000: train_loss: 2.754229870077604 train_error 18.38% test_error 12.50%\n",
      "================================9803===================================\n",
      "9803/10000: train_loss: 2.7542731179568674 train_error 18.38% test_error 12.50%\n",
      "================================9804===================================\n",
      "9804/10000: train_loss: 2.754316569057708 train_error 18.38% test_error 12.50%\n",
      "================================9805===================================\n",
      "9805/10000: train_loss: 2.754359973850943 train_error 18.50% test_error 12.50%\n",
      "================================9806===================================\n",
      "9806/10000: train_loss: 2.754403496402126 train_error 18.50% test_error 12.50%\n",
      "================================9807===================================\n",
      "9807/10000: train_loss: 2.7544464646401505 train_error 18.50% test_error 12.50%\n",
      "================================9808===================================\n",
      "9808/10000: train_loss: 2.7544870509046353 train_error 18.50% test_error 12.50%\n",
      "================================9809===================================\n",
      "9809/10000: train_loss: 2.7545260209312206 train_error 18.50% test_error 12.50%\n",
      "================================9810===================================\n",
      "9810/10000: train_loss: 2.7545620313011345 train_error 18.50% test_error 12.50%\n",
      "================================9811===================================\n",
      "9811/10000: train_loss: 2.7545983674451606 train_error 18.50% test_error 12.50%\n",
      "================================9812===================================\n",
      "9812/10000: train_loss: 2.7546346900715903 train_error 18.50% test_error 12.50%\n",
      "================================9813===================================\n",
      "9813/10000: train_loss: 2.7546701684078956 train_error 18.50% test_error 12.50%\n",
      "================================9814===================================\n",
      "9814/10000: train_loss: 2.7547103951894725 train_error 18.50% test_error 12.50%\n",
      "================================9815===================================\n",
      "9815/10000: train_loss: 2.754743597522241 train_error 18.50% test_error 12.50%\n",
      "================================9816===================================\n",
      "9816/10000: train_loss: 2.7547715553638463 train_error 18.50% test_error 12.50%\n",
      "================================9817===================================\n",
      "9817/10000: train_loss: 2.7547975417911212 train_error 18.50% test_error 12.50%\n",
      "================================9818===================================\n",
      "9818/10000: train_loss: 2.7548257019397866 train_error 18.50% test_error 12.50%\n",
      "================================9819===================================\n",
      "9819/10000: train_loss: 2.7548544149813283 train_error 18.50% test_error 12.50%\n",
      "================================9820===================================\n",
      "9820/10000: train_loss: 2.754881739349047 train_error 18.50% test_error 12.50%\n",
      "================================9821===================================\n",
      "9821/10000: train_loss: 2.7549068256824696 train_error 18.50% test_error 12.50%\n",
      "================================9822===================================\n",
      "9822/10000: train_loss: 2.7549327292832695 train_error 18.50% test_error 12.50%\n",
      "================================9823===================================\n",
      "9823/10000: train_loss: 2.7549593464862094 train_error 18.50% test_error 12.50%\n",
      "================================9824===================================\n",
      "9824/10000: train_loss: 2.754984983354487 train_error 18.50% test_error 12.50%\n",
      "================================9825===================================\n",
      "9825/10000: train_loss: 2.7550072840227795 train_error 18.50% test_error 12.50%\n",
      "================================9826===================================\n",
      "9826/10000: train_loss: 2.755030348914095 train_error 18.50% test_error 12.50%\n",
      "================================9827===================================\n",
      "9827/10000: train_loss: 2.755054764387895 train_error 18.50% test_error 12.50%\n",
      "================================9828===================================\n",
      "9828/10000: train_loss: 2.755078155028426 train_error 18.50% test_error 12.50%\n",
      "================================9829===================================\n",
      "9829/10000: train_loss: 2.755102191104969 train_error 18.50% test_error 12.50%\n",
      "================================9830===================================\n",
      "9830/10000: train_loss: 2.755126630473613 train_error 18.50% test_error 12.50%\n",
      "================================9831===================================\n",
      "9831/10000: train_loss: 2.7551522757981775 train_error 18.50% test_error 12.50%\n",
      "================================9832===================================\n",
      "9832/10000: train_loss: 2.7551809567197494 train_error 18.50% test_error 12.50%\n",
      "================================9833===================================\n",
      "9833/10000: train_loss: 2.7552077703883873 train_error 18.50% test_error 12.50%\n",
      "================================9834===================================\n",
      "9834/10000: train_loss: 2.755231426539466 train_error 18.50% test_error 12.50%\n",
      "================================9835===================================\n",
      "9835/10000: train_loss: 2.7552536559844683 train_error 18.50% test_error 12.50%\n",
      "================================9836===================================\n",
      "9836/10000: train_loss: 2.7552740604205987 train_error 18.50% test_error 12.50%\n",
      "================================9837===================================\n",
      "9837/10000: train_loss: 2.7552923094345543 train_error 18.50% test_error 12.50%\n",
      "================================9838===================================\n",
      "9838/10000: train_loss: 2.7553049595983006 train_error 18.50% test_error 12.50%\n",
      "================================9839===================================\n",
      "9839/10000: train_loss: 2.755318134417442 train_error 18.50% test_error 12.50%\n",
      "================================9840===================================\n",
      "9840/10000: train_loss: 2.7553321893861153 train_error 18.38% test_error 12.50%\n",
      "================================9841===================================\n",
      "9841/10000: train_loss: 2.7553466663771955 train_error 18.38% test_error 12.50%\n",
      "================================9842===================================\n",
      "9842/10000: train_loss: 2.7553604511615886 train_error 18.38% test_error 12.50%\n",
      "================================9843===================================\n",
      "9843/10000: train_loss: 2.7553740962595166 train_error 18.38% test_error 12.50%\n",
      "================================9844===================================\n",
      "9844/10000: train_loss: 2.7553883843659355 train_error 18.38% test_error 12.50%\n",
      "================================9845===================================\n",
      "9845/10000: train_loss: 2.7554028739699445 train_error 18.38% test_error 12.50%\n",
      "================================9846===================================\n",
      "9846/10000: train_loss: 2.755419985966062 train_error 18.38% test_error 12.50%\n",
      "================================9847===================================\n",
      "9847/10000: train_loss: 2.755436643847763 train_error 18.38% test_error 12.50%\n",
      "================================9848===================================\n",
      "9848/10000: train_loss: 2.755453697388371 train_error 18.38% test_error 12.50%\n",
      "================================9849===================================\n",
      "9849/10000: train_loss: 2.755471343071031 train_error 18.38% test_error 12.50%\n",
      "================================9850===================================\n",
      "9850/10000: train_loss: 2.7554881885260785 train_error 18.38% test_error 12.50%\n",
      "================================9851===================================\n",
      "9851/10000: train_loss: 2.755507428721625 train_error 18.38% test_error 12.50%\n",
      "================================9852===================================\n",
      "9852/10000: train_loss: 2.7555279672279065 train_error 18.38% test_error 12.50%\n",
      "================================9853===================================\n",
      "9853/10000: train_loss: 2.7555462818915553 train_error 18.38% test_error 12.50%\n",
      "================================9854===================================\n",
      "9854/10000: train_loss: 2.755560952752992 train_error 18.38% test_error 12.50%\n",
      "================================9855===================================\n",
      "9855/10000: train_loss: 2.7555781816883407 train_error 18.38% test_error 12.50%\n",
      "================================9856===================================\n",
      "9856/10000: train_loss: 2.7555998911227424 train_error 18.38% test_error 12.50%\n",
      "================================9857===================================\n",
      "9857/10000: train_loss: 2.75562430886431 train_error 18.38% test_error 12.50%\n",
      "================================9858===================================\n",
      "9858/10000: train_loss: 2.7556478373779973 train_error 18.38% test_error 12.50%\n",
      "================================9859===================================\n",
      "9859/10000: train_loss: 2.755671061106886 train_error 18.38% test_error 12.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================9860===================================\n",
      "9860/10000: train_loss: 2.7556932978620567 train_error 18.38% test_error 12.50%\n",
      "================================9861===================================\n",
      "9861/10000: train_loss: 2.7557167784083227 train_error 18.38% test_error 12.50%\n",
      "================================9862===================================\n",
      "9862/10000: train_loss: 2.755742938753159 train_error 18.38% test_error 12.50%\n",
      "================================9863===================================\n",
      "9863/10000: train_loss: 2.7557730445389574 train_error 18.38% test_error 12.50%\n",
      "================================9864===================================\n",
      "9864/10000: train_loss: 2.7558078539270494 train_error 18.38% test_error 12.50%\n",
      "================================9865===================================\n",
      "9865/10000: train_loss: 2.755844711259507 train_error 18.38% test_error 12.50%\n",
      "================================9866===================================\n",
      "9866/10000: train_loss: 2.7558787383049843 train_error 18.38% test_error 12.50%\n",
      "================================9867===================================\n",
      "9867/10000: train_loss: 2.755909765677557 train_error 18.38% test_error 12.50%\n",
      "================================9868===================================\n",
      "9868/10000: train_loss: 2.7559396620750833 train_error 18.38% test_error 12.50%\n",
      "================================9869===================================\n",
      "9869/10000: train_loss: 2.7559721677797158 train_error 18.38% test_error 12.50%\n",
      "================================9870===================================\n",
      "9870/10000: train_loss: 2.756004490175396 train_error 18.38% test_error 12.50%\n",
      "================================9871===================================\n",
      "9871/10000: train_loss: 2.7560401047795895 train_error 18.38% test_error 12.50%\n",
      "================================9872===================================\n",
      "9872/10000: train_loss: 2.7560771479886896 train_error 18.38% test_error 12.50%\n",
      "================================9873===================================\n",
      "9873/10000: train_loss: 2.756112538761409 train_error 18.38% test_error 12.50%\n",
      "================================9874===================================\n",
      "9874/10000: train_loss: 2.756150427615716 train_error 18.38% test_error 12.50%\n",
      "================================9875===================================\n",
      "9875/10000: train_loss: 2.7561913139480874 train_error 18.38% test_error 12.50%\n",
      "================================9876===================================\n",
      "9876/10000: train_loss: 2.756232902300534 train_error 18.38% test_error 12.50%\n",
      "================================9877===================================\n",
      "9877/10000: train_loss: 2.7562746157348346 train_error 18.38% test_error 12.50%\n",
      "================================9878===================================\n",
      "9878/10000: train_loss: 2.7563166064267905 train_error 18.38% test_error 12.50%\n",
      "================================9879===================================\n",
      "9879/10000: train_loss: 2.756355246436899 train_error 18.38% test_error 12.50%\n",
      "================================9880===================================\n",
      "9880/10000: train_loss: 2.756392583806207 train_error 18.38% test_error 12.50%\n",
      "================================9881===================================\n",
      "9881/10000: train_loss: 2.7564289346406827 train_error 18.38% test_error 12.50%\n",
      "================================9882===================================\n",
      "9882/10000: train_loss: 2.7564655580650173 train_error 18.38% test_error 12.50%\n",
      "================================9883===================================\n",
      "9883/10000: train_loss: 2.756502787959482 train_error 18.38% test_error 12.50%\n",
      "================================9884===================================\n",
      "9884/10000: train_loss: 2.756534644069526 train_error 18.38% test_error 12.50%\n",
      "================================9885===================================\n",
      "9885/10000: train_loss: 2.7565640029304688 train_error 18.38% test_error 12.50%\n",
      "================================9886===================================\n",
      "9886/10000: train_loss: 2.7565898171994787 train_error 18.38% test_error 12.50%\n",
      "================================9887===================================\n",
      "9887/10000: train_loss: 2.7566060799762333 train_error 18.38% test_error 12.50%\n",
      "================================9888===================================\n",
      "9888/10000: train_loss: 2.756618956647451 train_error 18.38% test_error 12.50%\n",
      "================================9889===================================\n",
      "9889/10000: train_loss: 2.7566271944196643 train_error 18.38% test_error 12.50%\n",
      "================================9890===================================\n",
      "9890/10000: train_loss: 2.756637825500641 train_error 18.38% test_error 12.50%\n",
      "================================9891===================================\n",
      "9891/10000: train_loss: 2.7566467537690276 train_error 18.38% test_error 12.50%\n",
      "================================9892===================================\n",
      "9892/10000: train_loss: 2.7566545246126246 train_error 18.38% test_error 12.50%\n",
      "================================9893===================================\n",
      "9893/10000: train_loss: 2.7566641446741635 train_error 18.38% test_error 12.50%\n",
      "================================9894===================================\n",
      "9894/10000: train_loss: 2.7566770471316553 train_error 18.38% test_error 12.50%\n",
      "================================9895===================================\n",
      "9895/10000: train_loss: 2.7566884744628926 train_error 18.38% test_error 12.50%\n",
      "================================9896===================================\n",
      "9896/10000: train_loss: 2.7566991120800135 train_error 18.50% test_error 12.50%\n",
      "================================9897===================================\n",
      "9897/10000: train_loss: 2.756709800724577 train_error 18.50% test_error 12.50%\n",
      "================================9898===================================\n",
      "9898/10000: train_loss: 2.756721184139124 train_error 18.50% test_error 12.50%\n",
      "================================9899===================================\n",
      "9899/10000: train_loss: 2.756732896212176 train_error 18.50% test_error 12.50%\n",
      "================================9900===================================\n",
      "9900/10000: train_loss: 2.7567458867241634 train_error 18.50% test_error 12.50%\n",
      "================================9901===================================\n",
      "9901/10000: train_loss: 2.756760320587984 train_error 18.50% test_error 12.50%\n",
      "================================9902===================================\n",
      "9902/10000: train_loss: 2.7567750684436785 train_error 18.50% test_error 13.00%\n",
      "================================9903===================================\n",
      "9903/10000: train_loss: 2.7567901024929444 train_error 18.50% test_error 13.00%\n",
      "================================9904===================================\n",
      "9904/10000: train_loss: 2.7568102364306437 train_error 18.50% test_error 13.00%\n",
      "================================9905===================================\n",
      "9905/10000: train_loss: 2.7568280890372443 train_error 18.50% test_error 13.00%\n",
      "================================9906===================================\n",
      "9906/10000: train_loss: 2.756847224034284 train_error 18.50% test_error 13.00%\n",
      "================================9907===================================\n",
      "9907/10000: train_loss: 2.756862410181136 train_error 18.50% test_error 13.00%\n",
      "================================9908===================================\n",
      "9908/10000: train_loss: 2.756878301688671 train_error 18.50% test_error 13.00%\n",
      "================================9909===================================\n",
      "9909/10000: train_loss: 2.75689429810093 train_error 18.50% test_error 13.00%\n",
      "================================9910===================================\n",
      "9910/10000: train_loss: 2.756909671352001 train_error 18.50% test_error 13.00%\n",
      "================================9911===================================\n",
      "9911/10000: train_loss: 2.756924869550093 train_error 18.50% test_error 13.00%\n",
      "================================9912===================================\n",
      "9912/10000: train_loss: 2.756940231518021 train_error 18.50% test_error 13.00%\n",
      "================================9913===================================\n",
      "9913/10000: train_loss: 2.756957143550247 train_error 18.50% test_error 13.00%\n",
      "================================9914===================================\n",
      "9914/10000: train_loss: 2.756974462927076 train_error 18.50% test_error 13.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================9915===================================\n",
      "9915/10000: train_loss: 2.756991694612663 train_error 18.38% test_error 13.00%\n",
      "================================9916===================================\n",
      "9916/10000: train_loss: 2.75700892971776 train_error 18.38% test_error 13.00%\n",
      "================================9917===================================\n",
      "9917/10000: train_loss: 2.757028192102016 train_error 18.38% test_error 13.00%\n",
      "================================9918===================================\n",
      "9918/10000: train_loss: 2.7570418080439247 train_error 18.38% test_error 13.00%\n",
      "================================9919===================================\n",
      "9919/10000: train_loss: 2.7570530243223503 train_error 18.38% test_error 13.00%\n",
      "================================9920===================================\n",
      "9920/10000: train_loss: 2.757059821242163 train_error 18.38% test_error 13.00%\n",
      "================================9921===================================\n",
      "9921/10000: train_loss: 2.7570637760896695 train_error 18.38% test_error 13.00%\n",
      "================================9922===================================\n",
      "9922/10000: train_loss: 2.7570675261307303 train_error 18.38% test_error 13.00%\n",
      "================================9923===================================\n",
      "9923/10000: train_loss: 2.757071109134874 train_error 18.38% test_error 13.00%\n",
      "================================9924===================================\n",
      "9924/10000: train_loss: 2.757074850692062 train_error 18.38% test_error 13.00%\n",
      "================================9925===================================\n",
      "9925/10000: train_loss: 2.757080962294155 train_error 18.38% test_error 13.00%\n",
      "================================9926===================================\n",
      "9926/10000: train_loss: 2.757087022274642 train_error 18.38% test_error 13.00%\n",
      "================================9927===================================\n",
      "9927/10000: train_loss: 2.7570932857920827 train_error 18.38% test_error 13.00%\n",
      "================================9928===================================\n",
      "9928/10000: train_loss: 2.7570929037802356 train_error 18.38% test_error 13.00%\n",
      "================================9929===================================\n",
      "9929/10000: train_loss: 2.7570899263722906 train_error 18.50% test_error 13.00%\n",
      "================================9930===================================\n",
      "9930/10000: train_loss: 2.757083879661593 train_error 18.50% test_error 13.00%\n",
      "================================9931===================================\n",
      "9931/10000: train_loss: 2.757078686781884 train_error 18.50% test_error 13.00%\n",
      "================================9932===================================\n",
      "9932/10000: train_loss: 2.7570738706907707 train_error 18.50% test_error 13.00%\n",
      "================================9933===================================\n",
      "9933/10000: train_loss: 2.75706997319267 train_error 18.50% test_error 13.00%\n",
      "================================9934===================================\n",
      "9934/10000: train_loss: 2.7570651737284124 train_error 18.50% test_error 13.00%\n",
      "================================9935===================================\n",
      "9935/10000: train_loss: 2.7570618713884096 train_error 18.50% test_error 13.00%\n",
      "================================9936===================================\n",
      "9936/10000: train_loss: 2.7570593309293936 train_error 18.50% test_error 13.00%\n",
      "================================9937===================================\n",
      "9937/10000: train_loss: 2.757057732338099 train_error 18.50% test_error 13.00%\n",
      "================================9938===================================\n",
      "9938/10000: train_loss: 2.757056024640323 train_error 18.50% test_error 13.00%\n",
      "================================9939===================================\n",
      "9939/10000: train_loss: 2.757053734873267 train_error 18.50% test_error 13.00%\n",
      "================================9940===================================\n",
      "9940/10000: train_loss: 2.757050103709399 train_error 18.50% test_error 13.00%\n",
      "================================9941===================================\n",
      "9941/10000: train_loss: 2.757045673795848 train_error 18.50% test_error 13.00%\n",
      "================================9942===================================\n",
      "9942/10000: train_loss: 2.7570420719394457 train_error 18.50% test_error 13.00%\n",
      "================================9943===================================\n",
      "9943/10000: train_loss: 2.7570356195623575 train_error 18.50% test_error 13.00%\n",
      "================================9944===================================\n",
      "9944/10000: train_loss: 2.7570297641285673 train_error 18.50% test_error 13.00%\n",
      "================================9945===================================\n",
      "9945/10000: train_loss: 2.7570245429363993 train_error 18.50% test_error 13.00%\n",
      "================================9946===================================\n",
      "9946/10000: train_loss: 2.7570211000999727 train_error 18.50% test_error 13.00%\n",
      "================================9947===================================\n",
      "9947/10000: train_loss: 2.7570196538648846 train_error 18.50% test_error 13.00%\n",
      "================================9948===================================\n",
      "9948/10000: train_loss: 2.757018374504585 train_error 18.50% test_error 13.00%\n",
      "================================9949===================================\n",
      "9949/10000: train_loss: 2.757017318002867 train_error 18.50% test_error 13.00%\n",
      "================================9950===================================\n",
      "9950/10000: train_loss: 2.757016920535269 train_error 18.50% test_error 13.00%\n",
      "================================9951===================================\n",
      "9951/10000: train_loss: 2.757016446549658 train_error 18.50% test_error 13.00%\n",
      "================================9952===================================\n",
      "9952/10000: train_loss: 2.7570157127221804 train_error 18.50% test_error 13.00%\n",
      "================================9953===================================\n",
      "9953/10000: train_loss: 2.757012922963533 train_error 18.50% test_error 13.00%\n",
      "================================9954===================================\n",
      "9954/10000: train_loss: 2.7570076208177356 train_error 18.50% test_error 13.00%\n",
      "================================9955===================================\n",
      "9955/10000: train_loss: 2.757003777048633 train_error 18.50% test_error 13.00%\n",
      "================================9956===================================\n",
      "9956/10000: train_loss: 2.757001254485103 train_error 18.50% test_error 13.00%\n",
      "================================9957===================================\n",
      "9957/10000: train_loss: 2.7569976677298964 train_error 18.50% test_error 13.00%\n",
      "================================9958===================================\n",
      "9958/10000: train_loss: 2.7569942948962587 train_error 18.50% test_error 13.00%\n",
      "================================9959===================================\n",
      "9959/10000: train_loss: 2.756991280901527 train_error 18.50% test_error 13.00%\n",
      "================================9960===================================\n",
      "9960/10000: train_loss: 2.7569876892202063 train_error 18.50% test_error 13.00%\n",
      "================================9961===================================\n",
      "9961/10000: train_loss: 2.756983265945223 train_error 18.50% test_error 13.00%\n",
      "================================9962===================================\n",
      "9962/10000: train_loss: 2.756979830197822 train_error 18.50% test_error 13.00%\n",
      "================================9963===================================\n",
      "9963/10000: train_loss: 2.7569768950112707 train_error 18.50% test_error 13.00%\n",
      "================================9964===================================\n",
      "9964/10000: train_loss: 2.7569768220803885 train_error 18.50% test_error 13.00%\n",
      "================================9965===================================\n",
      "9965/10000: train_loss: 2.7569770502193554 train_error 18.50% test_error 13.00%\n",
      "================================9966===================================\n",
      "9966/10000: train_loss: 2.756977785830607 train_error 18.38% test_error 13.00%\n",
      "================================9967===================================\n",
      "9967/10000: train_loss: 2.7569783541481834 train_error 18.38% test_error 13.00%\n",
      "================================9968===================================\n",
      "9968/10000: train_loss: 2.7569789451393856 train_error 18.38% test_error 13.00%\n",
      "================================9969===================================\n",
      "9969/10000: train_loss: 2.756979332024028 train_error 18.38% test_error 13.00%\n",
      "================================9970===================================\n",
      "9970/10000: train_loss: 2.7569826133035673 train_error 18.38% test_error 13.00%\n",
      "================================9971===================================\n",
      "9971/10000: train_loss: 2.7569863402469514 train_error 18.38% test_error 13.00%\n",
      "================================9972===================================\n",
      "9972/10000: train_loss: 2.756989660802111 train_error 18.38% test_error 13.00%\n",
      "================================9973===================================\n",
      "9973/10000: train_loss: 2.7569917493340927 train_error 18.38% test_error 13.00%\n",
      "================================9974===================================\n",
      "9974/10000: train_loss: 2.75699495926082 train_error 18.38% test_error 13.00%\n",
      "================================9975===================================\n",
      "9975/10000: train_loss: 2.7569981042729474 train_error 18.38% test_error 13.00%\n",
      "================================9976===================================\n",
      "9976/10000: train_loss: 2.7570022267752243 train_error 18.38% test_error 13.00%\n",
      "================================9977===================================\n",
      "9977/10000: train_loss: 2.7570055552876704 train_error 18.38% test_error 13.00%\n",
      "================================9978===================================\n",
      "9978/10000: train_loss: 2.757007011191587 train_error 18.38% test_error 13.00%\n",
      "================================9979===================================\n",
      "9979/10000: train_loss: 2.757005401233475 train_error 18.38% test_error 13.00%\n",
      "================================9980===================================\n",
      "9980/10000: train_loss: 2.7570023276509747 train_error 18.38% test_error 13.00%\n",
      "================================9981===================================\n",
      "9981/10000: train_loss: 2.7569985353316393 train_error 18.38% test_error 13.00%\n",
      "================================9982===================================\n",
      "9982/10000: train_loss: 2.756990537389048 train_error 18.38% test_error 13.00%\n",
      "================================9983===================================\n",
      "9983/10000: train_loss: 2.7569818018460164 train_error 18.38% test_error 13.00%\n",
      "================================9984===================================\n",
      "9984/10000: train_loss: 2.7569693091170504 train_error 18.38% test_error 13.00%\n",
      "================================9985===================================\n",
      "9985/10000: train_loss: 2.756955963257314 train_error 18.38% test_error 13.00%\n",
      "================================9986===================================\n",
      "9986/10000: train_loss: 2.7569433804936954 train_error 18.38% test_error 13.00%\n",
      "================================9987===================================\n",
      "9987/10000: train_loss: 2.7569322487544654 train_error 18.38% test_error 13.00%\n",
      "================================9988===================================\n",
      "9988/10000: train_loss: 2.756919678938535 train_error 18.38% test_error 13.00%\n",
      "================================9989===================================\n",
      "9989/10000: train_loss: 2.7569045369303105 train_error 18.50% test_error 13.00%\n",
      "================================9990===================================\n",
      "9990/10000: train_loss: 2.7568908497153264 train_error 18.50% test_error 13.00%\n",
      "================================9991===================================\n",
      "9991/10000: train_loss: 2.756875916690247 train_error 18.50% test_error 13.00%\n",
      "================================9992===================================\n",
      "9992/10000: train_loss: 2.756858435164395 train_error 18.50% test_error 13.00%\n",
      "================================9993===================================\n",
      "9993/10000: train_loss: 2.7568371285757536 train_error 18.50% test_error 13.00%\n",
      "================================9994===================================\n",
      "9994/10000: train_loss: 2.756815685185012 train_error 18.50% test_error 13.00%\n",
      "================================9995===================================\n",
      "9995/10000: train_loss: 2.756793354169101 train_error 18.50% test_error 13.00%\n",
      "================================9996===================================\n",
      "9996/10000: train_loss: 2.7567709844155592 train_error 18.50% test_error 13.00%\n",
      "================================9997===================================\n",
      "9997/10000: train_loss: 2.7567493970685324 train_error 18.50% test_error 13.00%\n",
      "================================9998===================================\n",
      "9998/10000: train_loss: 2.756728389151887 train_error 18.50% test_error 13.00%\n",
      "================================9999===================================\n",
      "9999/10000: train_loss: 2.7567076752662696 train_error 18.50% test_error 13.00%\n"
     ]
    }
   ],
   "source": [
    "lr =  5e-4\n",
    "mini_batch_size = 200\n",
    "nb_epochs = 10000\n",
    "# modules = [Linear(2, 25), Relu(),Linear(25, 25),Relu(),Linear(25, 25),Relu(),Linear(25, 2), Tanh()]\n",
    "modules = [Linear(2, 25), Relu(), Linear(25,25), Relu(), Linear(25, 2), Tanh()]\n",
    "model = Sequential(modules)\n",
    "\n",
    "train_input, train_target, test_input, test_target = data[0:800,], target[0:800,], data[800:,], target[800:,]\n",
    "\n",
    "train_model(model, train_input, train_target, test_input, test_target, nb_epochs, lr, mini_batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
